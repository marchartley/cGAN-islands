% @String{cgforum = "Computer Graphics Forum"}
% @String{tog = "ACM TOG"}
@techreport{Hossain,
	title        = {CS348b Project: Light Field Camera Simulation},
	author       = {Zahid Hossain and Adam Spilfogel Backer and Yanlin Chen},
	abstract     = {Figure 1: Lightfield rendering to demonstrate focus at different depths. The left image is focused at a far plane near the tree while the right image is focused near flowers at a closer distance from the camera. Abstract We report a simulation platform for a lightfield camera. Our methods may be applied to develop and refine future lightfield acquisition systems. Furthermore, the rendering pipeline of PBRT has been augmented to include our camera simulator, permitting the generation of refocus-able computer-generated artwork. We demonstrate our simulation platform on various imaging scenarios that may prove challenging for more conventional imaging models.},
	keywords     = {imaging sys-tems and applications,lightfield,realistic camera simulation}
}
@techreport{Wilczkowiak,
	title        = {Calibrage de cam\'{e}ra et reconstruction 3D \`{a} l'aide de parall\'{e}l\'{e}pip\`{e}des},
	author       = {Marta Wilczkowiak and Edmond Boyer and Peter Sturm},
	url          = {https://hal.inria.fr/inria-00525656},
	abstract     = {Dans cet article, nous nous int\'{e}ressonsint\'{e}ressons`int\'{e}ressons\`{a} l'utilisation des parall\'{e}l\'{e}pip\`{e}des pour le calibrage de cam\'{e}ras et la reconstruction de sc\`{e}nes tridimensionnelles. Les parall\'{e}l\'{e}pip\`{e}des permettent d'exploiter, deman\`{\i} ere naturelle, les contraintes g\'{e}om\'{e}triques fr\'{e}quemment pr\'{e}sentes dans une sc\`{e}ne : le parall\'{e}lisme et l'ortho-gonalit\'{e} par exemple. Un sous ensemble des parall\'{e}l\'{e}pip\`{e}des-les cubo\textasciidieresis{}\i{}descubo\textasciidieresis{}\i{}des 1-ont d\'{e}j\`{a}d\'{e}j\`{a}\textasciiacute{}d\'{e}j\`{a}\'{e}t\'{e} utilis\'{e}s par le pass\'{e} pour le calibrage partiel de cam\'{e}ras, mais le potentiel qu'offrent les parall\'{e}l\'{e}pip\`{e}des en perception tridimensionnelle n'a jamais\'{e}t\'{e}jamais\textasciiacute{}jamais\'{e}t\'{e} clairement\'{e}tabliclairement\textasciiacute{}clairement\'{e}tabli. Dans ce document, nous mettons en\'{e}videnceen\textasciiacute{}en\'{e}vidence ce poten-tiel au travers d'un\'{e} etude approfondie des contraintes fournies par les parall\'{e}l\'{e}pip\`{e}des. Nous montrons en particulier la dualit\'{e} qui existe entre les caract\'{e}ristiques intrins\`{e}ques d'une cam\'{e}ra et celles d'un paral-l\'{e}l\'{e}pip\`{e}de. Pour illustrer cett\'{e} etude, nous pr\'{e}sentons par ailleurs une application interactive permettant la reconstruction d'une sc\`{e}n\`{e} a partir d'une seule image. Dans cette application, seul un faible nombre de connaissances sur la sc\`{e}ne sont n\'{e}cessaires, et un mod\`{e}le tridimensionnel peut rapidement\^{e}trerapidementˆrapidement\^{e}tre obten\`{u} a partir d'une seule image non calibr\'{e}e.},
	keywords     = {Mots-cl\'{e}s : calibrage,mono-image,parall\'{e}l\'{e}pip\`{e}de,reconstruction}
}
@misc{Felixchenfy,
	title        = {felixchenfy/Realtime-Action-Recognition: Apply ML to the skeletons from OpenPose; 9 actions; multiple people.},
	author       = {Felixchenfy},
	url          = {https://github.com/felixchenfy/Realtime-Action-Recognition}
}
@misc{TianzhongSong,
	title        = {TianzhongSong/Real-Time-Action-Recognition: Real-time pose estimation and action recognition},
	author       = {TianzhongSong},
	url          = {https://github.com/TianzhongSong/Real-Time-Action-Recognition}
}
@misc{Zhang2016Code,
	title        = {Real-time Action Recognition with Enhanced Motion Vector CNNs \vert{} Papers With Code},
	url          = {https://paperswithcode.com/paper/real-time-action-recognition-with-enhanced}
}
@misc{LuXia,
	title        = {View Invariant Human Action Recognition Using Histograms of 3D Joints},
	author       = {Lu Xia and Chia-Chih Chen and J. K. Aggarwal},
	url          = {http://cvrc.ece.utexas.edu/Publications/Xia_HAU3D12.pdf}
}
@techreport{Wang,
	title        = {Modeling and Simulation of the VideoRay Pro III Underwater Vehicle},
	author       = {Wei Wang and Christopher M Clark},
	isbn         = 1424401380,
	abstract     = {Accurate modeling and simulation of underwater vehicles is essential for autonomous control. In this paper, we present a dynamic model of the VideoRay Pro III microROV, in which the hydrodynamic derivatives are determined both theoretically and experimentally, based on the assumption that the motions in different directions are decoupled. The experi\- ments show that this assumption is reasonable within operating conditions of the VideoRay Pro fuw. A computer simulation with 3D graphics is also developed to help user to visualize the vehicle's motion.}
}
@techreport{Harris,
	title        = {Procedures for Gait Analysis},
	author       = {Gerald F. Harris and Jacqueline J. Wertsch},
	abstract     = {Harris GF, Wertsch JJ. Procedures for gait analysis. Arch Phys Med Rehabil 1994;75:216-25. l Observational gait analysis is clinically useful with videotape slow-motion replay and freeze-frame, offering significant improvement over unaided visual observation. Any form of observational gait analysis, however, has limited precision and is more descriptive than quantitative. This article reviews procedures that are available for gait analysis. Gait analysis systems have evolved from tine with manual digitization, electrogoniometry, and video technology to sophisticated automated tracking systems. When used in conjunction with biomechanical models, these systems allow quantitative analysis of many specific gait characteristics such as joint moments and powers (kinetic analysis), joint angles, angular velocities, and angular accelerations (kinematic analysis). Analysis of dynamic electromyographic activity and energy consumption adds useful clinical information to gait analysis. The combination of a careful clinical assessment and gait analysis can be a powerful tool for the clinician. 0 1993 by the American Congress qf Rehabilitation Medicine and the American Academy of Physical Medicine and Rehabilitation Gait analysis-the systematic analysis of locomotion-is}
}
@techreport{Chiu,
	title        = {Simulation of Positional Center of Gravity for Different Human Motions},
	author       = {Ching-Hua Chiu},
	journal      = {Journal of Medical and Biological Engineering},
	volume       = 25,
	pages        = {123--128},
	url          = {https://www.semanticscholar.org/paper/Simulation-of-Positional-Center-of-Gravity-for-Chiu/763372f811756405aa4dbf6ef457daf33126a7f5},
	abstract     = {To locate the center of gravity position, previous studies photographed human body motions and then applied body segmental parameters. This study presents a novel set of algorithm to locate three-dimensional center of gravity position. The purpose of this novel system is to aid establishing the gravity plumb line for rehabilitating patients. Control variables employed in this study were angular positions of ankle joints, knee joints, hip joints, shoulder joints, elbow joints, wrist joints, waist joint, and the neck. The study was grounded in five sources: the human body model by Zatsiorsky and Seluyanov [1], three basic homogeneous rotation matrices, three basic homogeneous translation matrices, a 4\texttimes{}4 identity matrix, and seven homogeneous transformation matrices developed by Chiu [2]. The first step in adopting this novel set of algorithm was to define body joints as 38 degrees of freedom. Then an algorithm was developed to locate the center of gravity position. Three male subjects participated in this study. Two motions were simulated by a computer. The first simulated motion was a subject squatting and then rising. During this squat, both arms swing from position at the sides of the body to a position adjacent to the head. During the second simulated motion, the subject leans horizontally at the waist from left to right, with both arms swinging upward. The experimental results demonstrated that the computer program successfully simulated the angular positions of particular postures, and the algorithm effectively established the relationship between the angular positions and the plumb line of the center of gravity. This novel system can assist paralyzed patients and those with muscular dystrophy by ensuring that correct postures are employed during rehabilitation. Furthermore, this system can also locate the center of gravity position during running, jumping, and walking.},
	issue        = 3,
	keywords     = {Body segment,Center of gravity,Matrix}
}
@techreport{Sun,
	title        = {Learning a Convolutional Neural Network for Non-uniform Motion Blur Removal},
	author       = {Jian Sun and Wenfei Cao and Zongben Xu and Jean Ponce},
	url          = {http://caffe.berkeleyvision.org},
	abstract     = {In this paper, we address the problem of estimating and removing non-uniform motion blur from a single blurry image. We propose a deep learning approach to predicting the probabilistic distribution of motion blur at the patch level using a convolutional neural network (CNN). We further extend the candidate set of motion kernels predicted by the CNN using carefully designed image rotations. A Markov random field model is then used to infer a dense non-uniform motion blur field enforcing motion smoothness. Finally, motion blur is removed by a non-uniform de-blurring model using patch-level image prior. Experimental evaluations show that our approach can effectively estimate and remove complex non-uniform motion blur that is not handled well by previous approaches.}
}
@techreport{Knoblauch,
	title        = {Field Studies of Pedestrian Walking Speed and Start-Up Time},
	author       = {Richard L Knoblauch and Martin T Pietrucha and Marsha Nitzburg},
	abstract     = {Today's traffic environment is not well adapted to the needs of the older pedestrian. Unfortunately, except in the case of children, little is known about the characteristics and behavior of pedestrians. Although the simple fact that older pedestrians walk more slowly than younger ones is easily supported by field data, existing data on walking speeds and start-up time (i.e., the time from the onset of a Walk signal until the pedestrian steps off the curb) have many shortcomings. A series of field studies was conducted to quantify the walking speed and start-up time of pedestrians of various ages under different conditions. Sixteen crosswalks in four urban areas were studied. Data were collected on walking speeds and start-up times relative to site and environmental factors, including street width, posted speed, curb height, grade, number of vehicle travel lanes, signal cycle length, pedestrian-signal type, street functional classification, crosswalk type, and channelization. Data on a subject group of pedestrians who appeared to be 65 years of age or older and a control group of pedestrians under age 65 were collected. Results indicate a broad range of walking speeds among pedestrians. The 15th-percentile walking speed for younger pedestrians (ages 14 to 64) was 1.25 m/sec (4.09 ft/sec); for older pedestrians (ages 65 and over) it was 0.97 m/sec (3.19 ft/sec). For design purposes values of 1.22 m/sec (4 ft/sec) for younger pedestrians and 0.91 m/sec (3 ft/sec) for older pedestrians are appropriate. Results also indicated that walking rates are influenced by a variety of factors, including the functional classification and vehicle volumes on the street being crossed, the street width, weather conditions, the number of pedestrians crossing in a group, the signal cycle length, the timing of the various pedestrian-signal phases, whether right turn on red is allowed, pedestrian signals, medians , curb cuts, crosswalk markings, stop lines, and on-street parking. However, for each of these factors, the effect on crossing speeds, although statistically significant, is not meaningful for design. The older road user has received much attention during the past decade, and with good reason. The proportion of those over age 65 in the North American population is increasing and will continue to increase dramatically. Research related to older road users has also increased. In 1992 the Federal Highway Administration was sponsoring eight major research projects on older road users. An examination of these projects indicates that older drivers, not older pedestrians , receive the majority of attention in research related to older road users. Today's traffic environment is not well adapted to the needs of the older pedestrian. Unfortunately, except in the case of children, very little is known about the characteristics and behavior of pedestrians. The simple fact that older pedestrians walk more slowly than younger ones is easily supported by field data; however, the existing data on walking speeds and start-up time (i.e., the time from the TRANSPORTATION RESEARCH RECORD 1538 27 onset of a Walk signal until the pedestrian steps off the curb) have many shortcomings. For example, Dahlstedt (1) instructed a group of people aged 70 or older to cross an intersection at fast, very fast, or normal speed. Fast for about 60 percent of the group was less than 1.22 m/sec (4 ft/sec); normal for 90 percent of the group was also less than 1.22 m/sec (4 ft/sec), and the 85th-percentile speed was about 0.67 m/sec (2.2 ft/sec). The Manual on Uniform Traffic Control Devices (MUTCD) (2) suggests a walking speed of 1.22 m/sec (4 ft/sec) for traffic signal timing. A literature review by McGee, et al. (3) indicated that many pedestrians-perhaps 30 percent of the population, many of whom are older-do not normally walk that quickly. In fact, the Traffic Control Devices Handbook (TCDH) (4) also notes that one-third of all pedestrians cross more slowly, with 15 percent at or below 1.06 m/sec (3.5 ft/sec). TCDH states that "those having slower walking speeds have the moral and legal right to complete the crossing once they have entered the intersection." The Traffic Engineering Handbook (5) suggests that 0.91 to 0.99 m/sec (3 to 3.25 ft/sec) would be a more appropriate value to use for traffic signal timing. An Institute of Transportation Engineers committee concerned with pedestrian issues (6) conducted a survey at a Florida location with a large population of elderly pedestrians. The committee recommended 0.76 m/sec (2.5 ft/sec) as an appropriate walk speed (for locations with a high volume of elderly pedestrians), and found this speed to be adequate for 87 percent of pedestrians observed. However, walking speeds are influenced by environmental, traffic, and pedestrian characteristics. The effects of terrain on walking speeds are unknown, although it can be expected that the elderly would be affected more when walking up or down a grade than the young. Similarly, it can be expected that the elderly would react more strongly to higher vehicular densities and traffic speeds, out of a fear of traffic. Moore (7) noted that the closer the approaching vehicle, the faster the mean crossing time-1.52 m/sec (5 ft/sec) when the approaching vehicle was 3 sec away, 1.22 m/sec (4 ft/sec) when the approaching vehicle was not too close. Finally, pedestrian speed on sidewalks and crosswalks is strongly related to the number of pedestrians in the flow. The relationship between speed, flow, and space occupied (i.e., density) for a representative population group has been examined by Fruin (8) and others. However , the abilities of the elderly in crowds have not yet been documented. Because of the shortcomings in data on the walking speeds of older pedestrians a series of field studies was conducted to quantify the walking speed and start-up time of pedestrians of various ages under different environmental conditions.}
}
@unpublished{Fougerolle,
	title        = {Constructive Solid Geometry using Supershapes},
	author       = {Yohan D Fougerolle and Andrei Gribok and Sebti Foufou and Fr\'{e}d\'{e}ric Truchetet and Mongi A Abidi},
	abstract     = {We propose an efficient method to polygonize CSG trees of globally deformed supershapes. More generally , our approach can handle primitives with both parametric and implicit representations. An implicit equation with guaranteed differential properties is obtained by simple combinations of the primitives' implicit representations using R-functions theory. The surface of the object, corresponding to the zero-set of its implicit equation, is efficiently and accurately polygonized using the primitives' parametric forms and sharp edges are accurately preserved.}
}
@misc{Svensson,
	title        = {Procedural creation of corals using Lindenmayer systems and OSL shaders in Blender Cycles},
	author       = {Samuel Svensson},
	url          = {https://samuelllsvensson.github.io/files/Procedurella_projekt.pdf}
}
@phdthesis{Barthe,
	title        = {Les champs implicites d'extrusion : un outil pr\'{e}cis pour cr\'{e}er, sculpter ou combiner des formes \`{a} l'aide de surfaces implicites},
	author       = {Lo\"{\i}c Barthe},
	pages        = {1--144},
	url          = {https://www.irit.fr/~Loic.Barthe/These/These_Loic_27_09_2000.pdf},
	abstract     = {Automatic continuous blending is a powerful and specific property of implicit surfaces. However it remains difficult to control this soft transition precisely. Indeed the shape produced at the transition level is not directly linked to geometric parameters. We introduce a new tool to manipulate implicit surfaces: implicit extrusion fields. Those fields are 2 dimensional spaces where each coordinate is a potential field of R3\textregistered{}R. Point coordinates are then iso-surfaces. Point is defined by its coordinates intersection which is a curve in 3D user space. A continuous curve (called profile) defined in this field is then represented by a surface in the user space. This surface is said to be the extrusion of profile in implicit extrusion field. 0 iso-surfaces of implicit extrusion field coordinates can be introduced in final object and profiles can be precisely defined using control points and vectors of the 3D user space. 1D cubic polynomial splines are functions of R\textregistered{}R which smoothly interpolate control points. Profiles defines by those functions allow us to propose different tools: \cdot{} Creation of 3D objects by extrusion of profile in implicit extrusion field. \cdot{} Sculpt a surface in integrating one of the 0 iso-surface of coordinates of implicit extrusion field in final object. Profile extrusion will then add or remove matter. \cdot{} Combine the two 0 iso-surfaces of the two implicit extrusion field coordinates. Profile extrusion will then precisely defined the blend. The use of polynomial splines allows us to introduce an ``almost'' free form blending. Profiles are defined by functions of R\textregistered{}R. This is why they are not free form profiles, indeed, they must be monotonous in the abscissa direction. We then propose ``almost'' free form curves. We just propose an introduction to different research ways to defined ``true'' free form profiles. More researches have now to be done in this topic to increase our model efficiency.}
}
@techreport{Lech,
	title        = {Designing a Combined World and Story Procedural Content Generation Engine},
	author       = {Brenden Lech and Sasha Azad and Jennifer Welnitz and Joel Jonasson and Chris Martens},
	url          = {http://www.exag.org/archive/lech2021designing.pdf}
}
@article{Matthews,
	title        = {Incorporating Coherent Terrain Types into Story-Driven Procedural Maps},
	author       = {EA Matthews and BA Malloy},
	journal      = {Meaningfulplay.Msu.Edu},
	url          = {http://meaningfulplay.msu.edu/proceedings2012/mp2012_submission_41.pdf},
	abstract     = {We present a system for procedurally generating a map for a story-driven game, where locations in the map are assigned algorithmically or by designer preference. In addition, we also generate terrain, together with climate to match the terrain, with smooth, coherent transitions between terrain exhibiting different weather. We summarize weather approximations using a tuple to represent conditions such as temperature and humidity. We then exploit our previous work in map construction by placing locations of interest in the story on the map and then build a terrain boundary map that determines the boundaries between ranges of tuple values that belong to specific terrain types. We complete our construction by combining the climate map with a terrain type lookup, producing a final map with cohesive terrains. We describe the implementation of our system and illustrate the construction with some procedurally generated maps, including the procedural generation of the Narshe/Figaro area from Final Fantasy VI.}
}
@misc{Brun,
	title        = {Liste biblio cartes topologiques},
	author       = {Luc Brun},
	url          = {https://brunl01.users.greyc.fr/BIBLI_PERSO/fr/themes/theme_hierarchical_authordate.html}
}
@book{Boudon,
	title        = {Mod\'{e}lisation G\'{e}om\'{e}trique Quelques propri\'{e}t\'{e}s des maillages Repr\'{e}sentation par Cartes Combinatoires G\'{e}n\'{e}ralis\'{e}es},
	author       = {Fred Boudon}
}
@misc{Ash,
	title        = {Generalized Dirichlet Tesselation},
	author       = {Peter F. Ash and Ethan D. Bolker},
	url          = {https://www.cs.umb.edu/~eb/dirichlet/generalizedDT.pdf}
}
@misc{Wronski,
	title        = {Nice list of posts about debluring},
	author       = {Bart\l{}omiej Wro\'{n}ski},
	url          = {https://bartwronski.com/}
}
@misc{BSPanda2016,
	title        = {Chordal Graphs : Theory and Algorithms Chordal graphs},
	author       = {B. S. Panda},
	url          = {https://web.iitd.ac.in/~bspanda/chordal.pdf}
}
@misc{CourseBartheFonctionsImplicites,
	title        = {Fonctions, formes 3D, assemblages et animation},
	author       = {Lo\"{\i}c Barthe},
	url          = {https://www.irit.fr/recherches/VORTEX/vulgarisation/Loic/2015-04_Sofia-Kovaleskaia_Loic-Barthe.pdf}
}
@misc{Nick2020,
	title        = {Nick's blog : Transport-Oriented Growth and Procedural Trees},
	author       = {Nicholas McDonald},
	url          = {https://nickmcd.me/2020/10/19/transport-oriented-growth-and-procedural-trees/}
}
@article{Christiansen,
	title        = {Simulation of Coral Growth},
	author       = {Kenneth Rohde Christiansen and Aard Keimpema},
	pages        = {1--15},
	url          = {https://calcifer.org/kenneth-christiansen/ComputerScience/2d-coral-growth-2.pdf},
	keywords     = {computational,computer science,coral reefs,lattice-boltzmann,navier-stokes,science,simulations}
}
@misc{NoCite,
	title        = {Charles Darwin 1842}
}
@techreport{Diaz-Pernil_noDate,
	title        = {A Cellular Sudoku Solver},
	author       = {Daniel D\'{\i}az-Pernil and Carlos M Fern\'{a}ndez-M\'{a}rquez and Manuel Garc\'{\i}a-Quismondo and Miguel A Guti\'{e}rrez-Naranjo and Miguel A Mart\'{\i}nez-Del-Amor},
	abstract     = {Sudoku is a very popular puzzle which consists on placing several numbers in a squared grid according to some simple rules. In this paper we present an efficient family of P systems which solve sudoku puzzles of any order verifying a specific property. The solution is searched by using a simple human-style method. If the sudoku cannot be solved by using this strategy, the P system detects this drawback and then the computations stops and returns No. Otherwise, the P system encodes the solution and returns Yes in the last computation step.}
}
@misc{Bebis_noDate,
	title        = {Deformable/Active Contours (or Snakes)},
	author       = {George Bebis}
}
@techreport{Shaker2016,
	title        = {Computational Synthesis and Creative Systems Procedural Content Generation in Games},
	author       = {Noor Shaker and Julian Togelius and Mark J Nelson},
	url          = {http://www.springer.com/series/15219}
}
@misc{FactsAndDetailsWebpage,
	title        = {CORAL: POLYPS, ALGAE, EGGS, MASS SPAWNS},
	author       = {ioa.actsanddetails.com},
	journal      = {ioa.factsanddetails.com},
	url          = {ioa.factsanddetails.com}
}
@inbook{Darwin1842Appendix,
	title        = {The structure and distribution of coral reefs - Appendix},
	author       = {Charles Darwin},
	year         = 1842,
	month        = 9,
	booktitle    = {The Structure and Distribution of Coral Reefs},
	publisher    = {Cambridge University Press},
	pages        = {149--205},
	doi          = {10.1017/CBO9781107325098.009},
	isbn         = 2013206534,
	url          = {https://www.cambridge.org/core/product/identifier/CBO9781107325098A014/type/book_part}
}
@inbook{Darwin1842SuppMaps,
	title        = {The structure and distribution of coral reefs - Supplementary maps},
	author       = {Charles Darwin},
	year         = 1842,
	booktitle    = {The Structure and Distribution of Coral Reefs},
	volume       = 11,
	pages        = {430--439},
	isbn         = 6103544947,
	issue        = 2,
	keywords     = {jel classification,l25,m11,performance,supply chain integration,supply chain management}
}
@inbook{Darwin1842NoticeNewBooks,
	title        = {The structure and distribution of coral reefs - Chap V : Notices of new books},
	author       = {Charles Darwin},
	year         = 1842,
	month        = 2,
	booktitle    = {The Structure and Distribution of Coral Reefs},
	volume       = 1,
	pages        = {381--389},
	doi          = {10.1144/GSL.JGS.1845.001.01.82},
	issn         = {0370-291X},
	url          = {https://www.lyellcollection.org/doi/10.1144/GSL.JGS.1845.001.01.82},
	issue        = 1
}
@inbook{Darwin1842Intro,
	title        = {The structure and distribution of coral reefs - Introduction},
	author       = {Charles Darwin},
	year         = 1842,
	month        = 9,
	booktitle    = {The Structure and Distribution of Coral Reefs},
	publisher    = {Cambridge University Press},
	volume       = {i},
	pages        = {1--4},
	doi          = {10.1017/CBO9781107325098.002},
	isbn         = 9781107325098,
	url          = {https://www.cambridge.org/core/product/identifier/CBO9781107325098A007/type/book_part}
}
@inbook{Darwin1842BarrierReefs,
	title        = {The structure and distribution of coral reefs - Chap II: Barrier-reefs},
	author       = {Charles Darwin},
	year         = 1842,
	booktitle    = {The Structure and Distribution of Coral Reefs},
	pages        = {41--50},
	isbn         = 9781107325098
}
@inbook{Darwin1842Preface,
	title        = {The structure and distribution of coral reefs - Preface},
	author       = {Charles Darwin},
	year         = 1842,
	booktitle    = {The Structure and Distribution of Coral Reefs},
	pages        = {1--2},
	isbn         = 2013206534
}
@inbook{Darwin1842Theory,
	title        = {The structure and distribution of coral reefs - Chap V: Theory of the formation of the different classes of coral-reefs},
	author       = {Charles Darwin},
	year         = 1842,
	booktitle    = {The Structure and Distribution of Coral Reefs},
	isbn         = 9781107325098
}
@inbook{Darwin1842AtollsLagoons,
	title        = {The structure and distribution of coral reefs - Chap I : Atolls or lagoon-islands},
	author       = {Charles Darwin},
	year         = 1842,
	month        = 9,
	booktitle    = {The Structure and Distribution of Coral Reefs},
	publisher    = {Cambridge University Press},
	pages        = {5--40},
	doi          = {10.1017/CBO9781107325098.003},
	isbn         = 9781107325098,
	url          = {https://www.cambridge.org/core/product/identifier/CBO9781107325098A008/type/book_part}
}
@inbook{Darwin1842,
	title        = {The Structure and Distribution of Coral Reefs: Being the First Part of the Geology of the Voyage of the 'Beagle,' under the Command of Capt. Fitzroy, R. N., during the Years 1832 to 1836},
	author       = {Charles Darwin and Colonel Jackson},
	year         = 1842,
	booktitle    = {The Structure and Distribution of Coral Reefs},
	volume       = 12,
	pages        = 115,
	doi          = {10.2307/1797986},
	issn         = {02666235},
	abstract     = {Darwin, Charles (1842), The Structure and Distribution of Coral Reefs. Being the first part of the geology of the voyage of the Beagle, under the command of Capt. Fitzroy, R.N. during the years 1832 to 1836, London: Smith Elder and Co},
	issue        = {May}
}
@inbook{Darwin1842Distribution,
	title        = {The structure and distribution of coral reefs - Chap VI: On the distribution of coral-reefs with reference to the theory of their formation},
	author       = {Charles Darwin},
	year         = 1842,
	booktitle    = {The Structure and Distribution of Coral Reefs},
	pages        = {119--148},
	isbn         = 9781107325098
}
@inbook{Darwin1842Errata,
	title        = {The structure and distribution of coral reefs - Errata},
	author       = {Charles Darwin},
	year         = 1842,
	booktitle    = {The Structure and Distribution of Coral Reefs},
	pages        = 2017,
	isbn         = 9781107325098
}
@inbook{Darwin1842FringingReef,
	title        = {The structure and distribution of coral reefs - Chap III: Fringing or shore reefs},
	author       = {Charles Darwin},
	year         = 1842,
	booktitle    = {The Structure and Distribution of Coral Reefs},
	volume       = {ii},
	isbn         = 9781107325098
}
@inbook{Stokes1850,
	title        = {On the Effect of the Internal Friction of Fluids on the Motion of Pendulums},
	author       = {George Gabriel Stokes},
	year         = 1850,
	booktitle    = {Transactions of the Cambridge Philosophical Society,},
	publisher    = {Pitt Press Cambridge},
	volume       = {IX},
	doi          = {10.1017/CBO9780511702266.002},
	url          = {https://www.cambridge.org/core/product/identifier/CBO9780511702266A006/type/book_part},
	abstract     = {Not Available}
}
@article{Murray1880,
	title        = {On the Structure and Origin of Coral Reefs and Islands},
	author       = {John Murray},
	year         = 1880,
	journal      = {Proceedings of the Royal Society of Edinburgh},
	publisher    = {Cambridge University Press (CUP)},
	volume       = 10,
	pages        = {505--518},
	doi          = {10.1017/s0370164600044230},
	issn         = {0370-1646},
	abstract     = {Darwin's Theory. –During the voyage of the ``Beagle'' and subsequently, Mr Darwin made a profound study of coral reefs, and has given a theory of their mode of formation which has since been universally accepted by scientific men. Darwin's theory may be said to rest on two facts--the one physiological, and the other physical--the former, that those species of corals whose skeletons chiefly make up reefs cannot live in depths greater than from 20 to 30 fathoms; the latter, that the surface of the earth is continually undergoing slow elevation or subsidence.}
}
@article{Davis1914,
	title        = {The Home Study of Coral Reefs. Part III},
	author       = {W. M. Davis},
	year         = 1914,
	journal      = {Bulletin of the American Geographical Society},
	volume       = 46,
	pages        = 721,
	doi          = {10.2307/201744},
	issn         = {01905929},
	url          = {https://www.jstor.org/stable/201744?origin=crossref},
	issue        = 10
}
@article{Daly1915,
	title        = {The Glacial-Control Theory of Coral Reefs},
	author       = {Reginald A . Daly},
	year         = 1915,
	journal      = {Proceedings of the American Academy of Arts and Sciences},
	volume       = 51,
	pages        = {157--251},
	url          = {http://www.jstor.org/s},
	issue        = 4
}
@article{Davis1922,
	title        = {The Barrier Reef of Tagula, New Guinea},
	author       = {W. M. Davis},
	year         = 1922,
	journal      = {Annals of the Association of American Geographers},
	volume       = 12,
	pages        = 97,
	doi          = {10.2307/2560592},
	issn         = {00045608},
	url          = {http://links.jstor.org/sici?sici=0004-5608%281922%2912%3C97%3ATBROTN%3E2.0.CO%3B2-P&origin=crossref},
	issue        = 1922
}
@techreport{Krempf1927,
	title        = {La forme des r\'{e}cifs coralliens et le r\'{e}gime des vents alternants},
	author       = {Armand Krempf},
	year         = 1927,
	url          = {https://aquadocs.org/bitstream/handle/1834/35861/memoire2.pdf?sequence=1},
	institution  = {Gouvernement g\'{e}n\'{e}ral de l'Indochine}
}
@book{Davis1928,
	title        = {The coral reef problem},
	author       = {William Morris Davis},
	year         = 1928,
	publisher    = {American Geographical Society},
	city         = {New York}
}
@article{Shields1936,
	title        = {Anwendung der Aehnlichkeitsmechanik und der Turbulenzforschung auf die Geschiebebewegung},
	author       = {A. Shields},
	year         = 1936,
	journal      = {Mitteilungen der Preu\ss{}ischen Versuchsanstalt f\"{u}r Wasserbau}
}
@article{Richardson1954,
	title        = {The sedimentation of a suspension of uniform spheres under conditions of viscous flow},
	author       = {J. F. Richardson and W. N. Zaki},
	year         = 1954,
	journal      = {Chemical Engineering Science},
	volume       = 3
}
@article{Stearns1954,
	title        = {The shape of atolls: An inheritance from subaerial erosion forms},
	author       = {F. Stearns MacNeil},
	year         = 1954,
	journal      = {American Journal of Science},
	volume       = 252,
	pages        = {402--427},
	issue        = {July}
}
@article{Solow1956,
	title        = {Growth model},
	author       = {R. M. Solow},
	year         = 1956,
	journal      = {The quarterly journal of economics},
	volume       = 18,
	pages        = {65--94},
	issue        = 70,
	keywords     = {asymptotic analysis,conservation biology,population dynamics,size-structured continuous model}
}
@article{Forster1958,
	title        = {Underwater Observations on the Fauna of Shallow Rocky Areas in the Neighbourhood of Plymouth},
	author       = {G.R. Forster},
	year         = 1958,
	month        = 6,
	journal      = {Journal of the Marine Biological Association of the United Kingdom},
	volume       = 37,
	pages        = {473--482},
	doi          = {10.1017/S0025315400023821},
	issn         = {0025-3154},
	url          = {https://www.cambridge.org/core/product/identifier/S0025315400023821/type/journal_article},
	abstract     = {A brief description is given of the commonest sessile animals observed by diving from twelve positions near Plymouth, including three offshore reefs. The coelenterate Corynactis viridis is generally abundant on shaded rock surfaces. Many sessile species, even where common, tend to be dispersed in scattered patches or colonies; from this it is suggested that their distribution is affected by predation from browsing animals, particularly Echinus esculentus.},
	issue        = 2
}
@article{Ranz1960,
	title        = {Mechanics of particle bounce},
	author       = {W. E. Ranz and G. R. Talandis and Bernard Gutterman},
	year         = 1960,
	month        = 3,
	journal      = {AIChE Journal},
	volume       = 6,
	pages        = {124--127},
	doi          = {10.1002/aic.690060123},
	issn         = {0001-1541},
	url          = {https://aiche.onlinelibrary.wiley.com/doi/10.1002/aic.690060123},
	abstract     = {Irregular particles bounce with randomly distributed angles of reflection. There is a certain probability that a particle striking at low angle will bounce at a high angle and be carried far out into the main fluid flow. Bounce phenomena were investigated with respect to bounce of a model particle, limitations on dust collection (back mixing), and energy loss during the flow of suspensions.},
	issue        = 1
}
@techreport{Harlow1962,
	title        = {The particle-in-cell method for numerical solution of problems in fluid dynamics},
	author       = {Francis Harlow},
	year         = 1962,
	month        = 3,
	doi          = {10.2172/4769185},
	url          = {https://www.osti.gov/servlets/purl/4769185/},
	city         = {Los Alamos, NM (United States)},
	institution  = {Los Alamos National Laboratory (LANL)}
}
@techreport{Guilcher1965,
	title        = {Les r\'{e}cifs coralliens et le lagon de l'\^{\i}le de Mayotte},
	author       = {Andr\'{e} Guilcher and L\'{e}opold Berthois and Yolande Le Calvez and Ren\'{e} Battistini and Alain Crosnier},
	year         = 1965,
	url          = {https://horizon.documentation.ird.fr/exl-doc/pleins_textes/pleins_textes_2/memoires/10967.pdf},
	city         = {Paris},
	institution  = {Office de la Recherche Scientifique et Technique Outre-Mer}
}
@article{Harlow1965,
	title        = {Numerical Calculation of Time-Dependent Viscous Incompressible Flow of Fluid with Free Surface},
	author       = {Francis H. Harlow and J. Eddie Welch},
	year         = 1965,
	month        = 12,
	journal      = {The Physics of Fluids},
	volume       = 8,
	pages        = {2182--2189},
	doi          = {10.1063/1.1761178},
	issn         = {0031-9171},
	url          = {https://pubs.aip.org/pfl/article/8/12/2182/951500/Numerical-Calculation-of-Time-Dependent-Viscous},
	abstract     = {<p>A new technique is described for the numerical investigation of the time-dependent flow of an incompressible fluid, the boundary of which is partially confined and partially free. The full Navier-Stokes equations are written in finite-difference form, and the solution is accomplished by finite-time-step advancement. The primary dependent variables are the pressure and the velocity components. Also used is a set of marker particles which move with the fluid. The technique is called the marker and cell method. Some examples of the application of this method are presented. All non-linear effects are completely included, and the transient aspects can be computed for as much elapsed time as desired.</p>},
	issue        = 12
}
@article{Verlet1967,
	title        = {Computer "Experiments" on Classical Fluids. I. Thermodynamical Properties of Lennard-Jones Molecules},
	author       = {Loup Verlet},
	year         = 1967,
	month        = 7,
	journal      = {Physical Review},
	volume       = 159,
	pages        = {98--103},
	doi          = {10.1103/PhysRev.159.98},
	issn         = {0031-899X},
	url          = {https://link.aps.org/doi/10.1103/PhysRev.159.98},
	abstract     = {The equation of motion of a system of 864 particles interacting through a Lennard-Jones potential has been integrated for various values of the temperature and density, relative, generally, to a Quid state. The equilibrium properties have been calculated and are shoran to agree very vreH vrith the corresponding properties of argon. It is concluded that, to a good approximation, the equilibrium state of argon can be described thlough a t\&o-twdy potential.},
	issue        = 1
}
@article{McDonald1969,
	title        = {Quantitative Method for Describing the Regional Topography of the Ocean Floor},
	author       = {Martin F. McDonald and Eli Joel Katz},
	year         = 1969,
	journal      = {J Geophys Res},
	volume       = 74,
	pages        = 25972607,
	doi          = {10.1029/jb074i010p02597},
	abstract     = {Statistical method for studying the two-dimensional topography of a patch of ocean floor from radial track soundings is discussed and then illustrated for a 18. 5-km square located at the intersection of a continental rise and slope. The topographic features highlighted by the sutdy are related to a detailed bathymetric map of the area with good correspondence. It is, therefore, suggested that a very useful description of an area can be obtained from a minimum number of intersecting tracks, and since the method is quantitative, it offers the possiblility of making objective comparison between different areas.},
	issue        = 10
}
@book{Scheidegger1970,
	title        = {Theoretical Geomorphology},
	author       = {Adrian E. Scheidegger},
	year         = 1970,
	journal      = {Theoretical Geomorphology},
	doi          = {10.1007/978-3-662-01025-9},
	isbn         = 9783662010273
}
@article{Honda1971,
	title        = {Description of the form of trees by the parameters of the tree-like body},
	author       = {H Honda},
	year         = 1971,
	journal      = {Journal of Theoretical Biology},
	volume       = 31,
	pages        = {331--338},
	abstract     = {An attempt was made to describe the multifarious form of erect trees by a few parameters. Trees were approximated by the tree-like body which was made up of repeated bifurcations of branches. Three-dimensional positions of the end-points of the branches could be calculated using suitable but tentative solid geometrical assumptions which included some parameters : branching angle and relative ratio of the branch lengths. The branching angle and the relative ratio of the branch lengths were well demonstrated to have great effects upon the whole form of the tree-like body. The whole form of actual trees, therefore, was speculated to be affected also by their branching angle and relative ratio of their branch lengths. This attempt had a relationship to the problems of the morphogenetic process in living organisms and, in general, of the pattern-generation by generation rules.}
}
@article{A.JOHNSON1972a,
	title        = {Ocean-Floor Erosion in the Equatorial Pacific},
	author       = {David A. Johnson},
	year         = 1972,
	journal      = {Geological Society of America Bulletin},
	volume       = 83,
	pages        = {3121--3144},
	issue        = {October}
}
@book{Jones1973Geo1,
	title        = {Biology and geology of coral reefs. Volume I: Geology 1},
	author       = {O.A. Jones and Robert Endean},
	year         = 1973,
	url          = {https://cloudflare-ipfs.com/ipfs/bafykbzaceakbeam64ev4xr7hw2hjxto7uxeo3ij55zvna7osguxwfqkzfvxim?filename=Owen Arthur Jones (Auth.) - Biology and Geology of Coral Reefs. Geology 1 (1973, Academic press).pdf},
	keywords     = {tributors}
}
@book{Jones1973Bio1,
	title        = {Biology and geology of coral reefs. Volume II: Biology 1},
	author       = {O.A. Jones and Robert Endean},
	year         = 1973,
	doi          = {10.1016/b978-0-12-395526-5.50012-2},
	url          = {https://cloudflare-ipfs.com/ipfs/bafykbzacebzkcwh3nhrmx6gc4a4r2kpyn3a6guo45qvdrrzydqrrtm7ma572c?filename=O.A. Jones (Eds.) - Biology and Geology of Coral Reefs. Biology 1 (1973, Academic Press).pdf}
}
@inproceedings{Caretto1973,
	title        = {Two calculation procedures for steady, three-dimensional flows with recirculation},
	author       = {L. S. Caretto and A. D. Gosman and Suhas V. Patankar and D. B. Spalding},
	year         = 1973,
	booktitle    = {Proceedings of the Third International Conference on Numerical Methods in Fluid Mechanics},
	volume       = 19,
	pages        = {60--68},
	isbn         = {978-3-540-06171-7},
	url          = {http://www.springerlink.com/content/x46n27271791j492/},
	abstract     = {Two procedures are described for solving the Navier-Stokes equations for steady, fully three-dimensional flows: both are extensions of earlier methods de- vised for three-dimensional boundary layers, and have the following common features: (i) the main dependent variables are the velocities and pressure; ( i i ) the latter are computed on a number of staggered, interlacing grids, each of which is associated with a particular variable; (iii) a hybrid central-upwind difference scheme is employed; and (iv) the solution algorithms are sufficiently implicit to obviate the need to approach the steady state via the time evolution of the flow, as is required by wholly explicit methods.}
}
@book{Jolly1974,
	title        = {Biogeography and Ecology in Madagascar},
	author       = {Alison Jolly and R. Battistini and G. Richard-Vindard},
	year         = 1974,
	journal      = {The Journal of Animal Ecology},
	volume       = 43,
	pages        = 906,
	doi          = {10.2307/3544},
	isbn         = 9789401571616,
	issn         = {00218790},
	url          = {https://cloudflare-ipfs.com/ipfs/bafykbzaced547uh2nhkuhh4kdxu2eh7bv6o4lip7liepdi3jsfqp2oq7c2vbg?filename=%28Monographiae Biologicae 21%29 R. Battistini %28auth.%29%2C R. Battistini%2C G. Richard-Vindard %28eds.%29 - Biogeography and Ecology in Madagascar-},
	issue        = 3
}
@article{Bell1975a,
	title        = {Statistical features of sea-floor topography},
	author       = {T. H. Bell},
	year         = 1975,
	journal      = {Deep-Sea Research and Oceanographic Abstracts},
	volume       = 22,
	pages        = {883--892},
	doi          = {10.1016/0011-7471(75)90090-X},
	issn         = {00117471},
	abstract     = {Statistical properties of sea-floor topography are interpreted in terms of a model based on the random distribution of hills. Special emphasis is placed on estimating and interpreting the power spectrum of sea-floor elevation.},
	issue        = 12
}
@article{Bishop1975,
	title        = {There is More than One Way to Frame a Curve},
	author       = {Richard L. Bishop},
	year         = 1975,
	journal      = {The American Mathematical Monthly},
	volume       = 82,
	pages        = 246,
	doi          = {10.2307/2319846},
	issn         = {00029890},
	abstract     = {The Frenet frame of a 3-timesc ontinuouslyd ifferentiab(lteh at is, C3) nondegeneratec urvei n euclideans pace has long been the standardv ehiclef ora nalysing propertieso f the curve invariantu nder euclidean motions. For arbitrarym oving framest, hati s, orthonormabl asis fields,w e can expresst he derivativeos f thef rame with respectt o the curvep arameteri n termso f the framei tself,a nd due to orthonormalityt he coefficienmt atrixi s alwayss kew-symmetrTich.u s it generallyh as three nonzeroe ntriesT. he Frenetf rameg ains part of its special significancfer omt he fact that one of the threed erivativeiss alwaysz ero.A notherf eatureo f the Frenetf rame is thati t is adapted to the curve:t he membersa re eithert angentt o or perpendicular to the curve. It is the purpose of this paper to show that there are other frames which have these same advantages and to compare them with the Frenet frame},
	issue        = 3
}
@inproceedings{Shamos2008,
	title        = {Geometric intersection problems},
	author       = {Michael Ian Shamos and Dan Hoey},
	year         = 1976,
	month        = 10,
	booktitle    = {17th Annual Symposium on Foundations of Computer Science (sfcs 1976)},
	publisher    = {IEEE},
	pages        = {208--215},
	doi          = {10.1109/SFCS.1976.16},
	url          = {http://ieeexplore.ieee.org/document/4567905/},
	abstract     = {We develop optimal algorithms for forming the intersection of geometric objects in the plane and apply them to such diverse problems as linear programming, hidden-line elimination, and wire layout. Given N line segments in the plane, finding all intersecting pairs requires O(N2) time. We give an O(N log N) algorithm to determine whether any two intersect and use it to detect whether two simple plane polygons intersect. We employ an O(N log N) algorithm for finding the common intersection of N half-planes to show that the Simplex method is not optimal. The emphasis throughout is on obtaining upper and lower bounds and relating these results to other problems in computational geometry.}
}
@article{Buddemesier1976,
	title        = {Coral growth},
	author       = {R. W. Buddemesier and R. A. Kinzie III},
	year         = 1976,
	journal      = {Oceanographic Marine Biology Annual Revue},
	volume       = 14,
	pages        = {183--225},
	doi          = {10.4324/9781315265353-4},
	abstract     = {The study of coral biology in genera\l{}, and coral skeletal growth in particular has a special fascination because it reaches back even beyond the origin of classical biology to the studies and collections of the earliest naturalis ts. Y et, in spite of the antiquity and continuity of scientific attention, many of the problems considered by these investigators are stillunder active study today, together with a wide variety of more recently formulated questions. Because of i ts long past and modern diversity the subject of coral growth has a large and scattered literature and a comparably diverse foUowing. As in any broadly interdisciplinary research area, communication and assimila- tion of results and concepts in the field as a whole often lag far behind the level of sophistication of specific sub-disciplines. Our intention in this review is to assemble and compare the questions and results of various studies of coral skeletal accretion in order to disseminate as widely as possible informa- tion about mutually relevant investigations with different purposes and methodologies. It should be clearly understood that 'coral growth studies' are in reality methods or experimental approaches to larger fields of interest, each with its own literature and terminology. We will summadze briefly the different reasons for investigation of coral growth before integrating these into a review of methods and results.}
}
@article{Bames1976,
	title        = {Coral growth},
	author       = {Harold Bames and R W Buddemeier},
	year         = 1976,
	journal      = {Oceanography Marine Biology Annual Reviews},
	volume       = 14,
	pages        = {183--225},
	issue        = 14
}
@article{Parsons1977,
	title        = {An analysis of the variation of ocean floor bathymetry and heat flow with age},
	author       = {Barry Parsons and John G. Sclater},
	year         = 1977,
	month        = 2,
	journal      = {Journal of Geophysical Research},
	volume       = 82,
	pages        = {803--827},
	doi          = {10.1029/JB082i005p00803},
	issn         = {01480227},
	url          = {http://doi.wiley.com/10.1029/JB082i005p00803},
	issue        = 5,
	keywords     = {doi:10.1029/JB082i005p00803,http://dx.doi.org/10.1029/JB082i005p00803}
}
@article{Davies1977,
	title        = {Holocene reef growth -- One Tree Island, Great Barrier Reef},
	author       = {P J Davies and D W Kinsey},
	year         = 1977,
	journal      = {Marine Geology},
	volume       = 24
}
@book{Jones1977Geo2,
	title        = {Biology and geology of coral reefs. Volume IV: Geology 2},
	author       = {O.A. Jones and Robert Endean},
	year         = 1977,
	url          = {https://cloudflare-ipfs.com/ipfs/bafykbzaceb5pizxwkpo6ppg3uiaqfriwdp6jnbruthzqfhj4pyydqysm6pblk?filename=O.A. Jones (Eds.) - Biology and Geology of Coral Reefs. Geology 2 (1977).pdf}
}
@book{Jones1977Bio2,
	title        = {Biology and geology of coral reefs. Volume III: Biology 2},
	author       = {O.A. Jones and Robert Endean},
	year         = 1977,
	isbn         = {0123896029},
	url          = {https://cloudflare-ipfs.com/ipfs/bafykbzacec4eaivxtfuk5kchm4lzzowbhyow3wvkl42cp5cstv2urfwiimqnq?filename=O.A. Jones (Eds.) - Biology and Geology of Coral Reefs. Biology 2 (1976, Academic Press).pdf}
}
@book{Kremer1978,
	title        = {A Coastal Marine Ecosystem},
	author       = {James N. Kremer and Scott W. Nixon},
	year         = 1978,
	publisher    = {Springer Berlin Heidelberg},
	volume       = 24,
	doi          = {10.1007/978-3-642-66717-6},
	isbn         = {978-3-642-66719-0},
	url          = {http://link.springer.com/10.1007/978-3-642-66717-6},
	city         = {Berlin, Heidelberg}
}
@inbook{Kinsey1979,
	title        = {Carbon turnover, calcification and growth in coral reef},
	author       = {D.W. Kinsey and P.J. Davies},
	year         = 1979,
	booktitle    = {Biogeochemical Cycling of Mineral-Forming Elements},
	volume       = 3,
	pages        = {131--162}
}
@misc{Rogue1980,
	title        = {Rogue},
	author       = {A.I. Design},
	year         = 1980,
	publisher    = {Epyx}
}
@article{DeReffye1981,
	title        = {Modele mathematique aleatoire et simulation de la croissance et de l'architecture du cafeier robusta. 1re partie. Etude du fonctionnement des meristemes et de la croissance des axes vegetatifs},
	author       = {P de Reffye},
	year         = 1981,
	journal      = {Cafe Cacao The},
	volume       = 25,
	pages        = {83--103},
	url          = {https://agritrop.cirad.fr/454168/1/De Reffye 1981-2.pdf},
	keywords     = {ET,growth model,plant architecture,simulation,stochastic model}
}
@article{Witten1981,
	title        = {Diffusion-limited aggregation, a kinetic critical phenomenon},
	author       = {T. A. Witten and L. M. Sander},
	year         = 1981,
	journal      = {Physical Review Letters},
	volume       = 47,
	pages        = {1400--1403},
	doi          = {10.1103/PhysRevLett.47.1400},
	issn         = {00319007},
	url          = {https://journals.aps.org/prl/pdf/10.1103/PhysRevLett.47.1400},
	abstract     = {A model for random aggregates is studied by computer simulation. The model is applicable to a metal-particle aggregation process whose correlations have been measured previously. Density correlations within the model aggregates fall off with distance with a fractional power law, like those of the metal aggregates. The radius of gyration of the model aggregates has power-law behavior. The model is a limit of a model of dendritic growth. \textcopyright{} 1981 The American Physical Society.},
	issue        = 19
}
@article{Swope1982,
	title        = {A computer simulation method for the calculation of equilibrium constants for the formation of physical clusters of molecules: Application to small water clusters},
	author       = {William C. Swope and Hans C. Andersen and Peter H. Berens and Kent R. Wilson},
	year         = 1982,
	journal      = {The Journal of Chemical Physics},
	volume       = 76,
	pages        = {637--649},
	doi          = {10.1063/1.442716},
	issn         = {00219606},
	abstract     = {We present a molecular dynamics computer simulation method for calculating equilibrium constants for the formation of physical clusters of molecules. The method is based on Hill's formal theory of physical clusters. In the method, a molecular dynamics calculation is used to calculate the average potential energy of a cluster of molecules as a function of temperature, and the equilibrium constants are calculated from the integral of the energy with respect to reciprocal temperature. The method is illustrated by calculations of the equilibrium constants for the formation of clusters of two to five water molecules that interact with each other by an intermolecular potential devised by Watts. The method is compared with other procedures for calculating the thermodynamic properties of clusters. \textcopyright{} 1982 American Institute of Physics.},
	issue        = 1
}
@article{Dietrich1982,
	title        = {Settling Velocity of Natural Particles},
	author       = {William E. Dietrich},
	year         = 1982,
	journal      = {Water Resorces Reaserch},
	volume       = 18,
	pages        = {1615--1626},
	url          = {papers3://publication/uuid/53387056-6D82-48C0-B3D0-29238B6AC606},
	issue        = 6
}
@article{Fournier1982,
	title        = {Computer rendering of stochastic models},
	author       = {Alain Fournier and Don Fussell and Loren Carpenter},
	year         = 1982,
	month        = 6,
	journal      = {Communications of the ACM},
	volume       = 25,
	pages        = {371--384},
	doi          = {10.1145/358523.358553},
	issn         = {0001-0782},
	url          = {https://dl.acm.org/doi/10.1145/358523.358553},
	abstract     = {<p>A recurrent problem in generating realistic pictures by computers is to represent natural irregular objects and phenomena without undue time or space overhead. We develop a new and powerful solution to this computer graphics problem by modeling objects as sample paths of stochastic processes. Of particular interest are those stochastic processes which previously have been found to be useful models of the natural phenomena to be represented. One such model applicable to the representation of terrains, known as ``fractional Brownian motion,'' has been developed by Mandelbrot.</p>},
	issue        = 6,
	keywords     = {135 [Computer Graphics]: Computational Geometry and Object Modeling-curve, surface, solid, and object representation,CR Categories and Subject Descriptors: 133 [Com-puter Graphics]: Picture/Image Generation-display algorithms,I37 [Computer Graphics]: Three Dimensional Graphics and Realism-color, shad-ing, shadowing, and texture General Term: Algorithms Additional Key Words and Phrases: fractals, terrain models, stochastic models}
}
@article{Sammarco1982,
	title        = {Polyp Bail-Out: An Escape Response to Environmental Stress and a New Means of Reproduction in Corals},
	author       = {Paul W. Sammarco},
	year         = 1982,
	month        = 11,
	journal      = {Marine Ecology Progress Series},
	volume       = 10,
	pages        = {57--65},
	doi          = {10.3354/meps010057},
	issn         = {0171-8630},
	url          = {http://www.int-res.com/articles/meps/10/m010p057.pdf},
	abstract     = {During a study of planulation in the central region of the Great Barrier Reef, it was determined that the coral Seriatopora hystrix Dana exhibits an escape response to environmental stress. Th.is response, which occurs relatively rapidly, has been termed 'polyp bail-out', It proceeded in 3 steps: (1) Isolation of individual polyps via the polyp-ward movement of coenosarc; (2) emergenceof polyps and detachment from the skeleton; (3) dispersal, re-attachment to the bottom, andsecretion o i a new skeleton. Of the 250 polyps observed 4 5 \% successfully settled and secreted skeletons within 7 to 9 d under laboratory conditions. Polyps retained zooxantheIlae during the process and usually possessed 2 slightly adhesive filaments which may have assisted in re-attachment. Bail-out may be induced at any time in the laboratory and has been observed to occur naturally in the field on several occasions. The peak period of planulation for S. hystrix was determined to be November (early summer, southern hemisphere) During the normal spawning period, some polyps were observed to detach themselves while carrying active planulae. These polyps later disintegrated, releasing the larvae which settled normally. It is suggested that 'bail-out' may be one factor contributing to doininance of this species within certain reef habitats. It would also appear that this process of isolation and detachment of individuals from a coral followed by dispersal, resettlement , and re-initiation of skeletenogenesis, represents a previously unknown mode of asexual reproduction in the Scleractinia.}
}
@techreport{Foley1982,
	title        = {Graphics and Image Processing Computer Rendering of Stochastic Models},
	author       = {James Foley and Alain Fournier and Don Fussell and St Joseph St},
	year         = 1982,
	abstract     = {the techniques used to implement the model. We introduce a new algorithm that computes a realistic, visually satisfactory approximation to fractional Brownian motion in faster time than with exact calculations. A major advantage of this technique is that it allows us to compute the surface to arbitrary levels of details without increasing the database. Thus objects with complex appearances can be displayed from a very small database. The character of the surface can be controlled by merely modifying a few parameters. A similar change allows complex motion to be created inexpensively. A recurrent problem in generating realistic pictures by computers is to represent natural irregular objects and phenomena without undue time or space overhead. We develop a new and powerful solution to this computer graphics problem by modeling objects as sample paths of stochastic processes. Of particular interest are those stochastic processes which previously have been found to be useful models of the natural phenomena to be represented. One such model applicable to the representation of terrains, known as "fractional Brownian motion ," has been developed by Mandelbrot. The value of a new approach to object modeling in computer graphics depends largely on the efficiency of B. Mandelbrot, on whose work this paper is based, has raised certain objections which will be published in a subsequent issue. This paper reports the results of two independent research efforts one by Carpenter and the other by Fournier and Fussell. They both submitted papers to the 1980 SIGGRAPH conference, and through the conference to CA CM. Both papers were accepted for CA CM with the understanding that the authors would consolidate their work into a single integrated and definitive piece.-J. Foley.},
	keywords     = {135 [Computer Graphics]: Computational Geometry and Object Modeling-curve, surface, solid, and object representation,CR Categories and Subject Descriptors: 133 [Com-puter Graphics]: Picture/Image Generation-display algorithms,I37 [Computer Graphics]: Three Dimensional Graphics and Realism-color, shad-ing, shadowing, and texture General Term: Algorithms Additional Key Words and Phrases: fractals, terrain models, stochastic models}
}
@article{SCOFFIN1983,
	title        = {The distribution and structure of coral reefs: one hundred years since Darwin},
	author       = {T. P. SCOFFIN and J. E. DIXON},
	year         = 1983,
	journal      = {Biological Journal of the Linnean Society},
	volume       = 20,
	pages        = {11--38},
	doi          = {10.1111/j.1095-8312.1983.tb01587.x},
	issn         = 10958312,
	abstract     = {Plate tectonic theory accounts for the steady subsidence of mid-plate oceanic islands by cooling of the lithosphere and so provides a sound basis for Darwin's theory of atoll formation. Now it is evident that because the lithosphere behaves elastically in response to loads such as islands, more localized subsidence and uplift patterns can also be explained. Tectonically active areas, where one plate is subducted beneath another, are also likely to contain regions of marked uplift, but are less amenable to modelling. These processes together provide a background motion framework for most reef settings with rates of vertical movement of the order of a few millimetres per year. Reef forms are greatly influenced by the configuration of their foundations. Holocene reef foundations were essentially moulded by processes of deposition and erosion during the Pleistocene when global sea level changes were often greater than 1 cm year-1. We are now developing a sufficient understanding of the rates and nature of reef processes of growth and destruction to be able to see the manner in which the structural development of reefs responds to the complex interplay of tectonic uplift and subsidence plus changes of sea level and climate. Copyright \textcopyright{} 1983, Wiley Blackwell. All rights reserved},
	issue        = 1,
	keywords     = {Corals reefs,atolls,oceanic islands,plate tectonics,reef geomorphology,reef sedimentation,sea level changes,subsidence,tectonic theory,uplift}
}
@article{Lewis1984,
	title        = {Texture synthesis for digital painting},
	author       = {John-Peter Lewis},
	year         = 1984,
	month        = 7,
	journal      = {ACM SIGGRAPH Computer Graphics},
	volume       = 18,
	pages        = {245--252},
	doi          = {10.1145/964965.808605},
	issn         = {0097-8930},
	url          = {https://dl.acm.org/doi/10.1145/964965.808605},
	abstract     = {<p>The problem of digital painting is considered from a signal processing viewpoint, and is reconsidered as a problem of directed texture synthesis. It is an important characteristic of natural texture that detail may be evident at many scales, and the detail at each scale may have distinct characteristics. A ``sparse convolution'' procedure for generating random textures with arbitrary spectral content is described. The capability of specifying the texture spectrum (and thus the amount of detail at each scale) is an improvement over stochastic texture synthesis processes which are scalebound or which have a prescribed 1/f spectrum. This spectral texture synthesis procedure provides the basis for a digital paint system which rivals the textural sophistication of traditional artistic media. Applications in terrain synthesis and texturing computer-rendered objects are also shown.</p>},
	issue        = 3,
	keywords     = {CR Categories and Subject Descriptors: i33 [Computer Graphics]: Picture/Image generation; 137 [Computer Graphics]: Three Dimensional Graphics and Realism-color,and texture Additional Key Words and Phrases: texture synthesis,fractals,painting,shading,shadowing,terrain models}
}
@misc{Elite1984,
	title        = {Elite},
	author       = {David Braben and Ian Bell},
	year         = 1984,
	publisher    = {Acornsoft}
}
@article{Wu1985,
	title        = {Ecological field theory: A spatial analysis of resource interference among plants},
	author       = {Hsin-I Wu and Peter J.H. Sharpe and Joe Walker and Les K. Penridge},
	year         = 1985,
	month        = 9,
	journal      = {Ecological Modelling},
	volume       = 29,
	pages        = {215--243},
	doi          = {10.1016/0304-3800(85)90054-7},
	issn         = {03043800},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/0304380085900547},
	issue        = {1-4}
}
@article{Perlin1985,
	title        = {An image synthesizer},
	author       = {Ken Perlin},
	year         = 1985,
	month        = 7,
	journal      = {ACM SIGGRAPH Computer Graphics},
	volume       = 19,
	pages        = {287--296},
	doi          = {10.1145/325165.325247},
	issn         = {0097-8930},
	url          = {https://dl.acm.org/doi/10.1145/325165.325247},
	abstract     = {<p>We introduce the concept of a Pixel Stream Editor. This forms the basis for an interactive synthesizer for designing highly realistic Computer Generated Imagery. The designer works in an interactive Very High Level programming environment which provides a very fast concept/implement/view iteration cycle.Naturalistic visual complexity is built up by composition of non-linear functions, as opposed to the more conventional texture mapping or growth model algorithms. Powerful primitives are included for creating controlled stochastic effects. We introduce the concept of "solid texture" to the field of CGI.We have used this system to create very convincing representations of clouds, fire, water, stars, marble, wood, rock, soap films and crystal. The algorithms created with this paradigm are generally extremely fast, highly realistic, and asynchronously parallelizable at the pixel level.</p>},
	issue        = 3,
	keywords     = {CR CATEGORIES AND SUBJECT DESCRIPTORS: 135 [Computer Graphics]: Three-Dimensional Graphics and Realism ADDITIONAL KEYWORDS AND PHRASES: pixel stream editor,algorithm development,fire,functional composition,interactive,solid texture,space function,stochastic modelling,turbulence,waves}
}
@article{Prusinkiewicz1986,
	title        = {Score Generation With L-Systems},
	author       = {Przemyslaw Prusinkiewicz},
	year         = 1986,
	journal      = {Proceedings of the 1986 International Computer Music Conference, ICMC 1986},
	pages        = {455--457},
	url          = {http://algorithmicbotany.org/papers/score.icmc86.pdf},
	abstract     = {A new method for algorithmically generating musical scores is presented and illustrated with examples. The idea is to produce a string of symbols using an L-system, and to interpret this string as a sequence of notes. The proposed musical interpretation of L-systems is closely related to their graphical interpretation, which in turn associates L-systems to fractals.},
	keywords     = {L-systems,fractals,generative modeling of music,turtle geometry}
}
@article{Prusinkiewicz1986a,
	title        = {Graphical Applications of L-Systems.},
	author       = {Przemyslaw Prusinkiewicz},
	year         = 1986,
	journal      = {Proceedings - Graphics Interface},
	pages        = {247--253},
	issn         = {07135424},
	url          = {http://algorithmicbotany.org/papers/graphical.gi86.pdf},
	abstract     = {A new method for generating pictures is presented and illustrated with examples. The idea is to generate a string of symbols using an L-system, and to interpret this string as a sequence of commands which control a 'turtle'. Suitable generalizations of the notions of the L-system and of a turtle are introduced. The resulting mathematical model can be used to create a variety of (finite approximations of) fractal curves, ranging from Koch curves, to classic space-filling curves, to relatively realistic-looking pictures of plants and trees. All these pictures are defined in a uniform and compact way.}
}
@article{Meakin1986,
	title        = {A New Model for Biological Pattern Formation},
	author       = {Paul Meakin},
	year         = 1986,
	journal      = {Journal of Theoretical Biology},
	volume       = 118,
	pages        = {101--113}
}
@inproceedings{Miller1986,
	title        = {The definition and rendering of terrain maps},
	author       = {Gavin S P Miller},
	year         = 1986,
	month        = 8,
	booktitle    = {Proceedings of the 13th annual conference on Computer graphics and interactive techniques},
	publisher    = {ACM},
	pages        = {39--48},
	doi          = {10.1145/15922.15890},
	isbn         = {0897911962},
	url          = {https://dl.acm.org/doi/10.1145/15922.15890},
	city         = {New York, NY, USA}
}
@article{Lorensen1987,
	title        = {Marching cubes: A high resolution 3D surface construction algorithm},
	author       = {William E. Lorensen and Harvey E. Cline},
	year         = 1987,
	month        = 8,
	journal      = {Proceedings of the 14th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH 1987},
	publisher    = {Association for Computing Machinery, Inc},
	volume       = 21,
	pages        = {163--169},
	doi          = {10.1145/37401.37422},
	isbn         = {0897912276},
	abstract     = {We present a new algorithm, called marching cubes, that creates triangle models of constant density surfaces from 3D medical data. Using a divide-and-conquer approach to generate inter-slice connectivity, we create a case table that defines triangle topology. The algorithm processes the 3D medical data in scan-line order and calculates triangle vertices using linear interpolation. We find the gradient of the original data, normalize it, and use it as a basis for shading the models. The detail in images produced from the generated surface models is the result of maintaining the inter-slice connectivity, surface data, and gradient information present in the original 3D data. Results from computed tomography (CT), magnetic resonance (MR), and single-photon emission computed tomography (SPECT) illustrate the quality and functionality of marching cubes. We also discuss improvements that decrease processing time and add solid modeling capabilities.},
	issue        = 4,
	keywords     = {Computer graphics,Medical imaging,Surface reconstruction,surface reconstruction}
}
@article{Edyvean1987,
	title        = {Growth rates of lithophyllum incrustans (Corallinales, rhodophyta) from south west wales},
	author       = {R. G.J. Edyvean and H. Ford},
	year         = 1987,
	journal      = {British Phycological Journal},
	volume       = 22,
	pages        = {139--146},
	doi          = {10.1080/00071618700650161},
	issn         = {00071617},
	abstract     = {Growth rates of Lithophyllum incrustans, a rock-encrusting coralline red alga, have been studied at three sites on the coast of Pembroke, south-west Wales. Horizontal and vertical growth rates and calcium carbonate deposition rates were determined. There are some significant differences between sites, especially in vertical growth rates which include the formation of reproductive tissue. The data indicates that L. incrustans is, on average, 2-25 years old before reproduction is initiated. Growth rates of this alga were found to be similar to other arctic and temperate encrusting red algae, but an order of magnitude less than those in the tropics. \textcopyright{} 1987 British Phycological Society.},
	issue        = 2
}
@phdthesis{Werner1987,
	title        = {A physical model of Wind-blown sand transport},
	author       = {Bradley T. Werner},
	year         = 1987,
	doi          = {10.7907/6cbp-es88}
}
@article{Lewis1987,
	title        = {Generalized stochastic subdivision},
	author       = {J. P. Lewis},
	year         = 1987,
	month        = 7,
	journal      = {ACM Transactions on Graphics},
	volume       = 6,
	pages        = {167--190},
	doi          = {10.1145/35068.35069},
	issn         = {0730-0301},
	url          = {https://dl.acm.org/doi/10.1145/35068.35069},
	abstract     = {<p>Stochastic techniques have assumed a prominent role in computer graphics because of their success in modeling a variety of complex and natural phenomena. This paper describes the basis for techniques such as stochastic subdivision in the theory of random processes and estimation theory. The popular stochastic subdivision construction is then generalized to provide control of the autocorrelation and spectral properties of the synthesized random functions. The generalized construction is suitable for generating a variety of perceptually distinct high-quality random functions, including those with non-fractal spectra and directional or oscillatory characteristics. It is argued that a spectral modeling approach provides a more powerful and somewhat more intuitive perceptual characterization of random processes than does the fractal model. Synthetic textures and terrains are presented as a means of visually evaluating the generalized subdivision technique.</p>},
	issue        = 3,
	keywords     = {133 [Computer Graphics]: Picture/Image Generation; 137 [Computer Graphics]: Three-Dimensional Graphics and Realism-color,Theory Additional Key Words and Phrases: Fractals,and texture General Terms: Algorithms,modeling of natural phenomena,shading,shadowing,stochastic inter-polation,stochastic models,texture synthesis}
}
@article{Balick1987,
	title        = {A forest canopy height surface model for scene simulation},
	author       = {Lee K. Balick},
	year         = 1987,
	month        = 7,
	journal      = {SIMULATION},
	volume       = 49,
	pages        = {5--12},
	doi          = {10.1177/003754978704900103},
	issn         = {0037-5497},
	url          = {https://journals.sagepub.com/doi/10.1177/003754978704900103},
	abstract     = {<p>A model of forest canopy heights can support realistic remote sensing scene simulation. The final pixel (x, y) array of canopy heights results from merging structural and statistical sub-models. The structural model considers tree crowns to be structural primitives and permits explicit specification of forest structural characteristics (crown forms and spacing). The statistical model allows the inclusion of smaller scale effects (clumping or rough ness), and nonstationary effects can be introduced by merging the structural and statistical model results with spatially varying weights. The model supports several tasks in realistic scene simu lation (e.g., for use with algorithms which use surface geometry to determine pixel brightness). It also helps define realistic forest- top geometry classes or types so that simulations do not require high-level user expertise or detailed specification. The model also provides controlled test-bed data for canopy measurement and analysis technique development. By retaining tree shape and spacing information in a height surface, the model partially fills the gap between stochastic texture modeling and three- dimensional tree (object) models in scene synthesis.</p>},
	issue        = 1,
	keywords     = {forest canopy structure,image modeling,point patterns,scene simulation,texture modeling}
}
@techreport{Reynolds1987,
	title        = {Flocks, Herds, and Schools: A Distributed Behavioral Model},
	author       = {Craig W Reynolds},
	year         = 1987,
	journal      = {Computer Graphics},
	volume       = 21,
	abstract     = {The aggregate motion of a flock of birds, a herd of land animals , or a school of fish is a beautiful and familiar part of the natural world. But this type of complex motion is rarely seen in computer animation. This paper explores an approach based on simulation as an alternative to scripting the paths of each bird individually. The simulated flock is an elaboration of a particle system, with the simulated birds being the particles. The aggregate motion of the simulated flock is created by a distributed behavioral model much like that at work in a natural flock; the birds choose their own course. Each simulated bird is implemented as an independent actor that navigates according to its local perception of the dynamic environment, the laws of simulated physics that rule its motion, and a set of behaviors programmed into it by the "animator." The aggregate motion of the simulated flock is the result of the dense interaction of the relatively simple behaviors of the individual simulated birds.},
	issue        = 4,
	keywords     = {1210 [Artificial Intelli-gence]: Vision and Scene Understanding,135 [Computer Graphics]: Computational Geometry and Object Modeling,137 [Computer Graphics]: Three-Dimensional Graphics and Realism-Animation,163 [Simulation and Modeling[: Appli-cations General Terms: Algorithms, design Additional Key Words, and Phrases: flock, herd, school, bird, fish, aggregate motion, particle system, actor, flight, behav-ioral animation, constraints, path planning}
}
@article{HIMANN1988,
	title        = {Age-related changes in speed of walking},
	author       = {Joan E. Himann and David A. Cunningham and Peter A. Rechnitzer and Donald H. Paterson},
	year         = 1988,
	month        = 4,
	journal      = {Medicine \& Science in Sports \& Exercise},
	volume       = 20,
	pages        = {161--166},
	doi          = {10.1249/00005768-198820020-00010},
	issn         = {0195-9131},
	url          = {http://journals.lww.com/00005768-198820020-00010},
	abstract     = {Self-paced walking was used as a measure of the neuromuscular slowing observed with aging. The effects of age on the choice of speed of walking, stride length, and step frequency were described for 289 males and 149 females aged 19 to 102 yr. These subjects were asked to walk at three self-selected paces (slow, normal, and fast) over an 80-m indoor course. Sixty-two years coincided with an accelerated decline in speed of walking. Before 62 yr, there was a 1 to 2\% per decade decline in normal walking speed. After 63 yr, females showed a 12.4\% per decade decrease and males showed a 16-1\% per decade decrease. The eldest group (63 yr and older) had a significantly slower speed of walking and smaller step length than the younger groups (19 to 39 and 40 to 62 yr) for all paces. Heart rate at the three paces was not changed across age. In a multiple regression analysis, the only significant independent variable for walking speed at all three paces was (age)3, which accounted for 19 to 38\% of the variance. When the population was divided into two age ranges (19 to 62 and 63 to 102 yr), walking speed was associated with height before 62 yr and with height and age after 62 yr. \textcopyright{} 1989 by the American College of Sports Medicine.},
	issue        = 2,
	keywords     = {Fitness in elderly,Self-paced walking}
}
@article{Gilbert1988,
	title        = {A characterization of the spectral density of residual ocean floor topography},
	author       = {Lewis E. Gilbert and Alberto Malinverno},
	year         = 1988,
	journal      = {Geophysical research letters},
	volume       = 15,
	pages        = {1401--1404},
	isbn         = 9780415475976,
	abstract     = {Ocean floor topography can be characterized as a signal related to lithospheric cooling by comparing the shape of its power spectrum with that of a fractal process. Power spectra of Seabeam profiles along a flowline in the South Atlantic are calculated; the data are resampled, pre-whitened by first differencing, tapered with a Hanning window, and passed to a FFT. The effect of the pre-whitening are removed and the spectra are smoothed. The spectra of ocean floor topologic residuals are curved (power increases less rapidly with increasing wavelength) at wavelengths greater than several 10's of kilometers and straight at shorter wavelengths.},
	issue        = 12
}
@article{Sabella1988,
	title        = {A rendering algorithm for visualizing 3D scalar fields},
	author       = {Paolo Sabella},
	year         = 1988,
	journal      = {Proceedings of the 15th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH 1988},
	volume       = 22,
	pages        = {51--58},
	doi          = {10.1145/54852.378476},
	isbn         = {0897912756},
	abstract     = {This paper presents a ray tracing algorithm for rendering 3D scalar fields. An illumination model is developed in which the field is characterized as a varying density emittter with a single level of scattering. This model is equivalent to a particle system in which the particles are sufficiently small. Along each ray cast from the eye, the field is expressed as a function of the ray parameter. The algorithm computes properties of the field along the ray such as the attenuated intensity, the peak density, and the center of gravity, etc.. These are mapped into HSV color space to produce an image for visualization. Images produced in this manner are perceived as a varying density 'cloud' where color highlights the computed attributes. The application of this technique is demonstrated for visualizing a three dimensional seismic data set.},
	issue        = 4,
	keywords     = {3D image,Light scattering,Ray tracing,Thresholding}
}
@inbook{Owen1988,
	title        = {Artificial Intelligence},
	author       = {Patrick Henry Winston},
	year         = 1988,
	month        = 4,
	booktitle    = {Robotica},
	volume       = 6,
	pages        = {165--165},
	doi          = {10.1017/S0263574700004070},
	issn         = {0263-5747},
	url          = {https://www.cambridge.org/core/product/identifier/S0263574700004070/type/journal_article},
	abstract     = {Creating robust artificial intelligence is one of the greatest challenges for game developers, yet the commercial success of a game is often dependent upon the quality of the AI. In this book, Ian Millington brings extensive professional experience to the problem of improving the quality of AI in games. He describes numerous examples from real games and explores the underlying ideas through detailed case studies. He goes further to introduce many techniques little used by developers today. The book's associated web site contains a library of C++ source code and demonstration programs, and a complete commercial source code library of AI algorithms and techniques."Artificial Intelligence for Games - 2nd edition" will be highly useful to academics teaching courses on game AI, in that it includes exercises with each chapter. It will also include new and expanded coverage of the following: AI-oriented gameplay; Behavior driven AI; Casual games (puzzle games). \textasteriskcentered The first comprehensive, professional tutorial and reference to implement true AI in games written by an engineer with extensive industry experience.\textasteriskcentered Walks through the entire development process from beginning to end.\textasteriskcentered Includes examples from over 100 real games, 10 in-depth case studies, and web site with sample code.},
	issue        = 2,
	keywords     = {0123747317 9780123747310}
}
@article{Kelley1988,
	title        = {Terrain simulation using a model of stream erosion},
	author       = {Alex D. Kelley and Michael C. Malin and Gregory M. Nielson},
	year         = 1988,
	journal      = {Proceedings of the 15th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH 1988},
	volume       = {M},
	pages        = {263--268},
	doi          = {10.1145/54852.378519},
	isbn         = {0897912756},
	abstract     = {The major process affecting the configuration and evolution of terrain is erosion by flowing water. Landscapes thus reflect the branching patterns of river and stream networks. The network patterns contain information that is characteristic of the landscape's topographic features. It is therefore possible to create an approximation to natural terrain by simulating the erosion of stream networks on an initially uneroded surface. Empirical models of stream erosion were used us a basis for the model presented here. Stream networks of various sizes and shapes are created by the model from a small number of initial parameters. The eroded surface is represented as a surface under tension, using the tension parameter to shape the profiles of valleys created by the stream networks. The model can be used to generate terrain databases for flight simulation and computer animation applications.},
	issue        = {July},
	keywords     = {Database amplification,Drainage network simulation,Erosion models,Structural models,Surfaces under tension}
}
@techreport{RicherdeForges1988,
	title        = {La campagne CORAIL 2 sur le plateau des \^{\i}les Chesterfield},
	author       = {Bertrand Richer de Forges and Christophe Chevillon and Pierre Laboute and Georges Bargibant and Jean-Louis Menou and Philippe Tirard},
	year         = 1988,
	url          = {http://dsiphoto.mnhn.fr/expeditions/Documents/CORAIL2/CRCorail2.pdf}
}
@article{Montgomery1988,
	title        = {Charles Darwin's theory of coral reefs and the problem of the chalk},
	author       = {William Montgomery},
	year         = 1988,
	journal      = {Earth Sciences History},
	volume       = 7,
	pages        = {111--120},
	abstract     = {Darwin's effort to relate his theory of coral reefs to global tectonic concepts failed to impress geologists more immediately interested in European phenomena. Charles Lyell had initially regarded coral reefs as a way to explain the European Chalk formation. However, he encountered criticism from catastrophist authors who thought the Chalk was a result of chemical precipitation. Lyell embraced Darwin's coral reef theory in an effort to strengthen his argument; and though C. G. Ehrenberg explained the Chalk as the product of fossil Foramanifera, he reinforced the general case in favor of organic deposition as opposed to chemical precipitation. As a result geologists tended to follow Lyell in discussing coral reef formation in the larger context of carbonate deposition generally.},
	issue        = 2
}
@article{Stoddart1988,
	title        = {Joseph Beete Jukes, the 'Cambridge connection', and the theory of reef development in Australia in the nineteenth century},
	author       = {D. R. Stoddart},
	year         = 1988,
	journal      = {Earth Sciences History},
	volume       = 7,
	pages        = {99--110},
	issue        = 2
}
@article{Brackbill1988,
	title        = {Flip: A low-dissipation, particle-in-cell method for fluid flow},
	author       = {J. U. Brackbill and D. B. Kothe and H. M. Ruppel},
	year         = 1988,
	journal      = {Computer Physics Communications},
	volume       = 48,
	pages        = {25--38},
	doi          = {10.1016/0010-4655(88)90020-3},
	issn         = {00104655},
	abstract     = {The FLIP (Fluid-Implicit-Particle) method uses fully Lagrangian particles to eliminate convective transport, the largest source of computational diffusion in calculations of fluid flow. FLIP is an adaptation to fluids of the implicit moment method for simulating plasmas, in which particles carry everything necessary to describe the fluid. Using the particle data, Lagrangian moment equations are solved on a grid. The solutions are then used to advance the particle variables from time step to time step. An adaptive grid and implicit time differencing extend the method to multiple time and space scale flows. Aspects of FLIP's properties are illustrated by modeling of a confined eddy, a Rayleigh-Taylor, an unstable subsonic stream, and a supersonic jet. The results demonstrate FLIP's instability applicability to hydrodynamic stability problems where low dissipation is crucial to correct modeling. \textcopyright{} 1988.},
	issue        = 1
}
@techreport{Rothman1988,
	title        = {Immiscible Cellular-Automaton Fluids},
	author       = {Daniel H Rothman and Jeffrey M Keller},
	year         = 1988,
	journal      = {Journal of Statistical Physics},
	volume       = 52,
	abstract     = {We introduce a new deterministic collision rule for lattice-gas (cellular-automaton) hydrodynamics that yields immiscible two-phase flow. The rule is based on a minimization principle and the conservation of mass, momentum, and particle type. A numerical example demonstrates the spontaneous separation of two phases in two dimensions. Numerical studies show that the surface tension coefficient obeys Laplace's formula. Recently, Frisch et aL (1) (FHP) introduced a discrete lattice-gas model for the numerical solution of the 2D incompressible Navier-Stokes equations. In their model, space, time, and the velocities of particles are discrete. Identical particles of equal mass populate a triangular lattice, obey simple collision rules, and travel to neighboring sites at each time step. Because the model is entirely discrete, and because the evolution of a site is determined by the state of the ;ite and its nearest neighbors, the lattice gas is a cellular automaton. (2) Despite its simplicity, the macroscopic behavior of the lattice-gas automaton asymptotically approaches continuum flow. Since its introduction, this new model of fluid dynamics has not only been the subject of extensive theoretical and numerical studies, ~ 7) but has also been extended to 3D (8) and applied to a wide range of problems (e.g., refs. \%11). Here we introduce a simple yet fundamental extension of the lattice gas that leads to immiscible two-phase flow with interracial tension between fluid phases. In regions occupied by only a single phase, our 2D model is (barring irrelevant details) identical to the FHP gas. When two phases occupy the same region, however, we apply a new collision rule that},
	issue        = 3,
	keywords     = {Cellular automata,lattice gases,phase separation,surface tension,two-phase flow}
}
@article{Kass1988,
	title        = {Snakes: Active contour models},
	author       = {Michael Kass and Andrew Witkin and Demetri Terzopoulos},
	year         = 1988,
	month        = 1,
	journal      = {International Journal of Computer Vision},
	publisher    = {KIuwer Academic Publishers},
	volume       = 1,
	pages        = {321--331},
	doi          = {10.1007/BF00133570},
	issn         = {0920-5691},
	url          = {http://link.springer.com/10.1007/BF00133570},
	abstract     = {A snake is an energy-minimizing spline guided by external constraint forces and influenced by image forces that pull it toward features such as lines and edges. Snakes are active contour models: they lock onto nearby edges, localizing them accurately. Scale-space continuation can be used to enlarge the capture region surrounding a feature. Snakes provide a unified account of a number of visual problems, including detection of edges, lines, and subjective contours; motion tracking; and stereo matching. We have used snakes successfully for interactive interpretation, in which user-imposed constraint forces guide the snake near features of interest.},
	issue        = 4
}
@article{Mareschal1989,
	title        = {Fractal reconstruction of sea-floor topography},
	author       = {Jean Claude Mareschal},
	year         = 1989,
	journal      = {Pure and Applied Geophysics PAGEOPH},
	volume       = 131,
	pages        = {197--210},
	doi          = {10.1007/BF00874487},
	issn         = {00334553},
	abstract     = {Sea-floor bathymetric profiles exhibit features at many different scales of length; this suggests that they could be described as fractals. An algorithm interpolating a fractal line between points has been used to reconstruct bathymetric profiles from a few data points. In general, this fractal line has the same Fourier amplitude spectrum as real bathymetry, and, if the parameters of the interpolation are suitably chosen, it has a very similar appearance. The success of this fractal reconstruction algorithm for the sea-floor raises the possibility that it could be used to extrapolate, from data collected at one scale, the properties of the sea-floor at finer scales, and that similar techniques could be used to interpolate a surface between bathymetric profiles. The fractal character is a sign that the processes that shape the sea-floor are scale invariant and suggests that the renormalization group technique could be used to model these processes. \textcopyright{} 1989 Birkh\"{a}user-Verlag.},
	issue        = {1-2},
	keywords     = {Fractal,bathymetry,fracture zone,interpolation,ridge,tectonics}
}
@article{Malinverno1989,
	title        = {Testing linear models of sea-floor topography},
	author       = {Alberto Malinverno},
	year         = 1989,
	journal      = {Pure and Applied Geophysics PAGEOPH},
	volume       = 131,
	pages        = {139--155},
	doi          = {10.1007/BF00874484},
	issn         = {00334553},
	abstract     = {Stochastic models can generate profiles that resemble topography by taking uncorrelated, zero-average noise as input, introducing some correlation in the time series of noise, and integrating the resulting correlated noise. The output profile will depict a nonstationary, randomly rough surface. Two models have been chosen for comparison: a fractal model, in which the noise is correlated even at large distances, and an autoregressive model of order 1, in which the correlation of the noise decays rapidly. Both models have as an end-member a random walk, which is the integration of uncorrelated noise. The models have been fitted to profiles of submarine topography, and the sample autocorrelation, power spectrum and variogram have been compared to the theoretical predictions. The results suggest that a linear system approach is a viable method to model and classify sea-floor topography. The comparison does not show substantial disagreement of the data with either the autoregressive or the fractal model, although a fractal model seems to give a better fit. However, the amplitudes predicted by a nonstationary fractal model for long wavelengths (of the order of 1000 km) are unreasonably large. When viewed through a large window, ocean floor topography is likely to have an expected value determined by isostasy, and to be stationary. Nonstationary models are best applied to wavelengths of the order of 100 km or less. \textcopyright{} 1989 Birkh\"{a}user-Verlag.},
	issue        = {1-2},
	keywords     = {Autoregressive processes,fractals,roughness,stochastic modeling,time series analysis,topography}
}
@article{Musgrave1989,
	title        = {The synthesis and rendering of eroded fractal terrains},
	author       = {Forest Kenton Musgrave and Craig E. Kolb and Robert S. Mace},
	year         = 1989,
	journal      = {Proceedings of the 16th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH 1989},
	pages        = {41--50},
	doi          = {10.1145/74333.74337},
	isbn         = {0897913124},
	url          = {https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.27.8939&rep=rep1&type=pdf},
	abstract     = {In standard fractal terrain models based on fractional Brownian motion the statistical character of the surface is, by design, the same everywhere. A new approach to the synthesis of fractal terrain height fields is presented which, in contrast to previous techniques, features locally independent control of the frequencies composing the surface, and thus local control of fractal dimension and other statistical characteristics. The new technique, termed noise synthesis, is intermediate in difficulty of implementation, between simple stochastic subdivision and Fourier filtering or generalized stochastic subdivision, and does not suffer the drawbacks of creases or periodicity. Varying the local crossover scale of fractal character or the fractal dimension with altitude or other functions yields more realistic first approximations to eroded landscapes. A simple physical erosion model is then suggested which simulates hydraulic and thermal erosion processes to create global stream/valley networks and talus slopes. Finally, an efficient ray tracing algorithm for general height fields, of which most fractal terrains are a subset, is presented.},
	keywords     = {Crossover scale,Erosion models,Fractal,Fractal dimension,Fractional brownian motion,Height fields,Lacunarity,Ray tracing,Stochastic subdivision,Terrain models}
}
@article{Mallet1989,
	title        = {Discrete Smooth Interpolation},
	author       = {Jean-Laurent Mallet},
	year         = 1989,
	journal      = {ACM Transactions on Graphics (TOG)},
	volume       = 8,
	pages        = {121--144},
	doi          = {10.1145/62054.62057},
	issn         = 15577368,
	url          = {https://dl.acm.org/doi/pdf/10.1145/62054.62057},
	abstract     = {Interpolation of a function ƒ(\cdot{}) known at some data points of RP is a common problem. Many computer applications (e.g., automatic contouring) need to perform interpolation only at the nodes of a given grid. Whereas most classical methods solve the problem by finding a function defined everywhere, the proposed method avoids explicitly computing such a function and instead produces values only at the grid points. For two-dimensional regular grids, a special case of this method is identical to the Briggs method (see ``Machine Contouring Using Minimum Curvature,'' Geophysics 17, 1 (1974)), while another special case is equivalent to a discrete version of thin plate splines (see J. Duchon, Fonctions Splines du type Plaque Mince en Dimention 2, S\'{e}minaire d'analyse num\'{e}rique, n 231, U.S.M.G., Grenoble, 1975; and J. Enriquez, J. Thomann, and M. Goupillot, Application of bidimensional spline functions to geophysics, Geophysics 48, 9 (1983)). \textcopyright{} 1989, ACM. All rights reserved.},
	issue        = 2,
	keywords     = {Interpolation,grid,smooth,splines}
}
@article{Prusinkiewicz1989,
	title        = {Lindermayer Systems, fractals, and plants},
	author       = {Przemyslaw Prusinkiewicz and James Hanan},
	year         = 1989,
	journal      = {Lecture Notes in Biomathematics},
	pages        = 120,
	isbn         = {0387970924 (U.S.)},
	issn         = {00361445},
	url          = {http://algorithmicbotany.org/papers/lsfp.pdf},
	abstract     = {1. Introduction 3 2. Fractals 11 3. Models of plant architecture 23 4. Models of plant organs 55 5. Models of cell layers 63 6. Other applications of L-systems 69 Patterns and tilings (-> Gr\"{u}nbaum, Shephard: Tilings and Patterns) Kolam patterns Fractal music 7. A guide to the references 81 8. Program listing 101 kleine C-Programme},
	keywords     = {Geometrie,Informatik,Mathematik},
	pmid         = 2452354
}
@article{Rockwood1989,
	title        = {The Displacement Method for Implicit Blending Surfaces in Solid Models},
	author       = {Alyn P. Rockwood},
	year         = 1989,
	journal      = {ACM Transactions on Graphics (TOG)},
	volume       = 8,
	pages        = {279--297},
	doi          = {10.1145/77269.77271},
	issn         = 15577368,
	url          = {https://dl.acm.org/doi/pdf/10.1145/77269.77271},
	abstract     = {To date, methods that blend solids, that is, B-rep or CSG models, with implicit functions require successive composition of the blending functions to handle an arbitrary solid model. The shape of the resulting surfaces depends upon the algebraic distances defined by these functions. To achieve meaningful shapes, previous methods have relied on blending functions that have a pseudo-Euclidean distance measure. These methods are abstracted, resulting in some general observations. Unfortunately, the functions used can exhibit unwanted discontinuities. A new method, the displacement form of blending, embeds the zero surface of the blending functions in a form for which algebraic distance is C1 continuous in the entire domain of definition. Characteristics of the displacement form are demonstrated using the superelliptic blending functions. Intuitive and mathematical underpinnings are provided. \textcopyright{} 1989, ACM. All rights reserved.},
	issue        = 4,
	keywords     = {Algebraic distance,blending,geometric modeling,implicit surfaces,sculptured surfaces,solid modeling}
}
@article{Young1989,
	title        = {Wave transformation over coral reefs},
	author       = {Ian R. Young},
	year         = 1989,
	month        = 7,
	journal      = {Journal of Geophysical Research: Oceans},
	volume       = 94,
	pages        = {9779--9789},
	doi          = {10.1029/JC094iC07p09779},
	issn         = {0148-0227},
	abstract     = {Ocean wave attenuation on coral reefs is discussed using data obtained from a preliminary field experiment and from the Seasat altimeter. Marked attenuation of the waves is observed, the rate being consistent with existing theories of bottom friction and wave breaking decay. In addition, there is a significant broadening of the spectrum during propagation across reefs. Three-dimensional effects, such as refraction and defraction, can also lead to substantial wave height reduction for significant distances adjacent to coral reefs. As a result, a matrix of such reefs provides significantly more wave attenuation than may initially be expected.},
	issue        = {C7}
}
@techreport{Greene1989,
	title        = {Voxel space automata: Modeling with stochastic growth processes in voxel space},
	author       = {Ned Greene},
	year         = 1989,
	journal      = {Computer Graphics},
	volume       = 23,
	abstract     = {A novel stochastic modeling technique is described which operates on a voxel data base in which objects are represented as collections of voxel records. Models are "grown" from predefined geometric elements according to rules based on simple relationships like intersection, proximity, and occlusion which can be evaluated more quickly and easily in voxel space than with analytic geometry. Growth is probabilistic: multiple trials are attempted in which an element's position and orientation are randomly perturbed, and the trial which best fits a set of rules is selected. The term voxel space automata is introduced to describe growth processes that sense and react to a voxel environment. Applications include simulation of plant growth, for which voxel representation facilitates sensing the environment. Illumination can be effidently estimated at each plant "node" at each growth iteration by casting rays into the voxel environment , allowing accurate simulation of reaction to light including heliotropism.},
	issue        = 3,
	keywords     = {CR Categories: 135 [Computer Graphics]: Computational Geometry and Object Modeling-Curve,automata,heliotropism,illumination,radiosity,solid and object representation 137 [Computer Graphics]: Three-Dimensional Graphics and Realism 16 [Simulation and Modeling]: Applications Additional Keywords and Phrases: Voxel,stochastic processes,surface}
}
@article{Perlin1989,
	title        = {Hypertexture},
	author       = {K. Perlin and E. M. Hoffert},
	year         = 1989,
	month        = 7,
	journal      = {ACM SIGGRAPH Computer Graphics},
	volume       = 23,
	pages        = {253--262},
	doi          = {10.1145/74334.74359},
	issn         = {0097-8930},
	url          = {https://dl.acm.org/doi/10.1145/74334.74359},
	abstract     = {<p> We model phenomena intermediate between shape and texture by using space-filling applicative functions to modulate density. The model is essentially an extension of procedural solid texture synthesis, but evaluated throughout a volumetric region instead of only at surfaces.We have been able to obtain visually realistic representations of such shape+texture ( <italic>hypertexture</italic> ) phenomena as hair, fur, fire, glass, fluid flow and erosion effects. We show how this is done, first by describing a set of base level functions to provide basic texture and control capability, then by combining these to synthesize various phenomena.Hypertexture exists within an intermediate region between object and not-object. We introduce a notion of <italic>generalized boolean shape operators</italic> to combine shapes having such a region.Rendering is accomplished by <italic>ray marching</italic> from the eye point through the volume to accumulate opacity along each ray. We have implemented our hypertexture rendering algorithms on a traditional serial computer, a distributed network of computers and a coarse-grain MIMD computer. Extensions to the rendering technique incorporating refraction and reflection effects are discussed. </p>},
	issue        = 3
}
@techreport{Lewis1989,
	title        = {Algorithms for Solid Noise Synthesis},
	author       = {J P Lewis},
	year         = 1989,
	journal      = {\textcent{} Computer Graphics},
	volume       = 23,
	abstract     = {A solid noise is a function that defines a random value at each point in space. Solid noises have immediate and powerful applications in surface texturing, stochastic modeling, and the animation of natural phenomena. Existing solid noise synthesis algorithms are surveyed and two new algorithms are presented. The first uses Wiener interpolation to interpolate random values on a discrete lattice. The second is an efficient sparse convolution algorithm. Both algorithms are developed for model-directed synthesis, in which sampling and construction of the noise occur only at points where the noise value is required, rather than over a regularly sampled region of space. The paper attempts to present the rationale for the selection of these particular algorithms. The new algorithms have advantages of efficiency, improved control over the noise power spectrum, and the absence of arti-facts. The convolution algorithm additionally allows quality to be traded for efficiency without introducing obvious deterministic effects. The algorithms are particularly suitable for applications where high-quality solid noises are required. Several sample applications in stochastic modeling and solid texturing are shown.},
	issue        = 3,
	keywords     = {CR Categories and Subject Descriptors: 133 [Computer Graphics]: Picture/Image Generation; 137 [Computer Graph-ics]: Three-Dimensional Graphics and Realism-color,Graphics Additional Key Words and Phrases: Solid noise,and texture General Terms: Algorithms,fractals,shading,shadowing,simulation of natural phenomena,stochastic modeling,texture,texture syn-thesis}
}
@inbook{Bloomenthal1990,
	title        = {Calculation Of Reference Frames Along A Space Curve},
	author       = {Jules Bloomenthal},
	year         = 1990,
	booktitle    = {Graphics Gems},
	volume       = 1,
	pages        = {567--571},
	doi          = {10.1016/B978-0-08-050753-8.50124-8},
	isbn         = 9780080507538,
	url          = {http://webhome.cs.uvic.ca/~blob/courses/305/notes/pdf/ref-frames.pdf}
}
@article{Moore1990,
	title        = {An individualistic model of vegetation stand dynamics},
	author       = {Andrew D. Moore and Ian R. Noble},
	year         = 1990,
	month        = 7,
	journal      = {Journal of Environmental Management},
	volume       = 31,
	pages        = {61--81},
	doi          = {10.1016/S0301-4797(05)80015-5},
	issn         = {03014797},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0301479705800155},
	issue        = 1
}
@article{Berlemont1990,
	title        = {Particle lagrangian simulation in turbulent flows},
	author       = {A. Berlemont and P. Desjonqueres and G. Gouesbet},
	year         = 1990,
	journal      = {International Journal of Multiphase Flow},
	volume       = 16,
	pages        = {19--34},
	doi          = {10.1016/0301-9322(90)90034-G},
	issn         = {03019322},
	abstract     = {A Lagrangian approach is used to describe particle dispersion in turbulent flows. Fluid particle trajectories are simulated with the aid of a correlation matrix evolving along the particle trajectory. Discrete particles are tracked in a given turbulent field taking into account crossing-trajectory effects, and the influence of the particles on the flow characteristics is deduced from momentum and energy exchanges between both phases. Comparisons of the simulations are given for both experimental and theoretical results for fluid particle diffusion problems. Particle dispersion predictions are presented for grid turbulence experiments, and for three two-phase turbulent round jets, from different authors. Predictions compared favourably with experimental results. \textcopyright{} 1990.},
	issue        = 1,
	keywords     = {Lagrangian simulation,dispersed flows,turbulence,turbulent diffusion,two-phase flows}
}
@inproceedings{Sims1990,
	title        = {Particle animation and rendering using data parallel computation},
	author       = {Karl Sims},
	year         = 1990,
	month        = 9,
	booktitle    = {Proceedings of the 17th annual conference on Computer graphics and interactive techniques},
	publisher    = {ACM},
	volume       = 24,
	pages        = {405--413},
	doi          = {10.1145/97879.97923},
	isbn         = {0897913442},
	url          = {https://dl.acm.org/doi/10.1145/97879.97923},
	abstract     = {1 Abstract Techniques are presented that are used to animate and render particle systems with the Connection Machine CM-2, a data parallel supercomputer. A particle behavior language provides an animator with levels of control from kinematic spllne motions to physically based simulations. A parallel particle rendering system allows particles of different shapes, sizes, colors and transparencies to be rendered with anti-allasing, hidden surfaces, and motion-blur. One virtual processor is assigned to each primitive data element: one to each particle, and during the rendering process, one to each pixeLsized particle fragment, and to each pixel. These tools are used to model dynamic phenomena such as wind, snow, water, and fire.},
	city         = {New York, NY, USA},
	issue        = 4
}
@article{Cazenave1991,
	title        = {Long wavelength topography, seafloor subsidence and flattening},
	author       = {Anny Cazenave and Bernard Lago},
	year         = 1991,
	month        = 7,
	journal      = {Geophysical Research Letters},
	volume       = 18,
	pages        = {1257--1260},
	doi          = {10.1029/91GL01605},
	issn         = {0094-8276},
	url          = {https://agupubs.onlinelibrary.wiley.com/doi/10.1029/91GL01605},
	abstract     = {<p>Seafloor subsidence effects due to cooling of the oceanic lithosphere have been removed from bathymetry data. The corrected ocean floor topography presents long wavelength highs, in particular over western Pacific. We show in this study that this long wavelength residual topography can be interpreted as either a term of seafloor flattening at old ages or a dynamic response to large-scale convection. Whatever its origin, this long wavelength residual topography is dominated by a degree 2 pattern highly correlated with geoid, lower mantle heterogeneities and plate age.</p>},
	issue        = 7
}
@article{Lienhardt1991,
	title        = {Subdivisions de surfaces et cartes g\'{e}n\'{e}ralis\'{e}es de dimension 2},
	author       = {Pascal Lienhardt},
	year         = 1991,
	journal      = {RAIRO - Theoretical Informatics and Applications},
	volume       = 25,
	pages        = {171--202},
	doi          = {10.1051/ita/1991250201711},
	issn         = {0988-3754},
	url          = {http://www.numdam.org/item/ITA_1991__25_2_171_0.pdf},
	issue        = 2
}
@article{Meakin1991,
	title        = {Growth of adaptive networks in a modified diffusion-limited-aggregation model},
	author       = {Paul Meakin and Jens Feder and Torstein Jossang},
	year         = 1991,
	journal      = {Physical Review A},
	volume       = 44,
	pages        = {5104--5110},
	doi          = {10.1103/PhysRevA.44.5104},
	issn         = 10502947,
	url          = {https://journals.aps.org/pra/pdf/10.1103/PhysRevA.44.5104},
	abstract     = {Adaptive-network growth has been obtained by a diffusion-limited- aggregation model in which particles of the cluster that do not connect active regions (regions in which deposition is occurring) to the seed or origin of the cluster are removed from the cluster. In the computer simulation of this model, the accumulated score associated with each of the Nb particles connecting a deposited particle to the seed is increased by 1/Nb when the particle is added. At the same time, the scores of all particles in the cluster are decreased by an amount 1/Nm, which is a parameter of the model. Particles with scores less than zero are then removed from the cluster. This model leads to the formation of clusters that reach a stationary state in which the cluster size s(t) fluctuates about a constant value controlled by the parameter Nm. The number of particles N(r) within a distance r from the seed is given by N(r)r, where the exponent (fractal dimensionality) 1.25. The scaling of the cluster size with Nm is described by s\guillemotright{}(t)=Nmf(t/Nm), where t is the time (number of particles that have contacted the cluster). The exponent has a value of about 0.75. The score of each surviving particle is a measure (r) that also exhibits interesting scaling behavior. \textcopyright{} 1991 The American Physical Society.},
	issue        = 8
}
@article{Wejchert1991,
	title        = {Animation aerodynamics},
	author       = {Jakub Wejchert and David Haumann},
	year         = 1991,
	journal      = {Proceedings of the 18th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH 1991},
	volume       = 25,
	pages        = {19--22},
	doi          = {10.1145/122718.122719},
	isbn         = {0897914368},
	url          = {https://dl.acm.org/doi/pdf/10.1145/122718.122719},
	abstract     = {Methods based on aerodynamics are developed to simulate and control the motion of objects in fluid flows. To simplify the physics for animation, the problem is broken down into two parts: a fluid flow regime and an objcct boundary regime. With tin's simplification one can approximate the realistic behaviour of objects moving in liquids or air. It also enables a simple way of designing and controlling animation sequences: from a set of flow primitives, an animator can design the spatial arrangement of flows, create Hows around obstacles and direct flow liming. Hie approach is fast, simple, and is easily fitted into simulators Thai model objects governed by classical mechanics. The methods arc applied to an animation that involves hundreds of flexible leaves be-ing blown by wind currents.},
	issue        = 4,
	keywords     = {Aerodynamics,Animation,Control,Flow primitives,Fluid mechanics,Motion design,Simulation,Wind}
}
@techreport{VanWijk1991,
	title        = {Spot Noise Texture Synthesis for Data Visualization},
	author       = {Jarke J Van Wijk},
	year         = 1991,
	journal      = {\@ \@ Computer Graphics},
	volume       = 25,
	abstract     = {The use of stochastic textures for the visualization of scalar and vector fields over surfaces is discussed. Current techniques for texture synthesis are not suitable, because they do not provide local control, and are not suited for the design of textures. A new technique, .YprM noise, is presented that does provide these features. Spot noise is synthesized by addition of randomly weighted and positioned spots. Local control of the texture is realized by variation of the spot, The spot is a useful primitive for texture design, because, in general, the relations between features of the spot and features of the texture are straightforward. Various examples and applications are shown, spot noise lends itself well for the synthesis of [exture over curved surfaces, and is therefore an alternative to solid texturing, The relations of spot noise with a variety of other techniques, such as random faults, tittering, sparse convolution, and particle systems , are discussed. It appears that spot noise provides a new perspective on those techniques.},
	issue        = 4,
	keywords     = {CR categories and subject descriptors: 133 [Computer Graphics]: Picture/image generation; 137 [Computer Graph-ics]: Three Dimensional Graphics and Realism-color,and texture Keywords: texture synthesis,flow visu-alization,fractals,particle systems,scientific visualization,shading}
}
@inproceedings{Kent1992,
	title        = {Shape transformation for polyhedral objects},
	author       = {James R. Kent and Wayne E. Carlson and Richard E. Parent},
	year         = 1992,
	month        = 7,
	booktitle    = {Proceedings of the 19th annual conference on Computer graphics and interactive techniques},
	publisher    = {ACM},
	pages        = {47--54},
	doi          = {10.1145/133994.134007},
	isbn         = {0897914791},
	url          = {https://dl.acm.org/doi/10.1145/133994.134007},
	abstract     = {Techniques that transform one two-dimensionaf image into another have gained widespread use m recent yeara. Extending these tech- niques to transform pairs of 3D objects, as opposed to 2D images of the objects, providea several advsntagea, including the ability to sn- imate the objects independently of the transformation. This paper presents an algorithm for computing such transformations. The al- gorithm merges the topological structures of a pair of 3D polyhedral models into a common vertex/edgeJface network. This allows trsms- formations from one object to the other to be easily computed by in- terpolating between corresponding v\@ex positions.},
	city         = {New York, NY, USA},
	issue        = {July},
	keywords     = {computer-aidedgeo-,computeranimation,interpolation,metric design,shape trans-}
}
@article{Sederberg1992,
	title        = {A Physically Based Approach to 2-D Shape Blending},
	author       = {Thomas W. Sederberg and Eugene Greenwood},
	year         = 1992,
	month        = 12,
	journal      = {ACM Computer Graphics},
	volume       = 26,
	url          = {https://www.cs.drexel.edu/~david/Classes/Papers/p25-sederberg.pdf},
	abstract     = {This paper presents a new algorithm for smoothly blending be- tween two 2-D polygonal shapes. The algorithm is based on a physical model wherein one of the shapes is considered to be con- structed of wire, and a solution is found whereby the first shape can be bent and/or stretched into the second shape with a min- imum amount of work. The resulting solution tends to associate regions on the two shapes which look alike. If the two polY- gons have m and n vertices respectively, the afgorithm is O(mn). The algorithm avoids local shape inversions in whkh intermediate polygons self-intersect, if such a solution exists.},
	issue        = 2
}
@phdthesis{Hanan1992,
	title        = {Parametric L-systems and their Application to the Modelling and Visualization of Plants},
	author       = {James Scott Hanan},
	year         = 1992,
	pages        = 178,
	isbn         = {0-315-83871-X},
	url          = {http://algorithmicbotany.org/papers/hanan.dis1992.pdf},
	abstract     = {In this dissertation, parametric L-systems are presented as the foundation of a computer graphics tool for simulating and visualizing the development of plants. L-systems were introduced in 1968 by Aristid Lindenmayer as a mathematical model of multicellular organisms. They employ a parallel string-rewriting mechanism to describe the development of branching structures. The resulting strings can be interpreted geometrically and visualized using computer graphics techniques to create both realistic and schematic images of the modelled structures. The formalism can be applied for a variety of scientific, educational, and commercial purposes. Parametric L-systems extend the original concept of L-systems by associating numerical parameters with the symbols representing plant components. This allows easy quantification of geometric attributes of a model, and provides a simple means for the expression of continuous processes, such as diffusion of hormones and the resulting distribution of concentrations. Formal definitions are proposed for context- free and context-sensitive parametric L-systems with either deterministic or stochastic application of production rules. The practical value of parametric L-systems is demonstrated in this dissertation by examples that include models of plants ranging from algae to trees. Model de- velopment is controlled by lineage mechanisms, with information passed from parent to child module. This mechanism is combined in some models with endogenous in- teraction, where information flows through a growing structure. Selected models are suitable for simulating time-lapse photography through computer animation. Extensions to the formalism of parametric L-systems incorporate useful features of other programming languages and provide techniques for creating hierarchical models.}
}
@article{Kant1992,
	title        = {Drawing planar graphs using the canonical ordering},
	author       = {Goos Kant},
	year         = 1992,
	journal      = {Proceedings - Annual IEEE Symposium on Foundations of Computer Science, FOCS},
	volume       = {1992-Octob},
	pages        = {101--110},
	doi          = {10.1109/SFCS.1992.267814},
	isbn         = {0818629002},
	issn         = {02725428},
	abstract     = {The author introduces a method to optimize the required area, minimum angle and number of bends of planar drawings of graphs on a grid. The main tool is a new type of ordering on the vertices and faces of triconnected planar graphs. With this method linear time and space algorithms can be designed for many graph drawing problems. He shows that every triconnected planar graph G can be drawn convexly with straight lines on an (2n-4)(n-2) grid. If G has maximum degree four (three), then G can be drawn orthogonal with at most (/sup 3n//2)+3 (at most (n/2)+1) bends on an nn grid ((n/2)(n/2) grid, respectively). If G has maximum degree d, then G can be drawn planar on an (2n-6)(3n-6) grid with minimum angle larger than 1//sub d-2/ radians and at most 5n-15 bends. These results give in some cases considerable improvements over previous results, and give new bounds in other cases. Several other results, e.g. concerning visibility representations, are included.},
	issue        = {October}
}
@article{Mallet1992,
	title        = {Discrete smooth interpolation in geometric modelling},
	author       = {Jean-Laurent Mallet},
	year         = 1992,
	journal      = {Computer-Aided Design},
	volume       = 24,
	pages        = {178--191},
	doi          = {10.1016/0010-4485(92)90054-E},
	issn         = {00104485},
	abstract     = {In such fields as geology and biology, a common problem is that of modelling complex surfaces that are defined by data of various types. Classical modelling techniques based on B\'{e}zier and spline interpolations can account for only some of these types of data. The paper proposes a different approach that is based on the discrete smooth interpolation method. In this approach, surfaces are modelled as 2D graphs whose node locations are determined for a wide variety of heterogeneous data. \textcopyright{} 1992.},
	issue        = 4,
	keywords     = {geometric modelling,interpolation}
}
@article{Prusinkiewicz1992,
	title        = {The Algorithmic Beauty of Plants},
	author       = {Przemyslaw Prusinkiewicz and Aristid Lindenmayer},
	year         = 1992,
	journal      = {SIAM Review},
	volume       = 34,
	pages        = {142--143},
	doi          = {10.1137/1034030},
	issn         = {0036-1445},
	url          = {http://algorithmicbotany.org/papers/abop/abop.pdf},
	abstract     = {The Algorithmic Beauty of Plants explores mathematical models of developmental processes and structures of plants, and illustrates them using state-of-the-art computer-generated images. Plant models which grow, interact with the environment, produce flowers and fruits, and finally die, have an immense intuitive appeal of "bringing life into a computer." In front of a graphics monitor it is easy to forget the underlying mathematical formulae and simply look at plants growing, self-replicating, responding to external factors, even mutating. Without compromising the mathematical rigor of presentation the authors have tried to preserve this "touch of magic" accompanying in their research. The following areas receive particular attention: methods for the modeling and rendering of plants which are suitable for realistic image synthesis; the scientific potential of computer graphics in the visualization of biological structures and processes; the relationship between control mechanisms employed by li- ing plants and the resulting complex developmental sequences and structures; and the relationship between developmental processes, self-similarity and fractals. The formalism of L-systems are adopted as the primary mathematical vehicle used to express developmental processes. The notion of L-systems was conceived in 1968 by Aristid Lindenmayer as a formal model of plant development. Its exceptional elegance was promptly recognized by mathematicians, who soon developed a comprehensive theory of L-systems. However, only recently has computer graphics revealed the full potential of L-systems applied to plant modeling. Although the focus is on the original results of joint research led by the authors, a survey of alternative methods for plant modeling is also included.},
	issue        = 1
}
@article{Duff1992,
	title        = {Interval arithmetic and recursive subdivision for implicit functions and constructive solid geometry},
	author       = {Tom Duff},
	year         = 1992,
	journal      = {Computer Graphics (ACM)},
	volume       = 26,
	pages        = {131--138},
	doi          = {10.1145/142920.134027},
	isbn         = {0897914791},
	issn         = {00978930},
	url          = {https://dl.acm.org/doi/pdf/10.1145/142920.134027},
	abstract     = {Recursive subdivision using interval arithmetic allows us to render CSG combinations of implicit function surfaces with or without anti-aliasing. Related algorithms will solve the collision detection problem for dynamic simulation, and allow us to compute mass, center of gravity, angular moments and other integral properties required for Newtonian dynamics. Our hidden surface algorithms run in 'constant time.' Their running times are nearly independent of the number of primitives in a scene, for scenes in which the visible details are not much smaller than the pixels. The collision detection and integration algorithms are utterly robust - collisions are never missed due to numerical error and we can provide guaranteed bounds on the values of integrals. CR Categories and Subject Descriptors: G.1.0 [Numerical Analysis] Numerical Algorithms I.3.3 [Picture and Image Generation] Display algorithms, Viewing algorithms, I.3.5 [Computational Geometry and Object Modeling] Curve, surface, solid and object representations, I.3.5 [Computational Geometry and Object Modeling] Hierarchy and geometric transformations. I.3.7 [Three-Dimensional Graphics and Realism] Visible line/surface algorithms, Animation},
	issue        = 2
}
@article{Fifield1992,
	title        = {A Hands-On Simulation of Natural Selection in an Imaginary Organism, Platysoma apoda},
	author       = {Steve Fifield and Bruce Fall},
	year         = 1992,
	journal      = {American Biology Teacher},
	volume       = 54,
	pages        = {230--235},
	doi          = {10.2307/4449461},
	issn         = {00027685},
	abstract     = {Over the years, we have modified the exercise to suit our needs, and we encourage you to tailor it to your situation. It may be particularly effective to combine the hands-on nature of the exercise with the speed and flexibility of computer simulations. But no matter what method we choose, if one of our goals as instructors is to help students construct an understanding of evolution, we must give them the opportunity to explore the causes and consequences of natural selection. \textcopyright{} 1992, National Association of Biology Teachers. All rights reserved.},
	issue        = 4
}
@article{Noser1992,
	title        = {Animation based on the Interaction of L-systems with Vector Force Fields},
	author       = {Hansrudi Noser and Daniel Thalmann and Russell Turner},
	year         = 1992,
	journal      = {Visual Computing},
	doi          = {10.1007/978-4-431-68204-2},
	isbn         = 9784431682042,
	abstract     = {Augmented Vision and Reality},
	issue        = {September}
}
@article{Bosscher1992,
	title        = {Computer simulation of reef growth},
	author       = {Hemmo Bosscher and Wolfgang Schlager},
	year         = 1992,
	journal      = {Sedimentology},
	volume       = 39,
	pages        = {503--512},
	doi          = {10.1111/j.1365-3091.1992.tb02130.x},
	issn         = 13653091,
	abstract     = {Light is one of the major controls on reef growth and carbonate production. The growth of present reef builders depends largely upon the amount of light available for photosynthesis. As light decreases with water depth, so does reef growth. The computer model presented extends this principle by combining two functions, one for photosynthesis and the other for the extinction of light in water. The model is used to simulate the growth of Alacran Reef, Mexico, two reefs of the Great Barrier Reef and the reefs of the windward platform of St Croix, US Virgin Islands. The model also gives an accurate simulation of the growth of fore-reef walls in Belize, in agreement with the accretion hypothesis developed for this feature. Copyright \textcopyright{} 1992, Wiley Blackwell. All rights reserved},
	issue        = 3
}
@article{Williams1992,
	title        = {A Fast Algorithm for Active Contours and Curve Estimation},
	author       = {Donna J. Williams and Mubarak Shah},
	year         = 1992,
	journal      = {CVGIP},
	volume       = 55,
	pages        = {14--26},
	issue        = 1
}
@inproceedings{Ogniewicz1992,
	title        = {Voronoi Skeletons: Theory and Applications},
	author       = {R Ogniewicz and M Ilg},
	year         = 1992,
	booktitle    = {Proceeding in CVPR '92},
	pages        = {63--69},
	abstract     = {The paper presents a novel method of robust skele-tonization based on the Voronoi diagram (VD) of boundary points, which is characterized by correct Eu-clidean metrics and inherent preservation of connec-tivity. The regularization of the Voronoi medial axis (VMA) in the sense of Blum's prairie re analogy is done by attributing each component of the VMA with a measure of prominence and stability. The resulting Voronoi skeletons (VSK) appear largely invariant with respect to typical noise conditions in the image and geometric transformations. Hierarchical clustering of the skeleton branches, the so-called skeleton pyramid, leads to further simpliication of the skeleton. Several applications demonstrate the suitability of the Voronoi skeleton to higher order tasks such as object recognition.}
}
@inproceedings{Sederberg1993,
	title        = {2-D shape blending},
	author       = {Thomas W. Sederberg and Peisheng Gao and Guojin Wang and Hong Mu},
	year         = 1993,
	month        = 9,
	booktitle    = {Proceedings of the 20th annual conference on Computer graphics and interactive techniques},
	publisher    = {ACM},
	pages        = {15--18},
	doi          = {10.1145/166117.166118},
	isbn         = {0897916018},
	url          = {https://dl.acm.org/doi/10.1145/166117.166118},
	abstract     = {This paper presentsan algorithmfor determiningthe paths alongwhich corresponding vertices travel in a 2–D shape blending. Rather than considering the vertex paths explicitly, the algorithmdefines the inter- mediate shapes by interpolating the intrinsic definitions of the initial and final shapes. The algorithm produces shape blends which gener- ally are more satisfactory than those produced using linear or cubic curve paths. Particularly, the algorithm can avoid the shrinkage that normally occurs when rotating rigid bodies are linearly blended, and avoids kinks in the blend when there were none in the key polygons.},
	city         = {New York, NY, USA}
}
@article{Prusinkiewicz1993a,
	title        = {Fractal model of mountains with rivers},
	author       = {Prezemyuslaw Prusinkiewicz and Mark Hammel},
	year         = 1993,
	journal      = {Proceedings - Graphics Interface},
	pages        = {174--180},
	issn         = {07135424},
	url          = {http://data.exppad.com/public/papers/A Fractal Model of Mountains with Rivers.pdf},
	abstract     = {This paper addresses the long-standing problem of generating fractal mountains with rivers, and presents a partial solution that incorporates a squig-curve model of a river's course into the mid-point-displacement model for mountains. The method is based on the observation that both models can be expressed by similar context-sensitive rewriting mechanisms. As a result, a mountain landscape with a river can be generated using a single integrated process.},
	issue        = {May},
	keywords     = {context-sensitive,els,geometric rewriting,midpoint displacement,modeling of natural phenomena,squig curve,terrain mod-}
}
@article{Wilson1993,
	title        = {Hierarchical constraint logic programming},
	author       = {Molly Wilson and Alan Borning},
	year         = 1993,
	journal      = {The Journal of Logic Programming},
	volume       = 16,
	pages        = {277--318},
	doi          = {10.1016/0743-1066(93)90046-J},
	issn         = {07431066},
	abstract     = {Constraint logic programming (CLP) is a general scheme for extending logic programming to include constraints. It is parametrized by D, the domain of the constraints. However, CLP(D) languages, as well as most other constraint systems, only allow the programmer to specify constraints that must hold. In many applications, such as interactive graphics, planning document formatting, and decision support, one needs to express preferences as well as strict requirements. If we wish to make full use of the constraint paradigm, we need ways to represent these defaults and preferences declaratively, as constraints, rather than encoding them in the procedural parts of the language. We describe a scheme for extending CLP(D) to include both required and preferential constraints. An arbitrary number of strengths of preference are allowed. We present a theory of such constraint hierarchies, and an extension, hierarchical constraint logic programming (HCLP), of the CLP scheme to include constraint hierarchies. We give an operational, model theoretic, and fixed-point semantics for the HCLP scheme. Finally, we describe two interpreters we have written for instances of the HCLP scheme, give example programs, and discuss related work. \textcopyright{} 1993.},
	issue        = {3-4}
}
@article{Bertrand1993,
	title        = {Algebraic specification and development in geometric modeling},
	author       = {Yves Bertrand and J. F. Dufourd and Jean Fran\c{c}on and Pascal Lienhardt},
	year         = 1993,
	journal      = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume       = {668 LNCS},
	pages        = {75--89},
	doi          = {10.1007/3-540-56610-4_57},
	isbn         = 9783540566106,
	issn         = 16113349,
	url          = {https://link.springer.com/content/pdf/10.1007/3-540-56610-4_57.pdf},
	abstract     = {For several years now, the Geometric Modeling Group of Strasbourg has been working on new formal concepts and tools for describing and manipulating the boundary representation of geometric objects. In a large project of an interactive modeller for volumic objects, the description of which is based on generalized maps, it attempts to cover the whole process from mathematical modeling to efficient implementation, via a complete algebraic specification. Basic concepts and results of this experiment in horizontal and vertical software specification and development are presented along with several illustrations. Advances in algebraic specification methodology are highlighted, specially hierarchical construction of ordered sorts and operations.}
}
@article{Roudier1993,
	title        = {Landscapes Synthesis Achieved through Erosion and Deposition Process Simulation},
	author       = {P. Roudier and B. Peroche and M. Perrin},
	year         = 1993,
	journal      = {Computer Graphics Forum},
	volume       = 12,
	pages        = {375--383},
	doi          = {10.1111/1467-8659.1230375},
	issn         = 14678659,
	note         = {No mass conservation},
	abstract     = {This paper describes an original approach to terrain evolution in landscapes synthesis. In order to create some realistic landforms, we simulate geologically contrasted terrains and apply to them deterministic erosion processes. This allows us to relate the erosion on any point of the landsurface to local geological parameters. Any height field may be chosen as an initial topographic surface. Small perturbations may be introduced to avoid unpleasant regularities. A 3D model defines the geological parameters of each point according to its elevation. Our method is iterative: at each step, rock removal and possible alluvial deposition are computed at each point of the landsurface. The available erosion laws simulate mechanical erosion, chemical dissolution and alluvial deposition. At the end of each iteration, a new landsurface and the corresponding river network are created. Landsurfaces can be visualized at the final stage by two rendering algorithms including natural textures mapping. The stream network and the ridges may also be visualized. \textcopyright{} 1993 Eurographics Association},
	issue        = 3,
	keywords     = {artificial landscapes modelling,geological phenomena simulation,landscapes rendering,natural textures}
}
@article{Gascuel1993,
	title        = {An implicit formulation for precise contact modeling between flexible solids},
	author       = {Marie Paule Gascuel},
	year         = 1993,
	journal      = {Proceedings of the 20th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH 1993},
	pages        = {313--320},
	doi          = {10.1145/166117.166157},
	isbn         = {0897916018},
	url          = {https://dl.acm.org/doi/pdf/10.1145/166117.166157},
	abstract     = {This paper presents an implicit deformable model, based on iso-surfaces of potential fields generated by skeletons, that provides elegant and unified formulations for both geometric parameters such as shape or deformation and physical properties such as rigidity. The model is especially designed to improve collision and contact processing for non-rigid objects. In particular, it generates and maintains exact contact surfaces during interactions.},
	keywords     = {Animation,Collision detection,Collision response,Deformation,Implicit surface,Simulation}
}
@article{Krissek1993,
	title        = {Essentials of oceanography},
	author       = {Lawrence A. Krissek},
	year         = 1993,
	journal      = {Geochimica et Cosmochimica Acta},
	volume       = 57,
	pages        = 4324,
	doi          = {10.1016/0016-7037(93)90327-s},
	issn         = {00167037},
	url          = {https://www.oakton.edu/user/4/billtong/eas125/Powerpoint/EoO_11e_Lecture_Ch13.pdf},
	abstract     = {applicability for this approach.},
	issue        = 17
}
@article{Chen1993,
	title        = {The Theoretical Basis for the Parameterization of Ice Crystal Habits: Growth by Vapor Deposition},
	author       = {Jen-Ping Chen and Dennis Lamb},
	year         = 1993,
	journal      = {Journal of the Atmospheric Sciences},
	volume       = 51,
	pages        = {1206--1221},
	issue        = 9
}
@phdthesis{RoudierThesis,
	title        = {Synth\`{e}se de paysages r\'{e}alistes par simulation de processus d'\'{e}rosion},
	author       = {Pascale Roudier},
	year         = 1993
}
@article{Kaufman1993,
	title        = {Volume graphics},
	author       = {A. Kaufman and D. Cohen and R. Yagel},
	year         = 1993,
	month        = 7,
	journal      = {Computer},
	publisher    = {IEEE},
	volume       = 26,
	pages        = {51--64},
	doi          = {10.1109/MC.1993.274942},
	issn         = {0018-9162},
	url          = {http://ieeexplore.ieee.org/document/274942/},
	issue        = 7
}
@article{Hoppe1993,
	title        = {Mesh optimization},
	author       = {Hugues Hoppe and Tony DeRose and Tom Duchampy and John McDonaldz and Werner Stuetzlez},
	year         = 1993,
	journal      = {Proceedings of the 20th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH 1993},
	volume       = {d},
	pages        = {19--26},
	doi          = {10.1145/166117.166119},
	isbn         = {0897916018},
	abstract     = {We present a method for solving the following problem: Given a set of data points scattered in three dimensions and an initial triangular meshM0, produce a mesh M, of the same topological type as M0, that fits the data well and has a small number of vertices. Our approach is to minimize an energy function that explicitly models the competing desires of conciseness of representation and fidelity to the data. We show that mesh optimization can be effectively used in at least two applications: surface reconstruction from unorganized points, and mesh simplification (the reduction of the number of vertices in an initially dense mesh of triangles).},
	keywords     = {Geometric modeling,Model simplification,Range data analysis,Surface fitting,Three-dimensional shape recovery}
}
@article{Walton1993,
	title        = {Numerical simulation of inclined chute flows of monodisperse, inelastic, frictional spheres},
	author       = {Otis R. Walton},
	year         = 1993,
	month        = 8,
	journal      = {Mechanics of Materials},
	volume       = 16,
	pages        = {239--247},
	doi          = {10.1016/0167-6636(93)90048-V},
	issn         = {01676636},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/016766369390048V},
	abstract     = {Molecular-dynamics-like simulations are utilized to map regions of flow parameter space where steady flows occur for monodisperse assemblies of inelastic, frictional spheres, flowing down frictional, inclined planar surfaces. The trajectory-following technique utilizes nearly-rigid particles interacting via contact forces and gravity. Energy losses in the simulations occur only via displacement-dependent hysteretic loading/unloading paths and sliding friction. Initial scoping calculations are examining flows on an incline tilted 17 \textdegree{} from the horizontal, determining the boundaries of various flow regimes. Assemblies of inelastic spheres with interparticle friction coefficients less than the tangent of the inclination angle accelerate unboundedly. Those with friction coefficients somewhat greater than the tangent of the inclination angle develop steady velocity and density profiles for a variety of flow depths but result in arrested flow for coefficients of friction greatly exceeding the inclination angle tangent (e.g., by more than a factor of 2). Conversely, a significant range of inclination angles that will result in steady flows for a given set of assembly properties, is expected to exist.},
	issue        = {1-2}
}
@article{Prusinkiewicz1993b,
	title        = {Modeling and Visualization of Biological Structures},
	author       = {Przemyslaw Prusinkiewicz},
	year         = 1993,
	journal      = {Proceeding of Graphics Interface '93},
	volume       = 1993,
	pages        = {128--137},
	abstract     = {Rapid progress in the modeling of biological structures and simulation of their development has occurred over the last few years. It has been coupled with the visualization of simulation results, which has lead to a better understanding of morphogenesis and given rise to new procedural techniques for realistic image synthesis. This paper characterizes selected models of morphogenesis with a significant visual component.},
	keywords     = {L-system,cellular automaton,developmental models in biology,diffusion-limited growth,morpho-genesis,reaction-diffusion,realistic image synthesis,simulation and visualization of biological phenom-ena}
}
@article{Wilcok1993,
	title        = {Critical Shear Stress of Natural Sediments},
	author       = {Peter R. Wilcock},
	year         = 1993,
	month        = 4,
	journal      = {Journal of Hydraulic Engineering},
	publisher    = {American Society of Civil Engineers (ASCE)},
	volume       = 119,
	pages        = {491--505},
	doi          = {10.1061/(asce)0733-9429(1993)119:4(491)},
	issn         = {0733-9429},
	abstract     = {The critical shear stress of individual fractions "rci in unimodal and weakly bimodal sediments shows little variation with grain size and depends only on the mean grain size bf the mixture. For strongly bimodal sediments, ~'ci increases with grain size, an apparent result of a lateral segregation of the finer and coarser fractions on the bed surface that causes "rcl to deviate from size independence in the direction of unisize (Shields) values. A quantitative definition of mixture bi-modality may be used to estimate the degree of mixture bimodality beyond which a substantial size dependence of "r a is observed and to predict the variation of \%, with grain size in bimodal sediments. Because properties of sediment grain-size distributions other than bimodality appear to have little influence on "rc~, the trends presented here for 14 unimodal and bimodal sediments may be quite general.},
	issue        = 4
}
@article{Gero1994a,
	title        = {Evolutionary learning of novel grammars for design improvement},
	author       = {John S. Gero and Sushil J. Louis and Sourav Kundu},
	year         = 1994,
	journal      = {Artificial Intelligence for Engineering, Design, Analysis and Manufacturing},
	volume       = 8,
	pages        = {83--94},
	doi          = {10.1017/S089006040000069X},
	issn         = 14691760,
	abstract     = {This paper focuses on that form of learning that relates to exploration, rather than generalization. It uses the notion of exploration as the modification of state spaces within which search and decision making occur. It demonstrates that the genetic algorithm formalism provides a computational construct to carry out this learning. The process is exemplified using a shape grammar for a beam section. A new shape grammar is learned that produces a new state space for the problem. This new state space has improved characteristics. \textcopyright{} 1994, Cambridge University Press. All rights reserved.},
	issue        = 2,
	keywords     = {Evolution,Genetic Algorithms,Learning,Shape Grammars}
}
@article{Schroeder1994,
	title        = {Implicit modeling of swept surfaces and volumes},
	author       = {William J. Schroeder and William E. Lorensen and Steve Linthicum},
	year         = 1994,
	journal      = {Proceedings Visualization},
	pages        = {40--45},
	doi          = {10.1109/visual.1994.346339},
	issn         = 10702385,
	abstract     = {Swept surfaces and volumes are generated by moving a geometric model through space. Swept surfaces and volumes are important in many computer-aided design applications including geometric modeling, numerical cutter path generation, and spatial path planning. In this paper we describe a numerical algorithm to generate swept surfaces and volumes using implicit modeling techniques. The algorithm is applicable to any geometric representation for which a distance function can be computed. The algorithm also treats degenerate trajectories such as self-intersection and surface singularity. We show applications of this algorithm to maintainability design and robot path planning.},
	issue        = {May 2014}
}
@inbook{Bloomenthal1994,
	title        = {An Implicit Surface Polygonizer},
	author       = {Jules Bloomenthal},
	year         = 1994,
	booktitle    = {Graphics Gems},
	pages        = {324--349},
	doi          = {10.1016/b978-0-12-336156-1.50040-9},
	url          = {https://people.eecs.berkeley.edu/~jrs/meshpapers/Bloomenthal.pdf},
	abstract     = {An algorithm for the polygonization of implicit surfaces is described and an implementation in C is provided. The discussion reviews implicit surface polygonization, and compares various methods.}
}
@article{Elter,
	title        = {Cellular complexes as structured semi-simplicial sets},
	author       = {Herv\'{e} Elter and Pascal Lienhardt},
	year         = 1994,
	month        = 12,
	journal      = {International Journal of Shape Modeling},
	volume       = {01},
	pages        = {191--217},
	doi          = {10.1142/S021865439400013X},
	issn         = {0218-6543},
	url          = {http://www.worldscientific.com/doi/abs/10.1142/S021865439400013X},
	abstract     = {This study aims to find out and analyze the contribution of regional taxes to regional original income (PAD) and regional tax growth in 2013-2017. The location of this study was conducted at the Regional Financial and Asset Agency in Bantul Regency. This type of research is qualitative descriptive. Data analysis techniques using ratio analysis. The results showed that local tax revenues and local revenue (PAD) in Bantul Regency experienced a significant increase. The contribution of local taxes to local revenue is "quite good", averaging 32.645\%. The largest regional tax contribution is dominated by the Tax Transfer of Land and Building Rights (BPHTB). Regional tax growth and regional original income in that year were positively correlated, on average 18.75\% and 18.35\%},
	issue        = {02}
}
@phdthesis{Velho1994,
	title        = {Piecewise Descriptions of Implicit Surfaces and Solids},
	author       = {Luiz Velho},
	year         = 1994,
	url          = {http://web.cs.ucla.edu/~dt/theses/velho-thesis.pdf},
	abstract     = {This thesis presents a complete framework for the description of implicit surfaces and solids We propose piecewise representations that are based on decomposition models and constructed using methods adapted to the geometry of ob jects These models are general in the sense that they can represent arbitrary shapes and support variable precision permitting approximations at any desirable resolution The contribution of our work consists of i an original characterization of the implicit description of shapes ii a new method for generating a smooth implicit function corresponding to a solid ob ject and iii two new piecewise representation schemes based on a multiscale decomposition of the implicit function and on an adapted simplicial decomposition of the domain of the implicit function We characterize the implicit model through an analysis of the implicit function We show that the skeleton of a shape and the tubular neighborhood of its boundary are dual structures that relate an ob ject with the space in which it is embedded We develop a method that allows the generation of smooth implicit functions from the characteristic function of an ob ject It employs multiresolution edge detection and reconstruction using dyadic wavelets We introduce a functional decomposition model based on B spline scaling func tions that generate nested multiscale approximating spaces The Laplacian transform is employed to compute a pyramid in terms of these B spline bases We introduce a spatial decomposition model based on adapted simplicial subdivi sion Physics based deformation adapts to the boundary of the ob ject a mesh derived from this simplicial complex Some of the applications of these methods include approximate conversion be tween volumetric implicit and parametric representations surface rendering volume visualization and animation of implicit objects In summary the relevance of this thesis is twofold it provides a conceptual as well as a practical scheme for piecewise shape description The piecewise implicit representations that we have developed are e ective and e cient They capture the spatial features of ob jects using composite structures that are constructed from simple elements},
	institution  = {University of Toronto}
}
@article{Sims1994a,
	title        = {Evolving 3D Morphology and Behavior by Competition},
	author       = {Karl Sims},
	year         = 1994,
	journal      = {Artificial Life},
	volume       = 1,
	pages        = {353--372},
	doi          = {10.1162/artl.1994.1.4.353},
	issn         = {1064-5462},
	url          = {https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=625cf770e697cc01b9201fd3b67456ac56a7a27b},
	abstract     = {This article describes a system for the evolution and coevolution of virtual creatures that compete in physically simulated three-dimensional worlds. Pairs of individuals enter one-on-one contests in which they contend to gain control of a common resource. The winners receive higher relative fitness scores allowing them to survive and reproduce. Realistic dynamics simulation including gravity, collisions, and friction, restricts the actions to physically plausible behaviors.The morphology of these creatures and the neural systems for controlling their muscle forces are both genetically determined, and the morphology and behavior can adapt to each other as they evolve simultaneously. The genotypes are structured as directed graphs of nodes and connections, and they can efficiently but flexibly describe instructions for the development of creatures' bodies and control systems with repeating or recursive components. When simulated evolutions are performed with populations of competing creatures, interesting and diverse strategies and counterstrategies emerge.},
	issue        = 4
}
@article{Sims1994b,
	title        = {Evolving virtual creatures},
	author       = {Karl Sims},
	year         = 1994,
	journal      = {Proceedings of the 21st Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH 1994},
	pages        = {15--22},
	doi          = {10.1145/192161.192167},
	isbn         = {0897916670},
	url          = {https://dl.acm.org/doi/pdf/10.1145/192161.192167},
	abstract     = {This paper describes a novel system for creating virtual creatures that move and behave in simulated three-dimensional physical worlds. The morphologies of creatures and the neural systems for controlling their muscle forces are both generated automatically using genetic algorithms. Different fitness evaluation functions are used to direct simulated evolutions towards specific behaviors such as swimming, walking, jumping, and following. A genetic language is presented that uses nodes and connections as its primitive elements to represent directed graphs, which are used to describe both the morphology and the neural circuitry of these creatures. This genetic language defines a hyperspace containing an indefinite number of possible creatures with behaviors, and when it is searched using optimization techniques, a variety of successful and interesting locomotion strategies emerge, some of which would be difficult to invent or build by design.}
}
@article{Gourlay1994,
	title        = {Wave transformation on a coral reef},
	author       = {M.R. Gourlay},
	year         = 1994,
	month        = 5,
	journal      = {Coastal Engineering},
	volume       = 23,
	pages        = {17--42},
	doi          = {10.1016/0378-3839(94)90013-2},
	issn         = {03783839},
	abstract     = {Wave transformation of regular waves was measured in a laboratory model of a fringing reef with a steep face and an outer reef-top slope gradually decreasing in the landward direction. Data was obtained for various wave conditions and water levels. A nonlinearity parameter, Fco = g1.25Ho0.5T2.5/hc1.75, based upon one proposed by Swart and Loubser (1979), is proposed as a suitable parameter for classifying wave transformation regimes on this reef. In particular, when Fco > 150, waves plunge on the reef edge and the amount of wave energy reaching a shore or structure is small \leqslant{} 16\%. When Fin co \leqslant{} 100, waves spill on the reef-top but the greater part of their energy is transmitted over the reef-top. The maximum values of the wave height to water depth ratio on the reef-top were found to be consistent with Nelson's analyses for laboratory and field data which indicate that the maximum stable wave height to depth ratio H/d on a horizontal bottom never exceeds 0.55 for shallow water waves (Fc > 500). The experimental data confirms that the maximum value of H/d decreases when Fc decreases but that it also increases when the bottom slope increases.},
	issue        = {1-2}
}
@book{Vreugdenhil1994,
	title        = {Numerical Methods for Shallow-Water Flow},
	author       = {C. B. Vreugdenhil},
	year         = 1994,
	publisher    = {Springer Netherlands},
	volume       = 13,
	doi          = {10.1007/978-94-015-8354-1},
	isbn         = {978-90-481-4472-3},
	url          = {http://link.springer.com/10.1007/978-94-015-8354-1},
	city         = {Dordrecht}
}
@book{Barton1995,
	title        = {Fractals in the Earth Sciences},
	author       = {Christopher C. Barton and Paul R. La Pointe},
	year         = 1995,
	pages        = 277,
	isbn         = 9789896540821,
	abstract     = {Fractals have changed the way we understand and study nature. This change has been brought about mainly by the work of B. B. Mandelbrot and his book The Fractal Geometry of Nature. Now here is a book that collects articles treating fractals in the earth sciences. The themes chosen span, as is appropriate for a discourse on fractals, many orders of magnitude; including earthquakes, ocean floor topography, fractures, faults, mineral crystallinity, gold and silver deposition. There are also chapters on dynamical processes that are fractal, such as rivers, earthquakes, and a paper on self-organized criticality. Many of the chapters discuss how to estimate fractal dimensions, Hurst exponents, and other scaling exponents. This book, in a way, represents a snapshot of a field in which fractals has brought inspiration and a fresh look at familiar subjects. New ideas and attempts to quantify the world we see around us are found throughout. Many of these ideas will grow and inspire further work, others will be superseded by new observations and insights, most probably with future contributions by the authors of these chapters. It is wonderful to witness that the idea of fractal geometry has lead to such a high rate of discovery in the earth sciences. I believe that this book will also inspire others to take part in the scientific process of revealing the unseen, clarifying what is incomplete, discarding views that turn out not to stand up to the test of experiments and observations and thereby extending our understanding of the earth.}
}
@techreport{Boers1995,
	title        = {Using L-Systems as Graph Grammar: G2L-Systems},
	author       = {Egbert J. W. Boers},
	year         = 1995,
	url          = {https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.54.9935&rep=rep1&type=pdf},
	abstract     = {This paper will show how the interpretation of strings resulting from L-systems can be adapted in such a way that L-systems can be used as graph grammars. One of the advantages of this adaptation is the possibility to make use of the context dependency available in L-systems. This context is calculated by using the graph interpretation of the strings at each successive step of the rewriting mechanism. The modifications to L-systems necessary in order to use them as graph grammars will be explained. A simple proof will be given that every possible directed graph can be generated using this representation. At the end of the paper an application of this G2L-system based graph grammar will be presented. In this application a genetic algorithm optimizes the rewriting rules of an G2L-system, trying to come to a more scalable method for finding good artificial neural network architectures in comparison with methods that do not use graph grammars. The presented G2L-system was specifically designed for this application to favour modular networks, but might be useful in general as well},
	issue        = {October},
	keywords     = {artificial neural networks,genetic algorithms,graph grammars,l-systems,modularity}
}
@article{Pasko1995,
	title        = {Function representation in geometric modeling: concepts, implementation and applications},
	author       = {A. Pasko and V. Adzhiev and A. Sourin and V. Savchenko},
	year         = 1995,
	journal      = {The Visual Computer},
	volume       = 11,
	pages        = {429--446},
	doi          = {10.1007/BF02464333},
	issn         = {01782789},
	url          = {http://papers.cumincad.org/data/works/att/d935.content.pdf},
	abstract     = {Concepts of functionally based geometric modeling including sets of objects, operations, and relations are discussed. Transformations of a defining real function are described for set-theoretic operations, blending, offsetting, bijective mapping, projection, cartesian products, and metamorphosis. Inclusion, point membership, and intersection relations are also described. We use a high-level geometric language that can extend the interactive modeling system by input symbolic descriptions of primitives, operations, and predicates. This approach supports combinations of representational styles, including constructive geometry, sweeping, soft objects, voxel-based objects, deformable and other animated objects. Application examples of aesthetic design, collisions simulation, NC machining, range data processing, and 3D texture generation are given. \textcopyright{} 1995 Springer-Verlag.},
	issue        = 8,
	keywords     = {Geometric modeling,Implicit surfaces,R functions,Real functions,Solid modeling}
}
@article{Chrobak1995,
	title        = {A linear-time algorithm for drawing a planar graph on a grid},
	author       = {M. Chrobak and T. H. Payne},
	year         = 1995,
	journal      = {Information Processing Letters},
	volume       = 54,
	pages        = {241--246},
	doi          = {10.1016/0020-0190(95)00020-D},
	issn         = {00200190},
	abstract     = {We present a linear-time algorithm that, given an n-vertex planar graph G, finds an embedding of G into a (2n - 4) \texttimes{} (n - 2) grid such that the edges of G are straight-line segments. \textcopyright{} 1995.},
	issue        = 4,
	keywords     = {Algorithms}
}
@article{Robinson1995,
	title        = {Scientific Diving Under Sea Ice in the Southern Ocean},
	author       = {C. Robinson and H. J. Hill and S. Archer and R. J. G Leakey and P. W. Boyd and S. J. Bury},
	year         = 1995,
	journal      = {Underwater Technology},
	volume       = 21,
	pages        = {21--27},
	doi          = {10.3723/175605495783328845},
	issn         = 17560543,
	url          = {https://www.ingentaconnect.com/content/sut/unwt/1995/00000021/00000001/art00005?crawler=true},
	abstract     = {Scientific Diving techniques were employed during a 54 day oceanographic research cruise to the Bellings-hausen Sea, Southern Ocean (65\textdegree{}S-72\textdegree{}S, 80 0 W-87\textdegree{}W), in order to position sampling and data collecting instrumentation beneath sea ice. Eight Scientific Divers and a Field Diving Officer safely completed 112 individual dives (range 2-80 minutes, 2-28 m); 94 of these were roped dives through holes cut in 1 m thick sea ice. Seawater temperature was-1.8\textdegree{}C, horizontal visibility 30 m + and water depth 600 m or more. No problems were encountered with the diving equipment used. Diving techniques enabled the collection of an important data set describing the dynamics of phytoplankton and zooplankton growth beneath sea ice. Recommendations for future under-ice oceanic scientific diving inc1ude the use of dive tables with ascent rates of less than 15 m/min, the provision for therapeutic oxygen at the dive site, and adequate shelter for surface tenders.},
	issue        = 1
}
@article{Carleton1995,
	title        = {Quantitative video sampling of coral reef benthos: large-scale application},
	author       = {J. H. Carleton and T. J. Done},
	year         = 1995,
	month        = 2,
	journal      = {Coral Reefs},
	volume       = 14,
	pages        = {35--46},
	doi          = {10.1007/BF00304070},
	issn         = {0722-4028},
	url          = {http://link.springer.com/10.1007/BF00304070},
	issue        = 1
}
@article{OBrien1995,
	title        = {Dynamic simulation of splashing fluids},
	author       = {James F. O'Brien and Jessica K. Hodgins},
	year         = 1995,
	journal      = {Proceedings Computer Animation, CA 1995},
	pages        = {198--205},
	doi          = {10.1109/CA.1995.393532},
	isbn         = {0818670622},
	url          = {https://arxiv.org/pdf/2302.06087.pdf},
	abstract     = {We describe a method for modeling the dynamic behavior of splashing fluids. The model simulates the behavior of a fluid when objects impact or float on its surface. The forces generated by the objects create waves and splashes on the surface of the fluid. To demonstrate the realism and limitations of the model, images from a computer-generated animation are presented and compared with video frames of actual splashes occurring under similar initial conditions.}
}
@inproceedings{Caselles1995,
	title        = {Geodesic active contours},
	author       = {Vicent Caselles and Ron Kimmel and Guillermo Sapiro},
	year         = 1995,
	booktitle    = {IEEE International Conference on Computer Vision},
	publisher    = {IEEE},
	pages        = {694--699},
	doi          = {10.1109/iccv.1995.466871},
	abstract     = {A novel scheme for the detection of object boundaries is presented. The technique is based on active contours deforming according to intrinsic geometric measures of the image. The evolving contours naturally split and merge, allowing the simultaneous detection of several objects and both interior and exterior boundaries. The proposed approach is based on the relation between active contours and the computation of geodesics or minimal distance curves. The minimal distance curve lays in a Riemannian space whose metric is defined by the image content. This geodesic approach for object segmentation allows to connect classical 'snakes' based on energy minimization and geometric active contours based on the theory of curve evolution. Previous models of geometric active contours are improved as showed by a number of examples. Formal results concerning existence, uniqueness, stability, and correctness of the evolution are presented as well.}
}
@article{Neilson1995,
	title        = {A Model for Predicting Continental-Scale Vegetation Distribution and Water Balance},
	author       = {Ronald P. Neilson},
	year         = 1995,
	month        = 5,
	journal      = {Ecological Applications},
	volume       = 5,
	pages        = {362--385},
	doi          = {10.2307/1942028},
	issn         = {1051-0761},
	url          = {https://esajournals.onlinelibrary.wiley.com/doi/10.2307/1942028},
	abstract     = {<p>A Mapped Atmosphere-Plant-Soil System (MAPSS) has been constructed for simulating the potential biosphere impacts and biosphere-atmosphere feedbacks from climatic change. The system calculates the potential vegetation type and leaf area that could be supported at a site, within the constraints of the abiotic climate. Both woody vegetation and grass are supported and compete for light and water. The woody vegetation can be either trees or shrubs, evergreen or deciduous, and needleleaved or broadleaved. A complete site water balance is calculated and integrates the vegetation leaf area and stomatal conductance in canopy transpiration and soil hydrology. The MAPSS model accurately simulates the distributions of forests, grasslands, and deserts and reproduces observed monthly runoff. The model can be used for predictions of new vegetation distribution patterns, soil moisture, and runoff patterns in alternative climates.</p>},
	issue        = 2,
	keywords     = {biogeography: biotme,climaite,distribution,forest,grasslaind,mnodeling,shru/bland,vegetatioII}
}
@article{Shigesada1995,
	title        = {Modeling Stratified Diffusion in Biological Invasions},
	author       = {Nanako Shigesada and Kohkichi Kawasaki and Yasuhiko Takeda},
	year         = 1995,
	month        = 8,
	journal      = {The American Naturalist},
	volume       = 146,
	pages        = {229--251},
	doi          = {10.1086/285796},
	issn         = {0003-0147},
	url          = {https://www.journals.uchicago.edu/doi/10.1086/285796},
	issue        = 2
}
@inproceedings{Kennedy1995,
	title        = {Particle swarm optimization},
	author       = {J. Kennedy and R. Eberhart},
	year         = 1995,
	month        = 11,
	booktitle    = {Proceedings of ICNN'95 - International Conference on Neural Networks},
	publisher    = {IEEE},
	volume       = 4,
	pages        = {1942--1948},
	doi          = {10.1109/ICNN.1995.488968},
	isbn         = {0-7803-2768-3},
	url          = {http://ieeexplore.ieee.org/document/488968/},
	abstract     = {A concept for the optimization of nonlinear functions using particle swarm methodology is introduced. The evolution of several paradigms is outlined, and an implementation of one of the paradigms is discussed. Benchmark testing of the paradigm is described, and applications, including nonlinear function optimization and neural network training, are proposed. The relationships between particle swarm optimization and both artificial life and genetic algorithms are described, 1 INTRODUCTION This paper introduces a method for optimization of continuous nonlinear functions. The method was discovered through simulation of a simplified social model; thus the social metaphor is discussed, though the algorithm stands without metaphorical support. This paper describes the particle swarm optimization concept in terms of its precursors, briefly reviewing the stages of its development from social simulation to optimizer. Discussed next are a few paradigms that implement the concept. Finally, the implementation of one paradigm is discussed in more detail, followed by results obtained from applications and tests upon which the paradigm has been shown to perform successfully.}
}
@inbook{Gunn1995,
	title        = {Improving snake performance via a dual active contour},
	author       = {Steve R. Gunn and Mark S. Nixon},
	year         = 1995,
	pages        = {600--605},
	doi          = {10.1007/3-540-60268-2_351},
	url          = {http://link.springer.com/10.1007/3-540-60268-2_351},
	abstract     = {A dual active contour can use two snakes to seek an energy minimum which lies between their initial positions. This relieves problems associated with initialisation. The contraction force is removed by the inclusion of local shape information within the snakes and the parameters required to control their evolution can be combined within a single regularisation parameter. An adaptive driving force is used to move the snakes which reduces the sensitivity to parameters. These developments are demonstrated to provide a performance superior to that of a conventional single snake approach.},
	keywords     = {Active Contours,Dual Active Contour,Snakes}
}
@article{VanLawickvanPabst1996,
	title        = {Dynamic Terrain Generation Based on Multifractal Techniques},
	author       = {Joost van Lawick van Pabst and Hans Jense},
	year         = 1996,
	journal      = {High Performance Computing for Computer Graphics and Visualisation},
	pages        = {186--203},
	doi          = {10.1007/978-1-4471-1011-8_13},
	abstract     = {The work, described in this paper, covers three topics: real-world terrain analysis, synthetic terrain generation based upon the results of the analysis stage, and dynamic terrain generation. Each topic involves the theory of multifractals. First, a summary of four known fractal-based techniques for terrain generation is presented including fractional Brownian motion, Mid-point displacement, Iterated Function Systems and the multifractal formalism. The multifractal formalism was chosen for both the analysis of realworld terrain data, as well as the generation of synthetic terrain surfaces. The authors implemented a multifractal terrain analysis algorithm that captures terrain characteristics of real-world data, into five parameters. These parameters were put into a multifractal terrain generation algorithm that produced synthetic terrain with features similar to those in the terrain that was analysed. Also, an algorithm for zooming in on synthetic terrain was developed. Finally, an application was developed that generates terrain dynamically. 1}
}
@article{Alt1996,
	title        = {Discrete Geometric Shapes: Matching, Interpolation, and Approximation},
	author       = {Helmut Alt and Leonidas J. Guibas},
	year         = 1996,
	journal      = {Handbook of computational geometry},
	pages        = {1--34},
	isbn         = {978-0-44-482537-7},
	url          = {http://books.google.com/books?hl=en&lr=&id=uZdAqAWB3BcC&oi=fnd&pg=PA121&dq=Discrete+Geometric+Shapes:+Matching,+Interpolation,+and+Approximation&ots=lEx_DDwLMF&sig=xPC67HoYTYvLgSKz-t-E7XBJUbg},
	abstract     = {In this chapter we survey geometric techniques which have been used to measure the sim- ilarity or distance between shapes, as well as to approximate shapes, or interpolate between shapes. Shape is a modality which plays a key role in many disciplines, ranging from com- puter vision to molecular biology. We focus on algorithmic techniques based on computational geometry that have been developed for shape matching, simplification, and morphing.},
	issue        = {MARCH 1997}
}
@article{Fiorio1996,
	title        = {A topologically consistent representation for image analysis: The frontiers topological graph},
	author       = {Christophe Fiorio},
	year         = 1996,
	journal      = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume       = 1176,
	pages        = {151--162},
	doi          = {10.1007/3-540-62005-2_13},
	isbn         = 9783540620051,
	issn         = 16113349,
	url          = {https://link.springer.com/content/pdf/10.1007/3-540-62005-2_13.pdf},
	abstract     = {In this paper a ``topologically consistent'' representation for images is presented. It is called the Frontiers Topological Graph and is derived from the combinatorial maps model. Thus it establishes a link between image analysis and image synthesis. An efficient algorithm which constructs the Frontiers Topological Graph is developed.},
	keywords     = {Combinatorial map,Graph,Image representation,Topology}
}
@article{Crespin1996,
	title        = {Implicit sweep objects},
	author       = {Beno\^{\i}t Crespin and Carole Blanc and Christophe Schlick},
	year         = 1996,
	journal      = {Computer Graphics Forum},
	volume       = 15,
	pages        = {165--174},
	doi          = {10.1111/1467-8659.1530165},
	issn         = {01677055},
	issue        = 3
}
@article{Berlemont1996,
	title        = {Une approche lagrangienne pour la simulation d'interactions particule/particule en \'{e}coulement},
	author       = {Alain Berlemont and Zhezou Chang and G\'{e}rard Gouesbet},
	year         = 1996,
	journal      = {La Houille Blanche},
	volume       = 82,
	pages        = {57--63},
	doi          = {10.1051/lhb/1996007},
	issn         = {0018-6368},
	url          = {https://www.shf-lhb.org/articles/lhb/pdf/1996/01/lhb1996007.pdf},
	issue        = {1-2}
}
@article{Pettit1996,
	title        = {Functional Explanation and Virtual Selection},
	author       = {Philip Pettit},
	year         = 1996,
	journal      = {British Journal for the Philosophy of Science},
	volume       = 47,
	pages        = {291--302},
	doi          = {10.1093/bjps/47.2.291},
	issn         = {00070882},
	abstract     = {Invoking its social function can explain why we find a certain functional trait or institution only if we can identify a mechanism whereby the playing of the function connects with the explanandum. That is the main claim in the missing-mechanism critique of functionalism. Is it correct? Yes, if functional explanation is meant to make sense of the actual presence of the trait or institution. No, if it is meant to make sense of why the trait or institution is resilient: why we can rely on it to survive various contingencies. The lesson? Social functionalism should be taken, and may have been taken by its founders, as a programme for explaining resilience. 1 Introduction 2 Functionalism and the missing-mechanism argument 3 Functional explanations that avoid the argument 4 A significant research programme.},
	issue        = 2
}
@phdthesis{Ye1996,
	title        = {A rule-based approach to animating multi-agent environments},
	author       = {Victor Ye},
	year         = 1996,
	doi          = {http://dx.doi.org/10.24382/4939},
	url          = {https://pearl.plymouth.ac.uk/bitstream/handle/10026.1/2812/VICTOR YE.PDF?sequence=1},
	abstract     = {This dissertation describes ESCAPE (Expert Systems in Computer Animation Production Environments), a multi-agent animation system for building domain-oriented, rulebased visual programming environments. Much recent work in computer graphics has been concerned with producing behavioural animations of artificial life-forms mainly based on algorithmic approaches. This research indicates how, by adding an inference engine and rules that describe such behaviour, traditional computer animation environments can be enhanced. The comparison between using algorithmic approaches and using a rule-based approach for representing multi-agent worlds is not based upon their respective claims to completeness, but rather on the ease with which end users may express their knowledge and control their animations with a minimum of technical knowledge. An environment for the design of computer animations incorporating an expert system approach is described. In addition to direct manipulation of objects on the screen, the environment allows users to describe behavioural rules based upon both the physical and non-physical attributes of objects. These rules can be interpreted to suggest the transition from stage to stage or to automatically produce a longer animation. The output from the system can be integrated into a commercially available 3D modelling and rendering package. Experience indicates that a hybrid environment, mixing algorithmic and rulebased approaches, would be very promising and offer benefits in application areas such as creating realistic background scenes and modelling human beings or animals either singly or in groups. A prototype evaluation system and three different domains are described and illustrated with preliminary animated images.},
	institution  = {University of Plymouth}
}
@inproceedings{Marhefka1996,
	title        = {Simulation of contact using a nonlinear damping model},
	author       = {D.W. Marhefka and D.E. Orin},
	year         = 1996,
	booktitle    = {Proceedings of IEEE International Conference on Robotics and Automation},
	publisher    = {IEEE},
	volume       = 2,
	pages        = {1662--1668},
	doi          = {10.1109/ROBOT.1996.506951},
	isbn         = {0-7803-2988-0},
	url          = {http://ieeexplore.ieee.org/document/506951/},
	abstract     = {I n this paper, a sample nonlinear contact model is presented f o r use in computer simulation. The nonlinear model is shown to maintain the computational simplicity of the linear model while addressing many of its deficiencies. One such advantage is that contact forces vary continuously over time. A new phase plane solution f o r the nonlinear model is obtained which reveals m a n y previously unnoted properties. These include proper variation of the coejjicient of restitution with impact velocity over a wide range of impact velocities , independence of model parameters, and lack of tensile (sticking) forces in simple impacts. A n example is presented which demonstrates the use of the contact model i n simulating the foot-ground interaction during the locomotion cycle of a walking machine.}
}
@inproceedings{Worley1996,
	title        = {A cellular texture basis function},
	author       = {Steven Worley},
	year         = 1996,
	month        = 8,
	booktitle    = {Proceedings of the 23rd annual conference on Computer graphics and interactive techniques},
	publisher    = {ACM},
	pages        = {291--294},
	doi          = {10.1145/237170.237267},
	isbn         = {0897917464},
	url          = {https://dl.acm.org/doi/10.1145/237170.237267},
	abstract     = {Solid texturing is a powerful way to add detail to the surface of rendered objects. Perlin's "noise" is a 3D basis function used in some of the most dramatic and useful surface texture algorithms. We present a new basis function which complements Perlin noise, based on a partitioning of space into a random array of cells. We have used this new basis function to produce textured surfaces resembling flagstone-like tiled areas, organic crusty skin, crumpled paper, ice, rock, mountain ranges, and craters. The new basis function can be computed efficiently without the need for precalculation or table storage.},
	city         = {New York, NY, USA}
}
@article{Shneiderman1997,
	title        = {Direct manipulation for comprehensible, predictable and controllable user interfaces},
	author       = {Ben Shneiderman},
	year         = 1997,
	journal      = {International Conference on Intelligent User Interfaces, Proceedings IUI},
	pages        = {33--39},
	doi          = {10.1145/238218.238281},
	abstract     = {Direct manipulation user interfaces have proven their worth over two decades, but they are still in their youth. Dramatic opportunities exist to develop direct manipulation programming to create end-user programming tools, dynamic queries to perform information search in large databases, and information visualization to support network database browsing. Direct manipulation depends on visual representation of the objects and actions of interest, physical actions or pointing instead of complex syntax, and rapid incremental reversible operations whose effect on the object of interest is immediately visible. This strategy can lead to user interfaces that are comprehensible, predictable and controllable. Direct manipulation interfaces are seen as more likely candidates to influence advanced user interfaces than adaptive, autonomous, intelligent agents. User control and responsibility are highly desirable.}
}
@article{Polana1997,
	title        = {Detection and Recognition of Periodic, Nonrigid Motion},
	author       = {Ramprasad Polana and Randal C Nelson},
	year         = 1997,
	journal      = {International Journal of Computer Vision},
	publisher    = {Kluwer Academic Publishers},
	volume       = 23,
	pages        = {261--282},
	doi          = {https://doi.org/10.1023/A:1007975200487},
	abstract     = {The recognition of nonrigid motion, particularly that arising from human movement (and by extension from the locomotory activity of animals) has typically made use of high-level parametric models representing the various body parts (legs, arms, trunk, head etc.) and their connections to each other. Such model-based recognition has been successful in some cases; however, the methods are often difficult to apply to real-world scenes, and are severely limited in their generalizability. The first problem arises from the difficulty of acquiring and tracking the requisite model parts, usually specific joints such as knees, elbows or ankles. This generally requires some prior high-level understanding and segmentation of the scene, or initialization by a human operator. The second problem, with generalization, is due to the fact that the human model is not much good for dogs or birds, and for each new type of motion, a new model must be hand-crafted. In this paper, we show that the recognition of human or animal locomotion, and, in fact, any repetitive activity can be done using low-level, non-parametric representations. Such an approach has the advantage that the same underlying representation is used for all examples, and no individual tailoring of models or prior scene understanding is required. We show in particular, that repetitive motion is such a strong cue, that the moving actor can be segmented, normalized spatially and temporally, and recognized by matching against a spatio-temporal template of motion features. We have implemented a real-time system that can recognize and classify repetitive motion activities in normal gray-scale image sequences. Results on a number of real-world sequences are described.},
	issue        = 3
}
@article{Smith1997,
	title        = {Global sea floor topography from satellite altimetry and ship depth soundings},
	author       = {Walter H.F. Smith and David T. Sandwell},
	year         = 1997,
	journal      = {Science},
	volume       = 277,
	pages        = {1956--1962},
	doi          = {10.1126/science.277.5334.1956},
	issn         = {00368075},
	abstract     = {A digital bathymetric map of the oceans with a horizontal resolution of 1 to 12 kilometers was derived by combining available depth soundings with high-resolution marine gravity information from the Geosat and ERS-1 spacecraft. Previous global bathymetric maps lacked features such as the 1600-kilometer-long Foundation Seamounts chain in the South Pacific. This map shows relations among the distributions of depth, sea floor area, and sea floor age that do not fit the predictions of deterministic models of subsidence due to lithosphere cooling but may be explained by a stochastic model in which randomly distributed reheating events warm the lithosphere and raise the ocean floor.},
	issue        = 5334
}
@misc{MARAK,
	title        = {Terrain erosion model based on rewriting of matrices},
	author       = {Ivo Marak and Bedrich Benes and Pavel Slavik},
	year         = 1997,
	journal      = {Journal of WSCG},
	volume       = 5,
	pages        = {341--350},
	isbn         = {80-7082-306-2},
	url          = {http://cat.inist.fr/?aModele=afficheN&cpsidt=2723081},
	abstract     = {This paper introduces a new approach to erosions of models of terrains. This approach is based on two dimensional generalization of the rewriting process - array grammars. A height field representing the terrain is considered as the matrix and context sensitive rewriting of this matrix, represents the erosion process. This approach is quite general and allows us to use an arbitrary kind of erosion which can be expressed by means of rewriting productions.},
	issue        = {1-3}
}
@article{Mallet1997,
	title        = {Discrete modeling for natural objects},
	author       = {Jean-Laurent Mallet},
	year         = 1997,
	journal      = {Mathematical Geology},
	volume       = 29,
	pages        = {199--219},
	doi          = {10.1007/BF02769628},
	issn         = {08828121},
	abstract     = {This paper presents a discrete technique specially designed for modeling the geometry and the properties of natural objects as those encountered in biology and geology. Contrary to classical Computer-Aided Design methods based on continuous (polynomial) functions, the proposed approach is based on a discretization of the objects close to the finite-element techniques used for solving differential equations. Each object is modeled as a set of interconnected nodes holding the geometry and the physical properties of the objects and the Discrete Smooth Interpolation method is used for fitting the geometry and the properties to complex data. Data are turned into linear constraints and some constraints related to typical information encountered in geology are presented.},
	issue        = 2,
	keywords     = {DSI,Geometrical modeling,Interpolation}
}
@article{Bloomenthal1997,
	title        = {The Geometry of Implicit Surfaces},
	author       = {Jules Bloomenthal},
	year         = 1997,
	journal      = {Introduction to implicit surfaces},
	pages        = {3--51},
	isbn         = {155860233X},
	url          = {http://www.cs.princeton.edu/courses/archive/fall03/cs526/papers/bloomenthal02.pdf},
	abstract     = {Implicit surfaces are two-dimensional, geometric shapes that exist in three dimensional space. They are defined according to a particular mathematical form. This article examines their definition, representation, and geometric properties. Related fields are discussed and practical methods are reviewed.}
}
@article{Hallock1997,
	title        = {Reefs and Reef Limestones in Earth History},
	author       = {Pamela Hallock},
	year         = 1997,
	journal      = {Life and Death of Coral Reefs},
	pages        = {13--42},
	doi          = {10.1007/978-1-4615-5995-5_2},
	url          = {https://www.marine.usf.edu/reefslab/documents/evol_ecol2007/Hallock_Reefhistory.pdf},
	abstract     = {To seafarers, a reef is a submerged hazard to navigation, usually a ridge of rocks or sand at or near the surface of the water. This is why the Exxon Valdez could hit a "reef" in Prince William Sound, Alaska, thousands of miles from the nearest coral reef. Historically, tropical waters were particularly treacherous for mariners because reefs constructed by coral communities may lurk just below the surface in otherwise open seas. In both calm seas and storms, often the first indication that a reef was nearby was when a ship ran aground. The earliest European "settlers" in the Florida Keys made their living salvaging shipwrecks. Today the most visible indication of many Pacific atolls is a rusting freighter.}
}
@article{Cheng1997,
	title        = {Simplified Settling Velocity Formula for Sediment Particle},
	author       = {Nian-Sheng Cheng},
	year         = 1997,
	journal      = {Journal of Hydraulic Engineering},
	volume       = 123,
	pages        = {149--152},
	doi          = {10.1061/(asce)0733-9429(1997)123:2(149)},
	issn         = {0733-9429},
	url          = {https://dr.ntu.edu.sg/bitstream/10356/83675/2/121. Simplified settling velocity formula for sediment particle..pdf},
	abstract     = {A new and simplified formula for predicting the settling velocity of natural sediment particles is developed. The formula proposes an explicit relationship between the particle Reynolds number and a dimensionless particle parameter. It is applicable to a wide range of Reynolds numbers from the Stokes flow to the turbulent regime. The proposed formula has the highest degree of prediction accuracy when compared with other published formulas. It also agrees well with the widely used diagrams and tables proposed by the U.S. Inter-Agency Committee in 1957.},
	issue        = 2
}
@article{Garland1997,
	title        = {Surface simplification using quadric error metrics},
	author       = {Michael Garland and Paul S. Heckbert},
	year         = 1997,
	journal      = {Proceedings of the 24th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH 1997},
	pages        = {209--216},
	doi          = {10.1145/258734.258849},
	isbn         = {0897918967},
	abstract     = {Many applications in computer graphics require complex, highly detailed models. However, the level of detail actually necessary may vary considerably. To control processing time, it is often desirable to use approximations in place of excessively detailed models. We have developed a surface simplification algorithm which can rapidly produce high quality approximations of polygonal models. The algorithm uses iterative contractions of vertex pairs to simplify models and maintains surface error approximations using quadric matrices. By contracting arbitrary vertex pairs (not just edges), our algorithm is able to join unconnected regions of models. This can facilitate much better approximations, both visually and with respect to geometric error. In order to allow topological joining, our system also supports non-manifold surface models.},
	keywords     = {level of detail,mutiresolution modeling,non-manifold,pair contraction,surface simplification}
}
@article{Noca1997,
	title        = {Measuring instantaneous fluid dynamic forces on bodies, using only velocity fields and their derivatives},
	author       = {F. Noca and D. Shiels and D. Jeon},
	year         = 1997,
	month        = 4,
	journal      = {Journal of Fluids and Structures},
	volume       = 11,
	pages        = {345--350},
	doi          = {10.1006/jfls.1997.0081},
	issn         = {08899746},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0889974697900815},
	abstract     = {We present an exact expression for the evaluation of instantaneous forces on a body in an incompressible cross-flow which only requires the knowledge of the velocity and vorticity field in a finite and arbitrarily chosen region enclosing the body. This expression is particularly useful for experimental techniques like Digital Particle Image Velocimetry (DPIV) which provide instantaneous , 2-D velocity and vorticity fields but not pressure fields. The present formula is tested on a numerical flow simulation using a high-resolution vortex method and experimentally with DPIV on a circular cylinder flow .},
	issue        = 3
}
@article{Grim1997,
	title        = {The undecidability of the spatialized prisoner's dilemma},
	author       = {Patrick Grim},
	year         = 1997,
	journal      = {Theory and Decision},
	volume       = 42,
	pages        = {53--80},
	abstract     = {In the spatialized Prisoner's Dilemma, players compete against their immediate neighbors and adopt a neighbor's strategy should it prove locally superior. Fields of strategies evolve in the manner of cellular automata (Nowak and May, 1993; Mar and St. Denis, 1993a,b; Grim 1995, 1996). Often a question arises as to what the eventual outcome of an initial spatial configuration of strategies will be: Will a single strategy prove triumphant in the sense of progressively conquering more and more territory without opposition, or will an equilibrium of some small number of strategies emerge? Here it is shown, for finite configurations of Prisoner's Dilemma strategies embedded in a given infinite background, that such questions are formally undecidable: there is no algorithm or effective procedure which, given a specification of a finite configuration, will in all cases tell us whether that configuration will or will not result in progressive conquest by a single strategy when embedded in the given field. The proof introduces undecidability into decision theory in three steps: by (1) outlining a class of abstract machines with familiar undecidability results, by (2) modelling these machines within a particular family of cellular automata, carrying over undecidability results for these, and finally by (3) showing that spatial configurations of Prisoner's Dilemma strategies will take the form of such cellular automata.},
	keywords     = {Prisoner's Dilemma,Undecidability,cellular automata,computability,decision theory,game the-ory}
}
@article{Nelson1997,
	title        = {Modeling forest canopy heights: The effects of canopy shape},
	author       = {Ross Nelson},
	year         = 1997,
	month        = 6,
	journal      = {Remote Sensing of Environment},
	publisher    = {\textcopyright{}Elsevier Science Inc},
	volume       = 60,
	pages        = {327--334},
	doi          = {10.1016/S0034-4257(96)00214-3},
	issn         = {00344257},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0034425796002143},
	issue        = 3
}
@article{Braun1997,
	title        = {Modelling landscape evolution on geological time scales: A new method based on irregular spatial discretization},
	author       = {Jean Braun and Malcolm Sambridge},
	year         = 1997,
	journal      = {Basin Research},
	publisher    = {Blackwell Publishing Ltd.},
	volume       = 9,
	pages        = {27--52},
	doi          = {10.1046/j.1365-2117.1997.00030.x},
	issn         = {0950091X},
	abstract     = {We present simulations of large-scale landscape evolution on tectonic time scales obtained from a new numerical model which allows for arbitrary spatial discretization. The new method makes use of efficient algorithms from the field of computational geometry to compute the set of natural neighbours of any irregular distribution of points in a plane. The natural neighbours are used to solve geomorphic equations that include erosion/deposition by channelled flow and diffusion. The algorithm has great geometrical flexibility, which makes it possible to solve problems involving complex boundaries, radially symmetrical uplift functions and horizontal tectonic transport across strike-slip faults. The algorithm is also ideally suited for problems which require large variations in spatial discretization and/or self-adaptive meshing. We present a number of examples to illustrate the power of the new approach and its advantages over more 'classical' models based on regular (rectangular) discretization. We also demonstrate that the synthetic river networks and landscapes generated by the model obey the laws of network composition and have scaling properties similar to those of natural landscapes. Finally we explain how orographically controlled precipitation and flexural isostasy may be easily incorporated in the model without sacrificing efficiency.},
	issue        = 1
}
@article{Chiba1998a,
	title        = {An Erosion Model Based on Velocity Fields for the Visual Simulation of Mountain Scenery},
	author       = {N. Chiba and K. Muraoka and K. Fujita},
	year         = 1998,
	journal      = {Journal of Visualization and Computer Animation},
	volume       = 9,
	pages        = {185--194},
	doi          = {10.1002/(SICI)1099-1778(1998100)9:4<185::AID-VIS178>3.0.CO;2-2},
	issn         = 10498907,
	abstract     = {Visual simulation of natural scenery using computer graphics is an interesting research field with wide applications such as flight simulation and special effects in movies. There have been many studies of fractal techniques that use 1/f noise generated by FFT or the midpoint displacement method as modelling methods for imaginary mountain scenery. These methods are suitable for creating impressive mountain scenes, but they cannot create clear ridge and valley lines, which are notable features of mountains produced by erosion processes. Although a few reports have presented modelling methods that take erosion processes into account, the results have not been satisfactory. In this paper we present a simple 'quasi-physically based' method for simulating the topography of eroded mountains based on velocity fields of water flow. \textcopyright{} 1998 John Wiley \& Sons, Ltd.},
	issue        = 4,
	keywords     = {Computer graphics,Erosion processes,Natural phenomena,Terrain,Visual simulation}
}
@article{Euler1998,
	title        = {A new tool to seal a 3D earth model: A cut with constraints},
	author       = {Nicolas Euler and Charles H. Sword and Jean Claude Dulac},
	year         = 1998,
	journal      = {1998 SEG Annual Meeting},
	doi          = {10.1190/1.1820562},
	abstract     = {Current developments in 3-D Earth Modeling are having a significant impact on the practice of reservoir model construction, seismic inversion, and velocity analysis. From seimic surveys, acquired and interpreted by geophysicists, geological objects are generated. These objects (horizons and faults) are edited and modified as necessary. Once the set of horizons and faults--the structural framework--has been validated, it is used to build a reservoir or velocity model. One difficulty of model building lies in finding the intersections between geological objects. Those intersections have to be clearly defined and controlled by structural information. We present in this article a new work-flow for building a sealed topologically consistent structural framework.}
}
@inproceedings{Akleman,
	title        = {Implicit painting of CSG solids},
	author       = {E Akleman},
	year         = 1998,
	booktitle    = {Proc. of CSG},
	pages        = {1--15},
	url          = {http://people.tamu.edu/~ergun/research/artisticdepiction/papers/csg98.pdf}
}
@article{Akleman1998,
	title        = {Implicit Surface Painting},
	author       = {Ergun Akleman},
	year         = 1998,
	journal      = {Proceedings of the Third International Eurographics/ACM SIGGRAPH Workshop on Implicit Surfaces 1998 (IS'98, June 15--16, 1998,Seattle, USA)},
	pages        = {63--68},
	url          = {http://www-viz.tamu.edu/faculty/ergun/research/artisticdepiction/implicitpaint/},
	abstract     = {Implicit painting is a non-photorealistic rendering method for painting\nimplicit surfaces. The method is based on the fact that when a difference\nequation is applied to a set of particles, these particles will move\nin 3D space. The motion of the particles is viewed as the motion\nof the hands of several painters and the trajectories of the particles\nas long unbroken brush strokes, over the implicit surfaces. These\nsurfaces are used as if they are the canvases of painters. We consider\nimplicit surface painting as a creative or `artistic' process in\nwhich the resulting artwork can be an image, a stereo image or even\nan animation that shows the painting process.}
}
@article{Baraff1998,
	title        = {Large steps in cloth simulation},
	author       = {David Baraff and Andrew Witkin},
	year         = 1998,
	journal      = {Proceedings of the 25th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH 1998},
	pages        = {43--54},
	doi          = {10.1145/280814.280821},
	url          = {https://www.cs.cmu.edu/~baraff/papers/sig98.pdf},
	abstract     = {The bottle-neck in most cloth simulation systems is that time steps must be small to avoid numerical instability. This paper describes a cloth simulation system that can stably take large time steps. The simulation system couples a new technique for enforcing constraints on individual cloth particles with an implicit integration method. The simulator models cloth as a triangular mesh, with internal cloth forces derived using a simple continuum formulation that supports modeling operations such as local anisotropic stretch or compression; a unified treatment of damping forces is included as well. The implicit integration method generates a large, unbanded sparse linear system at each time step which is solved using a modified conjugate gradient method that simultaneously enforces particles' constraints. The constraints are always maintained exactly, independent of the number of conjugate gradient iterations, which is typically small. The resulting simulation system is significantly faster than previous accounts of cloth simulation systems in the literature.},
	keywords     = {Cloth,Constraints,Implicit integration,Physically-based modeling,Simulation}
}
@article{Dorin1998,
	title        = {Physically based, self-organizing cellular automata},
	author       = {Alan Dorin},
	year         = 1998,
	journal      = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume       = 1544,
	pages        = {74--87},
	doi          = {10.1007/10693067_6},
	isbn         = 3540654771,
	issn         = 16113349,
	url          = {https://users.monash.edu/~aland/PAPERS/DAI98forWWW.pdf},
	abstract     = {A physically based system of interacting polyhedral objects is used to model self-assembly and spontaneous organization of complex structures. The surfaces of the polyhedra in the simulation are covered with bonding sites in states akin to those of cellular automata. The bonding sites interact with sites on neighbouring polyhedra to apply forces of attraction and repulsion between bodies and to trigger transitions in their states. Using only these mechanisms, the elements exhibit chaining, membrane and cluster formation, and differentiation/segregation. Examples of each of these phenomena are given along with explanations as to how they are formed. Assembly without the guidance of an external agent or central control is in-frequently used in the construction of complex artificial structures, but is the norm for biological construction. This paper presents a model by which the construction of complex structures may be simulated using multiple reactive, artificial agents, acting independently under artificial physical and chemical laws.},
	keywords     = {Artificial life,Assembly,Cellular automata,Molecular dynamics,Organization,Physical modelling,Self}
}
@article{Galzin1998,
	title        = {Objectives and background to the 1994 Franco-Australian expedition to Taiaro Atoll (Tuamotu Archipelago, French Polynesia)},
	author       = {R. Galzin and S. Planes and M. Adjeroud and C. Chauvet and P. J. Doherty and J. Poupin},
	year         = 1998,
	month        = 4,
	journal      = {Coral Reefs},
	volume       = 17,
	pages        = {15--21},
	doi          = {10.1007/s003380050087},
	issn         = {07224028},
	abstract     = {The 9 km2 uplifted lagoon of Taiaro Atoll (15\textdegree{}45'S, 144\textdegree{}38'W) is hypersaline due to its isolation from the ocean, yet it contains a high diversity of fish. The question unifying our expedition was to discover whether these assemblages could be self-sustaining despite very limited contact with the ocean. Although we were constrained by time, collections of fish larvae showed that some species can complete their life-cycle within the lagoon, while others differed genetically between the lagoon and the ocean, consistent with restricted gene flow. The lagoon contained few oceanic species of zooplankton, confirming its general isolation, but nevertheless some fish species may depend upon infrequent colonisation from the ocean (when large waves drive water over the normally dry reef crest). Isotopic signatures in fish otoliths suggest the basis for a more definitive and inclusive test of the sources of the lagoonal assemblage.},
	issue        = 1,
	keywords     = {Coral reef fishes,Hydrodynamics,Larval dispersal,Life cycle,Surveys}
}
@inproceedings{Deussen1998,
	title        = {Realistic modeling and rendering of plant ecosystems},
	author       = {Oliver Deussen and Pat Hanrahan and Bernd Lintermann and Radom\'{\i}r M\v{e}ch and Matt Pharr and Przemyslaw Prusinkiewicz},
	year         = 1998,
	booktitle    = {Proceedings of the 25th annual conference on Computer graphics and interactive techniques  - SIGGRAPH '98},
	publisher    = {ACM Press},
	pages        = {275--286},
	doi          = {10.1145/280814.280898},
	isbn         = {0897919998},
	url          = {http://portal.acm.org/citation.cfm?doid=280814.280898},
	abstract     = {Modeling and rendering of natural scenes with thousands of plants poses a number of problems. The terrain must be modeled and plants must be distributed throughout it in a realistic manner, reflecting the interactions of plants with each other and with their environment. Geometric models of individual plants, consistent with their positions within the ecosystem, must be synthesized to populate the scene. The scene, which may consist of billions of primitives, must be rendered efficiently while incorporating the subtleties of lighting in a natural environment. We have developed a system built around a pipeline of tools that address these tasks. The terrain is designed using an interactive graphical editor. Plant distribution is determined by hand (as one would do when designing a garden), by ecosystem simulation, or by a combination of both techniques. Given parametrized procedural models of individual plants, the geometric complexity of the scene is reduced by approximate instancing, in which similar plants, groups of plants, or plant organs are replaced by instances of representative objects before the scene is rendered. The paper includes examples of visually rich scenes synthesized using the system.},
	city         = {New York, New York, USA},
	keywords     = {CR categories: I37 [Computer Graphics]: Three-Dimensional Graphics and Realism,I63 [Simulation and Modeling]: Appli-cations,J3 [Life and Medical Sciences]: Biology Keywords: realistic image synthesis,approximate instancing,ecosystem simulation,modeling of natural phenom-ena,plant model,self-thinning,vector quan-tization}
}
@article{Chen1998,
	title        = {Lattice Boltzmann method for fluid flows},
	author       = {Shiyi Chen and Gary D. Doolen},
	year         = 1998,
	month        = 1,
	journal      = {Annual Review of Fluid Mechanics},
	volume       = 30,
	pages        = {329--364},
	doi          = {10.1146/annurev.fluid.30.1.329},
	issn         = {0066-4189},
	url          = {https://www.annualreviews.org/doi/10.1146/annurev.fluid.30.1.329},
	abstract     = {<p>\blacksquare{} Abstract\hspace{0.6em} We present an overview of the lattice Boltzmann method (LBM), a parallel and efficient algorithm for simulating single-phase and multiphase fluid flows and for incorporating additional physical complexities. The LBM is especially useful for modeling complicated boundary conditions and multiphase interfaces. Recent extensions of this method are described, including simulations of fluid turbulence, suspension flows, and reaction diffusion systems.</p>},
	issue        = 1,
	keywords     = {fluid flow simulation,lattice Boltzmann method,mesoscopic approach}
}
@book{Czaran1998,
	title        = {Spatiotemporal models of population and community dynamics},
	author       = {Tamas Czaran},
	year         = 1998,
	month        = 1,
	publisher    = {Chapman \& Hall},
	pages        = 284,
	isbn         = {0412575507},
	abstract     = {This book presents a comprehensive typology and a comprehensible description of spatiotemporal models used in population dynamics. The main types included are: reaction-diffusion systems, patch models, matapopulation approaches, host parasitoid models, cellular automata (interacting particle systems), tessellations and distance models. The models are introduced through examples and with informative verbal explanations to help understanding. Some of the cellular automation examples are models not yet published elsewhere. Possible extensions of certain model types are suggested.},
	city         = {London}
}
@article{Nelson1999,
	title        = {XGobi vs the C2: Results of an experiment comparing data visualization in a 3-D immersive virtual reality environment with a 2-D workstation display},
	author       = {Laura Nelson and Dianne Cook and Carolina Cruz-Neira},
	year         = 1999,
	month        = 9,
	journal      = {Computational Statistics},
	publisher    = {Springer-Verlag GmbH Co. KG},
	volume       = 14,
	pages        = {39--51},
	doi          = {10.1007/pl00022704},
	issn         = {09434062},
	url          = {https://link.springer.com/article/10.1007/PL00022704},
	abstract     = {Virtual environments are an emerging technology, which make use of 3-D display devices. Currently very little research into using this new technology for statistical graphics has been done. In association with the Iowa Center for Emerging Manufacturing Technology we have been building a statistical graphics application in the highly immersive C2 environment,called VR-Gobi. This paper describes an experiment conducted to determine if the new technology provides an improved exploratory data analysis environment over traditional workstation graphics environments, such as XGobi. A good analogy comparing the difference between the two environments is that one is like a desk and the other like a room. The visualization tasks we compare between the two environments are detecting clusters, dimensionality and radial sparseness in high-dimensional data, and we also compare the ease of interaction between the computer and human user in the two environments.},
	issue        = 1,
	keywords     = {Economic Theory/Quantitative Economics/Mathematica,Probability Theory and Stochastic Processes,Probability and Statistics in Computer Science,Statistics,general}
}
@article{Motoshilanaka,
	title        = {A Study on Walk-Recognition by Frequency Analysis of Footsteps},
	author       = {Motoshi TANAKA and Hiroshi INOUE},
	year         = 1999,
	journal      = {IEEJ Transactions on Electronics, Information and Systems},
	volume       = 119,
	pages        = {762--763},
	doi          = {10.1541/ieejeiss1987.119.6_762},
	issn         = {0385-4221},
	url          = {https://www.jstage.jst.go.jp/article/ieejeiss1987/119/6/119_6_762/_article},
	abstract     = {The human footsteps recognition (walk-recognition) is discussed. The pitch frequency related with walking pace, and the first peak frequency of a footstep, are characterized by frequency analysis, and used as a feature vector for the recognition. A simple recognition method comparing with the Euclidean distance are used. The recognition rate is approximately 83 \%, and then the feasibility of walk-recognition is confirmed.},
	issue        = 6,
	keywords     = {feature extraction,footsteps,frequency analysis,walk-recognition}
}
@article{Schettino1999,
	title        = {Polygon intersections in spherical topology: Application to plate tectonics},
	author       = {Antonio Schettino},
	year         = 1999,
	journal      = {Computers and Geosciences},
	volume       = 25,
	pages        = {61--69},
	doi          = {10.1016/S0098-3004(98)00081-8},
	issn         = {00983004},
	abstract     = {This paper describes a set of algorithms for performing overlay operations on polygonal regions in spherical topology. A solution to the intersection problem for a polygonal region on the unit sphere with respect to a base set of polygons is proposed. The method is based upon a variant of the point-in-polygon procedure and has been successfully used to reconstruct ancient ocean-floor age maps and plate boundaries.},
	issue        = 1,
	keywords     = {Computational geometry,Ocean-floor age grid,Plate tectonics,Point-in-polygon,Polygons}
}
@article{Stam1999,
	title        = {Stable fluids},
	author       = {Jos Stam},
	year         = 1999,
	journal      = {Proceedings of the 26th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH 1999},
	pages        = {121--128},
	doi          = {10.1145/311535.311548},
	isbn         = {0201485605},
	abstract     = {Building animation tools for fluid-like motions is an important and challenging problem with many applications in computer graphics. The use of physics-based models for fluid flow can greatly assist in creating such tools. Physical models, unlike key frame or procedural based techniques, permit an animator to almost effortlessly create interesting, swirling fluid-like behaviors. Also, the interaction of flows with objects and virtual forces is handled elegantly. Until recently, it was believed that physical fluid models were too expensive to allow real-time interaction. This was largely due to the fact that previous models used unstable schemes to solve the physical equations governing a fluid. In this paper, for the first time, we propose an unconditionally stable model which still produces complex fluid-like flows. As well, our method is very easy to implement. The stability of our model allows us to take larger time steps and therefore achieve faster simulations. We have used our model in conjuction with advecting solid textures to create many fluid-like animations interactively in two- and three-dimensions. Copyright ACM 1999.},
	keywords     = {Advected textures,Animation of fluids,Gaseous phenomena,Implicit elliptic PDE solvers,Interactive modeling,Navier-Stokes,Stable solvers}
}
@phdthesis{Curry1999,
	title        = {On the Evolution of Parametric L-systems},
	author       = {Roger Curry},
	year         = 1999,
	pages        = 27,
	url          = {http://algorithmicbotany.org/papers/on-the-evolution-of-parametric-l-systems.pdf},
	abstract     = {L-systems have been shown to be a useful tool for modeling plants; however, the generation of realistic plant models requires an extensive knowledge of L-systems. People who are not L-system experts require a simpler way of creating plant models. This paper will describe my attempts at designing a user interface which allows the user to guide the evolution of plant models generated from a parametric L-system and the genetic algorithm employed to facilitate this evolution. The nal goal of this research would be a design environment in which plant models could be easily and quickly generated without explicit knowledge of L-systems. The plant models would still be L-systems but the user would not ever need to see them. By exploring the concept of evolution as a method for developing plant models we m a y also gain insight i n to the development of plants themselves.}
}
@article{Ahronovitz1999,
	title        = {Topological operators on the topological graph of frontiers},
	author       = {Ehoud Ahronovitz and Christophe Fiorio and Sylvain Glaize},
	year         = 1999,
	journal      = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume       = 1568,
	pages        = {207--217},
	doi          = {10.1007/3-540-49126-0_16},
	isbn         = 3540656855,
	issn         = 16113349,
	url          = {https://link.springer.com/content/pdf/10.1007/3-540-49126-0_16.pdf},
	abstract     = {The Topological Graph of Frontiers is in our opinion a good graph structure representing the topology of segmented images. In this paper we deal with topological operators which achieve directly on the graph current operations performed on segmented images. Well known graph structures such as the Region Adjacency Graph [Pav77] [Ros74] do not (and cannot) keep track of the topology and so cannot maintain it. We claim that the structures and operators described here, on the contrary, allow and do this maintenance. One of the most important informations in such images is the inclusion of nested regions and one of the most important operators is the union of regions. We deal essentially with these in this paper. They are described in detail herein and we show how the topological coherence is maintained. This is why we entitle them topological operators. Other operators that we have already developed are briefly described.},
	keywords     = {Enclosed region,Segmented image manipulation,Topological graph of frontiers,Topological operator,Topological representation}
}
@article{Bertrand1999,
	title        = {Border map: A topological representation for nD image analysis},
	author       = {Yves Bertrand and Christophe Fiorio and Yann Pennaneach},
	year         = 1999,
	journal      = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume       = 1568,
	pages        = {242--257},
	doi          = {10.1007/3-540-49126-0_19},
	isbn         = 3540656855,
	issn         = 16113349,
	url          = {https://link.springer.com/content/pdf/10.1007/3-540-49126-0_19.pdf},
	abstract     = {This article presents an algorithm computing a border map of an image that generalizes to the n dimension graph structures used in image analysis. Such a map represents simple and multiple adjacencies, inclusion of regions, as well as the frontier type between two adjacent regions. An algorithm computing a border map, linear to the number of elements of an image, is defined in 2D, then generalized in 3D and in nD.},
	keywords     = {Adjacency graph,Combinatorial maps,Generalized maps,Image modeling,Topology}
}
@article{Ge1999,
	title        = {Geometric constraint satisfaction using optimization methods},
	author       = {Jian Xin Ge and Shang Ching Chou and Xiao Shan Gao},
	year         = 1999,
	journal      = {CAD Computer Aided Design},
	volume       = 31,
	pages        = {867--879},
	doi          = {10.1016/S0010-4485(99)00074-3},
	issn         = {00104485},
	abstract     = {The numerical approach to solving geometric constraint problems is indispensable for building a practical CAD system. The most commonly-used numerical method is the Newton-Raphson method. It is fast, but has the instability problem: the method requires good initial values. To overcome this problem, recently the homotopy method has been proposed and experimented with. According to the report, the homotopy method generally works much better in terms of stability. In this paper we use the numerical optimization method to deal with the geometric constraint solving problem. The experimental results based on our implementation of the method show that this method is also much less sensitive to the initial value. Further, a distinctive advantage of the method is that under- and over-constrained problems can be handled naturally and efficiently. We also give many instructive examples to illustrate the above advantages.},
	issue        = 14,
	keywords     = {optimization method,parametric design,variational geometry}
}
@article{Wyvill1999,
	title        = {Extending the CSG Tree. Warping, Blending and Boolean Operations in an Implicit Surface Modeling System},
	author       = {Brian Wyvill and Andrew Guy and Eric Galin},
	year         = 1999,
	month        = 6,
	journal      = {Computer Graphics Forum},
	volume       = 18,
	pages        = {149--158},
	doi          = {10.1111/1467-8659.00365},
	issn         = {0167-7055},
	url          = {https://onlinelibrary.wiley.com/doi/10.1111/1467-8659.00365},
	abstract     = {<p> Automatic blending has characterized the major advantage of implicit surface modeling systems. Recently, the introduction of deformations based on space warping and Boolean operations between primitives has increased the usefulness of such systems. We propose a further enhancement which will extend the range of models that can be easily and intuitively defined with a skeletal implicit surface system. We describe a hierarchical method which allows arbitrary compositions of models that make use of blending, warping and Boolean operations. We call this structure the <italic>BlobTree</italic> . Blending and space warping are treated in the same way as union, difference and intersection, i.e. as nodes in the <italic>BlobTree</italic> . The traversal of the <italic>BlobTree</italic> is described along with two rendering algorithms; a polygonizer and a ray tracer. We present some examples of interesting models which can be made easily using our approach that would be very difficult to represent with conventional systems. </p>},
	issue        = 2,
	keywords     = {blending,implicit surfaces,polygonizing,raytracing,warping}
}
@article{Komosinski1999,
	title        = {Framsticks: Towards a simulation of a nature-like world, creatures and evolution},
	author       = {Maciej Komosi\'{n}ski and Szymon Ulatowski},
	year         = 1999,
	journal      = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume       = 1674,
	pages        = {261--265},
	doi          = {10.1007/3-540-48304-7_33},
	isbn         = 3540664521,
	issn         = 16113349,
	url          = {https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=46e1984cde2545907a285cb412c6c97a0a5702ec},
	abstract     = {In this paper we describe our attempt to create a nature-like simulation model of artificial creatures. The model includes physical simulation of creatures, their interaction with the environment, their neural network control, and both directed and open-ended evolution. We describe a complex, three-dimensional simulation system, where various fitness criteria can be selected for evolving species, and a spontaneous evolution can be run. The work is still being developed, and we hope to make it a realistic model capable of producing real-life phenomena through an open-ended evolution in a life-like world of stick creatures.},
	issue        = {September}
}
@article{Sumner1999,
	title        = {Animating sand, mud, and snow},
	author       = {Robert W. Sumner and James F. O'Brien and Jessica K. Hodgins},
	year         = 1999,
	journal      = {Computer Graphics Forum},
	volume       = 18,
	pages        = {17--26},
	doi          = {10.1111/1467-8659.00299},
	issn         = {01677055},
	abstract     = {Computer animations often lack the subtle environmental changes that should occur due to the actions of the characters. Squealing car tires usually leave no skid marks, airplanes rarely leave jet trails in the sky, and most runners leave no footprints. In this paper, we describe a simulation model of ground surfaces that can be deformed by the impact of rigid body models of animated characters. To demonstrate the algorithms, we show footprints made by a runner in sand, mud, and snow as well as bicycle tire tracks, a bicycle crash, and a falling runner. The shapes of the footprints in the three surfaces are quite different, but the effects were controlled through only five essentially independent parameters. To assess the realism of the resulting motion, we compare the simulated footprints to human footprints in sand.},
	issue        = 1,
	keywords     = {animation,ground interaction,mud,physical simulation,sand,snow,terrain}
}
@techreport{Ostoma1999,
	title        = {Cellular automata theory and physics: A New Paradigm For The Unification of Physics},
	author       = {Tom Ostoma and Mike Trushyk},
	year         = 1999,
	abstract     = {ACKNOWLEGMENTS We wish to thank R. Mongrain (P. Eng.) for his encouragement, constructive criticisms, and for the lengthy conversations on the nature of space, time, light, matter, and CA theory.}
}
@article{Zhang2000,
	title        = {A flexible new technique for camera calibration},
	author       = {Zhengyou Zhang},
	year         = 2000,
	month        = 11,
	journal      = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	volume       = 22,
	pages        = {1330--1334},
	doi          = {10.1109/34.888718},
	issn         = {01628828},
	abstract     = {We propose a flexible new technique to easily calibrate a camera. It only requires the camera to observe a planar pattern shown at a few (at least two) different orientations. Either the camera or the planar pattern can be freely moved. The motion need not be known. Radial lens distortion is modeled. The proposed procedure consists of a closed-form solution, followed by a nonlinear refinement based on the maximum likelihood criterion. Both computer simulation and real data have been used to test the proposed technique and very good results have been obtained. Compared with classical techniques which use expensive equipment such as two or three orthogonal planes, the proposed technique is easy to use and flexible. It advances 3D computer vision one more step from laboratory environments to real world use. The corresponding software is available from the author's Web page. \textcopyright{} 2000 IEEE.},
	issue        = 11,
	keywords     = {2d pattern,Absolute conic,Calibration from planes,Camera calibration,Closed-form solution,Flexible plane-based calibration,Flexible setup,Lens distortion,Maximum likelihood estimation,Projective mapping}
}
@article{Dingwell2000,
	title        = {Nonlinear time series analysis of normal and pathological human walking},
	author       = {Jonathan B. Dingwell and Joseph P. Cusumano},
	year         = 2000,
	month        = 12,
	journal      = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
	volume       = 10,
	pages        = {848--863},
	doi          = {10.1063/1.1324008},
	issn         = {1054-1500},
	url          = {https://pubs.aip.org/cha/article/10/4/848/134404/Nonlinear-time-series-analysis-of-normal-and},
	abstract     = {<p>Characterizing locomotor dynamics is essential for understanding the neuromuscular control of locomotion. In particular, quantifying dynamic stability during walking is important for assessing people who have a greater risk of falling. However, traditional biomechanical methods of defining stability have not quantified the resistance of the neuromuscular system to perturbations, suggesting that more precise definitions are required. For the present study, average maximum finite-time Lyapunov exponents were estimated to quantify the local dynamic stability of human walking kinematics. Local scaling exponents, defined as the local slopes of the correlation sum curves, were also calculated to quantify the local scaling structure of each embedded time series. Comparisons were made between overground and motorized treadmill walking in young healthy subjects and between diabetic neuropathic (NP) patients and healthy controls (CO) during overground walking. A modification of the method of surrogate data was developed to examine the stochastic nature of the fluctuations overlying the nominally periodic patterns in these data sets. Results demonstrated that having subjects walk on a motorized treadmill artificially stabilized their natural locomotor kinematics by small but statistically significant amounts. Furthermore, a paradox previously present in the biomechanical literature that resulted from mistakenly equating variability with dynamic stability was resolved. By slowing their self-selected walking speeds, NP patients adopted more locally stable gait patterns, even though they simultaneously exhibited greater kinematic variability than CO subjects. Additionally, the loss of peripheral sensation in NP patients was associated with statistically significant differences in the local scaling structure of their walking kinematics at those length scales where it was anticipated that sensory feedback would play the greatest role. Lastly, stride-to-stride fluctuations in the walking patterns of all three subject groups were clearly distinguishable from linearly autocorrelated Gaussian noise. As a collateral benefit of the methodological approach taken in this study, some of the first steps at characterizing the underlying structure of human locomotor dynamics have been taken. Implications for understanding the neuromuscular control of locomotion are discussed.</p>},
	issue        = 4
}
@article{Wynn2000,
	title        = {The Northwest African slope apron: A modern analogue for deep-water systems with complex seafloor topography},
	author       = {Russell B. Wynn and Douglas G. Masson and Dorrik A.V. Stow and Phillip P.E. Weaver},
	year         = 2000,
	journal      = {Marine and Petroleum Geology},
	volume       = 17,
	pages        = {253--265},
	doi          = {10.1016/S0264-8172(99)00014-8},
	issn         = {02648172},
	abstract     = {The Northwest African slope apron is an interesting modern analogue for deep-water systems with complex seafloor topography. A sediment process map of the Northwest African continental margin illustrates the relative roles of different sedimentary processes acting across the entire margin. Fine-grained pelagic and hemipelagic sedimentation is dominant across a large area of the margin, and is considered to result from 'background' sedimentary processes. Alongslope bottom currents smooth and mould the seafloor sediments, and produce bedforms such as erosional furrows, sediment waves and contourite drifts. Downslope gravity flows (debris avalanches, debris flows and turbidity currents) are infrequent but important events on the margin, and are the dominant processes shaping the morphology of the slope and rise. The overall distribution of sedimentary facies and morphological elements on the Northwest African margin is characteristic of a fine-grained clastic slope apron. However, the presence of numerous volcanic islands and seamounts along the margin leads to a more complex distribution of sedimentary facies than is accounted for by slope apron models. In particular, the distribution and thickness of turbidite sands are controlled by the location of the break-of-slope, which is itself controlled by the pre-existing submarine topography. (C) 2000 Elsevier Science Ltd. All rights reserved.},
	issue        = 2,
	keywords     = {Northwest Africa,Slope apron,Turbidity currents}
}
@article{Rigaudiere2000,
	title        = {Shape Modelling with Skeleton based Implicit Primitives},
	author       = {Dominique Rigaudi\`{e}re and Gilles Gesqui\`{e}re and Dominique Faudot},
	year         = 2000,
	journal      = {Methods},
	url          = {https://www.graphicon.ru/html/2000/2D GRAPHICS/Rigaudiere.pdf},
	keywords     = {Skeleton, Implicit Primitives,d,implicit primitives,m,min,modelling,sk i,skeleton}
}
@article{Bertrand2000,
	title        = {Topological encoding of 3D segmented images},
	author       = {Yves Bertrand and Guillaume Damiand and Christophe Fiorio},
	year         = 2000,
	journal      = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume       = {1953 LNCS},
	pages        = {311--324},
	doi          = {10.1007/3-540-44438-6_26},
	isbn         = 3540413960,
	issn         = 16113349,
	url          = {https://link.springer.com/content/pdf/10.1007/3-540-44438-6_26.pdf},
	abstract     = {In this paper we define the 3d topological map and give an optimal algorithm which computes it from a segmented image. This data structure encodes totally all the information given by the segmentation. More, it allows to continue segmentation either algorithmically or interactively. We propose an original approach which uses several levels of maps. This allows us to propose a reasonable and implementable solution where other approaches don't allow suitable solutions. Moreover our solution has been implemented and the theoretical results translate very well in practical applications. \textcopyright{} Springer-Verlag Berlin Heidelberg 2000.}
}
@article{Onoue2000,
	title        = {A method for modeling and rendering dunes with wind-ripples},
	author       = {K. Onoue and T. Nishita},
	year         = 2000,
	journal      = {Proceedings - Pacific Conference on Computer Graphics and Applications},
	volume       = {2000-Janua},
	pages        = {427--428},
	doi          = {10.1109/PCCGA.2000.883978},
	isbn         = {0769508685},
	issn         = 15504085,
	abstract     = {This paper proposes a method for modeling and rendering realistic desert scenes. A desert terrain includes sand dunes and wind ripples. We use two types of scale models to form them. We render the dunes with the wind-ripples by bump-mapping using LOD (levels of detail).},
	keywords     = {Clouds,Computational modeling,Computer graphics,Creep,Equations,Large-scale systems,Layout,Rendering (computer graphics),Terrain mapping,Vegetation mapping}
}
@inbook{Halbwachs2000,
	title        = {Generalized Maps in Geological Modeling: Object-Oriented Design of Topological Kernels},
	author       = {Yvon Halbwachs and \O{}yvind Hjelle},
	year         = 2000,
	pages        = {339--356},
	doi          = {10.1007/978-3-642-57172-5_11},
	url          = {http://link.springer.com/10.1007/978-3-642-57172-5_11}
}
@article{Li2000,
	title        = {Why is the holistic approach becoming so important in landscape ecology?},
	author       = {Bai-Lian Li},
	year         = 2000,
	month        = 8,
	journal      = {Landscape and Urban Planning},
	volume       = 50,
	pages        = {27--41},
	doi          = {10.1016/S0169-2046(00)00078-5},
	issn         = {01692046},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0169204600000785},
	abstract     = {Landscape ecology is a way of thinking about the evolution and dynamics of heterogeneous landscapes. It is also viewed as the body of knowledge or facts about ecological space, spatial heterogeneity, and scaling. Studies in this \textregistered{}eld have been dominated by taking things apart and characterizing various attributes of spatial patterns. These studies generally do not address the intrinsic causality and underlying dynamics of the pattern. Therefore, they cannot explain why patterns change with biotic and abiotic conditions. The time is ripe for change; a holistic approach is needed. In this paper, I begin with mathematical formulation of the part\pm{}whole relation in ecological systems and show analytically why the ecological system cannot be understood by reducing it to its parts, which is the central theme for all holistic approaches. Using Prigogine's self-organization theory and Haken's synergetics, I further illustrate suf\textregistered{}ciency and necessity of such a holistic approach to study how the cooperation of these subsystems of landscape brings about spatial, temporal and functional structures on macroscopic scales. Four fundamental principles that may govern these processes of self-organization of landscape are proposed. Several examples of applying this approach to theoretical and practical landscape problems are also given. \#},
	issue        = {1-3},
	keywords     = {Emergent properties,Holistic approach,Landscape ecology,Nonequilibrium thermo-dynamics,Self-organized systems,Synergetics}
}
@article{MaciejKomosinski2000,
	title        = {The World of Framsticks: Simulation, Evolution, Interaction},
	author       = {MaciejKomosinski},
	year         = 2000,
	journal      = {Proceedings of 2nd International Conference on Virtual Worlds},
	pages        = {214--224},
	url          = {http://www.frams.alife.pl/},
	abstract     = {A three-dimensional virtual world simulation is described, where evolutiontakesplaceanditispossibletoinvestigatebehaviorsofcreaturesin real-time.Bodiesofthesecreaturesaremadeofsticks,andtheirbrainsarebuilt fromartificialneurons.Therearenoconstraintsontopologyandcomplexityof neuralnetworks,aswellasonthesizeofmorphology.Themodelisinspiredby biology,soenergeticissuessuchasenergygainsandlossesarealsoconsidered. Theevolutionaryprocesscanbeguidedbysomepre-definedcriteria,however, itispossibletomimicspontaneousevolutionwhenthefitnessisdefinedasthe life span of the organisms. Interactions in the virtual world are discussed (includingthepossibilityofworldwide-distributedsimulation),andtheresults ofso-farexperimentsarepresented. 1Introduction},
	issue        = {July 2000}
}
@article{Edinger2000,
	title        = {Normal Coral Growth Rates on Dying Reefs: Are Coral Growth Rates Good Indicators of Reef Health?},
	author       = {Evan N. Edinger and Gino V. Limmon and Jamaluddin Jompa and Wisnu Widjatmoko and Jeffrey M. Heikoop and Michael J. Risk},
	year         = 2000,
	month        = 5,
	journal      = {Marine Pollution Bulletin},
	volume       = 40,
	pages        = {404--425},
	doi          = {10.1016/S0025-326X(99)00237-4},
	issn         = {0025326X},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0025326X99002374},
	abstract     = {Massive coral growth rates may be poor indicators of coral reef health where coral reefs are subject to combined eutrophication and sedimentation. Massive coral growth (vertical extension) rates on polluted reefs were not different from extension rates on unpolluted reefs, while live coral cover was low and bioerosion intensity high, leading to net reef erosion and death of the polluted reefs. These combined patterns of coral growth rates, coral cover and bioerosion were documented on reefs aected by landbased pollution in the Java Sea, South Sulawesi and Ambon, Indonesia. Acid-insoluble content in coral skeletons re\textasciimacron{}ected land-based pollution stress on reefs more reliably than did coral extension rates. Coral skeletal density was lower on polluted Java Sea reefs than on unpolluted reefs used as reference sites, but coral calci\textregistered{}- cation rates were not signi\textregistered{}cantly dierent. The most eutrophied Java Sea reefs had net carbonate loss, indicating net reef erosion, while a fringing reef adjacent to mangroves and two unpolluted coral cays both had positive net carbonate production. Coral growth and reef growth were decoupled, in that coral growth rates did not reliably predict rates of reef accretion. The apparently paradoxical combination of normal to rapid coral growth and net reef erosion on polluted reefs illustrates the need for a whole-reef perspective on coral reef health},
	issue        = 5,
	keywords     = {bioindicators,coral growth rates,coral reef health,eutrophication,indonesia,sedimentation}
}
@unpublished{Blow2000,
	title        = {Terrain Rendering at High Levels of Detail Part I : Fast Reduction of Texture Memory Usage for Terrain Rendering},
	author       = {Jonathan Blow},
	year         = 2000
}
@article{Lindstrom2000,
	title        = {Out-of-Core Simplification of Large Polygonal Models},
	author       = {Peter Lindstrom},
	year         = 2000,
	journal      = {SIGGRAPH 2000 - Proceedings of the 27th Annual Conference on Computer Graphics and Interactive Techniques},
	pages        = {259--262},
	doi          = {10.1145/344779.344912},
	isbn         = 1581132085,
	abstract     = {We present an algorithm for out-of-core simplification of large polygonal datasets that are too complex to fit in main memory. The algorithm extends the vertex clustering scheme of Rossignac and Borrel [13] by using error quadric information for the placement of each cluster's representative vertex, which better preserves fine details and results in a low mean geometric error. The use of quadrics instead of the vertex grading approach in [13] has the additional benefits of requiring less disk space and only a single pass over the model rather than two. The resulting linear time algorithm allows simplification of datasets of arbitrary complexity. In order to handle degenerate quadrics associated with (near) flat regions and regions with zero Gaussian curvature, we present a robust method for solving the corresponding underconstrained least-squares problem. The algorithm is able to detect these degeneracies and handle them gracefully. Key features of the simplification method include a bounded Hausdorff error, low mean geometric error, high simplification speed (up to 100,000 triangles/second reduction), output (but not input) sensitive memory requirements, no disk space overhead, and a running time that is independent of the order in which vertices and triangles occur in the mesh.}
}
@article{Bidarra2000,
	title        = {Semantic feature modelling},
	author       = {R Bidarra and W.F Bronsvoort},
	year         = 2000,
	month        = 3,
	journal      = {Computer-Aided Design},
	volume       = 32,
	pages        = {201--225},
	doi          = {10.1016/S0010-4485(99)00090-1},
	isbn         = {00104485/00},
	issn         = {00104485},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0010448599000901},
	abstract     = {Almost all current feature modelling systems are parametric, history-based modelling systems. These systems suffer from a number of shortcomings with regard to the modelling process. In particular, they lack a complete specification of feature semantics, and therefore fail to maintain the meaning of the features during modelling. Also, modelling operations sometimes are hampered by the model history, and occasionally even have ill-defined semantics. In the semantic feature modelling approach presented here, the semantics of features is well defined and maintained during all modelling operations. The result of these operations is independent of the order of feature creation, and is well defined. The specification of feature classes, the structure and functionality of the feature model, in particular the Cellular Model, and the model validity maintenance scheme are described. The advantages and disadvantages of the approach, compared to current feature modelling approaches, are pointed out.},
	issue        = 3,
	keywords     = {Declarative modelling,Feature modelling,Feature semantics,History-based modelling,Validity maintenance}
}
@techreport{Yamamoto2000,
	title        = {Invited Review Forest Gap Dynamics and Tree Regeneration},
	author       = {Shin-Ichi Yamamoto},
	year         = 2000,
	journal      = {J. For. Res},
	volume       = 5,
	pages        = {223--229},
	isbn         = 1201602002402
}
@techreport{Gaston2000,
	title        = {Global patterns in biodiversity},
	author       = {Kevin J Gaston},
	year         = 2000,
	url          = {www.nature.com},
	abstract     = {B iodiversity, the variety of life, is distributed heterogeneously across the Earth. Some areas teem with biological variation (for example, some moist tropical forests and coral reefs), others are virtually devoid of life (for example, some deserts and polar regions), and most fall somewhere in between. Determining why these differences occur has long been a core objective for ecologists and biogeographers. It constitutes a continuing, an important, and to many an enthralling, challenge. Indeed, the past decade has seen a veritable explosion of studies documenting broad-scale (geographical) spatial patterns in biodiversity, seeking to explain them, and exploring their implications. The reasons for this interest are twofold. First, it reflects increased opportunity provided by improvements in available data and analytical tools, the former resulting mostly from extensive collation of existing specimen and species occurrence records, the establishment of dedicated distribution-mapping schemes, and the use of remote-sensing technology (to measure vegetation and other environmental variables). Second, it reflects concern over the future of biodiversity, and the resultant need to determine its current status, to predict its likely response to global environmental change, and to identify the most effective schemes for in situ conservation and sustainable use. Many of these issues can be addressed satisfactorily only by resolving the historical mismatch between the fine resolution of study plots in ecological field work (typically a few square metres) and, by comparison, the poor resolution of land-use planning and models of environmental change. A host of global patterns of spatial variation in biodiversity has been explored (Fig. 1). This includes patterns in hotspots and coldspots (highs and lows) of diversity (includ-ing comparisons between biological realms and between biogeographical regions), variation with spatial scale (for example, species-area relationships and relationships between local and regional richness) and along gradients across space or environmental conditions (for example, latitude, longitude, altitude, depth, peninsulas, bays, isolation, productivity/energy and aridity 1,2). Although several different levels of organization (genes to ecosystems) of biological variation can be distinguished, most analyses of spatial variation concern biodiversity as measured by the number of species observed or estimated to occur in an area (species richness). This results from widespread recognition of the significance of the species as a biological unit, and from the practical issues of the ease and magnitude of data acquisition. Consideration of spatial variation in other measures of biodiversity, particularly those concerning the difference between entities rather than simply their numbers, has been remarkably sparse (with the possible exception of patterns in body size and morphology). Thus, although much attention has been paid to latitu-dinal variation in species richness, little is known about variation in the diversity of genes, individuals or populations along latitudinal gradients. The growth of interest in broad-scale spatial variation in biodiversity has been particularly striking with regard to four areas of enquiry: latitudinal gradients in species richness , species-energy relationships, relationships between local and regional richness, and taxonomic covariance in species richness. In this review, the progress being made in each of these areas will be used to substantiate four broader cross-cutting observations about global patterns of biodiversity: respectively, that no single mechanism adequately explains all examples of a given pattern, that the patterns observed may vary with spatial scale, that processes operating at regional scales influence patterns observed at local ones, and that the relative balance of causal mechanisms means that there will invariably be variations in and exceptions to any given pattern. Latitudinal gradients in species richness High proportions of terrestrial and freshwater species occur in the tropics. Moving from high to low latitudes the average species richness within a sampling area of a given size increases, as has been documented for a wide spectrum of taxonomic groups (including groups as different as protists, trees, ants, woodpeckers and primates) for data across a range of spatial resolutions 3,4. Such gradients in species richness may be steep (for a given area, tropical assemblages are often several times more speciose than temperate ones), and have been a persistent feature of the To a first approximation, the distribution of biodiversity across the Earth can be described in terms of a relatively small number of broad-scale spatial patterns. Although these patterns are increasingly well documented, understanding why they exist constitutes one of the most significant intellectual challenges to ecologists and biogeographers. Theory is, however, developing rapidly, improving in its internal consistency, and more readily subjected to empirical challenge.}
}
@book{Baukal2000,
	title        = {Computational fluid dynamics in industrial combustion},
	author       = {Charles E. Jr Baukal and Vladimir Y. Gershtein and Xianming Li},
	year         = 2000
}
@article{Bednar2000,
	title        = {Speleogenesis: Evolution of Karst Aquifers},
	author       = {D.M Bednar, Jr},
	year         = 2000,
	month        = 12,
	journal      = {Journal of Hydrology},
	publisher    = {Elsevier BV},
	volume       = 240,
	pages        = {145--146},
	doi          = {10.1016/s0022-1694(00)00341-3},
	issn         = {00221694},
	abstract     = {Determining the beginning and the end of the life of a karst system is a substantial problem. In contrast to most of living systems development of a karst system can be " frozen " and then rejuvenated several times (polycyclic and polygenetic nature). The principal problems may include precise definition of the beginning of karstification (e.g. inception in speleogenesis) and the manner of preservation of the products of karstification. Karst evolution is particularly dependent upon the time available for process evolution and on the geographical and geological conditions of the exposure of the rock. The longer the time, the higher the hydraulic gradient and the larger the amount of solvent water entering the karst system, the more evolved is the karst. In general, stratigraphic discontinuities, i.e. intervals of nondeposition (disconformities and unconformities), directly influence the intensity and extent of karstification. The higher the order of discontinuity under study, the greater will be the problems of dating processes and events. The order of unconformities influences the stratigraphy of the karst through the amount of time available for subaerial processes to operate. The end of karstification can also be viewed from various perspectives. The final end occurs at the moment when the host rock together with its karst phenomena is completely eroded/denuded. In such cases, nothing remains to be dated. Karst forms of individual evolution stages (cycles) can also be destroyed by erosion, denudation and abrasion without the necessity of the destruction of the whole sequence of karst rocks. Temporary and/or final interruption of the karstification process can be caused by the fossilisation of karst due to loss of its hydrological function. Such fossilisation can be caused by metamorphism, mineralisation, marine transgressions, burial by continental deposits or volcanic products, tectonic movements, climatic change etc. Known karst records for the 1 st and 2 nd orders of stratigraphic discontinuity cover only from 5 to 60 \% of geological time. The shorter the time available for karstification, the greater is the likelihood that karst phenomena will be preserved in the stratigraphic record. While products of short-lived karstification on shallow carbonate platforms can be preserved by deposition during the immediately succeeding sea-level rise, products of more pronounced karstification can be destroyed by a number of different geomorphic processes. The longer the duration of subaerial exposure, the more complex are those geomorphic agents. Owing to the fact that unmetamorphosed or only slightly metamorphosed karst rocks containing karst and caves have occurred since Archean, we can apply a wide range of geochronologic methods. Most established dating methods can be utilised for direct and/or indirect dating of karst and paleokarst. The karst/paleokarst fills are very varied in composition, including a wide range of clastic and chemogenic sediments, products of surface and subsurface volcanism (lava, volcaniclastic materials, tephra), and deep-seated processes (hydrothermal activity, etc). Stages of evolution can also be based on dating correlated sediments that do not fill karst voids directly. The application of individual dating methods depends on their time ranges: the older the subject of study, the more limited is the choice of method. Karst and cave fills are relatively special kinds of geologic materials. The karst environment favours both the preservation of paleontological remains and their destruction. On one hand, karst is well known for its richness of paleontological sites, on the other hand most cave fills are complete sterile, which is true especially for the inner-cave facies. Another problematic feature of karst records is the reactivation of processes, which can degrade a record by mixing karst fills of different ages. Principle:The time scale for the development of karst features cannot be longer than that of the rocks on which they form. (White 1988, p. 302)},
	issue        = {1-2}
}
@article{Gatto2000,
	title        = {Soil freeze–thaw-induced changes to a simulated rill: potential impacts on soil erosion},
	author       = {Lawrence W Gatto},
	year         = 2000,
	month        = 2,
	journal      = {Geomorphology},
	volume       = 32,
	pages        = {147--160},
	doi          = {10.1016/S0169-555X(99)00092-6},
	issn         = {0169555X},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0169555X99000926},
	abstract     = {Flows in natural rills on hillslopes transport significantly more sediment down slope than overland flows, which makes rills geomorphically significant landscape features. The erosivity, e.g., sediment transport capacity, of the flows in rills is partially a function of the cross-sectional geometry of the rill which determines flow velocity and depth. Conversely, rill geometry is determined by flow erosivity and by soil processes that affect the erodibility and stability of soil along the rill. Thus, complex feedbacks exist in the mechanics of rill erosion. The objective of this study was to measure the effects of one \v{Z}. of the soil processes that affect rill geometry, soil freeze-thaw FT cycling. An unvegetated rectangular rill was subjected to two FT cycles, each lasting several days, in a controlled laboratory setting. The FT cycling increased the water content and reduced the cohesion in the surface soil along the rill sufficiently to induce soil slumps and mud flows along the sidewalls of the rill. These mass failures changed the rectangular rill to a triangular one, which reduced the hydraulic radius of the rill by 32\%. Using Manning's equation, it was estimated that this new geometry could reduce the velocity of the flow in this altered rill by about 25\%. The persistence of the new rill shape and, thus, that of the slower flow would depend on the complex interactions between flow velocity and the resistance of the slumped sediment to those flows. That persistence was not investigated in this experiment. These results can be used in parameterizing models of rill evolution that incorporate widening of rills by mass failures along the rill sidewalls. q},
	issue        = {1-2},
	keywords     = {cross-sectional geometry,erosion potential,freeze-thaw,mass failures,rill widening,rills}
}
@article{Berger2000,
	title        = {A new approach to spatially explicit modelling of forest dynamics: spacing, ageing and neighbourhood competition of mangrove trees},
	author       = {Uta Berger and Hanno Hildenbrandt},
	year         = 2000,
	month        = 8,
	journal      = {Ecological Modelling},
	volume       = 132,
	pages        = {287--302},
	doi          = {10.1016/S0304-3800(00)00298-2},
	issn         = {03043800},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0304380000002982},
	abstract     = {This paper presents a new approach to spatially explicit modelling that enables the influence of neighbourhood effects on the dynamics of forests and plant communities to be analysed. We refer to this approach as 'field of neighbourhood' (FON). It combines the 'neighbourhood philosophy' of grid-based models with the description of individual spacing in the 'zone of influence' (ZOI) approach. The novel feature of FON is that modelling of local competition between neighbouring trees is based on the notion of a field of neighbourhood exerted by each tree. This field is defined only on the ZOI of a tree and depends on the distance to the stemming point. For the demonstration of FON's power, a simulation model (KiWi) was implemented that focuses on the dynamic of mangrove forests. The realistic self-thinning behaviour of modelled stands of A6icennia germinans and Rhizophora mangle confirms the suitability of the FON approach for the description of intra-and inter-specific competition. In KiWi, mortality is modelled in terms of a 'memory function', i.e. the yearly stem increment of each tree is stored in its 'memory' over a certain time period and determines-as a sign of vitality-tree mortality. The results of KiWi demonstrate that this description is sufficient to keep the maximum age of the trees within a reasonable limit. The model thus manages without a description of individual tree age. This is an important feature considering the fact that a direct relationship between tree age and mortality is questioned and there is no established method as yet for determining the age of mangrove trees.},
	issue        = 3,
	keywords     = {A6icennia germinans,Competition,Individual-based model,Local interactions,Mangrove forest,Rhizophora mangle wwwelseviercom/locate/ecolmodel,Self-thinning,Spatially explicit modeling}
}
@article{DaSilva2001,
	title        = {A dynamic simulation model of the widgeon grass Ruppia maritima and its epiphytes in the estuary of the Patos Lagoon, RS, Brazil},
	author       = {Eduardo Teixeira Da Silva and Milton L. Asmus},
	year         = 2001,
	month        = 2,
	journal      = {Ecological Modelling},
	publisher    = {Elsevier},
	volume       = 137,
	pages        = {161--179},
	doi          = {10.1016/S0304-3800(00)00425-7},
	issn         = {03043800},
	abstract     = {The dynamics of the vegetated beds of the estuary of the Patos Lagoon was investigated using a simulation model for two important benthic primary producers (the widgeon grass Ruppia maritima and its epiphytes). The model, of deterministic characteristics, simulated two development cycles of the beds from summer 1992/1993 to 1993/1994. Model validation and calibration were accomplished by using R. maritima biomass collected in shallow bays of the Paros Lagoon estuary during the two simulated cycles. The model simulated the seasonal variations in the biomass of blades, stems, roots plus rhizomes, seeds and fruit of R. maritima, by using the experimental components method, and the epiphytes biomass, by using the compartmental system method, all expressed in g dry wt. (gDW) m-2. The model accurately reproduced the processes of building and decay of R. maritima biomass, representing the maximum values observed in the environment. Plant height and its phenological stage were two important attributes included in the model. They were important to control the processes of light attenuation, beginning of the epiphytes installation and the removal of the grass by hydrodynamic action. Bending of the grass and biomass removal were very important to the model results and they seemed to be the primary factors that control the plant decay in late summer. Ecological modeling has proved to be a powerful tool for the proposition of new control mechanisms for the dynamics of the vegetated beds of the estuary of the Paros Lagoon.},
	issue        = {2-3},
	keywords     = {Biomass partition,Epiphytes,Hydrodynamic action,Phenological development,Ruppia maritima,Simulation model}
}
@article{Grabiner2001,
	title        = {Age-related changes in spatial and temporal gait variables},
	author       = {Penny C. Grabiner and S. Tina Biswas and Mark D. Grabiner},
	year         = 2001,
	month        = 1,
	journal      = {Archives of Physical Medicine and Rehabilitation},
	publisher    = {W.B. Saunders},
	volume       = 82,
	pages        = {31--35},
	doi          = {10.1053/apmr.2001.18219},
	issn         = {00039993},
	abstract     = {Objective: To extend recent findings describing the effect of age on spatial and temporal gait variables. Design: Experimental. Setting: A gait analysis laboratory. Participants: Two experiments with healthy nonfallers were conducted. Experiment 1 included 33 subjects (n = 15, 72.13 \pm{} 3.96yr; n = 18, 25.06 \pm{} 4.02yr); and experiment 2 included 24 subjects (n = 14, 75.57 \pm{} 6.15yr; n = 10; 28.10 \pm{} 3.48yr). Interventions: The effect of age, walking velocity, shoe condition, and performance of an attention-splitting task on gait variables was investigated. Main Outcome Measures: Temporal and spatial gait variables were quantified using an instrumented surface across which subjects walked. The independent variables were walking velocity variability, stride length variability, stride width variability, and stride time variability. Results: Stride width variability of older adults was significantly larger than that of younger adults in both experiments. The remaining gait variables demonstrated nonsystematic or no age-related differences. Conclusions: With the exception of stride width variability, the variability of the remaining gait variables of interest were insensitive to the speed at which subjects walked, whether the subjects were wearing shoes or not, and performing an attention-splitting task while walking. These findings contribute to an emerging interpretive framework established by similar work published by others regarding gait variability. \textcopyright{} 2001 by the American Congress of Rehabilitation Medicine and the American Academy of Physical Medicine and Rehabilitation.},
	issue        = 1,
	keywords     = {Biomechanics,Gait,Rehabilitation,Walking}
}
@article{Ridao2001,
	title        = {Dynamics model of an underwater robotic vehicle},
	author       = {Pere Ridao and Joan Batlle and Marc Carrera},
	year         = 2001,
	journal      = {Research report IIiA},
	pages        = {1--50},
	url          = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.18.4430&amp;rep=rep1&amp;type=pdf},
	abstract     = {This report takes an in-depth look at the physical laws governing the behavior of an underwater robotic vehicle. A complete 3D kinematics and dynamics matrix-based model is also presented. This model uses the dynamics equations which describe the movement of a rigid body and the main hydrodynamic equations affecting this movement through a fluid environment. This model depends on a set of physical parameters which are obtained from experimentation. This report goes on to describe an identification methodology for slow Underwater Vehicles. As an example, it presents the identified model of an underwater robotic vehicle called GARBI. Real experiments are provided demonstrating the feasibility of the presented model as well as the identification methodology.},
	issue        = {April 2016}
}
@article{Thorseth2001,
	title        = {Diversity of life in ocean floor basalt},
	author       = {I. H. Thorseth and T. Torsvik and V. Torsvik and F. L. Daae and R. B. Pedersen},
	year         = 2001,
	journal      = {Earth and Planetary Science Letters},
	volume       = 194,
	pages        = {31--37},
	doi          = {10.1016/S0012-821X(01)00537-4},
	issn         = {0012821X},
	abstract     = {Electron microscopy and biomolecular methods have been used to describe and identify microbial communities inhabiting the glassy margins of ocean floor basalts. The investigated samples were collected from a neovolcanic ridge and from older, sediment-covered lava flows in the rift valley of the Knipovich Ridge at a water depth around 3500 m and an ambient seawater temperature of -0.7\textdegree{}C. Successive stages from incipient microbial colonisation, to well-developed biofilms occur on fracture surfaces in the glassy margins. Observed microbial morphologies are various filamentous, coccoidal, oval, rod-shaped and stalked forms. Etch marks in the fresh glass, with form and size resembling the attached microbes, are common. Precipitation of alteration products around microbes has developed hollow subspherical and filamentous structures. These precipitates are often enriched in Fe and Mn. The presence of branching and twisted stalks that resemble those of the iron-oxidising Gallionella, indicate that reduced iron may be utilised in an energy metabolic process. Analysis of 16S-rRNA gene sequences from microbes present in the rock samples, show that the bacterial population inhabiting these samples cluster within the \ensuremath{\gamma}-and \ensuremath{\epsilon}-Proteobacteria and the Cytophaga/Flexibacter/Bacteroides subdivision of the Bacteria, while the Archaea all belong to the Crenarchaeota kingdom. This microbial population appears to be characteristic for the rock and their closest relatives have previously been reported from cold marine waters in the Arctic and Antarctic, deep-sea sediments and hydrothermal environments. \textcopyright{} 2001 Elsevier Science B.V. All rights reserved.},
	issue        = {1-2},
	keywords     = {Alteration,Basalts,Biosphere,Glasses,Microorganisms,Oceanic crust}
}
@article{Gamito2001,
	title        = {Procedural landscapes with overhangs},
	author       = {MN Gamito and Forest Kenton Musgrave},
	year         = 2001,
	journal      = {10th Portuguese Computer Graphics \ldots{}},
	url          = {http://virtual.inesc-id.pt/virtual/10epcg/actas/pdfs/gamito.pdf},
	abstract     = {Overhangs have been a major stumbling block in the context of terrain synthesis models. These models resort invariably to a heightfield paradigm, which immediately precludes the existence of any type of overhang. This article presents a new technique for the generation of surfaces, with the ability to model overhangs in a procedural way. This technique can be used generally to model landscape elements, not only terrains but also the surface of the sea. The technique applies non-linear deformations to an initial heightfield surface. The deformations occur after the surface has been displaced along some specified vector field. The method is conceptually simple and enhances greatly the class of landscapes synthesized with procedural models.},
	issue        = {May},
	keywords     = {adaptive level of detail,procedural models,ray-tracing,surface deformation,surface overhangs}
}
@inproceedings{Fedkiw2001,
	title        = {Visual Simulation of Smoke},
	author       = {Ronald Fedkiw and Henrik Wann Jensen},
	year         = 2001,
	booktitle    = {SIGGRAPH 2001 Conference Proceedings, Annual Conference Series},
	pages        = {15--22},
	note         = {This paper is cited by Josh Stam \&quot;Real-time fluid dynamics for video games\&quot; as a way to control the small vortex created in the fluid simulation. At this point my water simulation is not realistic as there is a lot of vortex. Should check this for improvements.},
	abstract     = {In this paper, we propose a new approach to numerical smoke simulation for computer graphics applications. The method pro- posed here exploits physics unique to smoke in order to design a numerical method that is both fast and efficient on the relatively coarse grids traditionally used in computer graphics applications (as compared to the much finer grids used in the computational fluid dynamics literature). We use the inviscid Euler equations in our model, since they are usually more appropriate for gas mod- eling and less computationally intensive than the viscous Navier- Stokes equations used by others. In addition, we introduce a physically consistent vorticity confinement term to model the small scale rolling features characteristic of smoke that are absent on most coarse grid simulations. Our model also correctly handles the inter- action of smoke with moving objects.}
}
@article{Veltkamp2001,
	title        = {Shape matching: Similarity measures and algorithms},
	author       = {Remco C. Veltkamp},
	year         = 2001,
	journal      = {Proceedings - International Conference on Shape Modeling and Applications, SMI 2001},
	pages        = {188--197},
	doi          = {10.1109/SMA.2001.923389},
	isbn         = {0769508537},
	url          = {https://webspace.science.uu.nl/~veltk101/publications/art/smi2001.pdf},
	abstract     = {Shape matching is an important ingredient in shape retrieval, recognition and classification, alignment and registration, and approximation and simplification. This paper treats various aspects that are needed to solve shape matching problems: choosing the precise problem, selecting the properties of the similarity measure that are needed for the problem, choosing the specific similarity measure, and constructing the algorithm to compute the similarity. The focus is on methods that lie close to the field of computational geometry. \textcopyright{} 2001 IEEE.}
}
@inproceedings{Benes2001a,
	title        = {Parallel implementation of terrain erosion applied to the surface of Mars},
	author       = {Bed\v{r}ich Bene\v{s} and Rafael Forsbach},
	year         = 2001,
	month        = 11,
	booktitle    = {Proceedings of the 1st international conference on Computer graphics, virtual reality and visualisation},
	publisher    = {ACM},
	pages        = {53--57},
	doi          = {10.1145/513867.513880},
	isbn         = 1581134460,
	url          = {https://dl.acm.org/doi/10.1145/513867.513880},
	city         = {New York, NY, USA}
}
@article{Stolte2001,
	title        = {Novel techniques for robust voxelization and visualization of implicit surfaces},
	author       = {Nilo Stolte and Arie Kaufman},
	year         = 2001,
	journal      = {Graphical Models},
	volume       = 63,
	pages        = {387--412},
	doi          = {10.1006/gmod.2001.0559},
	issn         = 15240703,
	url          = {https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.153.5836&rep=rep1&type=pdf},
	abstract     = {Voxelization is the transformation of geometric surfaces into voxels. Up to date this process has been done essentially using incremental algorithms. Incremental algorithms have the reputation of being efficient but they lack an important property: robustness. The voxelized representation should envelop its continuous model. However, without robust methods this cannot be guaranteed. This article describes novel techniques of robust voxelization and visualization of implicit surfaces. First of all our recursive subdivision voxelization algorithm is reviewed. This algorithm was initially inspired by Duff's image space subdivision method. Then, we explain the algorithm to voxelize implicit surfaces defined in spherical or cylindrical coordinates. Next, we show a new technique to produce infinite replications of implicit objects and their voxelization method. Afterward, we comment on the parallelization of our voxelization procedure. Finally we present our voxel visualization algorithm based on point display. Our voxelization algorithms can be used with any data structure, thanks to the fact that a voxel is only stored once the last subdivision level is reached. We emphasize the use of the octree, though, because it is a convenient way to store the discrete model hierarchically. In a hierarchy the discrete model refinement is simple and possible from any previous voxelized scene thanks to the fact that the voxelization algorithms are robust. \textcopyright{} 2001 Elsevier Science (USA).},
	issue        = 6,
	keywords     = {3D visualization,Implicit surfaces,Interval arithmetic,Parallel processing,Voxel,Voxelization}
}
@article{Benes2001,
	title        = {Layered data representation for visual simulation of terrain erosion},
	author       = {Bed\v{r}ich Bene\v{s} and Rafael Forsbach},
	year         = 2001,
	journal      = {Proceedings - Spring Conference on Computer Graphics, SCCG 2001},
	pages        = {80--86},
	doi          = {10.1109/SCCG.2001.945341},
	isbn         = {0769512151},
	url          = {https://data.exppad.com/public/papers/Layered_data_representation_for_Visual_Simulation_of_Terrain_Erosion.pdf},
	abstract     = {New data structure for visual simulation of 3D terrains is introduced. The representation is inspired by real geological measurements and presents good trade-off between commonly used inexpensive, but inaccurate, height fields and memory demanding voxel representation. The representation is based on horizontal stratified layers consisting of one material. The layers are captured in certain positions of the landscape. This representation is then discretized into a 2D array. We demonstrate that the classical algorithm simulating thermal erosion (F.K. Musgrave, 1989), can run on this representation and we can even simulate some new properties. The simulation has been done on artificial data as well as on real data from Mars.},
	keywords     = {Terrain erosion,height field,layers,voxels}
}
@article{Bertrand2017,
	title        = {Topological Map : Minimal Encoding of 3d Segmented Images},
	author       = {Yves Bertrand and Guillaume Damiand and Christophe Fiorio},
	year         = 2001,
	journal      = {GBR: Graph-Based Representation in Pattern Recognition},
	pages        = {64--73},
	url          = {https://hal-lirmm.ccsd.cnrs.fr/lirmm-01168509/file/gbr_2001_damiand.pdf}
}
@phdthesis{Damiand2001,
	title        = {Th\`{e}se D\'{e}finition et \'{e}tude d'un mod\`{e}le topologique minimal de repr\'{e}sentation d'images 2d et 3d},
	author       = {Guillaume Damiand},
	year         = 2001,
	journal      = {No\^{u}s}
}
@article{Hoffman2001,
	title        = {Decomposition Plans for Geometric Constraint Problems, Part II: New Algorithms},
	author       = {Christoph M. Hoffman and Andrew Lomonosov and Meera Sitharam},
	year         = 2001,
	journal      = {Journal of Symbolic Computation},
	volume       = 31,
	pages        = {409--427},
	doi          = {10.1006/jsco.2000.0403},
	issn         = {07477171},
	abstract     = {We systematically design two new decomposition-recombination (DR) planners, geared to perform well with respect to several performance measures. The DR-planning problem and the performance measures were formally defined in Part I of this paper to closely reflect specific requirements of CAD/CAM applications. As expected, in analysis and comparison based on all of these performance measures, one of the new DR-planners, the modified frontier algorithm (MFA), represents a significant improvement over existing planners based on SR (constraint shape recognition) and MM (maximum matching) that were analyzed in Part I. We also present salient heuristics and data structures used in the implementation of MFA. \textcopyright{} 2001 Academic Press.},
	issue        = 4
}
@article{Carr2001,
	title        = {Reconstruction and representation of 3D objects with radial basis functions},
	author       = {J. C. Carr and R. K. Beatson and J. B. Cherrie and T. J. Mitchell and W. R. Fright and B. C. McCallum and T. R. Evans},
	year         = 2001,
	journal      = {Proceedings of the 28th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH 2001},
	pages        = {67--76},
	doi          = {10.1145/383259.383266},
	isbn         = {158113374X},
	url          = {https://www.cs.jhu.edu/~misha/Fall05/Papers/carr01.pdf},
	abstract     = {We use polyharmonic Radial Basis Functions (RBFs) to reconstruct smooth, manifold surfaces from point-cloud data and to repair incomplete meshes. An object's surface is defined implicitly as the zero set of an RBF fitted to the given surface data. Fast methods for fitting and evaluating RBFs allow us to model large data sets, consisting of millions of surface points, by a single RBF - previously an impossible task. A greedy algorithm in the fitting process reduces the number of RBF centers required to represent a surface and results in significant compression and further computational advantages. The energy-minimisation characterisation of polyharmonic splines result in a "smoothest" interpolant. This scale-independent characterisation is well-suited to reconstructing surfaces from non-uniformly sampled data. Holes are smoothly filled and surfaces smoothly extrapolated. We use a non-interpolating approximation when the data is noisy. The functional representation is in effect a solid model, which means that gradients and surface normals can be determined analytically. This helps generate uniform meshes and we show that the RBF representation has advantages for mesh simplification and remeshing applications. Results are presented for real-world rangefinder data. \textcopyright{} 2001 ACM.},
	keywords     = {RBF,Radial Basis Function,geometry compression,mesh repair,point-cloud surfacing,solid modeling,surface reconstruction,variational implicit surfaces}
}
@article{Barthe2001,
	title        = {Extrusion of ID implicit profiles: theory and first application},
	author       = {Lo\"{\i}c Barthe and Veronique Gaildrat and R Caubet},
	year         = 2001,
	journal      = {International Journal of Shaping Modeling},
	volume       = 7,
	pages        = {179--198},
	doi          = {10.1142/s0218654301000114},
	issn         = {02186543},
	url          = {https://www.irit.fr/recherches/VORTEX/publications/rendu-geometrie/IJSM2001_Barthe_et_al.pdf},
	abstract     = {This paper presents a new interpretation of the general definition of the binary blending operator of implicit modeling. Instead of considering the operator as a composition of potential functions or as a function defined in the combined primitives metric, we propose to consider it as an implicit curve extruded in an implicit extrusion field. An implicit extrusion field is a 2D space for which each coordinate is a potential field. The study of general concepts around implicit extrusion field allows us to introduce theoretical notion of free-form blending controlled point-by-point by the user. Through the use of functional interpolation functions, we propose modeling tools to create, sculpt or combine implicit primitives by extrusion of a profile in an implicit extrusion field. \textcopyright{} World Scientific Publishing Company.},
	issue        = 2,
	keywords     = {Boolean composition operators,Free-form transitions,Implicit curves,Implicit modeling}
}
@article{AmEnde2001,
	title        = {3D mapping of underwater caves},
	author       = {B.A. am Ende},
	year         = 2001,
	journal      = {IEEE Computer Graphics and Applications},
	volume       = 21,
	pages        = {14--20},
	doi          = {10.1109/38.909011},
	issn         = {02721716},
	abstract     = {Wakulla Springs-a group of deep, underground, water-filled caves south of Tallahassee, FL, USA-is an example where mapping has proved challenging. The Wakulla 2 expedition of the US Deep Caving Team Inc. had one primary goal-to automatically build the first fully 3D cave map. To make the map, divers had to survive the hostile environment. The divers' attention mostly focuses on staying alive, so the more automatic the surveying, the better. The critical piece of equipment for the Wakulla 2 expedition was the Digital Wall Mapper (DWM). The device was designed specifically for the project to gather survey data to make the 3D map. 32 sonar transducers were spirally arrayed around the nose of the 2-m long, 150-kg instrument. Thus, four times a second, the DWM sends and receives 32 equally spaced radial readings. The distance to the walls was important but not useful unless we knew the DWM's exact position and orientation. To record this information, we used an inertial measurement unit (IMU), which is located in the center of the DWM},
	issue        = 2
}
@inbook{Roberts2001,
	title        = {Sticky Pixels: Evolutionary Growth by Random Drop Ballistic Aggregation},
	author       = {Jonathan C. Roberts},
	year         = 2001,
	booktitle    = {Eurographics UK 2001 Conference Proceedings},
	pages        = {149--155},
	isbn         = {0954032101},
	url          = {https://kar.kent.ac.uk/13627/1/sticky_pixels_evolutionary_roberts.pdf}
}
@article{Taylor2001,
	title        = {Recent developments in the evolution of morphologies and controllers for physically simulated creatures},
	author       = {Tim Taylor and Colm Massey},
	year         = 2001,
	journal      = {Artificial Life},
	volume       = 7,
	pages        = {77--87},
	doi          = {10.1162/106454601300328034},
	isbn         = 1064546013,
	issn         = 10645462,
	abstract     = {Karl Sims' work [25, 26] on evolving body shapes and controllers for three-dimensional, physically simulated creatures generated wide interest on its publication in 1994. The purpose of this article is threefold: (a) to highlight a spate of recent work by a number of researchers in replicating, and in some cases extending, Sims' results using standard PCs (Sims' original work was done on a Connection Machine CM-5 parallel computer). In particular, a re-implementation of Sims' work by the authors will be described and discussed; (b) to illustrate how off-the-shelf physics engines can be used in this sort of work, and also to highlight some deficiencies of these engines and pitfalls when using them; and (c) to indicate how these recent studies stand in respect to Sims' original work. \textcopyright{} 2001 Massachusetts Institute of Technology.},
	issue        = 1,
	keywords     = {Brain-body evolution,Morphological evolution,Physics engine,Virtual creature evolution},
	pmid         = 11461690
}
@book{Kaandorp2001,
	title        = {The Algorithmic Beauty of Seeweeds, Sponges, and Corals},
	author       = {J A Kaandorp and J E K\"{u}bler},
	year         = 2001,
	pages        = 189,
	isbn         = {3-540-67700-33},
	url          = {https://beckassets.blob.core.windows.net/product/readingsample/540349/9783540677000_excerpt_001.pdf},
	keywords     = {Fractal}
}
@phdthesis{Wei2001,
	title        = {Modeling and Manipulation of Amorphous Objects},
	author       = {Xiaoming Wei},
	year         = 2001,
	url          = {https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=014d52cb7ce5122e1bfdb78c40a87525158bc83e},
	institution  = {Center for Visual Computing and State University of New York}
}
@book{Harmon2001,
	title        = {Landscape erosion and evolution modeling},
	author       = {R. S. (Russell S.) Harmon and William W. Doe},
	year         = 2001,
	publisher    = {Kluwer Academic/Plenum Publishers},
	pages        = 540,
	isbn         = {0306467186},
	abstract     = {In this interdisciplinary review of the latest in modeling of soil erosion and landscape evolution based on 1999 workshops, 17 contributed chapters by international experts unearth the complex natural processes impacted by land use. Such models serve as the basis for decision support systems for public land managers, with the accent here on issues facing the US Army's Land Management System (LMS). Harmon (Army Research Laboratory, Research Triangle Park, NC) and Doe (Center for Environmental Management of Military Land, Colorado State U., Fort Collins) provide context for soil erosion processes, best management practices, modeling approaches, and linking models to reality. The final section treats model successes, limitations, and future LMS directions. Annotation copyrighted by Book News Inc., Portland, OR. Introduction to Soil Erosion and Landscape Evolution Modeling -- Soil Erosion Management and Model Development -- Soil Erosion Processes -- Models and Modeling Approaches -- Linking Reality and Modeling -- Erosion Problems on U.S. Army Training Lands -- Regulatory Controls -- Plant Material Development and Use on Military Lands -- Physical Erosion and Sediment Controls -- Applying Science in Erosion and Sediment Control -- Effects of Freeze-Thaw Cycling on Soil Erosion -- Effects of Soil Freeze-Thaw Cycling -- Future Research Needs -- Determination of Slope Displacement Mechanisms and Causes -- Bluff Geometry and Stratigraphy -- Ground Water Conditions -- Soil Characteristics -- Slope Displacement Monitoring Methods -- Displacement Models -- Causes of Displacement -- Processes of Bluff Failure -- Limit Equilibrium Analyses -- Using Cosmogenic Nuclide Measurements in Sediments to Understand Background Rates of Erosion and Sediment Transport -- Methods -- Cosmogenic Nuclide Systematics and Interpretative Models -- Implications Of Sediment Cosmogenic Nuclide Measurements -- Erosion Modeling -- Empirical Models -- Process-Based Models -- Model Testing -- Model Validation -- Model Application -- The Water Erosion Prediction Project (WEPP) Model -- WEPP Model Development History -- WEPP Hillslope Model Component -- WEPP Model Watershed Component -- Model Validation Study Results -- Data and Model Uncertainty: Impacts on Model Evaluation and Application -- WEPP Model Status and Current Activities.}
}
@article{Gobron2001,
	title        = {Crack pattern simulation based on 3D surface cellular automata},
	author       = {St\'{e}phane Gobron and Norishige Chiba},
	year         = 2001,
	month        = 6,
	journal      = {Visual Computer},
	volume       = 17,
	pages        = {287--309},
	doi          = {10.1007/s003710100099},
	issn         = {01782789},
	abstract     = {This article describes a method for modeling the propagation of cracks on any 3D surface. This method allows almost any type of cracks on any type of triangulated 3D object. Our model's main advantage is that it proposes a semi-physical solution, making it both user controllable and easily extensible. We first introduce the general development of cracks. We then present our original model of spectrum stress, followed by a description of the mutual interaction between cracks and stresses. Then, we describe special rendering techniques including the multi-thickness anti-aliasing linked-segment method and the crack mirror special effect. The final section presents intermediate graphical results that review the entire model as well as a set of different crack patterns using various types of material such as concrete, ceramic, mud, and glaze.},
	issue        = 5,
	keywords     = {Cellular automaton,Cracking,Hyper-texture,Multi-layer modeling,Simulation}
}
@article{Perlin2001,
	title        = {Noise Hardware},
	author       = {Ken Perlin},
	year         = 2001,
	journal      = {Real-Time Shading SIGGRAPH Course Notes}
}
@article{Perlin2001b,
	title        = {Flow Noise},
	author       = {Ken Perlin and Fabrice Neyret},
	year         = 2001,
	month        = 8,
	journal      = {28th International Conference on Computer Graphics and Interactive Techniques (Technical Sketches and Applications)},
	volume       = 28,
	pages        = {1--187},
	url          = {www.mrl.nyu.edu}
}
@article{Chan2001,
	title        = {Active Contours Without Edges},
	author       = {Tony F Chan and Luminita A Vese},
	year         = 2001,
	journal      = {IEEE Transactions on image processing},
	volume       = 10,
	abstract     = {In this paper, we propose a new model for active contours to detect objects in a given image, based on techniques of curve evolution, Mumford-Shah functional for segmentation and level sets. Our model can detect objects whose boundaries are not necessarily defined by gradient. We minimize an energy which can be seen as a particular case of the minimal partition problem. In the level set formulation, the problem becomes a "mean-curvature flow"-like evolving the active contour, which will stop on the desired boundary. However, the stopping term does not depend on the gradient of the image, as in the classical active contour models, but is instead related to a particular segmentation of the image. We will give a numerical algorithm using finite differences. Finally, we will present various experimental results and in particular some examples for which the classical snakes methods based on the gradient are not applicable. Also, the initial curve can be anywhere in the image, and interior contours are automatically detected.},
	issue        = 2,
	keywords     = {Index Terms-Active contours,curvature,energy minimization,finite differences,level sets,partial differential equations,segmen-tation}
}
@inproceedings{Turk2001,
	title        = {Implicit surfaces that interpolate},
	author       = {G. Turk and Huong Quynh Dinh and J.F. O'Brien and G. Yngve},
	year         = 2001,
	month        = 4,
	booktitle    = {Proceedings International Conference on Shape Modeling and Applications},
	publisher    = {IEEE Computer Society},
	pages        = {62--71},
	doi          = {10.1109/SMA.2001.923376},
	isbn         = {0-7695-0853-7},
	url          = {http://ieeexplore.ieee.org/document/923376/},
	abstract     = {Implicit surfaces are ofren created by summing a collection of radial basis functions. Recently, researchers have begun to create implicit surfaces that exactly interpolate a given set of points by solving a simple linear system to assign weights to each basis function. Due to their ability to interpolate, these implicit su\$aces are more easily control-lable than traditional "blobby" implicits. There are several additional forms of control over these surfaces that make them attractive for a variety of applications. Surface nor-mals may be directly specijed at any location over the surface , and this allows the modeller to pivot the normal while still having the surface pass through the constraints. The degree of smoothness of the sudace can be controlled by changing the shape of the basis finctions, allowing the surface to be pinched or smooth. On a point-by-point basis the modeller may decide whether a constraint point should be exactly interpolated or approximated. Applications of these implicits include shape transformation, creating surfaces from computer vision data, creation of an implicit surface from a polygonal model, and medical surface reconstruction .}
}
@inbook{Hammes2001,
	title        = {Modeling of Ecosystems as a Data Source for Real-Time Terrain Rendering},
	author       = {Johan Hammes},
	year         = 2001,
	pages        = {98--111},
	doi          = {10.1007/3-540-44818-7_14},
	url          = {http://link.springer.com/10.1007/3-540-44818-7_14},
	abstract     = {With the advances in rendering hardware, it is possible to render very complex scenes in real-time. In general, computers do not have enough memory to store all the necessary information for sufficiently large areas. This paper discusses a way in which well-known techniques for modeling ecosystems can be applied to generate the placement of plants on a terrain automatically at run-time. Care was taken to pick algorithms that would be sufficiently fast to allow real-time computation, but also varied enough to allow for natural looking placement of plants and ecosystems while remaining deterministic. The techniques are discussed within a specific rendering framework, but can easily be adapted to other rendering engines.},
	keywords     = {compression,ecosystem modeling,ecotope modeling,real-time rendering,terrain modeling,terrain visualization}
}
@article{Ju2002,
	title        = {Dual contouring of hermite data},
	author       = {Tao Ju and Frank Losasso and Scott Schaefer and Joe Warren},
	year         = 2002,
	journal      = {Proceedings of the 29th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH '02},
	pages        = {339--346},
	doi          = {10.1145/566570.566586},
	isbn         = 1581135211,
	abstract     = {This paper describes a new method for contouring a signed grid whose edges are tagged by Hermite data (i.e; exact intersection points and normals). This method avoids the need to explicitly identify and process "features" as required in previous Hermite contouring methods. Using a new, numerically stable representation for quadratic error functions, we develop an octree-based method for simplifying contours produced by this method. We next extend our contouring method to these simpli\textsterling{}ed octrees. This new method imposes no constraints on the octree (such as being a restricted octree) and requires no "crack patching". We conclude with a simple test for preserving the topology of the contour during simplification. Copyright \textcopyright{} 2002 by the Association for Computing Machinery, Inc.},
	keywords     = {contouring,crack prevention,implicit functions,polyhedral simplification,quadratic error functions}
}
@phdthesis{Adams2002a,
	title        = {Automatic Generation of Dungeons for Computer Games},
	author       = {David Adams},
	year         = 2002,
	pages        = 60,
	url          = {http://www.dcs.shef.ac.uk/intranet/teaching/public/projects/archive/ug2002/pdf/u9da.pdf},
	abstract     = {The genre of dungeon games, or first-person shooter games as they are more commonly known, has emerged over the last ten years to become one of the most popular types of computer game. At present, the levels in this type of game are generated manually, which is a very expensive and time-consuming process for games companies. If levels could be generated automatically then this would not only reduce development costs, but allow levels to be generated at run-time, giving game players a new playing experience each time a game was played and greatly improving the replayability of the game. In this project, a technique known as graph grammars will be used in order to allow descriptions of randomly generated game levels to be created automatically. As part of the project, algorithms to assess the size, difficulty and fun-value of a level will be developed, to allow individual levels to be tailored to particular requirements. This project is being undertaken in cooperation with Infogrames.}
}
@article{Alexa2002,
	title        = {Recent advances in mesh morphing},
	author       = {Marc Alexa},
	year         = 2002,
	journal      = {Computer Graphics Forum},
	volume       = 21,
	pages        = {173--198},
	doi          = {10.1111/1467-8659.00575},
	issn         = {01677055},
	abstract     = {Meshes have become a widespread and popular representation of models in computer graphics. Morphing techniques aim at transforming a given source shape into a target shape. Morphing techniques have various applications ranging from special effects in television and movies to medical imaging and scientific visualization. Not surprisingly, morphing techniques for meshes have received a lot of interest lately. This work sums up recent developments in the area of mesh morphing. It presents a consistent framework to classify and compare various techniques approaching the same underlying problems from different angles.},
	issue        = 2
}
@article{Davis2002b,
	title        = {Analysis and recognition of walking movements},
	author       = {James W. Davis and Stephanie R. Taylor},
	year         = 2002,
	journal      = {Proceedings - International Conference on Pattern Recognition},
	volume       = 16,
	pages        = {315--318},
	doi          = {10.1109/icpr.2002.1044702},
	issn         = 10514651,
	url          = {https://sci-hub.mksa.top/10.1109/icpr.2002.1044702},
	abstract     = {We present an approach for recognizing human walking movements using low-level motion regularities and constraints. Biomechanical features for classification are automatically extracted from video sequences of walkers. A multiplicative classification rule using statistical distances is then used to determine whether an unknown motion is consistent with normal walking patterns. Recognition results are shown distinguishing walking examples across multiple speeds from other non-walking locomotions. \textcopyright{} 2002 IEEE.},
	issue        = 1
}
@article{Lee2002,
	title        = {Gait analysis for recognition and classification},
	author       = {L. Lee and W. E.L. Grimson},
	year         = 2002,
	journal      = {Proceedings - 5th IEEE International Conference on Automatic Face Gesture Recognition, FGR 2002},
	publisher    = {IEEE},
	pages        = {155--162},
	doi          = {10.1109/AFGR.2002.1004148},
	isbn         = {0769516025},
	abstract     = {This paper describes a representation of gait appearance for the purpose of person identification and classification. This gait representation is based on simple features such as moments extracted from orthogonal view video silhouettes of human walking motion. Despite its simplicity, the resulting feature vector contains enough information to perform well on human identification and gender classification tasks. We explore the recognition behaviors of two different methods to aggregate features over time under different recognition tasks. We demonstrate the accuracy of recognition using gait video sequences collected over different days and times and under varying lighting environments. In addition, we show results for gender classification based our gait appearance features using a support-vector machine. \textcopyright{} 2002 IEEE.},
	issue        = {Mld}
}
@techreport{Ayala,
	title        = {Fast Connected Component Labeling Algorithm : A non voxel-based approach},
	author       = {D. Ayala and J. Rodr\'{\i}guez and A. Aguilera},
	year         = 2002,
	month        = 3,
	journal      = {Faces},
	url          = {https://upcommons.upc.edu/bitstream/handle/2117/97534/R02-26.pdf},
	keywords     = {connected component labeling,image understanding,volume visualization}
}
@phdthesis{Karwolowski2002,
	title        = {Improving the Process of Plant Modeling : The L + C Modeling Language},
	author       = {Radoslaw Mateusz Karwolowski},
	year         = 2002,
	url          = {http://algorithmicbotany.org/papers/radekk.dis2002.pdf},
	institution  = {University of Calgary}
}
@article{Fradin2002,
	title        = {Partition de l'espace et hi\'{e}rarchie de cartes g\'{e}n\'{e}ralis\'{e}es : application aux complexes architecturaux},
	author       = {David Fradin and Daniel Meneveaux and Pascal Lienhardt},
	year         = 2002,
	journal      = {Actes des journ\'{e}es AFIG - Association Fran\c{c}aise d'Informatique Graphique},
	pages        = {199--210},
	url          = {http://xlim-sic.labo.univ-poitiers.fr/mr-archi/papers/Modeleur - AFIG2002.pdf},
	keywords     = {gmaps}
}
@inbook{Karavelas2002,
	title        = {Dynamic Additively Weighted Voronoi Diagrams in 2D},
	author       = {Menelaos I. Karavelas and Mariette Yvinec},
	year         = 2002,
	pages        = {586--598},
	doi          = {10.1007/3-540-45749-6_52},
	url          = {http://link.springer.com/10.1007/3-540-45749-6_52}
}
@techreport{Barthe2002,
	title        = {Different applications of two-dimensional potential fields for volume modeling},
	author       = {Lo\"{\i}c Barthe and N A Dodgson and M A Sabin and Brian Wyvill and V Gaildrat},
	year         = 2002,
	doi          = {10.48456/tr-541},
	url          = {https://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-541.pdf},
	institution  = {University of Cambridge, Computer Laboratory}
}
@article{Karpenko2002,
	title        = {Free-form sketching with variational implicit surfaces},
	author       = {Olga Karpenko and John F. Hughes and Ramesh Raskar},
	year         = 2002,
	journal      = {Computer Graphics Forum},
	volume       = 21,
	pages        = {585--594},
	doi          = {10.1111/1467-8659.00709},
	issn         = {0167-7055},
	issue        = 3
}
@article{Boissonnat2002,
	title        = {Smooth surface reconstruction via natural neighbour interpolation of distance functions},
	author       = {Jean Daniel Boissonnat and Fr\'{e}d\'{e}ric Gazais},
	year         = 2002,
	journal      = {Computational Geometry: Theory and Applications},
	volume       = 22,
	pages        = {185--203},
	doi          = {10.1016/S0925-7721(01)00048-7},
	isbn         = 1581132247,
	issn         = {09257721},
	url          = {https://dl.acm.org/doi/pdf/10.1145/336154.336208},
	abstract     = {We present an algorithm to reconstruct smooth surfaces of arbitrary topology from unorganised sample points and normals. The method uses natural neighbour interpolation, works in any dimension and accommodates nonuniform samples. The reconstructed surface interpolates the data points and is implicitly represented as the zero set of some pseudo-distance function. It can be meshed so as to satisfy a user-defined error bound, which makes the method especially relevant for small point sets. Experimental results are presented for surfaces in \mathbb{R}3. \textcopyright{}2001 Elsevier Science B.V. All rights reserved.},
	issue        = {1-3},
	keywords     = {Delaunay triangulation,Natural neighbour interpolation,Reconstruction,Smooth surface,Voronoi diagram}
}
@article{Berger2002,
	title        = {Towards a standard for the individual-based modeling of plant populations: Self-thinning and the field-of-neighborhood approach},
	author       = {Uta Berger and Hanno Hildenbrandt and Volker Grimm},
	year         = 2002,
	journal      = {Natural Resource Modeling},
	volume       = 15,
	pages        = {39--54},
	doi          = {10.1111/j.1939-7445.2002.tb00079.x},
	issn         = 19397445,
	abstract     = {In classical theoretical ecology there are numerous standard models which are simple, generally applicable, and have well-known properties. These standard models are widely used as building blocks for all kinds of theoretical and applied models. In contrast, there is a total lack of standard individual-based models (IBM's), even though they are badly needed if the advantages of the individual-based approach are to be exploited more efficiently. We discuss the recently developed `field-of-neighborhood' approach as a possible standard for modeling plant populations. In this approach, a plant is characterized by a circular zone of influence that grows with the plant, and a field of neighborhood that for each point within the zone of influence describes the strength of competition, i.e., growth reduction, on neighboring plants. Local competition is thus described phenomenologically. We show that a model of mangrove forest dynamics, KiWi, which is based on the FON approach, is capable of reproducing self-thinning trajectories in an almost textbook-like manner. In addition, we show that the entire biomass-density trajectory (bdt) can be divided into four sections which are related to the skewness of the stem diameter distributions of the cohort. The skewness shows two zero crossings during the complete development of the population. These zero crossings indicate the beginning and the end of the self-thinning process. A characteristic decay of the positive skewness accompanies the occurrence of a linear bdt section, the well-known self-thinning line. Although the slope of this line is not fixed, it is confined in two directions, with morphological constraints determining the lower limit and the strength of neighborhood competition exerted by the individuals marking the upper limit. \textcopyright{} 2002 Rocky Mountain Mathematics Consortium.},
	issue        = 1,
	keywords     = {Field of neighborhood,Individual-based model,Mangrove,Phenomenological description,Plant population,Self-thinning,Skewed size distribution,Standard model}
}
@article{Cutler2002,
	title        = {A procedural approach to authoring solid models},
	author       = {Barbara Cutler and Julie Dorsey and Leonard McMillan and Matthias M\"{u}ller and Robert Jagnow},
	year         = 2002,
	journal      = {ACM Transactions on Graphics},
	volume       = 21,
	pages        = {302--311},
	doi          = {10.1145/566654.566581},
	isbn         = 1581135211,
	issn         = {07300301},
	abstract     = {We present a procedural approach to authoring layered, solid models. Using a simple scripting language, we define the internal structure of a volume from one or more input meshes. Sculpting and simulation operators are applied within the context of the language to shape and modify the model. Our framework treats simulation as a modeling operator rather than simply as a tool for animation, thereby suggesting a new paradigm for modeling as well as a new level of abstraction for interacting with simulation environments. Capturing real-world effects with standard modeling techniques is extremely challenging. Our key contribution is a concise procedural approach for seamlessly building and modifying complex solid geometry. We present an implementation of our language using a flexible tetrahedral representation. We show a variety of complex objects modeled in our system using tools that interface with finite element method and particle system simulations.},
	issue        = 3,
	keywords     = {Signed-distance function,Tetrahedral representation,Volumetric modeling}
}
@article{Hornby2002,
	title        = {Creating high-level components with a generative representation for body-brain evolution.},
	author       = {Gregory S. Hornby and Jordan B. Pollack},
	year         = 2002,
	journal      = {Artificial life},
	volume       = 8,
	pages        = {223--246},
	doi          = {10.1162/106454602320991837},
	issn         = 10645462,
	abstract     = {One of the main limitations of scalability in body-brain evolution systems is the representation chosen for encoding creatures. This paper defines a class of representations called generative representations, which are identified by their ability to reuse elements of the genotype in the translation to the phenotype. This paper presents an example of a generative representation for the concurrent evolution of the morphology and neural controller of simulated robots, and also introduces GENRE, an evolutionary system for evolving designs using this representation. Applying GENRE to the task of evolving robots for locomotion and comparing it against a non-generative (direct) representation shows that the generative representation system rapidly produces robots with significantly greater fitness. Analyzing these results shows that the generative representation system achieves better performance by capturing useful bias from the design space and by allowing viable large scale mutations in the phenotype. Generative representations thereby enable the encapsulation, coordination, and reuse of assemblies of parts.},
	issue        = 3,
	keywords     = {body-brain evolution,generative},
	pmid         = 12537684
}
@article{Reynolds2002,
	title        = {Steering Behaviors For Autonomous Characters Steering Behaviors For Autonomous Characters},
	author       = {Craig W Reynolds},
	year         = 2002,
	pages        = {1--14},
	url          = {http://www.red3d.com/cwr/steer/gdc99/},
	abstract     = {This paper presents solutions for one requirement of autonomous characters in animation and games: the ability to navigate around their world in a lifelike and improvisational manner. These "steering behaviors" are largely independent of the particulars of the character's means of locomotion. Combinations of steering behaviors can be used to achieve higher level goals (For example: get from here to there while avoiding obstacles, follow this corridor, join that group of characters...) This paper divides motion behavior into three levels. It will focus on the middle level of steering behaviors, briefly describe the lower level of locomotion, and touch lightly on the higher level of goal setting and strategy.},
	keywords     = {animation techniques,artificial life,autonomous agent,behavioral animation,collision avoidance,embodied,evasion,flocking,games,group behavior,interactive environments,navigation,obstacle avoidance,path following,path planning,pursuit,reactive,simulation,situated,steering,vehicle,virtual}
}
@inbook{Ballet2002,
	title        = {Course on Cellular Automata, Reaction-Diffusion and Multiagents Systems for Artificial Cell Modeling},
	author       = {Pascal Ballet and Abdallah Zemirline and Lionel Marc\'{e} and Gilles Bernot and Franck Delaplace and Jean-Louis Giavitto and Olivier Michel and Jean-Marc Delosme and Patrick Amar and Roberto Incitti and Paul Bourgine and Christophe Godin and Fran\c{c}ois K\'{e}p\`{e}s and Philippe Tracqui and Vic Norris and Janine Guespin and Maurice Demarty and Camille Ripoll},
	year         = 2002,
	booktitle    = {Modelling and simulation of biological processes in the context of genomics},
	pages        = {257--280}
}
@article{Milliron2002,
	title        = {A framework for geometric warps and deformations},
	author       = {Tim Milliron and Robert J. Jensen and Ronen Barzel and Adam Finkelstein},
	year         = 2002,
	month        = 1,
	journal      = {ACM Transactions on Graphics},
	volume       = 21,
	pages        = {20--51},
	doi          = {10.1145/504789.504791},
	issn         = {0730-0301},
	url          = {https://dl.acm.org/doi/10.1145/504789.504791},
	abstract     = {<p> We present a framework for geometric warps and deformations. The framework provides a conceptual and mathematical foundation for analyzing known warps and for developing new warps, and serves as a common base for many warps and deformations. Our framework is composed of two components: a generic modular algorithm for warps and deformations; and a concise, geometrically meaningful formula that describes how warps are evaluated. Together, these two elements comprise a complete framework useful for analyzing, evaluating, designing, and implementing deformation algorithms. While the framework is independent of user-interfaces and geometric model representations and is formally capable of describing <italic>any</italic> warping algorithm, its design is geared toward the most prevalent class of user-controlled deformations: those computed using geometric operations. To demonstrate the expressive power of the framework, we cast several well-known warps in terms of the framework. To illustrate the framework's usefulness for analyzing and modifying existing warps, we present variations of these warps that provide additional functionality or improved behavior. To show the utility of the framework for developing new warps, we design a novel 3-D warping algorithm: a <italic>mesh warp</italic> ---useful as a modeling and animation tool---that allows users to deform a detailed surface by manipulating a low-resolution mesh of similar shape. Finally, to demonstrate the mathematical utility of the framework, we use the framework to develop guarantees of several mathematical properties such as commutativity and continuity for large classes of deformations. </p>},
	issue        = 1,
	keywords     = {Algorithms Additional Key Words and Phrases,Categories and Subject Descriptors,Deformation,I33 [Computer Graphics],Picture/Image Generation General Terms,warp}
}
@book{LeVeque2002,
	title        = {Finite Volume Methods for Hyperbolic Problems},
	author       = {Randall J. LeVeque},
	year         = 2002,
	month        = 8,
	publisher    = {Cambridge University Press},
	doi          = {10.1017/CBO9780511791253},
	isbn         = 9780521810876,
	url          = {https://www.cambridge.org/core/product/identifier/9780511791253/type/book}
}
@inproceedings{Lane2002,
	title        = {Generating Spatial Distributions for Multilevel Models of Plant Communities},
	author       = {Brendan Lane and Przemyslaw Prusinkiewicz},
	year         = 2002,
	month        = 5,
	booktitle    = {Proceedings of the Graphics Interface 2002 Conference},
	pages        = {69--80},
	doi          = {10.20380/GI2002.09},
	abstract     = {The simulation and visualization of large groups of plants has many applications. The extreme visual complexity of the resulting scenes can be captured using mul-tilevel models. For example, in two-level models, plant distributions may be determined using coarse plant representations , and realistic visualizations may be obtained by substituting detailed plant models for the coarse ones. In this paper, we focus on the coarse aspect of model-ing, the specification of plant distribution. We consider two classes of models: local-to-global models, rooted in the individual-based ecosystem simulations, and inverse , global-to-local models, in which positions of individual plants are inferred from a given distribution of plant densities. We extend previous results obtained using both classes of models with additional phenomena, including clustering and succession of plants. We also introduce the formalism of multiset L-systems to formalize the individual-based simulation models. 1 Introduction The simulation and visualization of plant ecosystems has many theoretical and practical applications. They include fundamental research in ecology, visual impact analysis of forestry practices, and synthesis of complex scenery for computer animations, among others. The inherent complexity of the scenes resulting from the ecosystem simulations can be managed using the multilevel approach to modeling [3]. Rather than model the entire ecosystem at the detailed level of plant organs, such as leaves, flowers, apices, and internodes [13], the multi-level approach employs a hierarchy of models. For example , in the simplest, two-level case, a high-level model determines the distribution of the plants, and lower-level models determine the plants' shapes. The models are coupled so that information created at a higher level can affect the outcome of the model at the lower level.},
	keywords     = {clustering,multilevel model-ing,multiset L-system,plant ecosystem,realistic image synthesis,spatial distribution,suc-cession}
}
@article{Bauer2002,
	title        = {Cyclic dynamics in simulated plant populations},
	author       = {Silke Bauer and Uta Berger and Hanno Hildenbrandt and Volker Grimm},
	year         = 2002,
	month        = 12,
	journal      = {Proceedings of the Royal Society B: Biological Sciences},
	publisher    = {Royal Society},
	volume       = 269,
	pages        = {2443--2450},
	doi          = {10.1098/rspb.2002.2186},
	issn         = 14712970,
	abstract     = {Despite the general interest in nonlinear dynamics in animal populations, plant populations are supposed to show a stable equilibrium that is attributed to fundamental differences compared with animals. Some studies find more complex dynamics, but empirical studies usually are too short and most modelling studies ignore important spatial aspects of local competition and establishment. Therefore, we used a spatially explicit individual-based model of a hypothetical, non-clonal perennial to explore which mechanisms might generate complex dynamics, i.e. cycles. The model is based on the field-of-neighbourhood approach that describes local competition and establishment in a phenomenological manner. We found cyclic population dynamics for a wide spectrum of model variants, provided that mortality is determined by local competition and recruitment is virtually completely suppressed within the zone of influence of established plants. This destabilizing effect of local processes within plant populations might have wide-ranging implications for the understanding of plant community dynamics and coexistence.},
	issue        = 1508,
	keywords     = {Field-of-neighbourhood model,Nonlinear dynamics,Oscillations,Recruitment,Spatial effects}
}
@article{Helbostad2003,
	title        = {The effect of gait speed on lateral balance control during walking in healthy elderly},
	author       = {Jorunn L. Helbostad and Rolf Moe-Nilssen},
	year         = 2003,
	month        = 10,
	journal      = {Gait and Posture},
	publisher    = {Elsevier},
	volume       = 18,
	pages        = {27--36},
	doi          = {10.1016/S0966-6362(02)00197-2},
	issn         = {09666362},
	abstract     = {The aim of this paper was to investigate the effect of speed dependency on lateral gait parameters. In 36 healthy elderly (mean age=72.5 years, S.D.=3.2 years), walking at four different self-administered speeds, mediolateral trunk acceleration and step width (SW), but not step-width variability (SWV), were found to have quadratic relations to gait speed. Normalizing for speed by curvilinear interpolation, and controlling for subject characteristics, disclosed smaller SW (adjusted R2=0.41, P<0.001), but larger SWV (adjusted R2=0.26, P=0.01) with increasing age in multiple regression models. These relations were camouflaged at preferred speed. \textcopyright{} 2002 Elsevier Science B.V. All rights reserved.},
	issue        = 2,
	keywords     = {Gait speed,Healthy elderly,Lateral balance control,Mediolateral trunk acceleration,Step width,Step-width variability},
	pmid         = 14654205
}
@inbook{Chellappa2003,
	title        = {Gait Analysis for Human Identification},
	author       = {A. Kale and N. Cuntoor and B. Yegnanarayana and A.N. Rajagopalan and R. Chellappa},
	year         = 2003,
	pages        = {706--714},
	doi          = {10.1007/3-540-44887-X_82},
	url          = {http://link.springer.com/10.1007/3-540-44887-X_82},
	abstract     = {Human gait is an attractive modality for recognizing people at a distance. In this paper we adopt an appearance-based approach to the problem of gait recognition. The width of the outer contour of the binarized silhouette of a walking person is chosen as the basic image feature. Different gait features are extracted from the width vector such as the dowsampled, smoothed width vectors, the velocity profile etc. and sequences of such temporally ordered feature vectors are used for representing a person's gait. We use the dynamic time-warping (DTW) approach for matching so that non-linear time normalization may be used to deal with the naturally-occuring changes in walking speed. The performance of the proposed method is tested using different gait databases.}
}
@inproceedings{Greuter2003,
	title        = {Real-time procedural generation of `pseudo infinite' cities},
	author       = {Stefan Greuter and Jeremy Parker and Nigel Stewart and Geoff Leach},
	year         = 2003,
	booktitle    = {Proceedings of the 1st international conference on Computer graphics and interactive techniques in Austalasia and South East Asia  - GRAPHITE '03},
	publisher    = {ACM Press},
	pages        = 87,
	doi          = {10.1145/604487.604490},
	isbn         = 1581135785,
	url          = {http://portal.acm.org/citation.cfm?doid=604471.604490},
	abstract     = {We present an approach to procedural generation of pseudo infinite virtual cities in real-time. The cities contain geometrically varied buildings that are generated as needed. The building generation parameters are created by a pseudo random number generator, seeded with an integer derived from the buildings position. The varied building geometries are extruded from a set of floor plans. The floor plans for each building are created by combining randomly generated polygons in an iterative process. A display list caching and frustum filling approach manages the generation of buildings and the use of system resources. This approach has been implemented on commodity PC hardware, resulting in interactive frame rates.},
	city         = {New York, New York, USA},
	keywords     = {architecture,frustum filling,lru caching,procedural generation,real-time,view}
}
@article{Muller2003,
	title        = {Particle-based fluid simulation for interactive applications},
	author       = {Matthias M\"{u}ller and David Charypar and Markus Gross},
	year         = 2003,
	journal      = {Proceedings of the 2003 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA 2003},
	isbn         = 1581136595,
	abstract     = {Realistically animated fluids can add substantial realism to interactive applications such as virtual surgery simulators or computer games. In this paper we propose an interactive method based on Smoothed Particle Hydrodynamics (SPH) to simulate fluids with free surfaces. The method is an extension of the SPH-based technique by Desbrun to animate highly deformable bodies. We gear the method towards fluid simulation by deriving the force density fields directly from the Navier-Stokes equation and by adding a term to model surface tension effects. In contrast to Eulerian grid-based approaches, the particle-based approach makes mass conservation equations and convection terms dispensable which reduces the complexity of the simulation. In addition, the particles can directly be used to render the surface of the fluid. We propose methods to track and visualize the free surface using point splatting and marching cubes-based surface reconstruction. Our animation method is fast enough to be used in interactive systems and to allow for user interaction with models consisting of up to 5000 particles.}
}
@article{Stam2003a,
	title        = {Real-Time Fluid Dynamics for Games},
	author       = {Jos Stam},
	year         = 2003,
	journal      = {Proceedings of the Game Developer Conference},
	volume       = 18,
	pages        = 17,
	issn         = {09574174},
	url          = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.12.6736&amp;rep=rep1&amp;type=pdf},
	abstract     = {In this paper we present a simple and rapid implementation of a fluid dynamics solver for game engines. Our tools can greatly enhance games by providing realistic fluid-like effects such as swirling smoke past a moving character. The potential applications are endless. Our algorithms are based on the physical equations of fluid flow, namely the Navier-Stokes equations. These equations are notoriously hard to solve when strict physical accuracy is of prime importance. Our solvers on the other hand are geared towards visual quality. Our emphasis is on stability and speed, which means that our simulations can be advanced with arbitrary time steps. We also demonstrate that our solvers are easy to code by providing a complete C code implementation in this paper. Our algorithms run in real-time for reasonable grid sizes in both two and three dimensions on standard PC hardware, as demonstrated during the presentation of this paper at the conference.},
	issue        = 11
}
@article{Stam2003,
	title        = {Flows on surfaces of arbitrary topology},
	author       = {Jos Stam},
	year         = 2003,
	journal      = {ACM Transactions on Graphics},
	volume       = 22,
	pages        = {724--731},
	doi          = {10.1145/882262.882338},
	issn         = {07300301},
	abstract     = {In this paper we introduce a method to simulate fluid flows on smooth surfaces of arbitrary topology: an effect never seen before. We achieve this by combining a two-dimensional stable fluid solver with an atlas of parametrizations of a Catmull-Clark surface. The contributions of this paper are: (i) an extension of the Stable Fluids solver to arbitrary curvilinear coordinates, (ii) an elegant method to handle cross-patch boundary conditions and (iii) a set of new external forces custom tailored for surface flows. Our techniques can also be generalized to handle other types of processes on surfaces modeled by partial differential equations, such as reaction-diffusion. Some of our simulations allow a user to interactively place densities and apply forces to the surface, then watch their effects in real-time. We have also computed higher resolution animations of surface flows off-line. \textcopyright{} 2003 ACM.},
	issue        = 3,
	keywords     = {Computational fluid dynamics,Subdivision Surfaces}
}
@article{Ugail2003,
	title        = {Efficient shape parametrisation for automatic design optimisation using a partial differential equation formulation},
	author       = {H. Ugail and M. J. Wilson},
	year         = 2003,
	journal      = {Computers and Structures},
	volume       = 81,
	pages        = {2601--2609},
	doi          = {10.1016/S0045-7949(03)00321-3},
	issn         = {00457949},
	url          = {https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.488.6400&rep=rep1&type=pdf},
	abstract     = {This paper presents a methodology for efficient shape parametrisation for automatic design optimisation using a partial differential equation (PDE) formulation. It is shown how the choice of an elliptic PDE enables one to define and parametrise geometries corresponding to complex shapes. By using the PDE formulation it is shown how the shape definition and parametrisation can be based on a boundary value approach by which complex shapes can be created and parametrised based on the shape information at the boundaries or the character lines defining the shape. Furthermore, this approach to shape definition allows complex shapes to be parametrised intuitively using a very small set of design parameters. Thus, it is shown that the PDE based approach to shape parametrisation when combined with a standard method for numerical optimisation is capable of setting up automatic design optimisation problems allowing practical design optimisation to be more feasible. \textcopyright{} 2003 Elsevier Ltd. All rights reserved.},
	issue        = {28-29},
	keywords     = {Automatic optimisation,PDEs,Parametric design,Shape parametrisation}
}
@book{Prusinkiewicz2003,
	title        = {L-systems and beyond},
	author       = {Przemyslaw Prusinkiewicz and Pavol Federl},
	year         = 2003,
	journal      = {Course notes from \ldots{}},
	url          = {http://scholar.google.com/scholar?hl=en&btnG=Search&q=intitle:L-systems+and+Beyond#0%5Cnhttp://scholar.google.com/scholar?hl=en&btnG=Search&q=intitle:L-systems+and+beyond#0},
	edition      = {SIGGRAPH Course}
}
@article{Belytschko2018,
	title        = {Structured extended finite element methods for solids defined by implicit surfaces},
	author       = {Ted Belytschko and Chandu Parimi and Nicolas Mo\"{e}s and N. Sukumar and Shuji Usui},
	year         = 2003,
	month        = 1,
	journal      = {International Journal for Numerical Methods in Engineering},
	volume       = 56,
	pages        = {609--635},
	doi          = {10.1002/nme.686},
	issn         = {0029-5981},
	url          = {https://onlinelibrary.wiley.com/doi/10.1002/nme.686},
	abstract     = {<p>A paradigm is developed for generating structured finite element models from solid models by means of implicit surface definitions. The implicit surfaces are defined by radial basis functions. Internal features, such as material interfaces, sliding interfaces and cracks are treated by enrichment techniques developed in the extended finite element method. Methods for integrating the weak form for such models are proposed. These methods simplify the generation of finite element models. Results presented for several examples show that the accuracy of this method is comparable to standard unstructured finite element methods. Copyright \textcopyright{} 2002 John Wiley \&amp; Sons, Ltd.</p>},
	issue        = 4
}
@article{Klette,
	title        = {Combinatorics on Adjacency Graphs and Incidence Pseudographs},
	author       = {Reinhard Klette},
	year         = 2003,
	month        = 3,
	journal      = {Electronic Notes in Discrete Mathematics},
	volume       = 12,
	pages        = {302--324},
	doi          = {10.1016/S1571-0653(04)00495-0},
	issn         = 15710653,
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S1571065304004950}
}
@article{Ershov2003,
	title        = {LGS: Geometric constraint solver},
	author       = {Alexey Ershov and Ilia Ivanov and Serge Preis and Eugene Rukoleev and Dmitry Ushakov},
	year         = 2003,
	journal      = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume       = 2890,
	pages        = {423--430},
	doi          = {10.1007/978-3-540-39866-0_42},
	issn         = {03029743},
	url          = {https://www.cs.purdue.edu/homes/cmh/distribution/papers/Constraints/CAD95.pdf},
	abstract     = {In the paper we present LGS - a geometric constraint solver developed, at LEDAS Ltd. We review different approaches in geometric constraint solving, present our one, describe in details LGS architecture and the ideas behind it. The main idea of LGS is to decompose the initial problem into a set of simpler ones, to map each instance to a class of problems, and to apply a specialized algorithm to each class. We emphasize key differences of our approach: extendible hierarchy of problem classes, new decomposition techniques, a broad range of numerical algorithms. \textcopyright{} Springer-Verlag Berlin Heidelberg 2003.},
	issue        = {January 1994}
}
@article{Ito2003,
	title        = {Modeling rocky scenery taking into account joints},
	author       = {T. Ito and T. Fujimoto and K. Muraoka and N. Chiba},
	year         = 2003,
	journal      = {Proceedings of Computer Graphics International Conference, CGI},
	volume       = {2003-Janua},
	pages        = {244--247},
	doi          = {10.1109/CGI.2003.1214475},
	isbn         = {0769519466},
	issn         = 15301052,
	abstract     = {Research on methods for representing natural objects and phenomena by computer graphics (CG) has been steadily broadening the scope of represented objects in recent years. Among such research, visual simulation of rocky scenery is an important issue that has a wide range of applications related to visual contents, such as in landscape simulation. In the early days of research on terrain scenery representation, a great deal of techniques for representing terrain shapes and rocky textures mainly using noise generation methods such as the midpoint displacement method and FFT were reported. In the natural rocky scenery, cracks called "joints" are an important visual feature. After cracking base rocks by joints, the change of the rock shapes according to some factors, such as eliminating rock pieces by weathering or moving by gravity, determines the consequent rocky scenery. In order to create such rocky scenery, we propose a rocky scenery modelling method based on joint formation and rock elimination/movement simulation.},
	issue        = {July 2014},
	keywords     = {Character generation,Chemicals,Computational modeling,Computer graphics,Indium tin oxide,Noise generators,Noise shaping,Shape,Surface cracks,Surface topography}
}
@article{Kundu2003,
	title        = {Random Generation of Combinatorial Structures using Context-Fee Grammars},
	author       = {Sukhamay Kundu},
	year         = 2003,
	journal      = {Electronic Notes in Discrete Mathematics},
	volume       = 15,
	pages        = 114,
	doi          = {10.1016/S1571-0653(04)00551-7},
	issn         = 15710653,
	abstract     = {The problem of computing a random combinatorial structure such as balanced strings, trees, and flowcharts arises in a variety of applications, including the evaluation of heuristic algorithms which use these structures. The main challenge here is to assure that each instance of the possible structure has the same probability of selection. A brute-force method of first creating a list of all instances of the structure with a given size, say, and then choosing one from the list at random is typically impractical because of the very large number of instances. We provide here a unified approach, using context-free grammars as a backbone for defining the desired combinatorial structure, for efficiently generating a random instance of that structure. The algorithm typically takes a linear or quadractic amount of time in the size of the structure, following some initial computations which is also polynomial in the size of the structure. \textcopyright{} 2005 Elsevier Ltd. All rights reserved.}
}
@article{Theisel2003,
	title        = {Compression of 2D Vector Fields Under Guaranteed Topology Preservation},
	author       = {H. Theisel and Ch R\"{o}ssl and H. P. Seidel},
	year         = 2003,
	journal      = {Computer Graphics Forum},
	volume       = 22,
	pages        = {333--342},
	doi          = {10.1111/1467-8659.00680},
	issn         = {01677055},
	url          = {https://domino.mpi-inf.mpg.de/intranet/ag4/ag4publ.nsf/93832a04987390a3c12567530068622d/21fe90c7c981a5e3c1256d050047db4b/$file/theiselroesslseidel03a.pdf},
	abstract     = {In this paper we introduce a new compression technique for 2D vector fields which preserves the complete topology, i.e., the critical points and the connectivity of the separatrices. As the theoretical foundation of the algorithm, we show in a theorem that for local modifications of a vector field, it is possible to decide entirely by a local analysis whether or not the global topology is preserved. This result is applied in a compression algorithm which is based on a repeated local modification of the vector field - namely a repeated edge collapse of the underlying piecewise linear domain. We apply the compression technique to a number of data sets with a complex topology and obtain significantly improved compression ratios in comparison to pre-existing topology-preserving techniques.},
	issue        = 3,
	keywords     = {Data visualization,Flow visualization,Vector field compression,Vector field topology}
}
@article{DeKemp2003,
	title        = {Interpretive tools for 3-D structural geological modeling part I: B\'{e}zier-based curves, ribbons and grip frames},
	author       = {Eric A. De Kemp and Kevin Boyce Sprague},
	year         = 2003,
	journal      = {GeoInformatica},
	volume       = 7,
	pages        = {55--71},
	doi          = {10.1023/A:1022822227691},
	issn         = 13846175,
	abstract     = {Interpreting the geometry of geological objects is a standard activity of field-based geologists. We present new graphics tools that will aid in extending this activity from 2-D geological mapping into a 3-D environment. Much of the existing 3-D geological modeling software supports the construction of objects with the input of dense control data. However, for regional mapping and near mine exploration work, sparse data is the norm. Tools are required therefore, which give the expert interpreter full control of the graphics objects, while at the same time constraining interpretations to specific control data from field observations. We present the initial results of a software design and programming project for the visualization of complex regional scale geologic objects using B\'{e}zier-based graphics tools that are optimized for sparse data interpretation. We also introduce the concept of a structural ribbon, which is a 3-D extended map trace, along with methods for the optimization of surface construction using graphical grip frames.},
	issue        = 1,
	keywords     = {3-D B\'{e}zier,Grip frames,Interpolation,Ribbons,Structural geology,Surface modeling}
}
@article{Lemon2003,
	title        = {Building solid models from boreholes and user-defined cross-sections},
	author       = {Alan M. Lemon and Norman L. Jones},
	year         = 2003,
	journal      = {Computers and Geosciences},
	volume       = 29,
	pages        = {547--555},
	doi          = {10.1016/S0098-3004(03)00051-7},
	issn         = {00983004},
	url          = {https://scholarsarchive.byu.edu/cgi/viewcontent.cgi?article=5237&context=facpub},
	abstract     = {Solid models of geologic structures are useful tools for geologists and engineers. Solid models completely and unambiguously define the stratigraphy for the site being modeled, including complex boundaries and embedded seams. Past research has focused on the "set operations" approach to create solid models. Whereas the set operations approach is flexible, it requires significant user intervention and is therefore difficult to use. A simple approach for generating solid models from borehole data, called the horizons method, is presented. The horizons method can be used to build solids directly from borehole data with minimal user intervention. The user first assigns horizon ids to each of the borehole contacts. The horizon ids represent the depositional sequence and increase from the bottom to the top of the boreholes. The solids are then built by interpolating each of the surfaces defined by the horizons and extruding the surface into a solid. In each case, the solid is built by extruding the solid from the current surface down to the uppermost surface defined by the top of all previous horizons. In cases where more control over the resulting solids is necessary, the horizons method can be easily modified to honor user-defined cross-sections in addition to the borehole data. \textcopyright{} 2003 Elsevier Science Ltd. All rights reserved.},
	issue        = 5,
	keywords     = {Cross-sections,Horizons method,Solid modeling,Stratigraphy modeling}
}
@article{Wu2003,
	title        = {An approach to computer modeling and visualization of geological faults in 3D},
	author       = {Qiang Wu and Hua Xu},
	year         = 2003,
	journal      = {Computers and Geosciences},
	volume       = 29,
	pages        = {503--509},
	doi          = {10.1016/S0098-3004(03)00018-9},
	issn         = {00983004},
	abstract     = {Computer modeling and visualization of geological faults in 3D is currently a topical research area because of its important theoretical and application value. The usual method demands enough fault data to be able to construct geological models in 3D. However, in reality, the quantity of the input data is sparse and undersampled. In this paper, we propose a novel approach to modeling faults in 3D. Following the basic properties of geological faults and by using a simple plane to simulate the fault or multiple combined planes to approximate the fault, we can deduce unknown points on a fault and implement mathematical description for the geometry of the fault. We also introduce a new technique called lag insertion and local reconstruction, and an object-oriented framework, which can carry out computer modeling and visualization of complex faults in 3D involving obverse/reverse faults and faults that terminate within geologic models. \textcopyright{} 2003 Elsevier Science Ltd. All rights reserved.},
	issue        = 4,
	keywords     = {Framework modeling,Lag insertion and local reconstruction,Modeling faults in 3D,Visualization}
}
@article{Wijns2003,
	title        = {Inverse modelling in geology by interactive evolutionary computation},
	author       = {Chris Wijns and Fabio Boschetti and Louis Moresi},
	year         = 2003,
	journal      = {Journal of Structural Geology},
	volume       = 25,
	pages        = {1615--1621},
	doi          = {10.1016/S0191-8141(03)00010-5},
	issn         = {01918141},
	url          = {https://repository.geologyscience.ru/bitstream/handle/123456789/34582/Wijn_03.pdf?sequence=1&isAllowed=y},
	abstract     = {Inverse modelling of geological processes, in the absence of established numerical criteria to act as inversion targets, requires an approach that uses human interaction to assess forward model results. The method of interactive evolutionary computation provides for the inclusion of qualitative geological expertise within a rigorous mathematical inversion scheme, by simply asking an expert user to evaluate a sequence of forward geological models. The traditional numerical misfit is replaced by a human appraisal of misfit. We use this interactive technique to successfully invert a geodynamic model for a conceptual pattern of fault spacing during crustal extension. \textcopyright{} 2003 Elsevier Science Ltd. All rights reserved.},
	issue        = 10,
	keywords     = {Faulting,Genetic algorithm,Interactive evolutionary computation,Inverse modelling}
}
@article{Belytschko2003,
	title        = {Topology optimization with implicit functions and regularization},
	author       = {T. Belytschko and S. P. Xiao and C. Parimi},
	year         = 2003,
	journal      = {International Journal for Numerical Methods in Engineering},
	volume       = 57,
	pages        = {1177--1196},
	doi          = {10.1002/nme.824},
	issn         = {00295981},
	abstract     = {Topology optimization is formulated in terms of the nodal variables that control an implicit function description of the shape. The implicit function is constrained by upper and lower bounds, so that only a band of nodal variables needs to be considered in each step of the optimization. The weak form of the equilibrium equation is expressed as a Heaviside function of the implicit function; the Heaviside function is regularized to permit the evaluation of sensitivities. We show that the method is a dual of the Bends\o{}e-Kikuchi method. The method is applied both to problems of optimizing single material and multi-material configurations; the latter is made possible by enrichment functions based on the extended finite element method that enable discontinuous derivatives to be accurately treated within an element. The method is remarkably robust and we found no instances of checkerboarding. The method handles topological merging and separation without any apparent difficulties. Copyright \textcopyright{} 2003 John Wiley \& Sons, Ltd.},
	issue        = 8,
	keywords     = {Implicit function,Topology optimization}
}
@techreport{Moenning2003,
	title        = {Fast Marching farthest point sampling for point clouds and implicit surfaces},
	author       = {Carsten Moenning and Neil A Dodgson},
	year         = 2003,
	month        = 5,
	doi          = {10.48456/tr-565},
	issn         = {1476-2986},
	url          = {http://www.cl.cam.ac.uk/http://www.cl.cam.ac.uk/TechReports/},
	abstract     = {In a recent paper [13], the Fast Marching farthest point sampling strategy (FastFPS) for planar domains and curved manifolds was introduced. The version of FastFPS for curved manifolds discussed in the paper [13] deals with surface domains in triangulated form only. Due to a restriction of the underlying Fast Marching method, the algorithm further requires the splitting of any obtuse into acute triangles to ensure the consistency of the Fast Marching approximation. In this paper, we overcome these restrictions by using M\'{e}moli and Sapiro's [11, 12] extension of the Fast Marching method to the handling of implicit surfaces and point clouds. We find that the extended FastFPS algorithm can be applied to surfaces in implicit or point cloud form without the loss of the original algorithm's computational optimality and without the need for any preprocessing.},
	issue        = {December},
	institution  = {University of Cambridge, Computer Laboratory}
}
@article{Harman2003,
	title        = {Differences in fish assemblages from different reef habitats at Hamelin Bay, south-western Australia},
	author       = {Nicole Harman and Euan S. Harvey and Gary A. Kendrick},
	year         = 2003,
	journal      = {Marine and Freshwater Research},
	volume       = 54,
	pages        = {177--184},
	doi          = {10.1071/MF02040},
	issn         = 13231650,
	abstract     = {Differences in the diversity of fish species between granite and limestone reefs, as well as high- and low-relief limestone reefs, were investigated at Hamelin Bay, south-western Australia. It was found that there were significant differences in the presence and abundance of fish species between granite reefs and limestone reefs. Granite reefs were characterized by greater numbers of Coris auricularis (western king wrasse) and Parma mccullochi (common scalyfin), whereas limestone reefs had greater numbers of the fish species Odax cyanomelas (herring cale), Pempheris klunzingeri (rough bullseye) and Kyphosus sydneyanus (common buffalo bream). A significant difference in fish diversity was also found between high-relief and low-relief limestone reefs in the same area. More species were found on the high-relief reefs than low-relief reefs. Complementing differences in fish assemblages, significant differences were found in algal assemblages from the different habitats. This was mainly owing to a dominance of Ecklonia radiata on low-relief limestone reefs. Ecklonia radiata was less dominant on granite reefs and on high-relief limestone reefs, where there was a lower overall algal biomass and a higher total number of species.},
	issue        = 2,
	keywords     = {Fish diversity,Habitat,Marine protected areas,Substrate complexity}
}
@book{Merks2003,
	title        = {Branching Growth in Stony Corals a modelling approach},
	author       = {Roeland Mattheus Hermanus Merks},
	year         = 2003,
	pages        = 158,
	isbn         = 9057761033,
	url          = {https://uva.computationalscience.nl/papers/archive/Merks2003b.pdf}
}
@article{Piller2003,
	title        = {Vertical versus horizontal growth strategies of coral framework (Tulamben, Bali, Indonesia)},
	author       = {W. E. Piller and B. Riegl},
	year         = 2003,
	journal      = {International Journal of Earth Sciences},
	volume       = 92,
	pages        = {511--519},
	doi          = {10.1007/s00531-003-0317-z},
	issn         = 14373254,
	abstract     = {Two different coral framework structures located in a shallow subtidal area on the east coast of Bali are described in this study. One structure is a typical coral carpet with a distinct internal succession of coral taxa and growth forms. It starts with a variety of coral species exhibiting massive, tabular, branching, and platy growth forms settling on volcanic boulders and cobbles. The main body of the coral carpet is composed almost monospecifically of Acropora cf. vaughani, which has filled all accommodating spaces up to the low-water sea level. Mostof this carpet died during the bleaching event of 1998 and the resultant dead Acropora framework is now capped by a platy Montipora assemblage. Some of the Acropora branches within the dead carpet, however, are still alive and display active growth. The Montipora cover protects the dead Acropora framework against mechanical and biological destruction. The few still growing Acropora branches may also contribute to the strength of the framework. The second coral framework is made up almost monogenerically of Montipora. One species of Montipora is of a laminar growth form and produces whorl-like colonies. Within this framework, only part of the Montipora colonies are dead; however, these are intensively fragmented. The fragments have been rapidly settled by a platy Montipora species, which has stabilized the fragments. In this case, the fragment shedding of the Montipora offers the opportunity for progradation of the framework on these fragments. Concerning the Acropora carpet, similar examples from the fossil record of the Miocene era of Spain and Austria have been reported.},
	issue        = 4,
	keywords     = {Acropora thicket,Actuopaleontology,Bali,Coral carpet,Coral ecology,Montipora framework}
}
@article{Hornus2003,
	title        = {Implicit Modelling Using Subdivision-curves},
	author       = {Samuel Hornus and Alexis Angelidis and Marie-paule Cani},
	year         = 2003,
	journal      = {The Visual Computer},
	volume       = 19,
	pages        = {94--104},
	url          = {https://inria.hal.science/inria-00510180v1/document}
}
@article{Wei2003,
	title        = {Blowing In the Wind},
	author       = {X Wei and Y Zhao and Z Fan and W Li and Yoakum-Stover Suzanne and Arie Kaufman},
	year         = 2003,
	journal      = {Symposium on Computer Animation},
	pages        = {75--85},
	doi          = {10.1001/jama.1974.03230380038024},
	issn         = 15383598,
	url          = {https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=de7c0de4040df7725de7d11f25f2d96258fee5b8},
	issue        = {July},
	pmid         = 4406673
}
@book{Ebert2003,
	title        = {Texturing and Modeling, A Procedural Approach},
	author       = {David S. Ebert and Darwyn Peachey and Steven Worley and John C. Hart and Kenton Musgrave and Ken Perlin and William R. Mark},
	year         = 2003,
	publisher    = {Morgan Kaufmann},
	volume       = {Third edition},
	isbn         = {978-1-55860-848-1}
}
@article{Pausas2003,
	title        = {The effect of landscape pattern on Mediterranean vegetation dynamics: A modelling approach using functional types},
	author       = {Juli G. Pausas},
	year         = 2003,
	journal      = {Journal of Vegetation Science},
	publisher    = {Wiley},
	volume       = 14,
	pages        = 365,
	doi          = {10.1658/1100-9233(2003)014[0365:teolpo]2.0.co;2},
	issn         = {1100-9233},
	abstract     = {We propose a hierarchical approach for plant functional classification in disturbed ecosystems to be used for vegetation modelling and global plant trait comparisons. Our framework is based on the persistence of plants at different levels of organization. We assume that the main parameters to determine persistence in chronically disturbed ecosystems are those related to: Individual-persistence capacity, Propagule-persistence capacity (persistence at the population level), Competitive capacity (persistence at the community level) and Dispersal capacity (persistence at the landscape level). The IPCD approach is illustrated for fire-prone and grazed ecosystems from the Mediterranean region and Australia and by assuming a binary classification of the four traits determining persistence which give a total 16 possible functional types. The IPCD framework provides a simple structured and synthetic view from which more elaborated schemes can be developed.},
	issue        = 3
}
@book{Woodroffe2003,
	title        = {Coasts: Form, process and evolution},
	author       = {Colid D. Woodroffe},
	year         = 2003,
	publisher    = {Press syndicate of the University of Cambridge},
	isbn         = {0521812542}
}
@article{Sax2003,
	title        = {Species diversity: From global decreases to local increases},
	author       = {Dov F. Sax and Steven D. Gaines},
	year         = 2003,
	month        = 11,
	journal      = {Trends in Ecology and Evolution},
	publisher    = {Elsevier Ltd},
	volume       = 18,
	pages        = {561--566},
	doi          = {10.1016/S0169-5347(03)00224-6},
	issn         = {01695347},
	abstract     = {Current patterns of global change can strongly affect biodiversity at global, regional and local scales. At global scales, habitat destruction and the introduction of exotic species are contributing to declines in species diversity. At regional and local scales, evidence for declines in diversity is mixed, and recent work suggests that diversity might commonly be increasing. In spite of these trends, considerable research continues to consider explicitly the effects of declines in diversity on processes that operate at regional and local scales (such as ecosystem functioning), without explicitly considering the converse set of questions, namely the effects of increases in diversity. Here, we examine evidence that indicates how species diversity is changing across spatial scales and argue that global decreases in diversity are commonly contrasted by increases in diversity at regional and local scales.},
	issue        = 11
}
@inproceedings{Benes2003,
	title        = {Modeling virtual ecosystems with the proactive guidance of agents},
	author       = {B. Benes and E.D. Espinosa},
	year         = 2003,
	booktitle    = {Proceedings 11th IEEE International Workshop on Program Comprehension},
	publisher    = {IEEE Comput. Soc},
	pages        = {126--131},
	doi          = {10.1109/CASA.2003.1199313},
	isbn         = {0-7695-1934-2},
	url          = {http://ieeexplore.ieee.org/document/1199313/},
	abstract     = {In mainstream geometric modeling, cultivating virtual plant ecosystems is a difficult task. Algorithms for realistic scene generation are rooted in procedural models with no explicit or poor external control. We propose that virtual ecosystems modeling may be boosted using software agents as behavioral tools. An ecosystem grows and is driven by its internal rules of development. If it is left to its own fate, it will reach stability on the edge of chaos. Agents interact with ecosystems by adding plants, cutting or killing them, watering, stepping-over, or favoring some plant species. An agent is a characterization artifact that shows proac-tive conduct and is described by its set of sensors, effectors, internal states, and habits. Habits are defined as continuous functions and allow for characterizing a wide variety of behaviors.}
}
@phdthesis{Hildenbrandt2003,
	title        = {The Field of Neighbourhood (FON) -ein ph\"{a}nomenologischer Modellansatz zur Beschreibung von Nachbarschaftsbeziehungen sessiler Organismen},
	author       = {Hanno Hildenbrandt},
	year         = 2003,
	month        = 7,
	journal      = {Ecological Modelling},
	volume       = 132,
	issn         = {03043800},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0304380000002982},
	abstract     = {In classical theoretical ecology, there are numerous standard models which are simple, generally applicable, and have well-know properties. These standard models are widely used as building blocks of all kinds of theoretical and applied models. In contrast, there are so far no standard individual-based models (IBMs), but they are badly needed to use the advantages of the individual-based approach more efficiently. In this thesis the field-of-neighborhood (FON) approach is developed as a possible standard for modeling plant populations. In this approach, a plant is characterized by a circular zone of influence which grows with the plant, and a field of neighborhood that for each point within the zone of influence describes the strength of competition, i.e. growth reduction, on neighboring plants. Local competition is thus described phenomenologically. Being firstly developed as the underlying competition model for the mangrove simulation model KiWi, the field of neighborhood approach shows the potential to describe local competition for various plant species and for sessile organisms in general.},
	city         = {Bremen},
	issue        = 3,
	institution  = {Universit\"{a}t Bremen}
}
@article{Qian2003,
	title        = {Physics-based modeling for heterogeneous objects},
	author       = {Xiaoping Qian and Debasish Dutta},
	year         = 2003,
	journal      = {Journal of Mechanical Design},
	publisher    = {American Society of Mechanical Engineers(ASME)},
	volume       = 125,
	pages        = {416--427},
	doi          = {10.1115/1.1582877},
	issn         = 10500472,
	abstract     = {Heterogeneous objects are composed of different constituent materials. In these objects, material properties from different constituent materials are synthesized into one part. Therefore, heterogeneous objects can offer new material properties and functionalities. The task of modeling material heterogeneity (composition variation) is a critical issue in the design and fabrication of such heterogeneous objects. Existing methods cannot efficiently model the material heterogeneity due to the lack of an effective mechanism to control the large number of degrees of freedom for the specification of heterogeneous objects. In this research, we provide a new approach for designing heterogeneous objects. The idea is that designers indirectly control the material distribution through the boundary conditions of a virtual diffusion problem in the solid, rather than directly in the native CAD (B-spline) representation for the distribution. We show how the diffusion problem can be solved using the B-spline shape function, with the results mapping directly to a volumetric B-Spline representation of the material distribution. We also extend this method to material property manipulation and time dependent heterogeneous object modeling. Implementation and examples, such as a turbine blade design and prosthesis design, are also presented. They demonstrate that the physics based B-spline modeling method is a convenient, intuitive, and efficient way to model object heterogeneity.},
	issue        = 3
}
@article{Hyun2004,
	title        = {The poset structures admitting the extended binary Hamming code to be a perfect code},
	author       = {Jong Yoon Hyun and Hyun Kwang Kim},
	year         = 2004,
	month        = 11,
	journal      = {Discrete Mathematics},
	publisher    = {North-Holland},
	volume       = 288,
	pages        = {37--47},
	doi          = {10.1016/j.disc.2004.07.010},
	issn         = {0012365X},
	abstract     = {Brualdi et al. introduced the concept of poset codes, and gave an example of poset structure which admits the extended binary Hamming code to be a double-error-correcting perfect P-code. Our study is motivated by this example. In this paper we classify all poset structures which admit the extended binary Hamming code to be a double or triple-error-correcting perfect P-code. \textcopyright{} 2004 Elsevier B.V. All rights reserved.},
	issue        = {1-3},
	keywords     = {Extended Hamming code,Perfect P-code,Poset codes,Strongly perfect P-code}
}
@article{Roden2004,
	title        = {From artistry to automation: A structured methodology for procedural content creation},
	author       = {Timothy Roden and Ian Parberry},
	year         = 2004,
	journal      = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume       = 3166,
	pages        = {151--156},
	doi          = {10.1007/978-3-540-28643-1_19},
	isbn         = 9783540286431,
	issn         = 16113349,
	abstract     = {Procedural techniques will soon automate many aspects of content creation for computer games. We describe an efficient, deterministic, methodology for procedurally generating 3D game content of arbitrary size and complexity. The technique progressively amplifies simple dynamically generated data structures into complex geometry. We use a procedural pipeline with a minimum set of controls at each stage to facilitate authoring. We show two examples from our research. Our terrain generator can synthesize massive 3D terrains in real-time while our level generator can be used to create indoor environments offline or in real-time. \textcopyright{} IFIP International Federation for Information Processing 2004.}
}
@article{Gille2004,
	title        = {Sea Floor Topography and Ocean Circulation},
	author       = {Sarah T. Gille and Joseph E. Metzger and Robin Tokmakjan},
	year         = 2004,
	journal      = {Oceanography},
	volume       = 17,
	abstract     = {Seafloor topoeraphu influences ocean circulation in two basic ways. First, it steers ocean flows. Second, it provides barriers that prevent deep waters from mixing, except within deep passageways that connect ocean basins or in hydraulically contrilled overflow regions. This paper explores the impact of both these processes on ocean circulation. The examples high-lighted here were among the broad range of topics explored at a workshop on "Ocean Circulation, Bathymetry~ and Climate," held at Scripps Institution of Oceanography in October 2002.},
	issue        = 1
}
@article{McNamara2004,
	title        = {Fluid control using the adjoint method},
	author       = {Antoine McNamara and Adrien Treuille and Zoran Popovi\'{c} and Jos Stam},
	year         = 2004,
	journal      = {ACM SIGGRAPH 2004 Papers, SIGGRAPH 2004},
	pages        = {449--456},
	doi          = {10.1145/1186562.1015744},
	abstract     = {We describe a novelmethod for controlling physics-based fluid simulations through gradient-based nonlinear optimization. Using a technique known as the adjoint method, derivatives can be computed efficiently, even for large 3D simulations with millions of control parameters. In addition, we introduce the first method for the full control of free-surface liquids. We show how to compute adjoint derivatives through each step of the simulation, including the fast marching algorithm, and describe a new set of control parameters specifically designed for liquids. Copyright \textcopyright{} 2004 ACM.},
	keywords     = {Adjoint method,Inverse control,Optimization}
}
@article{Olsen2004,
	title        = {Realtime procedural terrain generation},
	author       = {Jacob Olsen},
	year         = 2004,
	journal      = {Department of Mathematics And Computer Science},
	pages        = 20,
	url          = {https://pdfs.semanticscholar.org/5961/c577478f21707dad53905362e0ec4e6ec644.pdf%5Cnhttp://www.tsi.enst.fr/~bloch/P6/PRREC/terrain_generation.pdf%5Cnhttp://web.mit.edu/cesium/Public/terrain.pdf},
	abstract     = {The main goal of this paper is to provide an overview of a variety of methods for synthesis of eroded terrain for use in computer games, VR worlds and the like. Traditionally, such software uses either predefined terrains or runtime generated data based on simple fractal noise techniques. In recent years, the advances in processing power of average home computers have made it possible to simulate erosion processes near-realtime by putting emphasis on speed at the expense of physical correctness. This paper presents a fast method to synthesize natural looking fractal terrain and then proceeds to evaluate and suggest optimizations for two of the most commonly used erosion algorithms 1, 2. With some criteria for applicability in computer games in mind, a new and much faster algorithm is then proposed. Finally, a few issues regarding terrain modifications for maximum playability are discussed.}
}
@article{Zimmerman2016,
	title        = {Beyond the Individual: Toward a Nomological Network of Organizational Empowerment},
	author       = {N. Andrew Peterson and Marc A. Zimmerman},
	year         = 2004,
	month        = 9,
	journal      = {American Journal of Community Psychology},
	volume       = 34,
	pages        = {129--145},
	doi          = {10.1023/B:AJCP.0000040151.77047.58},
	issn         = {0091-0562},
	url          = {https://onlinelibrary.wiley.com/doi/10.1023/B%3AAJCP.0000040151.77047.58},
	abstract     = {<p>Empowerment research has generally been limited to the individual level of analysis. Efforts to study empowerment beyond the individual require conceptual frameworks suggesting attributes that define the construct and guide its measurement. This paper presents an initial attempt to describe the nomological network of empowerment at the organizational level of analysis--organizational empowerment (OE). Intraorganizational, interorganizational, and extraorganizational components of OE are described. Implications for empowerment theory and practice are discussed.</p>},
	issue        = {1-2},
	keywords     = {and,and so-,cess through which individuals,communities gain greater control,efficacy,empowered organizations,empowerment is an active,empowerment theory,measurement,organizations,participatory pro-}
}
@book{Damiand2004,
	title        = {Topological model for two-dimensional image representation: Definition and optimal extraction algorithm},
	author       = {Guillaume Damiand and Yves Bertrand and Christophe Fiorio},
	year         = 2004,
	journal      = {Computer Vision and Image Understanding},
	volume       = 93,
	pages        = {111--154},
	doi          = {10.1016/j.cviu.2003.09.001},
	isbn         = 3346741850,
	issn         = 10773142,
	abstract     = {In this paper, we define the two-dimensional topological map, a model which represents both topological and geometrical information of a two-dimensional labeled image. Since this model is minimal, complete, and unique, we can use it to define efficient image processing algorithms. The topological map is the last level of a map hierarchy. Each level represents the region boundaries of the image and is defined from the previous one in the hierarchy, thus giving a simple constructive definition. This model is similar to two existing structures but the main innovation of our approach is the progressive definition based on the successive map levels. These different maps can easily be extended in order to define the topological map in any dimension. Furthermore we provide an optimal extraction algorithm which extracts the different maps of the hierarchy in a single image scan. This algorithm is based on local configurations called precedes. Due to our constructive definition, different configurations are factorized which simplifies the implementation. \textcopyright{} 2003 Elsevier Inc. All rights reserved.},
	issue        = 2,
	keywords     = {Combinatorial map,Image representation,Interpixel boundaries,Segmentation,Topological model}
}
@article{Roa2004,
	title        = {Simulating desert scenery},
	author       = {Toney Roa and Bedrich Benes},
	year         = 2004,
	journal      = {Winter School of Computer Graphics SHORT communication Papers Proceedings},
	pages        = {17--22},
	url          = {https://dspace5.zcu.cz/bitstream/11025/6180/1/C79.pdf},
	abstract     = {An algorithm for simulating wind-ripples and moving sand is extended by the detection of fixed objects. This permits us simulation and animation of sand interacting with objects like houses, highways, cactuses, etc. Sand is accumulated on the windward side of an obstacle and the sand relocation and wind-ripples formation is diminished on the leeward side. The wind shadow depends on the object's geometry and the wind speed and direction. Sand tongues are formed as the result of the sand motion.},
	keywords     = {desert scenery,erosion,procedural modeling,regular height fields,visual simulation}
}
@article{Botsch2004,
	title        = {An intuitive framework for real-time freeform modeling},
	author       = {Mario Botsch and Leif Kobbelt},
	year         = 2004,
	journal      = {ACM SIGGRAPH 2004 Papers, SIGGRAPH 2004},
	pages        = {630--634},
	doi          = {10.1145/1186562.1015772},
	url          = {http://mesh.brown.edu/dgp/pdfs/Botsch-sg2004.pdf},
	abstract     = {We present a freeform modeling framework for unstructured triangle meshes which is based on constraint shape optimization. The goal is to simplify the user interaction even for quite complex freeform or multiresolution modifications. The user first sets various boundary constraints to define a custom tailored (abstract) basis function which is adjusted to a given design task. The actual modi fication is then controlled by moving one single 9-dof manipulator object. The technique can handle arbitrary support regions and piecewise boundary conditions with smoothness ranging continuously from C 0 to C2. To more naturally adapt the modification to the shape of the support region, the deformed surface can be tuned to bend with anisotropic stiffness. We are able to achieve real-time response in an interactive design session even for complex meshes by precomputing a set of scalar-valued basis functions that correspond to the degrees of freedom of the manipulator by which the user controls the modification. Copyright \textcopyright{} 2004 ACM.},
	issue        = 1,
	keywords     = {Freeform design,Surface editing,User interaction}
}
@article{Caumon2004,
	title        = {Building and Editing a Sealed Geological Model},
	author       = {Guillaume Caumon and Fran\c{c}ois Lepage and Charles H. Swordd and Jean-Laurent Mallet},
	year         = 2004,
	journal      = {Journal of the International Association for Mathematical Geology},
	doi          = {10.1023/B:MATG.0000029297.18098.8a},
	abstract     = {In Solid Modeling, a boundary representation (b-rep) defines solids by their bounding surfaces, providing an efficient volume description. Building on this representation, we present the notion of a Sealed Geological Model. In such a model, the geological surfaces define a partition ofthe domain ofinterest into regions; analytic functions can be defined in these regions to describe the spatial variations ofthe subsurface properties. Such descriptions can be used in Geophysics, 3D GIS, and for discretization purposes. In addition to the b-rep representational validity conditions, Sealed Geological Models must satisfy conditions ofgeological consistency. Bearing these conditions in mind, we describe a methodology to create and modify the shape of such sealed models interactively. We use the hierarchical relationship between geological surfaces to help reshape the contact between a fixed surface (a surface that other surfaces can slide along, such as a fault, erosion surface, or salt top) and a secondary deformable surface (e.g. horizon, older fault). Although designed to meet the demanding requirements of interactive model editing, our methodology could also make use of displacement vectors computed by an automatic process such as tomographic inversion or 3D balanced unfolding.},
	issue        = {May 2004},
	keywords     = {Algorithms,Boundary Representation,Geomodeling,Solid Modeling,Validity}
}
@misc{Busing2004,
	title        = {Advances in spatial, individual-based modelling of forest dynamics},
	author       = {Richard T. Busing and Daniel Mailly},
	year         = 2004,
	journal      = {Journal of Vegetation Science},
	publisher    = {Opulus Press AB},
	volume       = 15,
	pages        = {831--842},
	doi          = {10.1111/j.1654-1103.2004.tb02326.x},
	issn         = 11009233,
	abstract     = {Many individual-based models of forest dynamics lack spatial complexity. Although, in certain cases, spatially simple models may not be substantially inferior to spatially complex models, advances in vegetation science indicate potential weaknesses, particularly the lack of consideration of propagule availability in horizontal space, and varying patch (or canopy gap) dimensions. Models with vertical and horizontal spatial complexity can address these issues, but, thus far, evidence that they outperform patch (or gap) models is limited. Comparison of projections from models that differ only in their spatial complexity is needed to address the effects of propagule availability in space, spatial pattern of canopy tree mortality, and spatial resolution.},
	issue        = 6,
	keywords     = {Canopy gap model,Forest dynamics,Forest succession,Landscape,Simulation,Spatial pattern}
}
@article{Watanabe2004,
	title        = {A sketching interface for terrain modeling},
	author       = {Nayuko Watanabe and Takeo Igarashi},
	year         = 2004,
	journal      = {ACM SIGGRAPH 2004 Posters, SIGGRAPH 2004},
	pages        = 73,
	doi          = {10.1145/1186415.1186500},
	isbn         = 1581138962
}
@article{Barthe2004,
	title        = {Controllable binary CSG operators for "soft objects"},
	author       = {Lo\"{\i}c Barthe and Brian Wyvill and Erwin De Groot},
	year         = 2004,
	journal      = {International Journal of Shape Modeling},
	volume       = 10,
	pages        = {135--154},
	doi          = {10.1142/S021865430400064X},
	issn         = {02186543},
	url          = {https://pages.cpsc.ucalgary.ca/~blob/pdf/barthecsg.pdf},
	abstract     = {Potential functions allow the definition of both an implicit surface and its volume. In this representation, two categories can be distinguished: bounded and unbounded representations. Boolean composition operators are standard modelling tools allowing complex objects to be built by the combination of simple volume primitives. Though they are well defined for the second category, there is no clear definition of the properties that such operators should satisfy in order to provide bounded representation with both smooth and sharp transition. In this paper, we focus on bounded implicit representation. We first present fundamental properties to create adequate composition operators. From this theoretical framework, we derive a set of Boolean operators providing union, intersection and difference with or without smooth transition. Our new operators integrate accurate point-by-point control of smooth transitions and they generate G1 continuous potential fields even when sharp transition operators are used. \textcopyright{} World Scientific Publishing Company.},
	issue        = 2,
	keywords     = {Blending,Bounded representation,CSG operators,Implicit modelling,Soft objects}
}
@article{Spencer2004,
	title        = {SelSim: A program to simulate population genetic data with natural selection and recombination},
	author       = {Chris C.A. Spencer and Graham Coop},
	year         = 2004,
	journal      = {Bioinformatics},
	volume       = 20,
	pages        = {3673--3675},
	doi          = {10.1093/bioinformatics/bth417},
	issn         = 13674803,
	abstract     = {Summary: SelSim is a program for Monte Carlo simulation of DNA polymorphism data for a recombining region within which a single bi-allelic site has experienced natural selection. SelSim allows simulation from either a fully stochastic model of, or deterministic approximations to, natural selection within a coalescent framework. A number of different mutation models are available for simulating surrounding neutral variation. The package enables a detailed exploration of the effects of different models and strengths of selection on patterns of diversity. This provides a tool for the statistical analysis of both empirical data and methods designed to detect natural selection. \textcopyright{} Oxford University Press 2004; all rights reserved.},
	issue        = 18,
	pmid         = 15271777
}
@article{Desbenoit2004,
	title        = {Simulating and modeling lichen growth},
	author       = {Brett Desbenoit and Eric Galin and Samir Akkouche},
	year         = 2004,
	journal      = {Computer Graphics Forum},
	volume       = 23,
	pages        = {341--350},
	doi          = {10.1111/j.1467-8659.2004.00765.x},
	issn         = {01677055},
	url          = {https://perso.liris.cnrs.fr/eric.galin/Articles/2004-lichen.pdf},
	abstract     = {This paper presents a system for modeling lichens and simulating their propagation and growth in a virtual scene. Lichens colonize almost every substrate in nature and play an important role in the visual appearance of a natural object. The propagation of lichens over the substrate is performed by an Open Diffusion Limited Aggregation model constrained by the characteristics of the environment. The designer can control the development of lichens with simple parameters. Rendering the complex geometry and texture of lichens is achieved by instantiating three dimensional lichen models stored in an atlas of shapes created after real world images. The lichens obtained by our approach considerably increase the realism of complex natural scenes.},
	issue        = {3 SPEC. ISS.},
	keywords     = {Ecosystem simulation,Environment sensitive morphogenesis,Lichen growth,Plant modeling}
}
@article{Rogers2004,
	title        = {The Biology , Ecology and Vulnerability of Deep-Water Coral Reefs},
	author       = {Alex Rogers},
	year         = 2004,
	journal      = {International Union for Conservation of Nature \& Natural Resources},
	pages        = 13,
	url          = {https://www.iucn.org/sites/default/files/import/downloads/alexrogers_cbdcop7_deepwatercorals_complete.pdf},
	abstract     = {Deep-sea coral reefs live in the cold, dark waters of the oceans but like shallow water tropical coral reefs they have a distinct, diverse and sometimes highly endemic associated animal community. These reefs are under direct threat from deep-sea trawling and in some areas have already been seriously impacted by fishing. At present there is no protection for these habitats on the high seas.}
}
@article{Merks2004,
	title        = {Polyp oriented modelling of coral growth},
	author       = {Roeland M.H. Merks and Alfons G. Hoekstra and Jaap A. Kaandorp and Peter M.A. Sloot},
	year         = 2004,
	journal      = {Journal of Theoretical Biology},
	volume       = 228,
	pages        = {559--576},
	doi          = {10.1016/j.jtbi.2004.02.020},
	issn         = {00225193},
	abstract     = {The morphogenesis of colonial stony corals is the result of the collective behaviour of many coral polyps depositing coral skeleton on top of the old skeleton on which they live. Yet, models of coral growth often consider the polyps as a single continuous surface. In the present work, the polyps are modelled individually. Each polyp takes up resources, deposits skeleton, buds off new polyps and dies. In this polyp oriented model, spontaneous branching occurs. We argue that branching is caused by a so called "polyp fanning effect" by which polyps on a convex surface have a competitive advantage relative to polyps on a flat or concave surface. The fanning effect generates a more potent branching mechanism than the Laplacian growth mechanism that we have studied previously (J. Theor. Biol. 224 (2003) 153). We discuss the application of the polyp oriented model to the study of environmentally driven morphological plasticity in stony corals. In a few examples we show how the properties of the individual polyps influence the whole colony morphology. In our model, the spacing of polyps influences the thickness of coral branches and the overall compactness of the colony. Density variations in the coral skeleton may also be important for the whole colony morphology, which we address by studying two variants of the model. Finally, we discuss the importance of small scale resource translocation in the coral colony and its effects on the morphology of the colony. \textcopyright{} 2004 Elsevier Ltd. All rights reserved.},
	issue        = 4,
	keywords     = {Branching growth,Collective behaviour,Coral growth simulation,Morphogenesis,Resource translocation,Scleractinians},
	pmid         = 15178203
}
@article{Chevalier2004,
	title        = {Modeling the influence of wind and rivers on current, salinity and temperature over the French Guiana continental shelf during the rainy season},
	author       = {Crist\`{e}le Chevalier and Melika Baklouti and Alfred Ramamonjiarisoa},
	year         = 2004,
	journal      = {Journal of Coastal Research},
	volume       = 20,
	pages        = {1183--1197},
	doi          = {10.2112/03-0059r.1},
	issn         = {07490208},
	abstract     = {This paper deals first with the formulation of a three-dimensional numerical model intended to determine the spatial and temporal evolution of the oceanic circulation in coastal zones under the effects of various oceanic and meteorological constraints. Simulations are based on the Mobeehdycs model which was developed through collaborative work of several laboratories. Then, the paper presents the results of the application of the model to the continental shelf of French Guiana under academic but realistic climatic conditions. The application required the adaptation of the model and the use of appropriate techniques for solving the equations accounting for the peculiarities of the local constraints. The application is of importance as, because of the lack of systematic observations, the current, salinity and temperature fields at the site are poorly known. A better knowledge of these fields is recognized as of fundamental interest for a characterization of the site from the biological and the ecological viewpoints. The results clearly show the effects of the external forcing (wind and rivers) on the fields evolution, at the surface and with respect to the depth. The time scales of these evolutions as well as their mutual influence are identified. Finally, the results agree, at least qualitatively with some of the few observational results available at present.},
	issue        = 4,
	keywords     = {Numerical resolution of conservation equations,Oceanic circulation in coastal zones,Oceanic numerical modeling}
}
@article{Chenney2004,
	title        = {Flow tiles},
	author       = {Stephen Chenney},
	year         = 2004,
	journal      = {Computer Animation 2004 - ACM SIGGRAPH / Eurographics Symposium on Computer Animation},
	pages        = {233--242},
	doi          = {10.1145/1028523.1028553},
	isbn         = 3905673142,
	abstract     = {We present flow tiles, a novel technique for representing and designing velocity fields. Unlike existing procedural flow generators, tiling offers a natural user interface for field design. Tilings can be constructed to meet a wide variety of external and internal boundary conditions, making them suitable for inclusion in larger environments. Tiles offer memory savings through the re-use of prototypical elements. Each flow tile contains a small field and many tiles can be combined to produce large flows. The corners and edges of tiles are constructed to ensure continuity across boundaries between tiles. In addition, all our tiles and the resulting tiling are divergence-free and hence suitable for representing a range of effects. We discuss issues that arise in designing flow tiles, algorithms for creating tilings, and three applications: a crowd on city streets, a river flowing between banks, and swirling fog. The first two applications use stationary fields, while the latter demonstrates a dynamic field.},
	keywords     = {Fluid simulation,Tiles,Tiling,Velocity field}
}
@phdthesis{Perbet2004,
	title        = {Mod\'{e}lisation multi-\'{e}chelle proc\'{e}durale de sc\`{e}nes anim\'{e}es},
	author       = {Frank Perbet},
	year         = 2004,
	pages        = 150,
	url          = {https://theses.hal.science/tel-00528630/document},
	abstract     = {In computer graphics, 3D animated scenes are more and more rich and detailed. But the current techniques for managing such scenes cannot handle a wide range of observation scales. For example, creating models that allow to zoom from a galactic scale to an atomic scale is a very difficult task. Our goal is to address this problem in the scope of real-time visualization using standard computers. First, we show that multi-scale procedural modeling is particularly well suited to solve this problem. More precisely, we use complexification modeling which describes a model by its coarse representation and a set of functions which adds local details until the required precision according to perceptual criteria. We introduce a new formalism based on the C++ language which is able to describe a large set of 3D animated models over a large range of scales. We propose a tool which implements this formalism called DynamicGraph. This tool consists of a specialized graphical interface and a real-time rendering algorithm which efficently evaluates the visibility and the required precision. Finally, we illustrate the potential of this approach by several case studies.},
	institution  = {Institut National Polytechnique de Grenoble},
	keywords     = {3D,: computer graphics,dynamic,graph,multi-resolution,multi-scale,procedural modeling,real-time,visibility}
}
@article{Cohen-Steiner2004,
	title        = {Variational shape approximation},
	author       = {David Cohen-Steiner and Pierre Alliez and Mathieu Desbrun},
	year         = 2004,
	journal      = {ACM SIGGRAPH 2004 Papers, SIGGRAPH 2004},
	pages        = {905--914},
	doi          = {10.1145/1186562.1015817},
	abstract     = {A method for concise, faithful approximation of complex 3D datasets is key to reducing the computational cost of graphics applications. Despite numerous applications ranging from geometry compression to reverse engineering, efficiently capturing the geometry of a surface remains a tedious task. In this paper, we present both theoretical and practical contributions that result in a novel and versatile framework for geometric approximation of surfaces. We depart from the usual strategy by casting shape approximation as a variational geometric partitioning problem. Using the concept of geometric proxies, we drive the distortion error down through repeated clustering of faces into best-fitting regions. Our approach is entirely discrete and error-driven, and does not require parameterization or local estimations of differential quantities. We also introduce a new metric based on normal deviation, and demonstrate its superior behavior at capturing anisotropy. Copyright \textcopyright{} 2004 ACM.},
	keywords     = {Anisotropic remeshing,Geometric approximation,Geometric error metrics,Lloyd's clustering algorithm,Surfaces}
}
@article{Jaquet2004,
	title        = {Stochastic discrete model of karstic networks},
	author       = {O. Jaquet and P. Siegel and G. Klubertanz and H. Benabderrhamane},
	year         = 2004,
	month        = 7,
	journal      = {Advances in Water Resources},
	volume       = 27,
	pages        = {751--760},
	doi          = {10.1016/j.advwatres.2004.03.007},
	issn         = {03091708},
	abstract     = {Karst aquifers are characterised by an extreme spatial heterogeneity that strongly influences their hydraulic behaviour and the transport of pollutants. These aquifers are particularly vulnerable to contamination because of their highly permeable networks of conduits. A stochastic model is proposed for the simulation of the geometry of karstic networks at a regional scale. The model integrates the relevant physical processes governing the formation of karstic networks. The discrete simulation of karstic networks is performed with a modified lattice-gas cellular automaton for a representative description of the karstic aquifer geometry. Consequently, more reliable modelling results can be obtained for the management and the protection of karst aquifers. The stochastic model was applied jointly with groundwater modelling techniques to a regional karst aquifer in France for the purpose of resolving surface pollution issues. \textcopyright{} 2004 Elsevier Ltd. All rights reserved.},
	issue        = 7,
	keywords     = {Coupled effects,Finite elements,Karst geometry,Numerical simulation,Stochastic model}
}
@inproceedings{Shi2005,
	title        = {Image steganalysis based on moments of characteristic functions using wavelet decomposition, prediction-error image, and neural network},
	author       = {Yun Q. Shi and Guorong Xuan and Dekun Zou and Jianjiong Gao and Chengyun Yang and Zhenping Zhang and Peiqi Chai and Wen Chen and Chunhua Chen},
	year         = 2005,
	booktitle    = {IEEE International Conference on Multimedia and Expo, ICME 2005},
	volume       = 2005,
	pages        = {269--272},
	doi          = {10.1109/ICME.2005.1521412},
	isbn         = {0780393325},
	abstract     = {In this paper, a general blind image steganalysis system is proposed, in which the statistical moments of characteristic functions of the prediction-error image, the test image, and their wavelet subbands are selected as features. Artificial neural network is utilized as the classifier. The performance of the proposed steganalysis system is significantly superior to the prior arts. \textcopyright{} 2005 IEEE.}
}
@book{Bressan2005,
	title        = {Lecture Notes in Computer Science: Preface},
	author       = {St\'{e}phane Bressan and Stefano Ceri and Zohra Bellahsene and Ela Hunt and Zachary Ives and Rainer Unland and Michael Rys},
	year         = 2005,
	journal      = {Lecture Notes in Computer Science},
	volume       = 3671,
	isbn         = 9783540497769,
	issn         = {03029743},
	note         = {For pages, add 21<br/><br/>Can be useful:<br/>- Evolving Creatures in Virtual Ecosystems (p 11)<br/>? Ridge-Valley Lines Smoothing and Optimizing (p. 502)<br/>? Creating Dynamic Panorama Using Particle Swarm Optimization (p. 676)<br/>- Real-Time and Realistic Simulation of Large-Scale Deep Ocean Surface (p. 686)<br/>- Exploiting Frame-to-Frame Coherence for Rendering Terrain Using Continuous LOD (p. 695)<br/>- Animating Grass in Real-Time (p. 724)<br/>- Example-Based Realistic Terrain Generation (p. 811)<br/>? A Seamless Visualizaton Model of the Global Terrain Based on the QTM (p. 1136)<br/><br/>Curiosity:<br/>- Steering Behavior Model of Visitor NPCs in Virtual Exhibition (p. 113)<br/>- Emotion Recognition Using Physiological Signals (p. 437)<br/>- Sketch Based 3D Animation Copy (p. 474)<br/>- Robust Motion Tracking in Video Sequences Using Particle Filter (p. 540)}
}
@article{Ong2005,
	title        = {Terrain generation using genetic algorithms},
	author       = {Teong Joo Ong and Ryan Saunders and John Keyser and John J. Leggett},
	year         = 2005,
	journal      = {GECCO 2005 - Genetic and Evolutionary Computation Conference},
	pages        = {1463--1470},
	doi          = {10.1145/1068009.1068241},
	isbn         = 1595930108,
	abstract     = {We propose a method for applying genetic algorithms to create 3D terrain data sets. Existing procedural algorithms for generation of terrain have several shortcomings. The most popular approach, fractal-based terrain generation, is efficient, but is difficult for a user to control. Other methods tend to require too much user input. In this paper, we provide an alternative method of terrain generation that uses a two-pass genetic algorithm approach to produce a variety of terrain types using only intuitive user inputs. We allow a user to specify a rough sketch of terrain region boundaries, and we refine these boundaries using a genetic algorithm. We then couple this with a database of given terrain data to generate an artificial terrain, which we optimize using a second genetic algorithm. Copyright 2005 ACM.},
	keywords     = {Genetic algorithms,Geographic information systems (gis),Height field,Image processing,Terrain generation}
}
@article{Ashlock2005,
	title        = {Evolution of L-systems for compact virtual landscape generation},
	author       = {Daniel A. Ashlock and Stephen P. Gent and Kenneth M. Bryden},
	year         = 2005,
	journal      = {2005 IEEE Congress on Evolutionary Computation, IEEE CEC 2005. Proceedings},
	volume       = 3,
	pages        = {2760--2767},
	doi          = {10.1109/cec.2005.1555041},
	isbn         = {0780393635},
	abstract     = {An L-system or Lindenmayer system consists of a grammar and an interpreter. The grammar contains an axiom, usually a short string, that the grammar expands into a long, complex string. The interpreter then renders the string into an object. A midpoint L-system is a generalization of L-systems to two-dimensional arrays of characters inspired by midpoint displacement fractals. This study presents a system for simultaneously evolving the rules and and interpreter for a midpoint L-system that encodes a desired landscape. Unlike a midpoint displacement fractal a midpoint L-system is deterministic and can be evolved to yield fixed, complex shapes. The fractal character of a midpoint L-system permits the storage of a large complex virtual landscape in a small data object. The level of detail rendered by an L-system can be changed rapidly and, with a fast graphics engine, dynamically. This study introduces midpoint L-systems, gives techniques for evolving them, and demonstrates those techniques on trial landscapes that resemble hills and craters. The application of this work is for virtual reality where midpoint L-systems will allow a designer to select from many rugged versions of a landscape without requiring vast amounts of storage or machine time to render them. \textcopyright{} 2005 IEEE.},
	issue        = {January}
}
@phdthesis{Weiss2005,
	title        = {Fast Voxel-Based Hydraulic Erosion},
	author       = {Sebastian Weiss},
	year         = 2005,
	url          = {https://mediatum.ub.tum.de/doc/1310288/1310288.pdf},
	abstract     = {Simulating realistic looking hydraulic erosion can greatly increase the realism of terrains in computer graphics. Other areas of application include the fast evaluation of possible erosion scenarios which is needed in extreme weather conditions. The methods presented in this thesis are based on the SPH-method for simulating fluids using particles in 3D. The proposed extensions include the precise collision with a complex terrain represented as a sparsely stored level set. Furthermore, each particle carries its own amount of sediment which is exchanged with the terrain to simulate dissolving and deposition and with other particles to simulate sediment diffusion. By using particles and a level set instead of heightmaps, caves, overhangs and other complicated structures can be generated. The presented methods are fast enough to simulate and render up to 100,000 particles on a terrain with a resolution of 1024\textasteriskcentered1024\textasteriskcentered512.},
	institution  = {Technische Universitat Munchen}
}
@techreport{Marechal2005,
	title        = {Mod\`{e}le conceptuel de la structure et du fonctionnement du syst\`{e}me karstique de la Fontaine de N\^{\i}mes - Rapport final},
	author       = {Jean-christophe Mar\'{e}chal and B. Ladouche and N. Courtois and N. D\"{o}rfliger and P. Le Strat and A. Bironne},
	year         = 2005,
	pages        = 187,
	url          = {http://infoterre.brgm.fr/rapports/RP-53827-FR.pdf},
	abstract     = {Dans le cadre du programme de recherche KARSTEAU (PDR04EAU01) et de la convention n\textdegree{} 2003.07.23 \'{e}tablie avec la Ville de N\^{\i}mes, le BRGM a pour objectif de caract\'{e}riser la structure et le fonctionnement de l'hydrosyst\`{e}me karstique n\^{\i}mois et d'\'{e}valuer sa contribution \`{a} la gen\`{e}se et \`{a} la propagation des crues \'{e}clair, en travaillant \`{a} deux \'{e}chelles spatiales : celle de la totalit\'{e} du bassin d'alimentation et celle de sites pilotes li\'{e}s \`{a} un ou deux bassins versants ou sous-bassins versants de cadereaux. L'approche spatiale \`{a} l'\'{e}chelle de la totalit\'{e} du bassin d'alimentation est r\'{e}alis\'{e}e au sein : - du module 1 du projet, dont l'objectif est la connaissance de la structure et du fonctionnement hydrologique du bassin d'alimentation de la Fontaine de N\^{\i}mes ; - du module 2 du projet, dont l'objectif est la connaissance du fonctionnement hydrog\'{e}ologique de l'\'{e}pikarst et de la zone noy\'{e}e au moyen de l'acquisition de donn\'{e}es compl\'{e}mentaires. Dans le cadre du module 1, un premier bilan de l'\'{e}tat des connaissances a \'{e}t\'{e} effectu\'{e} au sein d'une synth\`{e}se bibliographique – rapport RP-53422-FR (Mar\'{e}chal et al., 2004). Le pr\'{e}sent rapport contient les premiers r\'{e}sultats des observations entreprises sur le syst\`{e}me karstique de la Fontaine de N\^{\i}mes dans le cadre de cette \'{e}tude (modules 1 et 2). Son principal objectif est de fournir un premier mod\`{e}le conceptuel du fonctionnement et de la structure du syst\`{e}me karstique \`{a} l'\'{e}chelle du bassin d'alimentation.},
	keywords     = {Innondation,Mod\'{e}lisation,N\^{\i}mes,eau souterraine,syst\`{e}me karstique}
}
@article{Igarashi2005,
	title        = {As-rigid-as-possible shape manipulation},
	author       = {Takeo Igarashi and Tomer Moscovich and John F. Hughes},
	year         = 2005,
	journal      = {ACM Transactions on Graphics},
	volume       = 24,
	pages        = {1134--1141},
	doi          = {10.1145/1073204.1073323},
	issn         = {07300301},
	url          = {https://graphics.stanford.edu/courses/cs468-07-winter/Papers/imh-rpsm-05.pdf},
	abstract     = {We present an interactive system that lets a user move and deform a two-dimensional shape without manually establishing a skeleton or freeform deformation (FFD) domain beforehand. The shape is represented by a triangle mesh and the user moves several vertices of the mesh as constrained handles. The system then computes the positions of the remaining free vertices by minimizing the distortion of each triangle. While physically based simulation or iterative refinement can also be used for this purpose, they tend to be slow. We present a two-step closed-form algorithm that achieves real-time interaction. The first step finds an appropriate rotation for each triangle and the second step adjusts its scale. The key idea is to use quadratic error metrics so that each minimization problem becomes a system of linear equations. After solving the simultaneous equations at the beginning of interaction, we can quickly find the positions of free vertices during interactive manipulation. Our approach successfully conveys a sense of rigidity of the shape, which is difficult in space-warp approaches. With a multiple-point input device, even beginners can easily move, rotate, and deform shapes at will. Copyright \textcopyright{} 2005 by the Association for Computing Machinery, Inc.},
	issue        = 3,
	keywords     = {Animation,Deformation,Image Editing,Interaction,Mesh Editing,Shape Manipulation}
}
@article{Schmidt2005,
	title        = {Implicit sweep surfaces},
	author       = {Ryan Schmidt and Brian Wyvill},
	year         = 2005,
	journal      = {Department of Computer Science. University of Calgary},
	url          = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.60.1738&amp;rep=rep1&amp;type=pdf},
	abstract     = {A technique is presented for generating implicit sweep objects that support direct specification and manipulation of the surface with no topological limitations on the 2D sweep template. The novelty of this method is that the under-lying scalar field is bounded and C 1 continuous, apart from surface creases. Bounded scalar fields guarantee local in-fluence when modeling with implicit surfaces, an important usbility requirement for interactive modeling. A discrete ap-proximation is also described that supports fast evaluation for bounded scalar fields. The new sweep objects are imple-mented in an interactive BlobTree modeling tool, provid-ing an intuitive and expressive free-form implicit modeling component. This sweep representation permits conversion of parametric sweep surfaces to implicit volumes. An ap-plication to volume reconstruction from parallel contours is also explored.}
}
@article{Moller2005,
	title        = {Fast, minimum storage ray/triangle intersection},
	author       = {Tomas M\"{o}ller and Ben Trumbore},
	year         = 2005,
	journal      = {ACM SIGGRAPH 2005 Courses, SIGGRAPH 2005},
	pages        = {1--7},
	doi          = {10.1145/1198555.1198746},
	url          = {https://gitea.yiem.net/QianMo/Real-Time-Rendering-4th-Bibliography-Collection/raw/branch/main/Chapter 1-24/[1231] [JGT 1997] Fast, Minimum Storage Ray-Triangle Intersection.pdf},
	abstract     = {We present a clean algorithm for determining whether a ray intersects a triangle. The algorithm translates the origin of the ray and then changes the base of that vector which yields a vector (t u v)T, where t is the distance to the plane in which the triangle lies and (u, v) represents the coordinates inside the triangle. One advantage of this method is that the plane equation need not be computed on the fly nor be stored, which can amount to significant memory savings for triangle meshes. As we found our method to be comparable in speed to previous methods, we believe it is the fastest ray/triangle intersection routine for triangles which do not have precomputed plane equations.},
	issue        = 1,
	keywords     = {Base transformation,Intersection,Ray tracing,Ray/triangle-intersection}
}
@article{Suzuki2005,
	title        = {Multi-physics simulation of sand-erosion phenomena on turbine blade},
	author       = {Masaya Suzuki and Kazuyuki Toda and Makoto Yamamoto},
	year         = 2005,
	journal      = {3rd M.I.T. Conference on Computational Fluid and Solid Mechanics},
	pages        = {1006--1008},
	isbn         = {0080444814},
	url          = {https://www.flair.monash.edu.au/intranet/proceedings/3mit/data/content/1006/paper.pdf},
	abstract     = {This paper presents a newly developed numerical procedure to predict three-dimensional sand-erosion phenomena. It is well known that sand erosion is a typical multi-physics problem, i.e. turbulent flow field, particle motions and wall deformations, among others, interact. In the present code, in order to simulate this phenomenon, turbulent flow field, particle trajectories and amount of erosion on an eroded wall are calculated repeatedly. The gas-particle two-phase turbulent flow around a turbine blade is computed to clarify sand-erosion phenomena on the turbine blade. The numerical results indicate that sand erosion occurs severely around the leading edge and on the pressure surface, the rebounding particles cause the mechanical damage on the suction surface, and the aerodynamic performance deteriorates with proceeding sand erosion. \textcopyright{} 2005 Elsevier Ltd.},
	keywords     = {Computational fluid dynamics,Multi-physics simulation,Sand erosion,Three-dimensional computation,Turbine blade}
}
@article{Neidhold2005,
	title        = {Interactive physically based fluid and erosion simulation},
	author       = {B. Neidhold and M. Wacker and Oliver Deussen},
	year         = 2005,
	journal      = {Natural Phenomena},
	pages        = {25--32},
	isbn         = 3905673290,
	issn         = 18160867,
	url          = {http://graphics.uni-konstanz.de/publikationen/Neidhold2005InteractivePhysicallyBased/Neidhold2005InteractivePhysicallyBased.pdf},
	abstract     = {Realistically eroded terrain is a base of almost every outdoor visualization for simulators or computer games. In order to achieve convincing results physically based erosion algorithms are necessary. We present a new method that combines a non-expensive fluid simulation with an erosion algorithm. Both parts are running at interactive rates so the artist is able to influence the erosion process in real-Time by changing simulation parameters or applying additional water to the scene. In this way, we support realism as well as design aspects during the terrain creation process. To simplify the three dimensional fluid simulation we use a newtonian physics approach that works on a two dimensional grid storing acceleration, velocity and mass. The method provides all features that are important for simulation of erosion e.g. moving, non-moving water (rivers, lakes) and evaporation. This allows us to support effects like dissolving, transportation and sedimentation of material in the erosion process. \textcopyright{} The Eurographics Association 2005.}
}
@article{Koren2005,
	title        = {Drawing graphs by eigenvectors: Theory and practice},
	author       = {Y. Koren},
	year         = 2005,
	journal      = {Computers and Mathematics with Applications},
	volume       = 49,
	pages        = {1867--1888},
	doi          = {10.1016/j.camwa.2004.08.015},
	issn         = {08981221},
	abstract     = {The spectral approach for graph visualization computes the layout of a graph using certain eigenvectors of related matrices. Two important advantages of this approach are an ability to compute optimal layouts (according to specific requirements) and a very rapid computation time. In this paper, we explore spectral visualization techniques and study their properties from different points of view. We also suggest a novel algorithm for calculating spectral layouts resulting in an extremely fast computation by optimizing the layout within a small vector space. \textcopyright{} 2005 Elsevier Ltd. All rights reserved.},
	issue        = {11-12},
	keywords     = {Eigenvectors,Fiedler vector,Force-directed layout,Graph drawing,Laplacian,Spectral graph theory}
}
@article{Valette2005,
	title        = {A preliminary approach of 3D simulation of soil surface degradation by rainfall},
	author       = {Gilles Valette and Michel Herbin and Laurent Lucas and Jo\"{e}l L\'{e}onard},
	year         = 2005,
	journal      = {Natural Phenomena},
	pages        = {41--50},
	isbn         = 3905673290,
	issn         = 18160867,
	url          = {https://diglib.eg.org/bitstream/handle/10.2312/NPH.NPH05.041-049/041-049.pdf?sequence=1},
	abstract     = {Soil surface structure and morphology deeply influence a lot of processes of high agronomic and environmental relevance, such as mass and heat transfer through the soil-Atmosphere interface, runoff and erosion, seed germination and seedling emergence. The soil surface structure of agricultural field is in continuous evolution: it is strongly affected by tillage, and in between tillage operations, erosion by rainfall and runoff causes a progressive degradation of the structure whose intensity and speed partly depend on the initial state associated to tillage modalities. A soil surface degradation model could allow to predict this evolution of the soil surface structure, and even to help choosing adequate tillage practices and sowing dates. Erosion modelling has been addressed by soil scientists but also by computer graphic scientists in order to add realism to virtual landscapes. Mixing both of these points of view would be interesting to simulate and visualize the evolution of the soil surface of a cultivated soil. In this paper, we present our project of a simulator of soil surface degradation by rainfall at a small spatial scale (1 m2 or less), including visualization, and which is mainly based on a 3D cellular automata approach with a specific type of cell. The choices made for the implementation of our model are discussed in the light of the results found in the literature with different modelling approaches. \textcopyright{} The Eurographics Association 2005.}
}
@article{Brandel2005,
	title        = {Automatic building of structured geological models},
	author       = {Sylvain Brandel and S\'{e}bastien Schneider and Michel Perrin and Nicolas Guiard and Jean Fran\c{c}ais Rainaud and Pascal Lienhard and Yves Bertrand},
	year         = 2005,
	journal      = {Journal of Computing and Information Science in Engineering},
	volume       = 5,
	pages        = {138--148},
	doi          = {10.1115/1.1884145},
	issn         = 15309827,
	url          = {https://d1wqtxts1xzle7.cloudfront.net/41885114/Automatic_Building_of_Structured_Geologi20160202-27158-1inzl1z-libre.pdf?1454417125=&response-content-disposition=inline%3B+filename%3DAutomatic_Building_of_Structured_Geologi.pdf&Expires=1666519771&Signature},
	abstract     = {The present article proposes a method to significantly improve the construction and updating of 3D geological models used for oil and gas exploration. We present a prototype of a "geological pilot" which enables monitoring the automatic building of a 3D model topologically and geologically consistent, on which geological links between objects can easily be visualized. This model can automatically be revised in case of changes in the geometric data or in the interpretation. Copyright \textcopyright{} 2005 by ASME.},
	issue        = 2
}
@article{Sprague2005,
	title        = {Interpretive tools for 3-D structural geological modelling part II: Surface design from sparse spatial data},
	author       = {Kevin B. Sprague and Eric A. de Kemp},
	year         = 2005,
	journal      = {GeoInformatica},
	volume       = 9,
	pages        = {5--32},
	doi          = {10.1007/s10707-004-5620-8},
	isbn         = 1070700456208,
	issn         = 13846175,
	abstract     = {We present software tools and methods applicable to the geological modelling of sparse spatial and structural data within a 3-D digital environment. Free-form surfaces derived from section-style control frames and constrained by field-based structural measurements are employed as partially automated design aids intended to speed up and streamline the 3-D geological model building process. Some design degrees of freedom such as NURBS tension (or weights), knot sequencing and tying surface features are also discussed with examples drawn from spatial and structural data collected in Baffin Island by the Geological Survey of Canada and near-mine exploration data from Canadian mines. Interpolation of field-based structural measurements along the boundary of an unknown surface is also demonstrated. This work is potentially relevant to regional mappers and others dealing with sparse spatial and structural data, and/or conceptual surface modelling. \textcopyright{} 2005 Springer Science + Business Media, Inc.},
	issue        = 1,
	keywords     = {B\'{e}zier,Geology,Map trace,Mining,NURBS,Orientation,Sparse,Structure,Surface}
}
@book{Grimm2005,
	title        = {Individual-based Modeling and Ecology},
	author       = {Volker Grimm and Steven F. Railsback},
	year         = 2005,
	publisher    = {Princeton University Press},
	pages        = 448,
	abstract     = {
		Individual-based models are an exciting and widely used new tool for ecology. These computational models allow scientists to explore the mechanisms through which population and ecosystem ecology arises from how individuals interact with each other and their environment. This book provides the first in-depth treatment of individual-based modeling and its use to develop theoretical understanding of how ecological systems work, an approach the authors call "individual-based ecology."

		Grimm and Railsback start with a general primer on modeling: how to design models that are as simple as possible while still allowing specific problems to be solved, and how to move efficiently through a cycle of pattern-oriented model design, implementation, and analysis. Next, they address the problems of theory and conceptual framework for individual-based ecology: What is "theory"? That is, how do we develop reusable models of how system dynamics arise from characteristics of individuals? What conceptual framework do we use when the classical differential equation framework no longer applies? An extensive review illustrates the ecological problems that have been addressed with individual-based models. The authors then identify how the mechanics of building and using individual-based models differ from those of traditional science, and provide guidance on formulating, programming, and analyzing models. This book will be helpful to ecologists interested in modeling, and to other scientists interested in agent-based modeling.
	}
}
@article{Stachniak2005,
	title        = {An Algorithm for Automated Fractal Terrain Deformation},
	author       = {S Stachniak and W Stuerzlinger},
	year         = 2005,
	journal      = {In Proceedings of Computer Graphics and Artificial Intelligence},
	pages        = {64--76},
	url          = {www.cs.yorku.ca/~wolfgang/%5Cnhttp://alter-unilim.teiath.gr/3ia_previous_conferences_cds/2005/Papers/Papers/Paper03.pdf},
	abstract     = {Fractal terrains provide an easy way to generate realistic landscapes. There are several methods to generate fractal terrains, but none of those algorithms allow the user much flexibility in controlling the shape or properties of the final outcome. A few methods to modify fractal terrains have been previously proposed, both algorithm-based as well as by hand editing, but none of these provide a general solution. In this work, we present a new algorithm for fractal terrain deformation. We present a general solution that can be applied to a wide variety of deformations. Our approach employs stochastic local search to identify a sequence of local modifications, which deform the fractal terrain to conform to a set of specified constraints. The presented results show that the new method can incorporate multiple constraints simultaneously, while still preserving the natural look of the fractal terrain.},
	keywords     = {2,3,7,8,according to acm ccs,and search,computer graphics,control methods,fractals,graph and tree search,graphics and realism,i,problem solving,strategies,three-dimensional}
}
@article{Hapke2005,
	title        = {Estimation of regional material yield from coastal landslides based on historical digital terrain modelling},
	author       = {C. J. Hapke},
	year         = 2005,
	journal      = {Earth Surface Processes and Landforms},
	volume       = 30,
	pages        = {679--697},
	doi          = {10.1002/esp.1168},
	issn         = {01979337},
	abstract     = {High-resolution historical (1942) and recent (1994) digital terrain models were derived from aerial photographs along the Big Sur coastline in central California to measure the long-term volume of material that enters the nearshore environment. During the 52-year measurement time period, an average of 21 000 \pm{} 3100 m3 km-1 a-1 of material was eroded from nine study sections distributed along the coast, with a low yield of 1000 \pm{} 240 m3 km-1 a-1 and a high of 46 700 \pm{} 7300 m3 km-1 a-1. The results compare well with known volumes from several deep-seated landslides in the area and suggest that the processes by which material is delivered to the coast are episodic in nature. In addition, a number of parameters are investigated to determine what influences the substantial variation in yield along the coast. It is found that the magnitude of regional coastal landslide sediment yield is primarily related to the physical strength of the slope-forming material. Coastal Highway 1 runs along the lower portion of the slope along this stretch of coastline, and winter storms frequently damage the highway. The California Department of Transportation is responsible for maintaining this scenic highway while minimizing the impacts to the coastal ecosystems that are part of the Monterey Bay National Marine Sanctuary. This study provides environmental managers with critical background data on the volumes of material that historically enter the nearshore from landslides, as well as demonstrating the application of deriving historical digital terrain data to model landscape evolution. Published in 2005 by John Wiley \& Sons, Ltd.},
	issue        = 6,
	keywords     = {Big Sur,Coastal landslides,Digital terrain models,Marine sanctuary,Material yield,Photogrammetry,Rock strength}
}
@article{Watson2005,
	title        = {A comparison of temperate reef fish assemblages recorded by three underwater stereo-video techniques},
	author       = {Dianne L. Watson and Euan S. Harvey and Marti J. Anderson and Gary A. Kendrick},
	year         = 2005,
	journal      = {Marine Biology},
	volume       = 148,
	pages        = {415--425},
	doi          = {10.1007/s00227-005-0090-6},
	issn         = {00253162},
	abstract     = {Three underwater stereo-video techniques were used to sample the relative densities and species richness of temperate reef fish assemblages at three reef locations and two habitats (high- and low-relief reef) within Hamelin Bay, south-western Australia. The three techniques compared were diver-operated stereo-video strip transects, baited remote stereo-video and unbaited remote stereo-video. While unbaited remote stereo-video and diver-operated stereo-video transects recorded greater species richness at high compared to low-relief reefs, baited remote stereo-video recorded similar species richness at the two habitat types. The diver-operated stereo-video system was manoeuvred through caves and under overhangs recording small, cryptic, cave-dwelling species that were not recorded by either remote video techniques (Trachinops noarlungae, Trachinops brauni, Chromis klunzingeri, Trachichthys australis). Both remote video techniques recorded greater species richness and relative density of the most common species of Labridae, Ophthalmolepsis lineolatus. Baited remote video recorded the rarer, large predatory fish species (e.g. Seriola hippos, Glaucosoma hebraicum, Heterodontus portusjacksoni). None of the techniques sampled small cryptic fish families such as Gobiidae or Blenniidae. A combination of survey techniques is recommended for comprehensive fishery-independent studies that aim to sample broad components of fish assemblages. \textcopyright{} Springer-Verlag 2005.},
	issue        = 2
}
@article{Johnson2005,
	title        = {Erosion and burial of granite rocky shores in the recent and late pleistocene of the Seychelles Islands: Physical and biological perspectives},
	author       = {Markes E. Johnson and B. Gudveig Baarli},
	year         = 2005,
	journal      = {Journal of Coastal Research},
	volume       = 21,
	pages        = {867--879},
	doi          = {10.2112/05-0019.1},
	issn         = {07490208},
	abstract     = {Modern and abandoned Pleistocene rocky shores are described for several of the Seychelles Islands in order to examine the range of erosional features typical of granite shores in a tropical setting and to gauge the prospects for their preservation at unconformities in the rock record. The proportion of sandy beaches to rocky shores is estimated for each of the various islands under consideration, including Mah\'{e}, Praslin, Ronde, La Digue, Grande S\oe{}ur, and Cocos. Aspects of physical geography related to the position of reefs and the variable width of lagoons that surround and buffer the islands is considered with respect to the regional pattern of prevailing winds and oceanic circulation. Literature on the erosion of granite landforms is reviewed and applied to the Seychelles Inner Islands and the Seychelles Bank on which they sit. Outcrops of Pleistocene limestone closely associated with granite surfaces were searched for body fossils that represent an intertidal rocky-shore biota. Coralline red algae and vermetid gastropods are the primary components of laminated limestone attached directly to granite surfaces as protective bioconstructions. Cemented limestone rubble includes the body fossils of a dozen different kinds of invertebrates also found extant on modern granite shores in the Seychelles. Among them are gastropods that represent a range of different life styles, as well as corals.},
	issue        = 5,
	keywords     = {Bornhardts,Coralline red algae,Corals,Gastropods,Inselbergs,Intertidal biotas,Isotope substage 5e,Monadnocks,Nubbins,Rillenstein,Tafoni}
}
@article{Coulais2005,
	title        = {Real-Time Animation of Particles and Seaweeds in Underwater Scenes},
	author       = {Y. Coulais and D. Ghazanfarpour and O. Terraz and S. Thon},
	year         = 2005,
	journal      = {EG UK Theory and Practice of Computer Graphics, TPCG 2005},
	isbn         = 3905673568,
	url          = {https://diglib.eg.org/bitstream/handle/10.2312/LocalChapterEvents.TPCG.TPCGUK05.019-026/019-026.pdf?sequence=1},
	abstract     = {Water is one of the most important natural phenomena to be rendered in computer graphics. Although ocean waves animation has been well studied in Computer graphics, only few studies have been done for underwater animation. In this paper, we present a new real-time method for animation of suspended particles and seaweeds in underwater scenes. One of the main advantages of this method, compared to other approaches, is the real-time animation of submerged objects by taking into account some natural underwater forces that govern their movements, such as forces generated by water surface in deep and shallow waters as well as underwater currents. Taking into account forces generated by ocean surface is an original approach in Computer Graphics. In addition, real-time animation of complex underwater scenes composed of a great number of particles and seaweeds can be performed by the use of appropriate levels of details.}
}
@phdthesis{Mehla2005,
	title        = {Modeling and Animation of Orb Webs},
	author       = {Anubhav Mehla},
	year         = 2005,
	url          = {https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=598c8b0a2f65c023fcc0ca0896a8d3a8c548cdc8},
	city         = {Saskatoon},
	institution  = {University of Saskatchewan}
}
@article{Patel2005,
	title        = {Simple Divergence-Free Fields for Artistic Simulation},
	author       = {Mayur Patel and Noah Taylor},
	year         = 2005,
	journal      = {Journal of Graphics Tools},
	volume       = 10,
	pages        = {49--60},
	doi          = {10.1080/2151237x.2005.10129206},
	issn         = {1086-7651},
	url          = {https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=18183ace6beab86bb0d9a505bfeb6ab7bb3b840b},
	abstract     = {We discuss tools for calculating divergence-free fields for artistic particle simulations. We introduce a simple, fast divergence-free noise function which can be used for turbulence. We also describe how the interpolation technique used by the noise function can be used for calculating artist-controlled divergence-free fields. The artist can create realistic unbounded flow fields without the complexity or memory cost of voxel-grid methods.},
	issue        = 4,
	keywords     = {gaseous phenomena,noise,particle systems,physically based modeling,simulation,turbulence}
}
@article{Dominguez2005,
	title        = {Vulnerability assessment of a retreating coast in SW Spain},
	author       = {L. Dom\'{\i}nguez and G. Anfuso and F. J. Gracia},
	year         = 2005,
	journal      = {Environmental Geology},
	volume       = 47,
	pages        = {1037--1044},
	doi          = {10.1007/s00254-005-1235-0},
	issn         = {09430105},
	abstract     = {The present study assesses coastal vulnerability to erosion processes along a 23-km-long coastal sector that presents different morphological features and grades of human occupation. Seven photogrammetric flights, at different scales, were used for reconstructing the coastal evolution from 1956 to 2001. Several sources were compiled to assess human activities and land uses in the coastal zones that were mapped and divided into four different types. As a further step, coastal vulnerability to erosion was assessed combining the potential coastal retreat with land-use type. More than one third of the studied coast presents a very high-medium risk level and many human structures and activities at Sanl\'{u}car village and La Ballena beach will be threatened by erosional processes in the near future. \textcopyright{} Springer-Verlag 2005.},
	issue        = 8,
	keywords     = {Aerial photos,Land use,Vulnerability}
}
@article{Kocurek2005,
	title        = {Aeolian dune field self-organization - Implications for the formation of simple versus complex dune-field patterns},
	author       = {Gary Kocurek and Ryan C. Ewing},
	year         = 2005,
	month        = 12,
	journal      = {Geomorphology},
	volume       = 72,
	pages        = {94--105},
	doi          = {10.1016/j.geomorph.2005.05.005},
	issn         = {0169555X},
	abstract     = {The interpretation of aeolian dune-field patterns as self-organizing complex systems is a new paradigm in which pattern evolution may be addressed. Computer simulations, supported by field and experimental data, indicate that a given wind regime produces a simple dune-field pattern. Dune type and crest orientation are determined by wind regime and pattern ordering occurs through dune-dune interactions over time. Because dunes reorient only at their crest terminations with a change in wind regime, the rate of formation of a new pattern of small dunes is typically faster than the rate of reorientation of the existing pattern, resulting in the superposition of simple patterns to give rise to complex patterns. Complex patterns are distinct from spatial changes in a simple pattern, and from the type of superposition that characterizes compound/complex dunes. Complex patterns necessarily indicate a rate of pattern formation that is rapid compared to the rate of sediment accumulation on the depositional surface. \textcopyright{} 2005 Elsevier B.V. All rights reserved.},
	issue        = {1-4},
	keywords     = {Aeolian,Complex systems,Sand-dune patterns,Self-organization}
}
@techreport{Cattaneo2005,
	title        = {Cellular Automata for 2D and 3D fluid-dynamics simulations},
	author       = {G Cattaneo and U Jocher},
	year         = 2005,
	url          = {http://www.cineca.it/editions/ssc97/html/cattaneo.htm},
	abstract     = {Si presentano due modelli basati sulle tecniche lattice gas per lo studio di fenomeni di fluidodinamica. Il modello FHP-N si basa su un reticolo esagonale e permette, con l'introduzione di un numero arbitrario ma finito di particelle ferme, di recuperare l'invarianza galileiana dell'equazione di Navier-Stokes. Il modello CRS \`{e} un modello in tre dimensioni che si basa sul rombododecaedro. Entrambi i modelli sono stati implementati sul Cray T3E del CINECA dove sono state ottenute ottime prestazioni e una buona scalabilit\`{a}. We introduce two lattice gas models for fluid-dynamic simulations. The FHP-N model is used for simulations in two dimensions, while the CRS model is used for the three dimensional case. Both the models have been implemented on the Cray T3E and here we present some performance and scalability data.}
}
@article{Cook2005,
	title        = {Wavelet noise},
	author       = {Robert L. Cook and Tony DeRose},
	year         = 2005,
	month        = 7,
	journal      = {ACM Transactions on Graphics},
	volume       = 24,
	pages        = {803--811},
	doi          = {10.1145/1073204.1073264},
	issn         = {0730-0301},
	url          = {https://dl.acm.org/doi/10.1145/1073204.1073264},
	abstract     = {<p>Noise functions are an essential building block for writing procedural shaders in 3D computer graphics. The original noise function introduced by Ken Perlin is still the most popular because it is simple and fast, and many spectacular images have been made with it. Nevertheless, it is prone to problems with aliasing and detail loss. In this paper we analyze these problems and show that they are particularly severe when 3D noise is used to texture a 2D surface. We use the theory of wavelets to create a new class of simple and fast noise functions that avoid these problems.</p>},
	issue        = 3,
	keywords     = {CR Categories: I33 [Picture/Image generation]: Antialiasing-[I37]: Three-Dimensional Graphics and Realism-Color,and texture Keywords: Multiresolution analysis,noise,procedural textures,rendering,shad-ing,shading,shadowing,texture synthesis,texturing,wavelets}
}
@article{Allen2005,
	title        = {Using L-systems for modeling source-sink interactions, architecture and physiology of growing trees: The L-PEACH model},
	author       = {M. T. Allen and P. Prusinkiewicz and T. M. DeJong},
	year         = 2005,
	month        = 6,
	journal      = {New Phytologist},
	volume       = 166,
	pages        = {869--880},
	doi          = {10.1111/j.1469-8137.2005.01348.x},
	issn         = {0028646X},
	abstract     = {Functional-structural plant models simulate the development of plant structure, taking into account plant physiology and environmental factors. The L-PEACH model is based on the development of peach trees. It demonstrates the usefulness of L-systems in constructing functional-structural models. L-PEACH uses L-systems both to simulate the development of tree structure and to solve differential equations for carbohydrate flow and allocation. New L-system-based algorithms are devised for simulating the behavior of dynamically changing structures made of hundreds of interacting, time-varying, nonlinear components. L-PEACH incorporates a carbon-allocation model driven by source-sink interactions between tree components. Storage and mobilization of carbohydrates during the annual life cycle of a tree are taken into account. Carbohydrate production in the leaves is simulated based on the availability of water and light. Apices, internodes, leaves and fruit grow according to the resulting local carbohydrate supply. L-PEACH outputs an animated three-dimensional visual representation of the growing tree and user-specified statistics that characterize selected stages of plant development. The model is applied to simulate a tree's response to fruit thinning and changes in water stress. L-PEACH may be used to assist in horticultural decision-making processes after being calibrated to specific trees. \textcopyright{} New Phytologist (2005).},
	issue        = 3,
	keywords     = {Carbon partitioning,Functional-structural plant modeling,L-system,Modeling plant growth and development},
	pmid         = 15869648
}
@inproceedings{Alsweis2005,
	title        = {Modeling and Visualization of symmetric and asymmetric plant competition},
	author       = {M Alsweis and O Deussen},
	year         = 2005,
	booktitle    = {Eurographics Workshop on Natural Phenomena},
	publisher    = {The Eurographics Association},
	doi          = {10.2312/NPH/NPH05/083-088},
	isbn         = {3-905673-29-0},
	issn         = {1816-0867},
	url          = {http://nbn-resolving.de/urn:nbn:de:bsz:352-opus-26559},
	abstract     = {In this paper we describe a new method for the visual simulation of evolving plant communities, which involves, aside from the known symmetric competition for resources also asymmetric competition. Asymmetric competition takes place if plants differ in their size and/or species. The discrete simulation methods proposed in this work help to visually simulate complex plant ecosystems for computer graphics.},
	editor       = {Pierre Poulin and Eric Galin},
	keywords     = {Computer Graphics Forum,EUROGRAPHICS}
}
@article{Hewitt2005,
	title        = {The importance of small-scale habitat structure for maintaining beta diversity},
	author       = {Judy E. Hewitt and Simon F. Thrush and Jane Halliday and Clinton Duffy},
	year         = 2005,
	journal      = {Ecology},
	publisher    = {Ecological Society of America},
	volume       = 86,
	pages        = {1619--1626},
	doi          = {10.1890/04-1099},
	issn         = {00129658},
	abstract     = {Marine soft sediments are often considered to be vast, homogeneous expanses of mud or sand; however, most exhibit small-scale biogenic structures. Generally such structures result from short-term processes, but mollusk shell debris can last for centuries, providing a settlement surface for plants and animals, which in turn stabilize the debris. This study sampled patches of shell debris and the surrounding sediment at increasing distances from the patches to determine the role of the patches in driving beta biodiversity. Sampling was conducted at three similar sites within 1 km in a marine reserve in New Zealand. The shell debris significantly affected beta diversity at all sites, although the magnitude of the effect was dependent on patch size, density, and debris particle size. These results have important implications for estimating and mapping biodiversity. They also have implications for marine conservation. The role of shell debris, suggested by this study, in increasing and maintaining biodiversity, emphasizes a need for reducing disturbance regimes and actively managing seafloor habitats in areas not previously considered for such. \textcopyright{} 2005 by the Ecological Society of America.},
	issue        = 6,
	keywords     = {Beta diversity,Conservation,Habitat heterogeneity,Marine reserve,New Zealand,Patch size,Seafloor management,Shell debris,Small-scale,Soft sediments}
}
@misc{Monaghan2005,
	title        = {Smoothed particle hydrodynamics},
	author       = {J. J. Monaghan},
	year         = 2005,
	month        = 8,
	journal      = {Reports on Progress in Physics},
	volume       = 68,
	pages        = {1703--1759},
	doi          = {10.1088/0034-4885/68/8/R01},
	issn         = {00344885},
	abstract     = {In this review the theory and application of Smoothed particle hydrodynamics (SPH) since its inception in 1977 are discussed. Emphasis is placed on the strengths and weaknesses, the analogy with particle dynamics and the numerous areas where SPH has been successfully applied. \textcopyright{} 2005 IOP Publishing Ltd.},
	issue        = 8
}
@techreport{Nacer2006,
	title        = {Image Compression Using Subband Wavelet Decomposition and DCT-based Quantization},
	author       = {Fatma Zohra Nacer and R\'{e}da Yahiaoui},
	year         = 2006,
	journal      = {WSEAS Transactions on Signal Processing},
	volume       = 2,
	pages        = {518--524},
	url          = {https://hal.archives-ouvertes.fr/hal-00080377},
	abstract     = {The aim of this work is to evaluate the performance of an image compression system based on wavelet-based subband decomposition. The compression method used in this paper differs from the classical procedure in the direction where the scalar quantization of the coarse scale approximation sub-image is replaced by a discrete cosine transform (DCT) based quantization. The images were decomposed using wavelet filters into a set of subbands with different resolutions corresponding to different frequency bands. The resulting high-frequency subbands were vector quantized according to the magnitude of their variances. The coarse scale approximation sub-image is quantized using scalar quantization and then using DCT-base quantization to show the benefit of this new optional method in term of CPU computationa1 cost vs restitution quality.},
	issue        = 4
}
@article{Glardon2006,
	title        = {Robust on-line adaptive footplant detection and enforcement for locomotion},
	author       = {Pascal Glardon and Ronan Boulic and Daniel Thalmann},
	year         = 2006,
	journal      = {Visual Comput},
	volume       = 22,
	pages        = {194--209},
	doi          = {10.1007/s00371-006-0376-9},
	abstract     = {A common problem in virtual character computer animation concerns the preservation of the basic foot-floor constraint (or footplant), consisting in detecting it before enforcing it. This paper describes a system capable of generating motion while continuously preserving the footplants for a real-time, dynamically evolving context. This system introduces a constraint detection method that improves classical techniques by adaptively selecting threshold values according to motion type and quality. The footplants are then enforced using a numerical inverse kinematics solver. As opposed to previous approaches, we define the footplant by attaching to it two effectors whose position at the beginning of the constraint can be modified, in order to place the foot on the ground, for example. However, the corrected posture at the constraint beginning is needed before it starts to ensure smoothness between the unconstrained and constrained states. We, therefore, present a new approach based on motion anticipation, which computes animation postures in advance, according to time-evolving motion parameters, such as locomotion speed and type. We illustrate our on-line approach with continuously modified locomotion patterns, and demonstrate its ability to correct motion artifacts, such as foot sliding, to change the constraint position and to modify from a straight to a curved walk motion.},
	keywords     = {Animation with constraints \cdot{},Human body simulation,Motion anticipation \cdot{}}
}
@article{Lefebvre2006,
	title        = {Perfect spatial hashing},
	author       = {Sylvain Lefebvre and Hugues Hoppe},
	year         = 2006,
	journal      = {ACM SIGGRAPH 2006 Papers, SIGGRAPH '06},
	pages        = {579--588},
	doi          = {10.1145/1179352.1141926},
	isbn         = 1595933646,
	url          = {https://hhoppe.com/perfecthash.pdf},
	abstract     = {We explore using hashing to pack sparse data into a compact table while retaining efficient random access. Specifically, we design a perfect multidimensional hash function - one that is precomputed on static data to have no hash collisions. Because our hash function makes a single reference to a small offset table, queries always involve exactly two memory accesses and are thus ideally suited for parallel SIMD evaluation on graphics hardware. Whereas prior hashing work strives for pseudorandom mappings, we instead design the hash function to preserve spatial coherence and thereby improve runtime locality of reference. We demonstrate numerous graphics applications including vector images, texture sprites, alpha channel compression, 3D-parameterized textures, 3D painting, simulation, and collision detection. Copyright \textcopyright{} 2006 by the Association for Computing Machinery, Inc.},
	keywords     = {3D-parameterized textures,adaptive textures,minimal perfect hash,multidimensional hashing,sparse data,vector images}
}
@phdthesis{Ng2006,
	title        = {Digital Light field photography},
	author       = {Ren Ng},
	year         = 2006,
	url          = {https://stanford.edu/class/ee367/reading/Ren Ng-thesis Lytro.pdf},
	abstract     = {This dissertation introduces a new approach to everyday photography, which solves the longstanding problems related to focusing images accurately. The root of these problems ismissing information. It turns out that conventional photographs tell us rather little about the light passing through the lens. In particular, they do not record the amount of light traveling along individual rays that contribute to the image. They tell us only the sum total of light rays striking each point in the image. To make an analogy with a music-recording studio, taking a conventional photograph is like recording all themusicians playing together, rather than recording each instrument on a separate audio track. In this dissertation, we will go after themissing information. With micron-scale changes to its optics and sensor, we can enhance a conventional camera so that it measures the light along each individual ray flowing into the image sensor. In other words, the enhanced camera samples the total geometric distribution of light passing through the lens in a single exposure. The price we will pay is collecting much more data than a regular photograph. However, I hope to convince you that the price is a very fair one for a solution to a problem as pervasive and long-lived as photographic focus. In photography, as in recordingmusic, it iswise practice to save asmuch of the source data as you can. Of course simply recording the light rays in the camera is not a complete solution to the focus problem. The other ingredient is computation.The idea is to re-sort the recorded light rays to where they should ideally have terminated, to simulate the flow of rays through the virtual optics of an idealized camera into the pixels of an idealized output photograph.},
	institution  = {Stanford University}
}
@article{Pi2006,
	title        = {Procedural terrain detail based on Patch-LOD algorithm},
	author       = {Xuexian Pi and Junqiang Song and Liang Zeng and Sikun Li},
	year         = 2006,
	journal      = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume       = {3942 LNCS},
	pages        = {913--920},
	doi          = {10.1007/11736639_111},
	isbn         = 3540334238,
	issn         = {03029743},
	abstract     = {The navigation and rendering of very large-scale terrain are facing a difficult problem that the geometry data and texture data cannot be used directly due to the storage space, computation capacity, and I/O bandwidth. To provide more realistic detail of terrain scene, procedural detail is a good solution. Firstly, this paper introduces a method of procedural geometry based on the terrain tile quad-tree and the Patch-LOD algorithm. Then, the texture generation operator is described and the method of dynamic pre-computation of patch-texture is presented. Finally, the experimental system based on these above ideas and methods has been implemented. The experimental results show that these methods are effective and are appropriate to the development of 3D games and battlefield applications. \textcopyright{} Springer-Verlag Berlin Heidelberg 2006.},
	issue        = 2002
}
@article{AbdelMalek2006,
	title        = {Swept volumes: Fundation, perspectives and applications},
	author       = {Karim Abdel-Malek and Jingzhou Yang and Denis Blackmore and Ken Joy},
	year         = 2006,
	month        = 6,
	journal      = {International Journal of Shape Modeling},
	volume       = 12,
	pages        = {87--127},
	doi          = {10.1142/S0218654306000858},
	issn         = {0218-6543},
	url          = {http://www.worldscientific.com/doi/abs/10.1142/S0218654306000858},
	issue        = {01}
}
@article{Eisemann2006,
	title        = {Fast scene voxelization and applications},
	author       = {Elmar Eisemann and Xavier D\'{e}coret},
	year         = 2006,
	journal      = {ACM SIGGRAPH 2006: Sketches, SIGGRAPH '06},
	doi          = {10.1145/1179849.1179859},
	isbn         = 1595933646,
	url          = {https://graphics.tudelft.nl/Publications-new/2006/ED06d/voxels05-final.pdf},
	abstract     = {This sketch paper presents an overview of "Fast Scene Voxelization and Applications" published at the ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games. It introduces slicemaps that correspond to a GPU friendly voxel representation of a scene. This voxelization is done at run-time in the order of milliseconds, even for complex and dynamic scenes containing more than 1M polygons. Creation and storage is performed on the graphics card avoiding unnecessary data transfer. Regular but also deformed grids are possible, in particular to better fit the scene geometry. Several applications are demonstrated: shadow calculation, refraction simulation and shadow volume culling/clamping.},
	keywords     = {gpu,refraction,shadows,voxelization}
}
@article{Benes2006,
	title        = {Hydraulic erosion},
	author       = {Bed\v{r}ich Bene\v{s} and V\'{a}clav T\v{e}\v{s}\'{\i}nsk\'{y} and Jan Horny\v{s} and Sanjiv K. Bhatia},
	year         = 2006,
	journal      = {Computer Animation and Virtual Worlds},
	volume       = 17,
	pages        = {99--108},
	doi          = {10.1002/cav.77},
	issn         = 15464261,
	abstract     = {This paper presents a generalized solution to modelling hydraulic erosion using ideas from fluid mechanics. The model is based on the Navier-Stokes equations, which provide the dynamics of velocity and pressure. These equations form the basis for the model to balance erosion and deposition that determine changes in the layers between water and erosion material. The eroded material is captured and relocated by water according to a material transport equation. The resulting model is fully 3D and is able to simulate a variety of phenomena including river meanders, low hill sediment wash, natural water springs and receding waterfalls. The simulations show the terrain morphogenesis and can be used for animations as well as for static scene generation. Copyright \textcopyright{} 2006 John Wiley \& Sons, Ltd.},
	issue        = 2,
	keywords     = {Hydraulic erosion,Terrain morphing,Virtual world,Visualization}
}
@article{Fradin2006,
	title        = {A hierarchical topology-based model for handling complex indoor scenes},
	author       = {David Fradin and Daniel Meneveaux and Pascal Lienhardt},
	year         = 2006,
	journal      = {Computer Graphics Forum},
	volume       = 25,
	pages        = {149--162},
	doi          = {10.1111/j.1467-8659.2006.00931.x},
	issn         = 14678659,
	abstract     = {This paper presents a topology-based representation dedicated to complex indoor scenes. It accounts for memory management and performances during modelling, visualization and lighting simulation. We propose to enlarge a topological model (called generalized maps) with multipartition and hierarchy. Multipartition allows the user to group objects together according to semantics. Hierarchy provides a coarse-to-fine description of the environment. The topological model we propose has been used for devising a modeller prototype and generating efficient data structure in the context of visualization, global illumination and 1 GHz wave propagation simulation. We presently handle buildings composed of up to one billion triangles. \textcopyright{} 2006 The Eurographics Association and Blackwell Publishing Ltd.},
	issue        = 2,
	keywords     = {Geometric modelling,Hierarchical model,Large buildings,Partitions,Visualization}
}
@article{Grasset-Simon2006,
	title        = {ND generalized map pyramids: Definition, representations and basic operations},
	author       = {Carine Grasset-Simon and Guillaume Damiand and Pascal Lienhardt},
	year         = 2006,
	journal      = {Pattern Recognition},
	volume       = 39,
	pages        = {527--538},
	doi          = {10.1016/j.patcog.2005.10.004},
	issn         = {00313203},
	abstract     = {Graph pyramids are often used for representing irregular image pyramids. For the 2D case, combinatorial pyramids have been recently defined in order to explicitly represent more topological information than graph pyramids. The main contribution of this work is the definition of pyramids of n-dimensional (nD) generalized maps. This extends the previous works to any dimension, and generalizes them in order to represent any type of pyramid constructed by using any removal and/or contraction operations. We give basic algorithms that allow to build an nD generalized pyramid that describes a multi-level segmented image. A pyramid of nD generalized maps can be implemented in several ways. We propose three possible representations and give conversion algorithms. \textcopyright{} 2005 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.},
	issue        = 4,
	keywords     = {Hierarchical data structure,Irregular pyramid,Multi-level segmented image,Pyramid of generalized maps}
}
@article{Baboud2010,
	title        = {Realistic Water Volumes in Real-Time},
	author       = {Lionel Baboud and Xavier D\'{e}coret and Lionel Baboud and Xavier D\'{e}coret and Realistic Water and Real-time Eurographics Workshop and Lionel Baboud and Xavier D\'{e}coret},
	year         = 2006,
	journal      = {Eurographics Workshop on Natural Phenomena},
	url          = {https://hal.inria.fr/inria-00510227/document},
	abstract     = {We present a real-time technique to render realistic water volumes. Water volumes are represented as the space enclosed between a ground heightfield and an animable water surface heightfield. This representation allows the application of recent GPU-based heightfield rendering algorithms. Our method is a simplified raytracing approach which correctly handles reflections and refractions and allows us to render complex effects such as light absorption, refracted shadows and refracted caustics. It runs at high framerates by exploiting the power of the latest graphic cards, and could be used in real-time applications like video games, or interactive simulation.}
}
@article{Frank2006,
	title        = {Geological information retrieval using tetrahedral meshes},
	author       = {Tobias Frank},
	year         = 2006,
	journal      = {IAMG 2006 - 11th International Congress for Mathematical Geology: Quantitative Geology from Multiple Sources},
	pages        = {12--15},
	isbn         = 9782960064407,
	url          = {https://www.ring-team.org/publications/2006/IAMG06_S14_12.pdf},
	abstract     = {Structured grids like Cartesian or stratigraphic grids are state-of-the-art for three dimensional modeling of the subsurface and a set of advanced visualization and modeling tools are available for these types of grids. However, tetrahedral meshes are becoming more and more important for geo-modeling applications since they can conform to complex geometries and provide more flexibility in terms of mesh resolution. Therefore, techniques for visualizing and modeling tetrahedral meshes need to be developed. Geological models are rich in information of different nature like topology of fault blocks, geological properties, geophysical data (e.g. seismic), stratigraphic layers or distances to geological interfaces like faults or to artifacts (e.g. wells). For an optimal interpretation, these layers of information can be combined into a single image using multi-texture capabilities of modern graphics hardware. An image consists of a set of user-defined iso-value surfaces and crosssections. Boolean operations of Constructive Solid Geometry with constant complexity are directly performed on the graphics hardware and allow complex geological and geometrical conditional queries. The computation and rendering of the iso-value surfaces is performed in real time on models with up to several hundred thousand cells on normal consumer hardware.},
	keywords     = {Geological co-rendering,Tetrahedral meshes,Visualization}
}
@article{Zhu2006,
	title        = {Approach to computer modeling of geological faults in 3D and an application},
	author       = {Liang Feng Zhu and Zheng He and Xin Pan and Xin Cai Wu},
	year         = 2006,
	journal      = {Journal of China University of Mining and Technology},
	volume       = 16,
	pages        = {461--465},
	doi          = {10.1016/S1006-1266(07)60048-0},
	issn         = 10061266,
	abstract     = {3D geological modeling, one of the most important applications in geosciences of 3D GIS, forms the basis and is a prerequisite for visualized representation and analysis of 3D geological data. Computer modeling of geological faults in 3D is currently a topical research area. Structural modeling techniques of complex geological entities containing reverse faults are discussed and a series of approaches are proposed. The geological concepts involved in computer modeling and visualization of geological fault in 3D are explained, the type of data of geological faults based on geological exploration is analyzed, and a normative database format for geological faults is designed. Two kinds of modeling approaches for faults are compared: A modeling technique of faults based on stratum recovery and a modeling technique of faults based on interpolation in subareas. A novel approach, called the Unified Modeling Technique for stratum and fault, is presented to solve the puzzling problems of reverse faults, syn-sedimentary faults and faults terminated within geological models. A case study of a fault model of bed rock in the Beijing Olympic Green District is presented in order to show the practical result of this method. The principle and the process of computer modeling of geological faults in 3D are discussed and a series of applied technical proposals established. It strengthens our profound comprehension of geological phenomena and the modeling approach, and establishes the basic techniques of 3D geological modeling for practical applications in the field of geosciences.},
	issue        = 4,
	keywords     = {Beijing Olympic Green District,Fault data,Geological fault,Stratum,Three dimensional geological modeling,Visualization}
}
@article{Schneider2006,
	title        = {Real-time editing, synthesis, and rendering of infinite landscapes on GPUs},
	author       = {Jens Schneider and T. Boldte and R\"{u}diger Westermann},
	year         = 2006,
	journal      = {Vision, modeling, and visualization 2006: proceedings},
	pages        = 145,
	isbn         = 3898380815,
	url          = {http://books.google.com/books?hl=en&amp;lr=&amp;id=zndnSzkfkXwC&amp;oi=fnd&amp;pg=PA145&amp;dq=real+time+editing+synthesis+and+rendering+of+infinite+landscapes+on+gpus&amp;ots=0Wd0aCUIo6&amp;sig=5tgTvz3EQ_seL0S9_g6soYekjds},
	abstract     = {Recent advances in algorithms and graphics hardware have opened the possibility to render large terrain fields at interactive rates on commodity PCs. Due to these advances it is possible today to interactively synthesize artificial terrains using procedural descriptions. Our paper extends on this work by presenting a new GPU method for real-time editing, synthesis, and rendering of infinite landscapes exhibiting a wide range of geological structures. Our method builds upon the concept of projected grids to achieve near-optimal sampling of the landscape. We describe the integration of procedural shaders for multifractals into this approach, and we propose intuitive options to edit the shape of the resulting terrain. The method is multi-scale and adaptive in nature, and it has been extended towards infinite and spherical domains. In combination with geo-typical textures that automatically adapt to the shape being synthesized, a powerful method for the creation and rendering of realistic landscapes is presented.}
}
@article{Schmidt2006,
	title        = {ShapeShop: Sketch-based solid modeling with BlobTrees},
	author       = {R. Schmidt and Brian Wyvill and M. C. Sousa and J. A. Jorge},
	year         = 2006,
	journal      = {SIGGRAPH 2006 - ACM SIGGRAPH 2006 Courses},
	pages        = {1--10},
	doi          = {10.1145/1185657.1185775},
	isbn         = 1595933646,
	url          = {https://www.inesc-id.pt/ficheiros/publicacoes/2607.pdf},
	abstract     = {Various systems have explored the idea of inferring 3D models from sketched 2D outlines. In all of these systems the underlying modeling methodology limits the complexity of models that can be created interactively. The ShapeShop sketch-based modeling system utilizes Hierarchical Implicit Volume Models (BlobTrees) as an underlying shape representation. The BlobTree framework supports interactive creation of complex, detailed solid models with arbitrary topology. A new technique is described for inflating 2D contours into rounded three-dimensional implicit volumes. Sketch-based modeling operations are defined that combine these basic shapes using standard blending and CSG operators. Since the underlying volume hierarchy is by definition a construction history, individual sketched components can be non-linearly edited and removed. For example, holes can be interactively dragged through a shape. ShapeShop also provides 2D drawing assistance using a new curve-sketching system based on variational contours. A wide range of models can be sketched with ShapeShop, from cartoon-like characters to detailed mechanical parts. Examples are shown which demonstrate significantly higher model complexity than existing systems.}
}
@inbook{Margin,
	title        = {Ocean Geologic Features},
	author       = {Paula Keener-Chavis},
	year         = 2006,
	booktitle    = {Learning Ocean Science through Ocean Exploration},
	pages        = {41--63},
	url          = {https://oceanexplorer.noaa.gov/edu/curriculum/section4a.pdf}
}
@article{Desbenoit2006,
	title        = {Modeling autumn sceneries},
	author       = {Brett Desbenoit and Eric Galin and Samir Akkouche and J\'{e}r\^{o}me Grosjean},
	year         = 2006,
	journal      = {EG - EuroGraphics},
	url          = {https://www.iut-arles.univ-provence.fr/web/brett-desbenoit/sites/brett-desbenoit/IMG/pdf/leaves-2006-2.pdf},
	abstract     = {This paper presents a system for modeling autumn leaves covering vegetation and monuments. We simulate the coloring and aging process by a stochastic model that represents the probability of evolution of a leaf according to the characteristics of the environment.We distribute leaves over the ground by approximating their complex move- ment by trajectory templates such as fluttering, rolling and tumbling. Leaves stack onto the ground in successive layers so as to improve the collision detection step.},
	keywords     = {aging and weathering,autumn coloring,ecosystem simulation}
}
@article{Tsubota2006,
	title        = {A particle method for blood flow simulation: application to flowing red blood cells and platelets},
	author       = {Ken-Ichi Tsubota and Shigeo Wada and Hiroki Kamada and Yoshitaka Kitagawa and Rui Lima and Takami Yamaguchi},
	year         = 2006,
	journal      = {Journal of the Earth Simulator},
	volume       = 5,
	pages        = {2--7},
	doi          = {http://hdl.handle.net/10198/1622},
	url          = {http://hdl.handle.net/10198/1622},
	abstract     = {A new computer simulation using a particle method was proposed to analyze the microscopic behavior of blood flow. A simulation region, including plasma, red blood cells (RBCs) and platelets, was modeled by an assembly of discrete particles. The proposed method was applied to the motions and deformations of a single RBC and multiple RBCs, and the thrombogenesis caused by platelet aggregation. It is expected that, combined with a sophisticated large-scale computational technique, the simulation method will be useful for understanding the overall properties of blood flow from blood cellular level (microscopic) to the resulting rheological properties of blood as a mass (macroscopic).},
	keywords     = {Blood Flow,Computational Biomechanics,Platelet,Red Blood Cell,Rheology}
}
@misc{DwarfFortress2006,
	title        = {Dwarf Fortress},
	author       = {Bay 12 Games},
	year         = 2006
}
@inbook{Sun2006,
	title        = {Dune fields / Mid-latitudes},
	author       = {J. Sun and D. R. Muhs},
	year         = 2006,
	month        = 1,
	booktitle    = {Encyclopedia of Quaternary Science},
	publisher    = {Elsevier Science Ltd.},
	pages        = {607--626},
	doi          = {10.1016/B0-44-452747-8/00157-5},
	isbn         = 9780444527479,
	abstract     = {Large dune fields, or sand seas, are widespread in the interiors of continental mid-latitudes. Most of them are found in China, Central Asia, Argentina, and the United States. Mid-latitude dune fields in the United States are generally smaller than those of low latitudes, but those in China, Central Asia, and Argentina are quite large. Where climates are arid, such as in western China and Central Asia, active dunes dominate these sand seas. Other dune fields, in the semiarid climates of eastern China, Argentina, and the United States, have mostly stabilized dunes. Mid-latitude dune fields are often near mountains, which supply much of the sediment to the sand seas on a regular basis, particularly during glacial periods. Many different kinds of eolian landforms are found in mid-latitude sand seas, including transverse dunes, longitudinal (linear) dunes, star dunes, parabolic dunes, and eolian sand sheets. Where dune fields of mid-latitudes occur in semiarid climates, they are particularly sensitive indicators of shifts in climate. In China, records of dune field expansion and contraction extend back hundreds of thousands of years.}
}
@inproceedings{Alsweis2006,
	title        = {Wang-Tiles for the Simulation and Visualization of Plant Competition},
	author       = {Monssef Alsweis and Oliver Deussen},
	year         = 2006,
	booktitle    = {Proceedings of the 24th International Conference on Advances in Computer Graphics},
	publisher    = {Springer-Verlag},
	pages        = {1--11},
	doi          = {10.1007/11784203_1},
	isbn         = {3-540-35638-X,978-3-540-35638-7},
	url          = {http://link.springer.com/10.1007/11784203_1},
	abstract     = {The Wang Tiles method is a successful and effective technique for the representation of 2D-texture or 3D-geometry. In this paper we present a new method to fill Wang tiles with a 2D-FON distribution or a 3D-geometry in order to achieve a more efficient runtime. We extend the Wang Tiles method to include information about their position. We further demonstrate how the individual tiles are filled with different intensities by using the FON distribution. Additionally, we present several new methods to eliminate errors between the tile edges and the different resource areas applying FON and corners relaxation techniques.}
}
@unpublished{Castle2006,
	title        = {Principles and Concepts of Agent-Based Modelling for Developing Geospatial Simulations},
	author       = {Christian J E Castle and Andrew T Crooks},
	year         = 2006,
	month        = 9,
	pages        = 62,
	abstract     = {
		The aim of this paper is to outline fundamental concepts and principles of the Agent-Based Modelling (ABM) paradigm, with particular reference to the development of geospatial simulations. The paper begins with a brief definition of modelling, followed by a classification of model types, and a comment regarding a shift (in certain circumstances) towards modelling systems at the individual-level. In particular, automata approaches (e.g. Cellular Automata, CA, and ABM) have been particularly popular, with ABM moving to the fore. A definition of agents and agent-based models is given; identifying their advantages and disadvantages, especially in relation to geospatial modelling. The potential use of agentbased models is discussed, and how-to instructions for developing an  gent-based model are provided. Types of simulation / modelling systems available for ABM are defined, supplemented with criteria to consider before choosing a particular system for a modelling endeavour. Information pertaining to a selection of simulation / modelling systems (Swarm, MASON, Repast, StarLogo, NetLogo, OBEUS, AgentSheets and AnyLogic) is provided, categorised by their licensing policy (open source, shareware / freeware and proprietary systems). The evaluation (i.e. verification, calibration, validation and analysis) of agentbased models and their output is examined, and noteworthy applications are  discussed.

		Geographical Information Systems (GIS) are a particularly useful medium for representing model input and output of a geospatial nature. However, GIS are not well suited to dynamic modelling (e.g. ABM). In particular, problems of representing time and change within GIS are highlighted. Consequently, this paper explores the opportunity of linking (through coupling or integration / embedding) a GIS with a simulation / modelling system purposely built, and therefore better suited to supporting the requirements of ABM. This paper concludes with a synthesis of the discussion that has proceeded.
	},
	city         = {London},
	institution  = {University College London}
}
@inproceedings{Hartman2006,
	title        = {Autonomous boids},
	author       = {Christopher Hartman and Bed\v{r}ich Bene\v{s}},
	year         = 2006,
	month        = 7,
	booktitle    = {Computer Animation and Virtual Worlds},
	volume       = 17,
	pages        = {199--206},
	doi          = {10.1002/cav.123},
	issn         = 15464261,
	abstract     = {The classical work of bird-like objects of Reynolds simulates polarized motion of groups of oriented particles, bird-like objects, or simply boids. To do this, three steering vectors are introduced. Cohesion is the tendency of boids to stay in the center of the flock, alignment smoothes their velocities to similar values, and separation helps them to avoid mutual collisions. If no impetus is introduced the boids wander somewhat randomly so an external leading force is necessary for the correct flock behavior. As can be observed during the bird flocking in the fall, birds sometimes move in a way that is not captured by the above described framework. Some of the birds, typically the ones on the edge of the flock, suddenly shoot-off. The flock then pursues this leader. In the original work by Reynolds the cohesion and separation are two complementary steers. We introduce a complementary force to the alignment that we call the change of leadership. This steer defines the chance of the boid to become a leader and try to escape. The leadership is derived from the boid position and the flock eccentricity. If a boid is on the front edge of the flock it has a higher chance to escape. Escaping from the flock is simulated as a sequence of velocity increases that are added to the current velocity of the boid. The entire system is easy to implement, is efficient, and runs simulations of hundreds of boids on a standard computer at 30 frames per second. Our system is aimed to real-time simulations and has the potential to be used in games, crowd simulations, etc. Copyright \textcopyright{} 2006 John Wiley \& Sons, Ltd.},
	issue        = {3-4},
	keywords     = {Artificial life,Bold,Computer animation,Flock,Particle system,Procedural animation}
}
@article{Bowen2007,
	title        = {Formal Models for Informal GUI Designs},
	author       = {Judy Bowen and Steve Reeves},
	year         = 2007,
	month        = 7,
	journal      = {Electronic Notes in Theoretical Computer Science},
	publisher    = {Elsevier},
	volume       = 183,
	pages        = {57--72},
	doi          = {10.1016/j.entcs.2007.01.061},
	issn         = 15710661,
	abstract     = {Many different methods exist for the design and implementation of software systems. These methods may be fully formal, such as the use of formal specification languages and refinement processes, or they may be totally informal, such as jotting design ideas down on paper prior to coding, or they may be somewhere in between these two extremes. Formal methods are naturally suited to underlying system behaviour while user-centred approaches to user interface design fit comfortably with more informal approaches. The challenge is to find ways of integrating user-centred design methods with formal methods so that the benefits of both are fully realised. This paper presents a way of capturing the intentions behind informal design artefacts within a formal environment and then shows several applications of this approach. \textcopyright{} 2007 Elsevier B.V. All rights reserved.},
	issue        = {SPEC. ISS.},
	keywords     = {Formal methods,GUIs,informal design artefacts,refinement,user-centred design}
}
@techreport{Roy2007,
	title        = {Vision par ordinateur: Calibration de Cam\'{e}ra et g\'{e}om\'{e}tri\'{e} epipolaire},
	author       = {S\'{e}bastien Roy and Jean-Philippe Tardif},
	year         = 2007
}
@article{Kelly2007a,
	title        = {Citygen: An interactive system for procedural city generation},
	author       = {George Kelly and Hugh McCabe},
	year         = 2007,
	journal      = {Fifth International Conference on Game Design and Technology},
	pages        = {8–16},
	isbn         = 9781902560182,
	url          = {http://www.citygen.net/files/citygen_gdtw07.pdf},
	note         = {Peut-\^{e}tre \`{a} associer \`{a} la simulation de karst de A. Peytavie},
	abstract     = {Contemporary 3D games are often situated within large urban environments. This necessitates a time-consuming and expensive content creation process involving the modelling of vast amounts of geometric detail: including terrain, roads, buildings, and other as- sociated features. We present a system called Citygen that aims to automate as much of this as possible by employing procedural generation methods to rapidly create the urban geometry typical of a modern city. Procedural methods have long been used within the graphics and game development communities to generate natural phenomena such as plants and trees. We employ these methods to generate the underlying road networks that form the structure of cities and urban neighbourhoods. These road networks are automatically mapped to any supplied terrain model, and adapt themselves to the specific geometry of the underlying terrain. Building footprints are automatically extracted from the resulting model and buildings can then be inserted either procedurally or by hand. Our system is unique in that it is designed to allow developers hands- on interactive control over the generation process. We achieve this by providing an interface allowing the user to directly manipulate geometric elements such as road intersection nodes, and to directly control and specify many aspects of the procedural generation. The results are updated in real time, thus facilitating an interactive design process.}
}
@article{Salgado2007,
	title        = {On the Simulation of Ocean Waves in Real-Time Using the GPU},
	author       = {Alex Salgado and Aura Conci},
	year         = 2007,
	journal      = {\ldots{} Symposium on Computer Graphics and Image \ldots{}},
	pages        = {6--7},
	url          = {http://www.lbd.dcc.ufmg.br/bdbcomp/servlet/Trabalho?id=15912},
	issue        = 1
}
@article{Franke2007a,
	title        = {Adaptive unstructured grid finite element simulation of two-dimensional magnetotelluric fields for arbitrary surface and seafloor topography},
	author       = {Antje Franke and Ralph Uwe B\"{o}rner and Klaus Spitzer},
	year         = 2007,
	journal      = {Geophysical Journal International},
	volume       = 171,
	pages        = {71--86},
	doi          = {10.1111/j.1365-246X.2007.03481.x},
	issn         = {0956540X},
	abstract     = {We present an adaptive unstructured triangular grid finite element approach for effectively simulating plane-wave diffusive electromagnetic fields in 2-D conductivity structures. The most striking advantage of irregular grids is their potential to incorporate arbitrary geometries including surface and seafloor topography. Adaptive mesh refinement strategies using an a posteriori error estimator yield most efficient numerical solutions since meshes are only refined where required. We demonstrate the robustness of this approach by comparison with analytical solutions and previously published numerical simulations. Maximum errors may systematically be reduced to, for example, 0.8 per cent for the apparent resistivity and 0.2\textdegree{} in the phase. An additional accuracy study of the thickness of the air layer in E-polarization suggests to keep a minimum thickness depending on lateral conductivity contrasts within the earth. Furthermore, we point out the new quality and flexibility of our simulation technique by addressing two marine magnetotelluric applications. In the first case, we discuss topographic effects associated with a synthetic sinusoidal sea bottom model and in the second case, we show a close-to-reality scenario using real bathymetry data from the East Pacific Rise at 17\textdegree{}S. \textcopyright{} 2007 The Authors Journal compilation \textcopyright{} 2007 RAS.},
	issue        = 1,
	keywords     = {Adaptive unstructured grids,Electromagnetic modelling,Electromagnetics,Finite element methods,Marine topography}
}
@article{Geiss2007,
	title        = {Cascades by NVIDIA},
	author       = {Ryan Geiss and Michael Thompson},
	year         = 2007,
	journal      = {Managing}
}
@article{Bridson2007a,
	title        = {Fluid simulation},
	author       = {Robert Bridson and Matthias M\"{u}ller-Fischer},
	year         = 2007,
	journal      = {ACM SIGGRAPH 2007 Papers - International Conference on Computer Graphics and Interactive Techniques},
	doi          = {10.1145/1281500.1281681}
}
@article{Bridson2007b,
	title        = {Fast poisson disk sampling in arbitrary dimensions},
	author       = {Robert Bridson},
	year         = 2007,
	journal      = {ACM SIGGRAPH 2007 Sketches, SIGGRAPH'07},
	doi          = {10.1145/1278780.1278807},
	url          = {https://www.cs.ubc.ca/~rbridson/docs/bridson-siggraph07-poissondisk.pdf},
	abstract     = {In many applications in graphics, particularly rendering, generating samples from a blue noise distribution is important. However, existing efficient techniques do not easily generalize beyond two dimensions. Here I demonstrate a simple modification to dart throwing which permits generation of Poisson disk samples in O(N) time, easily implemented in arbitrary dimension.},
	keywords     = {Blue noise,Poisson disk,Sampling}
}
@article{Runions2007,
	title        = {Modeling trees with a space colonization algorithm},
	author       = {Adam Runions and Brendan Lane and Przemyslaw Prusinkiewicz},
	year         = 2007,
	journal      = {Natural Phenomena},
	pages        = {63--70},
	isbn         = 9783905673494,
	issn         = 18160867,
	url          = {http://algorithmicbotany.org/papers/colonization.egwnp2007.pdf},
	abstract     = {We extend the open leaf venation model by Runions et al. [RFL05] to three dimensions and show that it generates surprisingly realistic tree structures. Model parameters correspond to visually relevant tree characteristics identified in landscaping, offering convenient control of tree shape and structure. \textcopyright{} The Eurographics Association 2007.},
	keywords     = {Generative tree modeling,Model control,Procedural modeling,Visual realism}
}
@article{Sorkine2007,
	title        = {As-Rigid-As-Possible Surface Modeling},
	author       = {Olga Sorkine and Marc Alexa},
	year         = 2007,
	journal      = {Symposium on Geometry processing},
	url          = {https://diglib.eg.org/bitstream/handle/10.2312/SGP.SGP07.109-116/109-116.pdf?sequence=1&isAllowed=n}
}
@inproceedings{Yoo2008,
	title        = {Blend Shape with Quaternions},
	author       = {Tae-Kyung Yoo and Won-Hyung Lee},
	year         = 2007,
	month        = 11,
	booktitle    = {2007 International Conference on Convergence Information Technology (ICCIT 2007)},
	publisher    = {IEEE},
	pages        = {776--780},
	doi          = {10.1109/ICCIT.2007.188},
	isbn         = {0-7695-3038-9},
	url          = {http://ieeexplore.ieee.org/document/4420354/},
	abstract     = {Animating 3D organic models to achieve compelling re- alism is a challenging task in the entertainment industry. Skin deformation based on an underlying skeleton is a com- mon method to animate believable organic models. The most widely used skeletal animation algorithm is linear blend skinning (LBS). We present a linear blend skinning technique using quaternion for deforming the skin geometry of the body of a digital creature around its skeleton. A case where blend shape is driven by Euler angle, we may even encounter gimbal lock. Our basic idea is to use quaternion representation as driven parameter for skin blend shape.}
}
@inbook{Crane2007,
	title        = {Real-Time Simulation and Rendering of 3D Fluids},
	author       = {Keenan Crane and Ignacio Llama and Sarah Tariq},
	year         = 2007,
	booktitle    = {GPU Gems 3},
	pages        = 1008,
	isbn         = {0321515269},
	url          = {http://www.amazon.com/GPU-Gems-3-Hubert-Nguyen/dp/0321515269%5Cnhttp://http.developer.nvidia.com/GPUGems3/gpugems3_ch03.html},
	abstract     = {The GPU Gems series features a collection of the most essential algorithms required by Next-Generation 3D Mittring, Lead Graphics Programmer, third volume of the best-selling GPU Gems series provides a snapshot of today's latest Graphics Processing Unit (GPU) programming techniques. The programmability of modern GPUs allows developers to not only distinguish themselves from one another but also to use this awesome processing power for non-graphics applications, such as physics simulation, financial analysis, and even virus detection, particularly with the CUDA architecture. Graphics remains the leading application for GPUs, and readers will find that the latest algorithms create ultra-realistic characters, better lighting, and post-rendering compositing effects. Major topics and EffectsPhysics SimulationGPU are from the following corporations and SystemsAppleBudapest University of Technology and Chinese University of Hong KongCornell Technical University in PragueDartmouth CollegeDigital Illusions Creative EntertainmentEindhoven University of TechnologyElectronic ArtsHavokHelsinki University of TechnologyImperial College LondonInfinity WardJuniper University of Bordeauxmental imagesMicrosoft ResearchMove InteractiveNCsoft CorporationNVIDIA CorporationPerpetual EntertainmentPlaylogic Game StudiosSEGA CorporationUFRGS (Brazil)Ulm UniversityUniversity of California, DavisUniversity of Central FloridaUniversity of CopenhagenUniversity of GironaUniversity of Illinois at Urbana-ChampaignUniversity of North Carolina Chapel HillUniversity of TokyoUniversity of WaterlooSection Editors include NVIDIA engineers: Cyril Zeller, Evan Hart, Ignacio Casta o, Kevin Bjorke, Kevin Myers, and Nolan Goodnight.The accompanying DVD includes complementary examples and sample programs.},
	issue        = {August 2007}
}
@article{Scott2007,
	title        = {Fractal-based fault simulations using a geological analogue - quantification of fault risk at Wyong, NSW, Australia},
	author       = {J. Scott and R. Dimitrakopoulos and S. Li and K. Bartlett},
	year         = 2007,
	journal      = {Australasian Institute of Mining and Metallurgy Publication Series},
	volume       = 14,
	pages        = {87--93},
	isbn         = 9781920806774,
	abstract     = {The modelling of fault populations and quantification of fault risk is a challenge for earth science and engineering applications, including minerals and coal mining, tunnel construction, forecasting of petroleum production, and selection of subterranean repositories for the disposal of toxic waste. This paper discusses a new advance in the use of stochastic fault simulation methods for the quantification of fault risk. The fractal properties of a fully known fault population are used as an analogue of the properties of an undiscovered fault population. The approach is elucidated through the quantification of fault risk in a prospective coalfield at Wyong, New South Wales, Australia, and incorporates spatial patterns of available 'hard' and 'soft' geological data. The method does not find faults unequivocally; rather the output is a map of fault probability. Simulations are found to be consistent with the available information and are statistically and spatially reasonable in geological terms. Significantly, the analogue approach provides a robust, quantified assessment of fault risk using limited exploration information.}
}
@article{Beardall2007,
	title        = {Goblins by spheroidal weathering},
	author       = {Matthew Beardall and McKay Farley and D. Ouderkirk and C. Reimschussel and J. Smith and M. Jones and P. Egbert},
	year         = 2007,
	journal      = {Natural Phenomena},
	pages        = {7--14},
	isbn         = 9783905673494,
	issn         = 18160867,
	url          = {https://diglib.eg.org/bitstream/handle/10.2312/NPH.NPH07.007-014/007-014.pdf?sequence=1&isAllowed=y#:~:text=to additional weathering.-,weathering.,Weathering weakens the rock.},
	abstract     = {Height map models of terrain are computationally efficient but cannot represent terrain with concave surfaces. We present an algorithm for generating sandstone goblins using a simulation of spheroidal weathering. Sandstone goblins are a kind of hoodoo which are characterized by rounded concave shapes. The weathering simulation uses bubbles centered on axis aligned voxels to approximate geometry-dependent effects of spheroidal weathering. We demonstrate that the algorithm, together with appropriate surface textures, produces visually plausible goblins at near interactive speeds for most simulation parameters. \textcopyright{} The Eurographics Association 2007.}
}
@article{Brosz2007,
	title        = {Terrain Synthesis by example},
	author       = {Jos\'{e} Brosz and Alpesh Ranchordas and Helder Ara\'{u}jo and Joaquim Jorge},
	year         = 2007,
	journal      = {Communications in Computer and Information Science},
	volume       = {4 CCIS},
	doi          = {10.1007/978-3-540-75274-5},
	isbn         = 9783540752721,
	issn         = 18650929,
	issue        = {January}
}
@article{Kamal2007,
	title        = {Parametrically controlled terrain generation},
	author       = {K. Raiyan Kamal and Yusuf Sarwar Uddin},
	year         = 2007,
	journal      = {Proceedings - GRAPHITE 2007, 5th International Conference on Computer Graphics and Interactive Techniques in Australasia and Southeast Asia},
	volume       = 1,
	pages        = {17--23},
	doi          = {10.1145/1321261.1321264},
	isbn         = 9781595939128,
	abstract     = {In this paper, we propose a novel approach towards parametrically controlled artificial terrain generation. Our proposed method focuses on generation of terrains having mountains of prespecified height and spread of base region and peak nearly at a prespecified location. Means of performing advanced tuning on the terrain to produce unusual artifacts on the terrain is also demonstrated and how our algorithm performs better in comparison with the well known terrain generation algorithms when used to solve the same problem is observed. Copyright \textcopyright{} 2007 by the Association for Computing Machinery, Inc.},
	issue        = 212,
	keywords     = {controlled terrain generation,parametric control,terrain generation}
}
@article{Neubert2007,
	title        = {Approximate image-based tree-modeling using particle flows},
	author       = {Boris Neubert and Thomas Franken and Oliver Deussen},
	year         = 2007,
	journal      = {Proceedings of the ACM SIGGRAPH Conference on Computer Graphics},
	volume       = 26,
	doi          = {10.1145/1275808.1276487},
	url          = {https://kops.uni-konstanz.de/bitstream/handle/123456789/39022/Neubert_0-408373.pdf},
	abstract     = {We present a method for producing 3D tree models from input photographs with only limited user intervention. An approximate voxel-based tree volume is estimated using image information. The density values of the voxels are used to produce initial positions for a set of particles. Performing a 3D flow simulation, the particles are traced downwards to the tree basis and are combined to form twigs and branches. If possible, the trunk and the first-order branches are determined in the input photographs and are used as attractors for particle simulation. The geometry of the tree skeleton is produced using botanical rules for branch thicknesses and branching angles. Finally, leaves are added. Different initial seeds for particle simulation lead to a variety, yet similar-looking branching structures for a single set of photographs. \textcopyright{} 2007 ACM.},
	keywords     = {Botanics,Image-based modeling,Plant models}
}
@inbook{Lienhardt2011,
	title        = {Mod\`{e}les topologiques},
	author       = {Pascal Lienhardt and Laurent Fuchs},
	year         = 2007,
	booktitle    = {Informatique graphique, mod\'{e}lisation g\'{e}om\'{e}trique et animation},
	pages        = {49--93},
	url          = {https://hal.archives-ouvertes.fr/hal-00580707/document}
}
@article{Poudret2007,
	title        = {Cartes combinatoires ouvertes},
	author       = {Mathieu Poudret and A. Arnould and Yves Bertrand and Pascal Lienhardt},
	year         = 2007,
	journal      = {Recherche},
	url          = {http://xlim-sic.labo.univ-poitiers.fr/publications/files/publi2015.pdf},
	issue        = {0}
}
@article{Nikolopoulos2007,
	title        = {Detecting holes and antiholes in graphs},
	author       = {Stavros D. Nikolopoulos and Leonidas Palios},
	year         = 2007,
	journal      = {Algorithmica (New York)},
	volume       = 47,
	pages        = {119--138},
	doi          = {10.1007/s00453-006-1225-y},
	issn         = {01784617},
	abstract     = {In this paper we study the problems of detecting holes and antiholes in general undirected graphs, and we present algorithms for these problems. For an input graph G on n vertices and m edges, our algorithms run in O(n + m 2) time and require O(n m) space; we thus provide a solution to the open problem posed by Hayward et al. asking for an O(n 4)-time algorithm for finding holes in arbitrary graphs. The key element of the algorithms is the use of the depth-first-search traversal on appropriate auxiliary graphs in which moving between any two adjacent vertices is equivalent to walking along a P 4 (i.e., a chordless path on four vertices) of the input graph or on its complement, respectively. The approach can be generalized so that for a fixed constant k \geq{} 5 we obtain an O(n k-1)-time algorithm for the detection of a hole (antihole resp.) on at least k vertices. Additionally, we describe a different approach which allows us to detect antiholes in graphs that do not contain chordless cycles on five vertices in O(n + m 2) time requiring O(n + m) space. Again, for a fixed constant k \geq{} 6, the approach can be extended to yield O(n k-2)-time and O(n 2)-space algorithms for detecting holes (antiholes resp.) on at least k vertices in graphs which do not contain holes (antiholes resp.) on k - 1 vertices. Our algorithms are simple and can be easily used in practice. Finally, we also show how our detection algorithms can be augmented so that they return a hole or an antihole whenever such a structure is detected in the input graph; the augmentation takes O(n + m) time and space. \textcopyright{} Springer 2007.},
	issue        = 2,
	keywords     = {Antiholes,Co-connectivity,Holes,Weakly chordal graphs}
}
@article{Wojtan2007,
	title        = {Animating corrosion and erosion},
	author       = {Chris Wojtan and Mark Carlson and Peter J. Mucha and Greg Turk},
	year         = 2007,
	journal      = {Natural Phenomena},
	pages        = {15--22},
	isbn         = 9783905673494,
	issn         = 18160867,
	url          = {https://pub.ist.ac.at/group_wojtan/projects/acid/acid_FINAL_nocolorplate.pdf},
	abstract     = {In this paper, we present a simple method for animating natural phenomena such as erosion, sedimentation, and acidic corrosion. We discretize the appropriate physical or chemical equations using finite differences, and we use the results to modify the shape of a solid body. We remove mass from an object by treating its surface as a level set and advecting it inward, and we deposit the chemical and physical byproducts into simulated fluid. Similarly, our technique deposits sediment onto a surface by advecting the level set outward. Our idea can be used for off-line high quality animations as well as interactive applications such as games, and we demonstrate both in this paper. \textcopyright{} The Eurographics Association 2007.}
}
@article{Belhadj2007,
	title        = {Terrain modeling: A constrained fractal model},
	author       = {Far\`{e}s Belhadj},
	year         = 2007,
	journal      = {ACM International Conference on Computer Graphics, Virtual Reality and Visualisation in Africa},
	pages        = {197--204},
	doi          = {10.1145/1294685.1294717},
	isbn         = 9781595939067,
	abstract     = {We present an algorithm mainly designed to reconstruct Digital Elevation Maps (DEM). Our approach relays on a fast and highly controllable fractal-based algorithm, we are able to create DEMs according to given constraints. Thus, these constraints can be given as scattered dataset of elevations obtained by satellite, our method supersamples this data and creates the according smooth terrain surface. Moreover, as a painter can make a sketch of his model, the final user can give or edit the main characteristics, local details and morphology, of his wanted DEM instantaneously obtaining the resulting terrain surface. Note that there is no limitation on the number of local constraints (that could vary from. 0 to the number of points of the final DEM). Thus, the method we propose gives the ability to modify the global aspect (the surface behavior) as well as to constrain any local detail of the final terrain model. This paper presents the algorithm, and reconstruction examples. Using a Root Mean Square Error computation between an original model and its downsampled-then-reconstructed version, the results confirm the method good behavior and show its efficiency. Other various terrain models and alternative applications are presented. Copyright \textcopyright{} 2007 by the Association for Computing Machinery, Inc.},
	keywords     = {Fractals,Midpoint displacement,Surface modeling,Surface reconstruction,Terrain}
}
@article{McInerney2007,
	title        = {Improved 3D Geology Modelling using an Implicit Function Interpolator and Forward Modelling of Potential Field Data},
	author       = {P. McInerney and A. Goldberg and P. Calcagno and G. Courrioux and R. Guillen and R. Seikel},
	year         = 2007,
	journal      = {Exploration 07: Fifth Decennial International Conference on Mineral Exploration},
	pages        = {919--922},
	url          = {https://www.911metallurgist.com/blog/wp-content/uploads/2015/10/Improved-3D-Geology-Modelling-using-an-Implicit-Function-Interpolator-and-Forward-Modelling-of-Potential-Field-Data.pdf},
	abstract     = {3D geometric modelling is a powerful tool enabling improved understanding of geology. It allows one to check and validate the consistency of separate 1D or 2D interpretations. Building a 3D model is also a way to share and communicate a geological view. Furthermore, a consistent 3D geometric model is essential for modelling computations of Earth-processes (such as groundwater studies) that need an accurate and coherent geometry of the distribution of physical properties of geological bodies. An original methodology has been developed in the BRGM to jointly interpolate geological contact locations and dips of the formations. The method uses the geological history of the area and the rock-relationships between the geological bodies. The model is calculated using an implicit 3D potential function as the interpolator for each component part of that geological history, and allows automatic computation of intersections between component parts and volume reconstruction. By using these tools, the geologist focuses on geological issues and easily tests different interpretations. This methodology has been applied to various geological contexts. The Elk gas field case-study is presented to illustrate the development of a 3D geology model, and the application of the model for computing conventional potential field model responses. For the Elk field the Gdd component of the gravity gradient tensor was computed for the 3D geology model, and those data compared to the first vertical derivative of the fully terrain-corrected Bouguer gravity airborne survey data. These comparisons of the computed vs. observed gravity data provided a basis for several iterations of interpretive adjustment of the 3D geology model. This iterative interpretive revision of the model was only practical by virtue of the ability to rapidly re-compute the 3D geology model using the potential field interpolator methodology. The outcome from this approach was an improved 3D geology model which honoured the available geology constraints from outcrop, drilling and seismic data, but which now had a modelled gravity response that was in better agreement with the observed gravity data.}
}
@article{Zhou2007,
	title        = {Terrain synthesis from digital elevation models},
	author       = {Howard Zhou and Jie Sun and Greg Turk and James M. Rehg},
	year         = 2007,
	journal      = {IEEE Transactions on Visualization and Computer Graphics},
	volume       = 13,
	pages        = {834--848},
	doi          = {10.1109/TVCG.2007.1027},
	issn         = 10772626,
	abstract     = {In this paper, we present an example-based system for terrain synthesis. In our approach, patches from a sample terrain (represented by a height field) are used to generate a new terrain. The synthesis is guided by a user-sketched feature map that specifies where terrain features occur in the resulting synthetic terrain. Our system emphasizes large-scale curvillnear features (ridges and valleys) because such features are the dominant visual elements in most terrains. Both the example height field and user's sketch map are analyzed using a technique from the field of geomorphology. The system finds patches from the example data that match the features found in the user's sketch. Patches are joined together using graph cuts and Poisson editing. The order in which patches are placed in the synthesized terrain is determined by breadth-first traversal of a feature tree and this generates improved results over standard raster-scan placement orders. Our technique supports user-controlled terrain synthesis in a wide variety of styles, based upon the visual richness of real-world terrain data. \textcopyright{} 2007 IEEE.},
	issue        = 4,
	keywords     = {Digital elevation models,Terrain analysis,Terrain synthesis,Texture synthesis},
	pmid         = 17495341
}
@article{Merrell2007,
	title        = {Example-based model synthesis},
	author       = {Paul Merrell},
	year         = 2007,
	journal      = {Proceedings - I3D 2007, ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games},
	pages        = {105--112},
	doi          = {10.1145/1230100.1230119},
	isbn         = 9781595936288,
	url          = {https://paulmerrell.org//model_synthesis.pdf},
	abstract     = {Model synthesis is a new approach to 3D modeling which automatically generates large models that resemble a small example model provided by the user. Model synthesis extends the 2D texture synthesis problem into higher dimensions and can be used to model many different objects and environments. The user only needs to provide an appropriate example model and does not need to provide any other instructions about how to generate the model. Model synthesis can be used to create symmetric models, models that change over time, and models that fit soft constraints. There are two important differences between our method and existing texture synthesis algorithms. The first is the use of a global search to find potential conflicts before adding new material to the model. The second difference is that we divide the problem of generating a large model into smaller subproblems which are easier to solve. Copyright \textcopyright{} 2007 by the Association for Computing Machinery, Inc.},
	keywords     = {Procedural modeling,Texture synthesis}
}
@article{Short2007,
	title        = {Global seagrass distribution and diversity: A bioregional model},
	author       = {F. Short and T. Carruthers and W. Dennison and M. Waycott},
	year         = 2007,
	journal      = {Journal of Experimental Marine Biology and Ecology},
	volume       = 350,
	pages        = {3--20},
	doi          = {10.1016/j.jembe.2007.06.012},
	issn         = {00220981},
	abstract     = {Seagrasses, marine flowering plants, are widely distributed along temperate and tropical coastlines of the world. Seagrasses have key ecological roles in coastal ecosystems and can form extensive meadows supporting high biodiversity. The global species diversity of seagrasses is low (< 60 species), but species can have ranges that extend for thousands of kilometers of coastline. Seagrass bioregions are defined here, based on species assemblages, species distributional ranges, and tropical and temperate influences. Six global bioregions are presented: four temperate and two tropical. The temperate bioregions include the Temperate North Atlantic, the Temperate North Pacific, the Mediterranean, and the Temperate Southern Oceans. The Temperate North Atlantic has low seagrass diversity, the major species being Zostera marina, typically occurring in estuaries and lagoons. The Temperate North Pacific has high seagrass diversity with Zostera spp. in estuaries and lagoons as well as Phyllospadix spp. in the surf zone. The Mediterranean region has clear water with vast meadows of moderate diversity of both temperate and tropical seagrasses, dominated by deep-growing Posidonia oceanica. The Temperate Southern Oceans bioregion includes the temperate southern coastlines of Australia, Africa and South America. Extensive meadows of low-to-high diversity temperate seagrasses are found in this bioregion, dominated by various species of Posidonia and Zostera. The tropical bioregions are the Tropical Atlantic and the Tropical Indo-Pacific, both supporting mega-herbivore grazers, including sea turtles and sirenia. The Tropical Atlantic bioregion has clear water with a high diversity of seagrasses on reefs and shallow banks, dominated by Thalassia testudinum. The vast Tropical Indo-Pacific has the highest seagrass diversity in the world, with as many as 14 species growing together on reef flats although seagrasses also occur in very deep waters. The global distribution of seagrass genera is remarkably consistent north and south of the equator; the northern and southern hemispheres share ten seagrass genera and only have one unique genus each. Some genera are much more speciose than others, with the genus Halophila having the most seagrass species. There are roughly the same number of temperate and tropical seagrass genera as well as species. The most widely distributed seagrass is Ruppia maritima, which occurs in tropical and temperate zones in a wide variety of habitats. Seagrass bioregions at the scale of ocean basins are identified based on species distributions which are supported by genetic patterns of diversity. Seagrass bioregions provide a useful framework for interpreting ecological, physiological and genetic results collected in specific locations or from particular species. \textcopyright{} 2007 Elsevier B.V. All rights reserved.},
	issue        = {1-2},
	keywords     = {Bioregional models,Diversity,Global distribution,Seagrass,Species,Temperate,Tropical}
}
@article{Santelices2007,
	title        = {The discovery of kelp forests in deep-water habitats of tropical regions},
	author       = {Bernab\'{e} Santelices},
	year         = 2007,
	journal      = {Proceedings of the National Academy of Sciences of the United States of America},
	volume       = 104,
	pages        = {19163--19164},
	doi          = {10.1073/pnas.0708963104},
	issn         = {00278424},
	issue        = 49,
	pmid         = 18042707
}
@article{He2007,
	title        = {Marine Ecoregions of the World},
	author       = {Fox He and Allen Gr and Lourie Sa and Martin Kd},
	year         = 2007,
	journal      = {World},
	pages        = {1--6},
	url          = {https://www.conservationgateway.org/ConservationPractices/Marine/Documents/Spalding et al MEOW.pdf},
	abstract     = {MEOW is a biogeographic classification of the world's coasts and shelves. It is the first ever comprehensive marine classification system with clearly defined boundaries and definitions and was developed to closely link to existing regional systems. The ecoregions nest within the broader biogeographic tiers of Realms and Provinces. See the maps.}
}
@article{Spalding2007,
	title        = {Marine ecoregions of the world: A bioregionalization of coastal and shelf areas},
	author       = {Mark D. Spalding and Helen E. Fox and Gerald R. Allen and Nick Davidson and Zach A. Ferda\~{n}a and Max Finlayson and Benjamin S. Halpern and Miguel A. Jorge and Al Lombana and Sara A. Lourie and Kirsten D. Martin and Edmund McManus and Jennifer Molnar and Cheri A. Recchia and James Robertson},
	year         = 2007,
	journal      = {BioScience},
	volume       = 57,
	pages        = {573--583},
	doi          = {10.1641/B570707},
	issn         = {00063568},
	abstract     = {The conservation and sustainable use of marine resources is a highlighted goal on a growing number of national and international policy agendas. Unfortunately, efforts to assess progress, as well as to strategically plan and prioritize new marine conservation measures, have been hampered by the lack of a detailed, comprehensive biogeographic system to classify the oceans. Here we report on a new global system for coastal and shelf areas: the Marine Ecoregions of the World, or MEOW, a nested system of 12 realms, 62 provinces, and 232 ecoregions. This system provides considerably better spatial resolution than earlier global systems, yet it preserves many common elements and can be cross-referenced to many regional biogeographic classifications. The designation of terrestrial ecoregions has revolutionized priority setting and planning for terrestrial conservation; we anticipate similar benefits from the use of a coherent and credible marine system. \textcopyright{} 2007 American Institute of Biological Sciences.},
	issue        = 7,
	keywords     = {Ecoregions,Mapping,Marine biogeography,Marine protected areas,Representative conservation}
}
@article{Lassabe2007,
	title        = {A new step for artificial creatures},
	author       = {Nicolas Lassabe and Herv\'{e} Luga and Yves Duthen},
	year         = 2007,
	journal      = {Proceedings of the 2007 IEEE Symposium on Artificial Life, CI-ALife 2007},
	pages        = {243--250},
	doi          = {10.1109/ALIFE.2007.367803},
	isbn         = {142440701X},
	abstract     = {In this article, we present our research on the evolution of morphology and behavior of complex creatures in virtual environments. We propose to study the evolution of creatures faced with different situations from crawling and walking to more complex activities like climbing and skating. Our creatures use solid 3D blocks and graphtals like Karl Sims's creatures and a new type of controller based on classifier system. The results constitute a new step toward creatures adapted to more complex environments. \textcopyright{} 2007 IEEE.}
}
@article{Mei2007,
	title        = {Fast hydraulic erosion simulation and visualization on GPU},
	author       = {Xing Mei and Philippe Decaudin and Bao Gang Hu},
	year         = 2007,
	journal      = {Proceedings - Pacific Conference on Computer Graphics and Applications},
	pages        = {47--56},
	doi          = {10.1109/PG.2007.27},
	isbn         = {0769530095},
	issn         = 15504085,
	url          = {https://xing-mei.github.io/files/erosion.pdf},
	abstract     = {Natural mountains and valleys are gradually eroded by rainfall and river flows. Physically-based modeling of this complex phenomenon is a major concern in producing realistic synthesized terrains. However, despite some recent improvements, existing algorithms are still computationally expensive, leading to a time-consuming process fairly impractical for terrain designers and 3D artists. In this paper, we present a new method to model the hydraulic erosion phenomenon which runs at interactive rates on today's computers. The method is based on the velocity field of the running water, which is created with an efficient shallow-water fluid model. The velocity field is used to calculate the erosion and deposition process, and the sediment transportation process. The method has been carefully designed to be implemented totally on GPU, and thus takes full advantage of the parallelism of current graphics hardware. Results from experiments demonstrate that the proposed method is effective and efficient. It can create realistic erosion effects by rainfall and river flows, and produce fast simulation results for terrains with large sizes. \textcopyright{} 2007 IEEE.}
}
@article{Nakamura2007,
	title        = {A geochemical model for coral reef formation},
	author       = {T. Nakamura and T. Nakamori},
	year         = 2007,
	journal      = {Coral Reefs},
	volume       = 26,
	pages        = {741--755},
	doi          = {10.1007/s00338-007-0262-6},
	issn         = {07224028},
	abstract     = {The conspicuous growth of a reef crest and the resulting differentiation of reef topography into a moat (shallow lagoon), crest and slope have long attracted the interest of scientists studying coral reefs. A geochemical model is here proposed for reef formation, taking into account diffusion-limited and light-enhanced calcification. First, to obtain data on net photosynthesis and calcification rates in the field, a typical coral community was cultured in situ on a reef flat. Using these data, equations including parameters for calcification were then developed and applied in computer simulations to model the development over time of reef profiles and the diffusion of carbon species. The reef topography simulated by the model was in general agreement with reef topography observed in nature. The process of reef growth as shown by the modeling was as follows. Increases in the shore-to-offshore gradients of the concentrations of carbonate species result from calcification by reef biota, giving a lower rate of growth on near-shore parts of the reef than on those further offshore. As a result, original topography is diversified into moat and reef crest for the first time. Reef growth on the reef crest is more rapid than in the inshore moat area, because more light is available at the crest. Reef growth on the near-shore side of the reef is further inhibited by damming of carbon-rich seawater on the seaward side of the reef by the reef crest. Over time, the topographic expression of the reef crest and moat becomes progressively more clearly defined by these geochemical processes. \textcopyright{} 2007 Springer-Verlag.},
	issue        = 4,
	keywords     = {Calcification,Photosynthesis,Reef formation,Simulation}
}
@article{Bridson2007c,
	title        = {Curl-noise for procedural fluid flow},
	author       = {Robert Bridson and Jim Houriham and Marcus Nordenstam},
	year         = 2007,
	journal      = {ACM Transactions on Graphics},
	volume       = 26,
	pages        = 46,
	doi          = {10.1145/1239451.1239497},
	issn         = {07300301},
	abstract     = {Procedural methods for animating turbulent fluid are often preferred over simulation, both for speed and for the degree of animator control. We offer an extremely simple approach to efficiently generating turbulent velocity fields based on Perlin noise, with a formula that is exactly incompressible (necessary for the characteristic look of everyday fluids), exactly respects solid boundaries (not allowing fluid to flow through arbitrarily-specified surfaces), and whose amplitude can be modulated in space as desired. In addition, we demonstrate how to combine this with procedural primitives for flow around moving rigid objects, vortices, etc.},
	issue        = 99,
	keywords     = {a of distance from,a smoothed step function,by a modu-,figure 1,fluids,incompressible 2d noise with,lation function,n,noise,procedural animation,pute the potential \ensuremath{\psi},solid boundaries,t,the,to com-,turbulence,we multiply scaled noise,x}
}
@inproceedings{Dvorak2007,
	title        = {Real-time terrain deformations},
	author       = {Radim Dvo\v{r}\'{a}k and Martin Drahansk\'{y}},
	year         = 2007,
	booktitle    = {Proceedings of the 4th International Conference on Image and Graphics, ICIG 2007},
	pages        = {1020--1025},
	doi          = {10.1109/ICIG.2007.88},
	isbn         = {0769529291},
	abstract     = {This paper presents a method for a physically based real-time terrain deformation. The motivation originates from the fact that there exist many deformable models, but the terrain deformation is a special problem in the field of computer graphics. OpenSceneGraph toolkit provides an excellent environment for the large terrain visualization and it was accepted as a standard for many graphic specialists. Therefore, the main goal of this method is the local deformation ability of some large terrain, which is represented by a sub-graph of OpenSceneGraph scene. However, the technique may be easily adaptable to any terrain representation. The results show a great potential of the used method and thus there is outlined the future work at the end. \textcopyright{} 2007 IEEE.}
}
@phdthesis{BelhadjThesis,
	title        = {Mod\'{e}lisation automatique de g\'{e}o-environnements naturels et multi-urbains},
	author       = {Far\`{e}s Belhadj},
	year         = 2007,
	city         = {Paris},
	institution  = {Universit\'{e} Paris 8}
}
@article{Harada2007,
	title        = {Smoothed Particle Hydrodynamics on GPUs},
	author       = {Takahiro Harada and Seiichi Koshizuka and Yoichiro Kawaguchi},
	year         = 2007,
	month        = 1,
	journal      = {The Visual Computer}
}
@inproceedings{Shen2008,
	title        = {Med vis: A real-time immersive visualization environment for the exploration of medical volumetric data},
	author       = {Rui Shen and Pierre Boulanger and Michelle Noga},
	year         = 2008,
	booktitle    = {Proceedings - 5th International Conference BioMedical Visualization, Information Visualization in Medical and Biomedical Informatics, MediVis 2008},
	pages        = {63--70},
	doi          = {10.1109/MediVis.2008.10},
	isbn         = 9780769532844,
	abstract     = {This paper describes the Medical Visualizer, a real-time visualization system for analyzing medical volumetric data in various virtual environments, such as autostereoscopic displays, dual-projector screens and immersive environments such as the CAVE. Direct volume rendering is used for visualizing the details of medical volumetric data sets without intermediate geometric representations. By interactively manipulating the color and transparency functions through the friendly user interface, radiologists can either inspect the data set as a whole or focus on a specific region. In our system, 3D texture hardware is employed to accelerate the rendering process. The system is designed to be platform independent, as all virtual reality functions are separated from kernel functions. Due to its modular design, our system can be easily extended to other virtual environments, and new functions can be incorporated rapidly. \textcopyright{} 2008 IEEE.}
}
@article{Bimber2008,
	title        = {The visual computing of projector-camera systems},
	author       = {Oliver Bimber and Daisuke Iwai and Gordon Wetzstein and Anselm Grundhofer},
	year         = 2008,
	journal      = {ACM SIGGRAPH 2008 Classes},
	pages        = 84,
	doi          = {10.1145/1401132.1401239},
	abstract     = {This article focuses on real-time image correction techniques that enable projector-camera systems to display images onto screens that are not optimized for projections, such as geometrically complex, colored and textured surfaces. It reviews hardware accelerated methods like pixel-precise geometric warping, radiometric compensation, multi-focal projection, and the correction of general light modulation effects. Online and offline calibration as well as invisible coding methods are explained. Novel attempts in super-resolution, high dynamic range and high-speed projection are discussed. These techniques open a variety of new applications for projection displays. Some of them will also be presented in this report. Categories and Subject Descriptors (according to ACM CCS): I.3.3 [Computer Graphics]: Picture/Image Generation I.4.8 [Image Processing and Computer Vision]: Scene Analysis I.4.9 [Image Processing and Computer Vision]: Applications \textcopyright{} The Eurographics Association 2007.},
	issue        = {June 2014},
	keywords     = {Gpu rendering,Image-correction,Projector-camera systems,Virtual and augmented reality}
}
@article{VanDerMaaten2008,
	title        = {Visualizing Data using t-SNE},
	author       = {Laurens Van Der Maaten and Geoffrey Hinton},
	year         = 2008,
	journal      = {Journal of Machine Learning Research},
	volume       = 9,
	pages        = {2579--2605},
	abstract     = {We present a new technique called "t-SNE" that visualizes high-dimensional data by giving each datapoint a location in a two or three-dimensional map. The technique is a variation of Stochastic Neighbor Embedding (Hinton and Roweis, 2002) that is much easier to optimize, and produces significantly better visualizations by reducing the tendency to crowd points together in the center of the map. t-SNE is better than existing techniques at creating a single map that reveals structure at many different scales. This is particularly important for high-dimensional data that lie on several different, but related, low-dimensional manifolds, such as images of objects from multiple classes seen from multiple viewpoints. For visualizing the structure of very large data sets, we show how t-SNE can use random walks on neighborhood graphs to allow the implicit structure of all of the data to influence the way in which a subset of the data is displayed. We illustrate the performance of t-SNE on a wide variety of data sets and compare it with many other non-parametric visualization techniques, including Sammon mapping, Isomap, and Locally Linear Embedding. The visualiza-tions produced by t-SNE are significantly better than those produced by the other techniques on almost all of the data sets.},
	keywords     = {dimensionality reduction,embedding algorithms,manifold learning,multidimensional scaling,visualization}
}
@article{Song2008,
	title        = {Biomechanics of overground vs. treadmill walking in healthy individuals},
	author       = {Joo Lee Song and Joseph Hidler},
	year         = 2008,
	month        = 3,
	journal      = {Journal of Applied Physiology},
	volume       = 104,
	pages        = {747--755},
	doi          = {10.1152/japplphysiol.01380.2006},
	issn         = 87507587,
	abstract     = {The goal of this study was to compare treadmill walking with overground walking in healthy subjects with no known gait disorders. Nineteen subjects were tested, where each subject walked on a split-belt instrumented treadmill as well as over a smooth, flat surface. Comparisons between walking conditions were made for temporal gait parameters such as step length and cadence, leg kinematics, joint moments and powers, and muscle activity. Overall, very few differences were found in temporal gait parameters or leg kinematics between treadmill and overground walking. Conversely, sagittal plane joint moments were found to be quite different, where during treadmill walking trials, subjects demonstrated less dorsiflexor moments, less knee extensor moments, and greater hip extensor moments. Joint powers in the sagittal plane were found to be similar at the ankle but quite different at the knee and hip joints. Differences in muscle activity were observed between the two walking modalities, particularly in the tibialis anterior throughout stance, and in the hamstrings, vastus medialis and adductor longus during swing. While differences were observed in muscle activation patterns, joint moments and joint powers between the two walking modalities, the overall patterns in these behaviors were quite similar. From a therapeutic perspective, this suggests that training individuals with neurological injuries on a treadmill appears to be justified. Copyright \textcopyright{} 2008 the American Physiological Society.},
	issue        = 3,
	keywords     = {Electromyogram,Gait,Motion analysis},
	pmid         = 18048582
}
@article{Carter2008,
	title        = {A comparison of step-detection methods: How well can you do?},
	author       = {Brian C. Carter and Michael Vershinin and Steven P. Gross},
	year         = 2008,
	month        = 1,
	journal      = {Biophysical Journal},
	publisher    = {Biophysical Society},
	volume       = 94,
	pages        = {306--319},
	doi          = {10.1529/biophysj.107.110601},
	issn         = {00063495},
	abstract     = {Many biological machines function in discrete steps, and detection of such steps can provide insight into the machines' dynamics. It is therefore crucial to develop an automated method to detect steps, and determine how its success is impaired by the significant noise usually present. A number of step detection methods have been used in previous studies, but their robustness and relative success rate have not been evaluated. Here, we compare the performance of four step detection methods on artificial benchmark data (simulating different data acquisition and stepping rates, as well as varying amounts of Gaussian noise). For each of the methods we investigate how to optimize performance both via parameter selection and via prefiltering of the data. While our analysis reveals that many of the tested methods have similar performance when optimized, we find that the method based on a chi-squared optimization procedure is simplest to optimize, and has excellent temporal resolution. Finally, we apply these step detection methods to the question of observed step sizes for cargoes moved by multiple kinesin motors in vitro. We conclude there is strong evidence for sub-8-nm steps of the cargo's center of mass in our multiple motor records. \textcopyright{} 2008 by the Biophysical Society.},
	issue        = 1,
	pmid         = 17827239
}
@article{Frade2008a,
	title        = {Genetic terrain programming an aesthetic approach to terrain generation},
	author       = {Miguel Frade and F. Fernandez De Vega and Carlos Cotta},
	year         = 2008,
	journal      = {Computer Games and Allied Technology 08, CGAT 08 - Animation, Multimedia, IPTV and Edutainment, Proceedings},
	pages        = {323--330},
	doi          = {10.5176/978-981-08-8227-3_cgat08-43},
	isbn         = 9789810806934,
	abstract     = {Nowadays there are a wide range of techniques for terrain generation, but are focused on providing realistic terrains often neglecting the aesthetic appeal. The Genetic Terrain Programming technique, based on evolutionary design with Genetic Programming, allows designers to evolve terrains according to their aesthetic feelings or desired features. This technique evolves TPs (Terrain Programmes) that are capable of generating different terrains, but consistently with the same features. This paper presents a study about the perseverance of terrain features of the TPs across different LODs (Levels Of Detail). Results showed it is possible to use low LODs during the evolutionary phase without compromising results and the terrain features generated by a TPs are scale invariant.},
	keywords     = {Evolutionary systems,Genetic terrain programming,Level of detail,Terrain generator}
}
@article{Frade2008,
	title        = {Modelling video games' Landscapes by means of Genetic Terrain Programming - A new approach for improving users' experience},
	author       = {Miguel Frade and F. Fernandez De Vega and Carlos Cotta},
	year         = 2008,
	journal      = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume       = {4974 LNCS},
	pages        = {485--490},
	doi          = {10.1007/978-3-540-78761-7_52},
	isbn         = 3540787607,
	issn         = {03029743},
	abstract     = {Terrain generation algorithms can provide a realistic scenario for video game experience and can help keep users interested in playing by providing new landscapes each time they play. Nowadays there are a wide range of techniques for terrain generation, but all of them are focused on providing realistic terrains. This paper proposes a new technique, Genetic Terrain Programming, based on evolutionary design with GP to allow game designers to evolve terrains according to their aesthetic feelings or desired features. The developed application produces Terrains Programs that will always generate different terrains, but consistently with the same features (e.g. valleys, lakes). \textcopyright{} 2008 Springer-Verlag Berlin Heidelberg.},
	keywords     = {Evolutionary art,Genetic programming,Terrain generation,Video games}
}
@misc{Baidoo-Williams2008,
	title        = {Application of Swarms for Exploration of Manganese in Deep Ocean},
	author       = {H. E. Baidoo-Williams and A. Vidyarthi and S Kapadia},
	year         = 2008,
	pages        = {1--18},
	abstract     = {Manganese, a metal with important industrial uses, is fast depleting due to various ecological constraints. There is therefore a need to find alternate mining sources. An alternative that has been constantly proffered is ocean floor mining of manganese. Ocean floor mining by human agents is not feasible. By this paper, we propose the use of swarming techniques similar to ants and termites, for the extraction of manganese nodules. Swarm applications are robust because agents in a swarm communicate locally rather than globally and failure/loss of an agent which is an inevitable occurrence in the terrain being considered will not affect the general objective of the swarm.}
}
@article{Sugihara2008,
	title        = {A Sketch-Based Method to Control Deformation in a Skeletal Implicit Surface Modeler},
	author       = {Masamichi Sugihara and Erwin De Groot and Brian Wyvill and Ryan Schmidt},
	year         = 2008,
	journal      = {Computational Geometry},
	url          = {http://diglib.eg.org/bitstream/handle/10.2312/SBM.SBM08.065-072/065-072.pdf?sequence=1&isAllowed=y}
}
@inproceedings{Eisemann2008,
	title        = {Single-pass GPU solid voxelization for real-time applications},
	author       = {Elmar Eisemann and Xavier Decoret},
	year         = 2008,
	booktitle    = {Proceedings - Graphics Interface},
	pages        = {73--80},
	isbn         = 9781568814230,
	issn         = {07135424},
	url          = {https://graphics.tudelft.nl/Publications-new/2008/ED08c/solidvoxelizationAuthorVersion.pdf},
	abstract     = {In this paper, we present a single-pass technique to voxelize the interior of watertight 3D models with high resolution grids in realtime during a single rendering pass. Further, we develop a filtering algorithm to build a density estimate that allows the deduction of normals from the voxelized model. This is achieved via a dense packing of information using bitwise arithmetic. We demonstrate the versatility of the method by presenting several applications like translucency effects, CSG operations, interaction for particle simulations, and morphological operations. The speed of our method opens up the road for previously impossible approaches in realtime: 300,000 polygons are voxelized into a grid of one billion voxels at > 90Hz with a recent graphics card.},
	keywords     = {Applications,GPU,Real-time,Solid voxelization}
}
@phdthesis{Runions2008,
	title        = {Modeling biological patterns using the space colonization algorithm},
	author       = {Adam Runions},
	year         = 2008,
	journal      = {A Thesis submitted to the faculty of graduate studies for degree of master of science},
	pages        = 74,
	issn         = {0147-958X},
	url          = {http://algorithmicbotany.org/papers/runionsa.th2008.pdf}
}
@article{Stava2008,
	title        = {Interactive terrain modeling using hydraulic erosion},
	author       = {Ond\v{r}ej \v{S}t'ava and Bed\v{r}ich Bene\v{s} and Matthew Brisbin and Jaroslav Kriv\'{a}nek},
	year         = 2008,
	journal      = {Computer Animation 2008 - ACM SIGGRAPH / Eurographics Symposium, SCA 2008 - Proceedings},
	pages        = {200--210},
	isbn         = 9783905674101,
	url          = {https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.173.5239&rep=rep1&type=pdf},
	abstract     = {We present a step toward interactive physics-based modeling of terrains. A terrain, composed of layers of materials, is edited with interactive modeling tools built upon different physics-based erosion and deposition algorithms. First, two hydraulic erosion algorithms for running water are coupled. Areas where the motion is slow become more eroded by the dissolution erosion, whereas in the areas with faster motion, the force-based erosion prevails. Second, when the water under-erodes certain areas, slippage takes effect and the river banks fall into the water. A variety of local and global editing operation is provided. The user has a great level of control over the process and receives immediate feedback since the GPU-based erosion simulation runs at least at 20 fps on off-the-shelf computers for scenes with grid resolution of 2048\texttimes{}1024 and four layers of material. We also present a divide and conquer approach to handle large terrain erosion, where the terrain is tiled, and each tile calculated independently on the GPU. We show a wide variety of erosion-based modeling features such as forming rivers, drying flooded areas, rain, interactive manipulation with rivers, spring, adding obstacles into the water, etc.}
}
@article{Jermann2008,
	title        = {Une approche orient\'{e}e hi\'{e}rarchie de contraintes pour la r\'{e}solution de probl\`{e}mes de contraintes g\'{e}om\'{e}triques},
	author       = {Christophe Jermann and Hiroshi Hosobe},
	year         = 2008,
	journal      = {7e Conf\'{e}rence Internationale de MOd\'{e}lisation et SIMulation}
}
@article{Damiand2008,
	title        = {Topological model for 3D image representation: Definition and incremental extraction algorithm},
	author       = {Guillaume Damiand},
	year         = 2008,
	journal      = {Computer Vision and Image Understanding},
	volume       = 109,
	pages        = {260--289},
	doi          = {10.1016/j.cviu.2007.09.007},
	issn         = 10773142,
	abstract     = {In this paper, we define the three-dimensional topological map, a model which represents both the topological and geometrical information of a three-dimensional labeled image. Since this model describes the image's topology in a minimal way, we can use it to define efficient image processing algorithms. The topological map is the last level of map hierarchy. Each level represents the region boundaries of the image and is defined from the previous level in the hierarchy, thus giving a simple constructive definition. This model is an extension of the similar model defined for 2D images. Progressive definition based on successive map levels allows us to extend this model to higher dimension. Moreover, with progressive definition, we can study each level separately. This simplifies the study of disconnection cases and the proofs of topological map properties. Finally, we provide an incremental extraction algorithm which extracts any map of the hierarchy in a single image scan. Moreover, we show that this algorithm is very efficient by giving the results of our experiments made on artificial images. \textcopyright{} 2007 Elsevier Inc. All rights reserved.},
	issue        = 3,
	keywords     = {3D image representation,Combinatorial map,Intervoxel boundaries,Structure for image processing,Topological model}
}
@article{Guillen2008,
	title        = {Geological modelling from field data and geological knowledge. Part II. Modelling validation using gravity and magnetic data inversion},
	author       = {A. Guillen and Ph Calcagno and G. Courrioux and A. Joly and P. Ledru},
	year         = 2008,
	journal      = {Physics of the Earth and Planetary Interiors},
	volume       = 171,
	pages        = {158--169},
	doi          = {10.1016/j.pepi.2008.06.014},
	issn         = {00319201},
	url          = {https://hal.archives-ouvertes.fr/hal-00532156/document},
	abstract     = {The analysis of multiple data sets is required to select a realistic 3D geological model among an infinite number of possibilities. An inverse method that aims at describing the 3D geometry of geological objects is presented. The method takes into account the geology and the physical properties of rocks, while respecting the topological properties of an a priori model. The a priori model is built from the geological data set and its geometry is largely dependent upon assumptions about inaccessible geology at depth. This method, referred to as "total litho-inversion" is a generalised 3D inversion that results in quantifying the lithology and the distribution of rock property in a probabilistic way. Its application is demonstrated through (i) a simple synthetic case and (ii) the relative distribution characterization of granites and diorites in an orogenic domain. \textcopyright{} 2008 Elsevier B.V. All rights reserved.},
	issue        = {1-4},
	keywords     = {3D geology,Gravity,Inverse problem,Magnetism,Metropolis,Potential field,Probability,Tensors}
}
@article{Orzan2008,
	title        = {Diffusion curves},
	author       = {Alexandrina Orzan and Adrien Bousseau and Holger Winnem\"{o}ller and Pascal Barla and Jo\"{e}lle Thollot and David Salesin},
	year         = 2008,
	month        = 8,
	journal      = {ACM Transactions on Graphics},
	volume       = 27,
	pages        = {1--8},
	doi          = {10.1145/1360612.1360691},
	issn         = {0730-0301},
	url          = {https://dl.acm.org/doi/10.1145/1360612.1360691},
	abstract     = {<p> We describe a new vector-based primitive for creating smooth-shaded images, called the <italic>diffusion curve</italic> . A diffusion curve partitions the space through which it is drawn, defining different colors on either side. These colors may vary smoothly along the curve. In addition, the sharpness of the color transition from one side of the curve to the other can be controlled. Given a set of diffusion curves, the final image is constructed by solving a Poisson equation whose constraints are specified by the set of gradients across all diffusion curves. Like all vector-based primitives, diffusion curves conveniently support a variety of operations, including geometry-based editing, keyframe animation, and ready stylization. Moreover, their representation is compact and inherently resolution-independent. We describe a GPU-based implementation for rendering images defined by a set of diffusion curves in realtime. We then demonstrate an interactive drawing system for allowing artists to create artworks using diffusion curves, either by drawing the curves in a freehand style, or by tracing existing imagery. The system is simple and intuitive: we show results created by artists after just a few minutes of instruction. Furthermore, we describe a completely automatic conversion process for taking an image and turning it into a set of diffusion curves that closely approximate the original image content. </p>},
	issue        = 3,
	keywords     = {color,gradient mesh,vector graphics,vectorization}
}
@article{Markenzon2008,
	title        = {Two methods for the generation of chordal graphs},
	author       = {Lilian Markenzon and Oswaldo Vernet and Luiz Henrique Araujo},
	year         = 2008,
	journal      = {Annals of Operations Research},
	volume       = 157,
	pages        = {47--60},
	doi          = {10.1007/s10479-007-0190-4},
	issn         = {02545330},
	abstract     = {In this paper two methods for automatic generation of connected chordal graphs are proposed: the first one is based on new results concerning the dynamic maintenance of chordality under edge insertions; the second is based on expansion/merging of maximal cliques. Theoretical and experimental results are presented. In both methods, chordality is preserved along the whole generation process. \textcopyright{} 2007 Springer Science+Business Media, LLC.},
	issue        = 1,
	keywords     = {Chordal graphs,Clique-tree,Dynamic algorithms,Graph generation}
}
@article{Vortsepneva2008,
	title        = {Saya de Malha Bank – an invisible island in the Indian Ocean},
	author       = {Elena Vortsepneva},
	year         = 2008,
	journal      = {Geomorfology, oceanology, biology},
	pages        = 44,
	url          = {https://lighthouse-foundation.org/Binaries/Binary1070/Saya-de-Malha-report-final.pdf},
	issue        = {November}
}
@article{Maximovitch2008,
	title        = {ORDINSKAYA CAVE - THE LONGEST UNDERWATER CAVE IN RUSSIA},
	author       = {N Maximovitch and O Shumilova},
	year         = 2008,
	journal      = {3-rd International Workshop on ice Caves: Proceedings, Kungur ice Cave, Perm region},
	pages        = {105--107},
	keywords     = {cave,chemistry,easternmost,european region of russia,form the,ice,in turn,mineralogy,perm region is the,situated near,stalagmites,the ural mountains,which}
}
@article{Galili2008,
	title        = {Ancient remotely-operated instruments recovered under water off the Israeli coast},
	author       = {Ehud Galili and Baruch Rosen},
	year         = 2008,
	journal      = {International Journal of Nautical Archaeology},
	volume       = 37,
	pages        = {283--294},
	doi          = {10.1111/j.1095-9270.2008.00187.x},
	issn         = 10572414,
	abstract     = {Underwater archaeological investigations in Israel have recovered instruments intended to be operated under water from a vessel on the surface, at depths and times beyond the ability of free divers. Some of these remotely-operated devices, including salvaging-rings, coral-harvesting devices, and grapnels, are described, classified and discussed. These humble but efficient instruments, the prototypes of sophisticated modern instruments, fulfilled necessary tasks in antiquity and are still being used today by traditional fishermen. \textcopyright{} 2008 The Authors. Journal Compilation \textcopyright{} 2008 Nautical Archaeology Society.},
	issue        = 2,
	keywords     = {Grapnel,Lead,Red coral,Salvaging,Shipwreck}
}
@article{Christensen-Dalsgaard2008,
	title        = {Evolution in Lego \textregistered{}: A Physical Simulation of Adaptation by Natural Selection},
	author       = {Jakob Christensen-Dalsgaard and Morten Kanneworff},
	year         = 2008,
	journal      = {Evolution: Education and Outreach},
	volume       = 2,
	pages        = {518--526},
	doi          = {10.1007/s12052-008-0099-7},
	isbn         = 1205200800,
	issn         = 19366434,
	abstract     = {We describe a physical simulation of natural selection in a population of legorgs, six-segment model organisms. Legorg morphology is genetically specified by five alleles on each segment. Legorgs show a simple form of motility that could evolve in originally sessile animals. This motility, the ability to move horizontally on a smooth surface, depends on the morphology and interaction of the six segments that produce different patterns of locomotion. Legorgs are selected for motility and reproduce in proportion to fitness. After just five generations, the average population motility increases 2.5 times. Additionally, we describe a slightly less time-consuming simulation of legorg evolution, where fitness is assigned by comparison with a template. The calculation of gene pools is precisely the same as in the previous simulation and produces very robust increases in fitness during five generations. The simulation is designed as a classroom experiment to explore the mechanism of natural selection. A test of its learning efficiency by evaluating the students' conception of central aspects of evolutionary theory before and after showed a significant improvement. The surprising power of natural selection in this very simple physical system may also be exploited in more advanced experiments.},
	issue        = 3,
	keywords     = {Active learning,Adaptation,Evolution,Natural selection,Simulation}
}
@article{Carvajal-rodriguez2008,
	title        = {Simulation of Genomes: A Review},
	author       = {Antonio Carvajal-rodr\'{\i}guez},
	year         = 2008,
	journal      = {Current Genomics},
	volume       = 9,
	pages        = {155--159},
	url          = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2679650/pdf/CG-9-155.pdf}
}
@article{Allemand2008,
	title        = {Coral Reefs and Climate Change},
	author       = {Denis Allemand},
	year         = 2008,
	journal      = {ocean-climate.org},
	pages        = {73--79},
	url          = {https://ocean-climate.org/wp-content/uploads/2017/03/coral-reefs_07-12.pdf}
}
@article{Jabin2008,
	title        = {A continuous size-structured red coral growth model},
	author       = {P.-E. Jabin and V. Lemesle and D. Aurelle},
	year         = 2008,
	month        = 11,
	journal      = {Mathematical Models and Methods in Applied Sciences},
	volume       = 18,
	pages        = {1927--1944},
	doi          = {10.1142/S0218202508003248},
	issn         = {0218-2025},
	url          = {https://www.worldscientific.com/doi/pdf/10.1142/S0218202508003248 https://www.worldscientific.com/doi/abs/10.1142/S0218202508003248},
	abstract     = {The aim of this paper is to derive and analyze the mathematical properties of a new continuous size-structured model for red coral (Corallium rubrum, L.) growth. Since historical Leslie models 4 are often used to deal with some ecological problems, a new approach is here proposed and give some promising results. The main advantage of using continuous model is that we hope to describe precisely the mass mortality events, observed in Mediterranean sea, and its consequences on red coral dynamics. Simulations' studies allow us to qualitatively discuss some questions about red coral populations dynamics. The development of this method should be useful for the study of the conservation of red coral populations.},
	issue        = 11,
	keywords     = {asymptotic analysis,conservation biology,population dynamics,size-structured continuous model}
}
@article{Rungjiratananon2008,
	title        = {Real-time Animation of Sand-Water Interaction},
	author       = {Witawat Rungjiratananon and Zoltan Szego and Yoshihiro Kanamori and Tomoyuki Nishita},
	year         = 2008,
	month        = 10,
	journal      = {Computer Graphics Forum},
	volume       = 27,
	pages        = {1887--1893},
	doi          = {10.1111/j.1467-8659.2008.01336.x},
	issn         = {0167-7055},
	url          = {https://onlinelibrary.wiley.com/doi/10.1111/j.1467-8659.2008.01336.x},
	abstract     = {Recent advances in physically-based simulations have made it possible to generate realistic animations. However, in the case of solid-fluid coupling, wetting effects have rarely been noticed despite their visual importance especially in interactions between fluids and granular materials.},
	issue        = 7
}
@article{Pilat2008,
	title        = {Creature Academy: A system for virtual creature evolution},
	author       = {Marcin L. Pilat and Christian Jacob},
	year         = 2008,
	journal      = {2008 IEEE Congress on Evolutionary Computation, CEC 2008},
	pages        = {3289--3297},
	doi          = {10.1109/CEC.2008.4631243},
	isbn         = 9781424418237,
	abstract     = {In this paper, we present Creature Academy, a virtual laboratory that allows for the evolution of form and function within simulated physical 3D environments. Creature Academy can be used to explore evolutionary mechanisms, design, learning and other processes studied in artificial life simulations. Our system allows to perform hierarchical evolutionary experiments and ecosystem-inspired setups to investigate bodied creatures that interact, compete, adapt, and evolve. As a first proof of concept, we use Creature Academy to evolve morphologies and motion strategies of virtual creatures that walk and jump. We then present results that compare hierarchical evolution scenarios to generate creatures that excel in both walking and jumping, demonstrating how to evolve from creature specialists to generalists. \textcopyright{} 2008 IEEE.}
}
@article{Miconi2008,
	title        = {Evosphere: Evolutionary dynamics in a population of fighting virtual creatures},
	author       = {Thomas Miconi},
	year         = 2008,
	journal      = {2008 IEEE Congress on Evolutionary Computation, CEC 2008},
	pages        = {3066--3073},
	doi          = {10.1109/CEC.2008.4631212},
	isbn         = 9781424418237,
	abstract     = {It is often suggested that traditional models of artificial evolution, based on explicit, human-defined fitness functions, are fundamentally more restricted and less creative than natural evolution, in which no such constraint exists. After a discussion and refinement of this statement, we suggest a classification of evolutionary systems according to their evolutionary "creativity". We describe an environment, called Evosphere, in which a population of 3D creatures interact, fight with each other, and evolve freely on the surface of a "microplanet". We demonstrate the onset of natural selection and adaptive evolution within this virtual world, both by visual inspection and statistical analysis. We show that the introduction of reproductively isolated species enriches the dynamics of the system, leading to simple evolutionary feedbacks among species. \textcopyright{} 2008 IEEE.}
}
@article{Chevalier2008,
	title        = {Numerical analysis of the combined action of littoral current, tide and waves on the suspended mud transport and on turbid plumes around French Guiana mudbanks},
	author       = {Crist\`{e}le Chevalier and Jean Marie Froidefond and Jean Luc Devenon},
	year         = 2008,
	journal      = {Continental Shelf Research},
	volume       = 28,
	pages        = {545--560},
	doi          = {10.1016/j.csr.2007.09.011},
	issn         = {02784343},
	abstract     = {Large mudbanks migrate westwards in the nearshore zone from the Cabo Cassipore in the Amapa state (Brazil) to the Waini River in Guiana. These mudbanks are noticeable by their size (about 4\texttimes{}109 m3 of sediment) and by the sediment dynamics they induce. Notably, visible remote sensing pictures present high turbid mud plume associated to mudbank erosion. The sediment transport is directly linked to the ambient forcing-littoral current, waves, and tide. In this paper, the turbid plume and the suspended mud transport around Guiana mudbanks are studied through a three-dimensional numerical study, under the three main different forcings. The study aims at describing the plume and the action of various physical processes in the suspended mud transport. The model results qualitatively agree with known observations issued from the literature. It is found that, the erosion-at the back of the bank-and the deposition-in front of the bank-could partly explain the migration process of these mudbanks. Waves are fundamental to create the erosion/deposition process, but littoral current and tide modulate it. Bottom flux and plume location vary with tide and these oscillations are accentuated during spring tide. In the same way, the wave incidence angle can explain the variability of erosion and deposition rate velocity along the Guiana coast. \textcopyright{} 2007 Elsevier Ltd. All rights reserved.},
	issue        = {4-5},
	keywords     = {French Guiana,Modeling,Mud,Mud banks,Suspended load,Turbid plume}
}
@article{Bourret2008,
	title        = {Tidal influence on the hydrodynamics of the French Guiana continental shelf},
	author       = {A. Bourret and J. L. Devenon and C. Chevalier},
	year         = 2008,
	journal      = {Continental Shelf Research},
	volume       = 28,
	pages        = {951--961},
	doi          = {10.1016/j.csr.2008.01.008},
	issn         = {02784343},
	abstract     = {This study investigates the circulation on the French Guiana continental shelf under tidal influence. Indeed, hydrodynamics are characterised by a weak salinity tongue located in the middle of the shelf and induced by the Amazon River, a coastal current flowing from the southeast, and a tidal standing wave whose co-range lines are parallel to the coast. In addition to field observations, a numerical model also is used to evaluate the tidal influence on coastal circulation. The model makes use of the MOBEEHDYCS code, a three-dimensional free surface time-splitting model whose domain is bounded with a closed coastal boundary, two active boundaries (offshore and lateral) and a passive boundary. The boundary configuration and hydrodynamics require a careful choice of passive open boundary conditions. The initial and boundary conditions come from field data. The tidal currents are essentially cross-shore and do not have a great influence on the main current direction on the offshore part of the shelf. The offshore currents remain parallel to the coast. In the inner shelf, the tidal influence is found to be much more important and the tidal currents can reach 0.45 m/s. Vertically, the tidal currents are barotropic, in spite of the high stratification and they induce a horizontal cross-shore migration (about 3 km) of the weak salinity tongue and vertical oscillations of the halocline without complete mixing. \textcopyright{} 2008 Elsevier Ltd. All rights reserved.},
	issue        = 7,
	keywords     = {Coast circulation modelling,French Guiana continental shelf,Tidal influence}
}
@article{Bilasco2008,
	title        = {LA S\'{E}MANTIQUE DE SC\`{E}NES 3D Une approche s\'{e}mantique pour l'adaptation et la r\'{e}utilisation de sc\`{e}nes 3D},
	author       = {Ioan Marius Bilasco},
	year         = 2008,
	journal      = {Le Monde des cartes},
	volume       = 198,
	pages        = {31--34},
	abstract     = {Cet article pr\'{e}sente les contributions apport\'{e}es par la prise en compte de la s\'{e}mantique des donn\'{e}es 3D dans leur processus de gestion (Bilasco 2007c). Leur recherche et r\'{e}utilisation deviennent plus efficaces car cette s\'{e}mantique comble la distance entre l'encodage de bas niveau d'une sc\`{e}ne et ce que per\c{c}oivent les utilisateurs des objets \`{a} part enti\`{e}re (b\^{a}timents, arbres, etc.). La visualisation adapt\'{e}e des sc\`{e}nes 3D tire \'{e}galement profit de cet enrichissement s\'{e}mantique. Car les informations sur la nature des objets peuvent \^{e}tre employ\'{e}es afin de filtrer ou, au contraire, de mettre \'{e}vidence certains objets ou cat\'{e}gories d'objets en relation avec les int\'{e}r\^{e}ts des utilisateurs. Nous proposons un mod\`{e}le extensible de description autour duquel nous construisons deux plateformes de r\'{e}utilisation et d'adaptation de sc\`{e}nes 3D. Nous avons valid\'{e} les apports de ces contributions via une application de construction de sc\`{e}nes urbaines.}
}
@book{SBGames2008,
	title        = {VII Brazilian Symposium on Computer Games and Digital Entertainment},
	author       = {Belo Horizonte -Mg -Brazil},
	year         = 2008
}
@article{Qiu2008,
	title        = {A GIS based spatially explicit model of dispersal agent behavior},
	author       = {Fang Qiu and Bin Li and Bryan Chastain and Mohammed Alfarhan},
	year         = 2008,
	month        = 2,
	journal      = {Forest Ecology and Management},
	volume       = 254,
	pages        = {524--537},
	doi          = {10.1016/j.foreco.2007.06.038},
	issn         = {03781127},
	abstract     = {Spatial simulation models of seed dispersal have been constructed at the landscape level under the assumption of ubiquitous or uniform dispersibility. The anisotropic nature of vegetation distribution caused by different dispersal agents such as wind, gravity, water and animals were ignored. We propose a prototype of a GIS-based spatially explicit model of dispersal agent behavior (SEMODAR) to simulate the seed dispersal process by considering the unique behavioral characteristics of each seed dispersal agent. As a result, the influence of dispersal agent behavior on the species coexistence in competitive communities with and without habitat destruction could be explored. The model consists of four module components: dispersal rules, species competition, species colonization, and habitat destruction. An experimental simulation was conducted using three hypothetical species with differing competitive and migration abilities in both intact and disturbed conditions for 250 years. The findings of this study support the theoretical expectation that inferior competitors can coexist with superior competitors given that the inferior competitors have efficient colonization ability. The simulation also reveals the important role of agent behavior in the seed dispersal process and the biased impact of environment fragmentation on superior competitors that are not superior dispersers. \textcopyright{} 2007 Elsevier B.V. All rights reserved.},
	issue        = 3,
	keywords     = {CA model,Dispersal agent behavior,Forest landscape modeling,GIS,Habitat destruction,Seed dispersal simulation,Species competition}
}
@inproceedings{Weiss2008,
	title        = {Sparse terrain pyramids},
	author       = {Kenneth Weiss and Leila De Floriani},
	year         = 2008,
	month        = 11,
	booktitle    = {Proceedings of the 16th ACM SIGSPATIAL international conference on Advances in geographic information systems},
	publisher    = {ACM},
	pages        = {1--10},
	doi          = {10.1145/1463434.1463454},
	isbn         = 9781605583235,
	url          = {https://dl.acm.org/doi/10.1145/1463434.1463454},
	city         = {New York, NY, USA}
}
@misc{Spore2008,
	title        = {Spore},
	author       = {Maxis},
	year         = 2008,
	publisher    = {Electronic Arts}
}
@article{Lipman2008,
	title        = {Green Coordinates},
	author       = {Yaron Lipman and David Levin and Daniel Cohen-Or},
	year         = 2008,
	month        = 8,
	journal      = {ACM Transactions on Graphics},
	volume       = 27,
	pages        = {1--10},
	doi          = {10.1145/1360612.1360677},
	issn         = {0730-0301},
	url          = {https://dl.acm.org/doi/10.1145/1360612.1360677},
	abstract     = {<p>We introduce Green Coordinates for closed polyhedral cages. The coordinates are motivated by Green's third integral identity and respect both the vertices position and faces orientation of the cage. We show that Green Coordinates lead to space deformations with a shape-preserving property. In particular, in 2D they induce conformal mappings, and extend naturally to quasi-conformal mappings in 3D. In both cases we derive closed-form expressions for the coordinates, yielding a simple and fast algorithm for cage-based space deformation. We compare the performance of Green Coordinates with those of Mean Value Coordinates and Harmonic Coordinates and show that the advantage of the shape-preserving property is not achieved at the expense of speed or simplicity. We also show that the new coordinates extend the mapping in a natural analytic manner to the exterior of the cage, allowing the employment of partial cages.</p>},
	issue        = 3
}
@article{Pagliara2008,
	title        = {Temporal Evolution of Plunge Pool Scour},
	author       = {Stefano Pagliara and Willi H. Hager and Jens Unger},
	year         = 2008,
	month        = 11,
	journal      = {Journal of Hydraulic Engineering},
	publisher    = {American Society of Civil Engineers (ASCE)},
	volume       = 134,
	pages        = {1630--1638},
	doi          = {10.1061/(asce)0733-9429(2008)134:11(1630)},
	issn         = {0733-9429},
	abstract     = {The temporal development of plunge pool scour was investigated using a novel experimental approach. Longitudinal profiles along the scour hole were recorded with an optical method to allow its definition at any time, from the initiation of scour to nearly the end-scour condition. The characteristics of the scour hole geometry were investigated, namely the maximum scour hole depth, the maximum ridge height, and their locations relative to the scour hole origin. It is demonstrated that the evolution is logarithmic, similar to that found for bridge pier and abutment scour. A distinction is further made between the developing and the developed scour hole phases. The main issue of the present research was to define the developed scour hole characteristics because the developing scour phase is influenced by turbulence features that may be difficult to assess. This work therefore allows for an appreciation of the temporal evolution of a scour process of engineering interest. \textcopyright{} 2008 ASCE.},
	issue        = 11
}
@article{Ovaskainen2008,
	title        = {Analytical and numerical tools for diffusion-based movement models},
	author       = {Otso Ovaskainen},
	year         = 2008,
	month        = 3,
	journal      = {Theoretical Population Biology},
	volume       = 73,
	pages        = {198--211},
	doi          = {10.1016/j.tpb.2007.11.002},
	issn         = {00405809},
	abstract     = {I present a general diffusion-based modeling framework for the analysis of animal movements in heterogeneous landscapes, including terms representing advection, mortality, and edge-mediated behavior. I use adjoint operator theory to develop mathematical machinery for the assessment of a number of biologically relevant quantities, such as occupancy times, hitting probabilities, quasi-stationary distributions, the backwards equation, and conditional probability densities. I derive finite-element approximations, which can be used to obtain numerical solutions in domains which do not allow for an analytical treatment. As an example, I model the movements of the butterfly Melitaea cinxia in an island consisting of a set of habitat patches and the intervening matrix habitat. I illustrate the behavior of the model and the mathematical theory by examining the effects of a hypothetical movement barrier and advection caused by prevailing wind conditions. \textcopyright{} 2007 Elsevier Ltd. All rights reserved.},
	issue        = 2,
	keywords     = {Advection,Corridor,Diffusion,Edge-mediated behavior,Heterogeneous landscape,Mark-recapture,Movement,Random walk},
	pmid         = 18199463
}
@article{Xu2009,
	title        = {Hand gesture recognition and virtual game control based on 3D accelerometer and EMG sensors},
	author       = {Zhang Xu and Chen Xiang and Wen Hui Wang and Ji Hai Yang and Vuokko Lantz and Kong Qiao Wang},
	year         = 2009,
	journal      = {International Conference on Intelligent User Interfaces, Proceedings IUI},
	pages        = {401--405},
	doi          = {10.1145/1502650.1502708},
	isbn         = 9781605581682,
	abstract     = {This paper describes a novel hand gesture recognition system that utilizes both multi-channel surface electromyogram (EMG) sensors and 3D accelerometer (ACC) to realize user-friendly interaction between human and computers. Signal segments of meaningful gestures are determined from the continuous EMG signal inputs. Multi-stream Hidden Markov Models consisting of EMG and ACC streams are utilized as decision fusion method to recognize hand gestures. This paper also presents a virtual Rubik's Cube game that is controlled by the hand gestures and is used for evaluating the performance of our hand gesture recognition system. For a set of 18 kinds of gestures, each trained with 10 repetitions, the average recognition accuracy was about 91.7\% in real application. The proposed method facilitates intelligent and natural control based on gesture interaction. Copyright 2009 ACM.},
	issue        = {January},
	keywords     = {Accelero-meter,Electromyogram.,Gesture recognition,Human computer interaction}
}
@article{Augustin2009,
	title        = {Laboratory and numerical studies of wave damping by emergent and near-emergent wetland vegetation},
	author       = {Lauren N. Augustin and Jennifer L. Irish and Patrick Lynett},
	year         = 2009,
	month        = 3,
	journal      = {Coastal Engineering},
	publisher    = {Elsevier},
	volume       = 56,
	pages        = {332--340},
	doi          = {10.1016/j.coastaleng.2008.09.004},
	issn         = {03783839},
	abstract     = {Wetlands protect mainland areas from erosion and damage by damping waves. Yet, this critical role of wetland is not fully understood at present, and a means for reliably determining wave damping by vegetation in engineering practice is not yet available. Laboratory experiments were conducted to measure wave attenuation resulting from synthetic emergent and nearly emergent wetland vegetation under a range of wave conditions and plant stem densities. The laboratory data were analyzed using linear wave theory to quantify bulk drag coefficients and with a nonlinear Boussinesq model to determine numerical friction factors to better represent wetland vegetation in engineering analysis. \textcopyright{} 2008 Elsevier B.V. All rights reserved.},
	issue        = 3,
	keywords     = {Bottom friction,Vegetation damping,Wave attenuation,Wetlands}
}
@article{Georgiades2009,
	title        = {Simulation of an underwater hexapod robot},
	author       = {Christina Georgiades and Meyer Nahon and Martin Buehler},
	year         = 2009,
	month        = 1,
	journal      = {Ocean Engineering},
	publisher    = {Pergamon},
	volume       = 36,
	pages        = {39--47},
	doi          = {10.1016/j.oceaneng.2008.10.005},
	issn         = {00298018},
	abstract     = {AQUA is an underwater hexapod robot that uses its paddles to propel itself and control its orientation. To aid in the vehicle development, a simulation was needed to predict the motion of the robot based on its paddle oscillations. The most difficult aspect of this simulation was the characterization of the forces generated by the paddles oscillating in the water. In this work, a model predicting the forces produced by an oscillating rigid paddle was developed and validated experimentally. Tests were performed on an experimental setup, which was designed and built to measure the forces and torques produced by a paddle oscillating in a water tank. Also, the forces produced by a flexible fin were determined experimentally and were compared to those generated by the rigid paddle. Finally, a simulation of the AQUA robot was developed, based on the validated rigid paddle model. \textcopyright{} 2008 Elsevier Ltd. All rights reserved.},
	issue        = 1,
	keywords     = {Biomimetic,Dynamics,Paddles,Underwater robot}
}
@article{Smelik2009,
	title        = {A survey of procedural methods for terrain modelling},
	author       = {Ruben M. Smelik and Klaas Jan De Kraker and Saskia A Groenewegen and Tim Tutenel and Rafael Bidarra},
	year         = 2009,
	journal      = {Proceedings of the CASA workshop on 3D advanced media in gaming and simulation (3AMIGAS)},
	abstract     = {Procedural methods are a promising but underused alternative to manual content creation. Commonly heard drawbacks are the randomness of and the lack of control over the output and the absence of integrated solutions, although more recent publications increasingly address these issues. This paper surveys procedural methods applied to terrain modelling, evaluating realism of their output, performance and control users can exert over the procedure}
}
@article{Smith2009,
	title        = {Rhythm-based level generation for 2D platformers},
	author       = {Gillian Smith and Mike Treanor and Jim Whitehead and Michael Mateas},
	year         = 2009,
	journal      = {FDG 2009 - 4th International Conference on the Foundations of Digital Games, Proceedings},
	pages        = {175--182},
	doi          = {10.1145/1536513.1536548},
	isbn         = 9781605584379,
	abstract     = {We present a rhythm-based method for the automatic generation of levels for 2D platformers, where the rhythm is that which the player feels with his hands while playing. Levels are created using a grammar-based method: first generating rhythms, then generating geometry based on those rhythms. Generation is constrained by a set of style parameters tweakable by a human designer. The approach also minimizes the amount of content that must be manually authored, instead relying on geometry components that are included in the level designer's tileset and a set of jump types. Our results show that this method produces an impressive variety of levels, all of which are fully playable. Copyright 2009 ACM.},
	keywords     = {2D platformers,Games,Levels,Procedural generation}
}
@article{Frade2009,
	title        = {Breeding terrains with genetic terrain programming: The evolution of terrain generators},
	author       = {Miguel Frade and F. Fernandez De Vega and Carlos Cotta},
	year         = 2009,
	journal      = {International Journal of Computer Games Technology},
	volume       = 2009,
	doi          = {10.1155/2009/125714},
	issn         = 16877047,
	abstract     = {Although a number of terrain generation techniques have been proposed during the last few years, all of them have some key constraints. Modelling techniques depend highly upon designer's skills, time, and effort to obtain acceptable results, and cannot be used to automatically generate terrains. The simpler methods allow only a narrow variety of terrain types and offer little control on the outcome terrain. The Genetic Terrain Programming technique, based on evolutionary design with Genetic Programming, allows designers to evolve terrains according to their aesthetic feelings or desired features. This technique evolves Terrain Programmes (TPs) that are capable of generating a family of terrainsdifferent terrains that consistently present the same morphological characteristics. This paper presents a study about the persistence of morphological characteristics of terrains generated with different resolutions by a given TP. Results show that it is possible to use low resolutions during the evolutionary phase without compromising the outcome, and that terrain macrofeatures are scale invariant.},
	issue        = 1
}
@article{Huang2009a,
	title        = {Consolidation of Unorganized Point Clouds for Surface Reconstruction},
	author       = {Hui Huang and Dan Li and Uri Ascher and Hao Zhang and Daniel Cohen-Or},
	year         = 2009,
	journal      = {ACM Transactions on Graphics},
	volume       = 28,
	pages        = {1--7},
	doi          = {10.1145/1618452.1618522},
	issn         = 15577368,
	abstract     = {We consolidate an unorganized point cloud with noise, outliers, non-uniformities, and in particular interference between close-by surface sheets as a preprocess to surface generation, focusing on reliable normal estimation. Our algorithm includes two new developments. First, a weighted locally optimal projection operator produces a set of denoised, outlier-free and evenly distributed particles over the original dense point cloud, so as to improve the reliability of local PCA for initial estimate of normals. Next, an iterative framework for robust normal estimation is introduced, where a priority-driven normal propagation scheme based on a new priority measure and an orientation-aware PCA work complementarily and iteratively to consolidate particle normals. The priority setting is reinforced with front stopping at thin surface features and normal flipping to enable robust handling of the close-by surface sheet problem. We demonstrate how a point cloud that is wellconsolidated by our method steers conventional surface generation schemes towards a proper interpretation of the input data. \textcopyright{} 2009, ACM. All rights reserved.},
	issue        = 5
}
@book{Nielsen2009,
	title        = {Coastal and Estuarine Processes},
	author       = {Peter Nielsen},
	year         = 2009,
	month        = 4,
	journal      = {Coastal And Estuarine Processes},
	publisher    = {WORLD SCIENTIFIC},
	volume       = 29,
	pages        = {1--360},
	doi          = {10.1142/7114},
	isbn         = {978-981-283-711-0},
	url          = {https://www.worldscientific.com/worldscibooks/10.1142/7114},
	abstract     = {This book covers water waves, surf zone hydrodynamics, tides in oceans and estuaries, storm surges, estuarine mixing, basic sediment transport, coastal morphodynamics and coastal groundwater dynamics. It is an introductory treatment, suitable for a first course in coastal and estuarine processes for earth scientists or engineers. Yet, there are substantial amounts of new material that are included, such as the explicit, analytical treatment of transient, forced long waves. Inclusion of this material will in turn strongly enhance the introductory treatment of tsunami, storm surges and surf beat. The treatment of sine wave theory emphasizes expressions which are explicit in the water depth h (using koh instead of kh) so that they can easily be differentiated or integrated with respect to h. This is a major pedagogical advantage because of the enhanced transparency. The treatment of turbulent mixing includes finite mixing length effects which provide an explanation for differential diffusion of different sediment sizes in suspension. The effects of acceleration skewness and boundary layer streaming are also included in the basic sediment transport models. The inclusion of beach groundwater dynamics - including the mechanisms by which waves as well as tides drive groundwater motion - provides a link between the previously unconnected fields of coastal hydraulics and regional groundwater modeling. Serving as a good reference book, it is fully indexed and comprehensively cross referenced. Abundant references to more detailed texts are also provided.}
}
@article{Forest2010,
	title        = {Real-Time Hierarchical Binary-Scene Voxelization},
	author       = {Vincent Forest and Loic Barthe and Mathias Paulin},
	year         = 2009,
	month        = 1,
	journal      = {Journal of Graphics, GPU, and Game Tools},
	volume       = 14,
	pages        = {21--34},
	doi          = {10.1080/2151237X.2009.10129283},
	issn         = {2151-237X},
	url          = {http://www.tandfonline.com/doi/abs/10.1080/2151237X.2009.10129283},
	issue        = 3
}
@article{Morris2009,
	title        = {Optical Properties of Water},
	author       = {D. P. Morris},
	year         = 2009,
	journal      = {Encyclopedia of Inland Waters},
	pages        = {682--689},
	doi          = {10.1016/B978-012370626-3.00069-7},
	isbn         = 9780123706263,
	url          = {http://misclab.umeoce.maine.edu/boss/classes/RT_Weizmann/Chapter3.pdf},
	abstract     = {Light is critical in structuring aquatic ecosystems. Seasonal variations in the heat energy provided by sunlight are responsible for thermal stratification and mixing regimes of aquatic systems. Sunlight used in photosynthesis (both terrestrial and aquatic) forms the foundation of all but the simplest microbial communities of aquatic ecosystems. This article addresses the fate of light in aquatic ecosystems. It starts with a discussion of the nature of light and the spectral output of the sun. Reflectance, scattering, and absorption in the atmosphere are addressed, along with the role of latitude, in regulating the incident flux of light at the surface of aquatic systems. Once light penetrates the air-water interface, it can either be scattered or absorbed. The inherent optical properties of absorptance, scatterance, and volume scattering function are defined as they pertain to aquatic systems. Wavelength-specific differences in scattering and absorption are discussed in the context of optically significant components of the water column such as dissolved organic carbon and phytoplankton. The diffuse attenuation coefficient is introduced as a parameter in defining the transparency of aquatic systems. Wavelength-specific differences in this parameter are discussed and placed in the context of a system's inherent optical properties. Finally, the environmental variability of transparency is illustrated using data from five Western Hemisphere lakes.},
	keywords     = {Absorption coefficient,Aquatic ecosystems,Chromophoric dissolved organic carbon,Diffuse attenuation coefficient,Reflectance,Scattering}
}
@article{Mullen2009,
	title        = {Energy-preserving integrators for fluid animation},
	author       = {Patrick Mullen and Keenan Crane and Dmitry Pavlov and Yiying Tong and Mathieu Desbrun},
	year         = 2009,
	journal      = {ACM Transactions on Graphics},
	volume       = 28,
	doi          = {10.1145/1531326.1531344},
	issn         = {07300301},
	url          = {https://www.cs.cmu.edu/~kmcrane/Projects/EnergyPreservingFluid/paper.pdf},
	abstract     = {Numerical viscosity has long been a problem in fluid animation. Existing methods suffer from intrinsic artificial dissipation and often apply complicated computational mechanisms to combat such effects. Consequently, dissipative behavior cannot be controlled or modeled explicitly in a manner independent of time step size, complicating the use of coarse previews and adaptive-time stepping methods. This paper proposes simple, unconditionally stable, fully Eulerian integration schemes with no numerical viscosity that are capable of maintaining the liveliness of fluid motion without recourse to corrective devices. Pressure and fluxes are solved efficiently and simultaneously in a time-reversible manner on simplicial grids, and the energy is preserved exactly over long time scales in the case of inviscid fluids. These integrators can be viewed as an extension of the classical energy-preserving Harlow-Welch / Crank-Nicolson scheme to simplicial grids. \textcopyright{} 2009 ACM.},
	issue        = 3,
	keywords     = {Energy preservation,Eulerian fluid animation,Time integration}
}
@article{Kristof2009,
	title        = {Hydraulic erosion using smoothed particle hydrodynamics},
	author       = {Peter Kri\v{s}tof and Bed\v{r}ich Bene\v{s} and J. K\v{r}iv\'{a}nek and Ond\v{r}ej \v{S}t'ava},
	year         = 2009,
	journal      = {Computer Graphics Forum},
	volume       = 28,
	pages        = {219--228},
	doi          = {10.1111/j.1467-8659.2009.01361.x},
	issn         = 14678659,
	abstract     = {This paper presents a new technique for modification of 3D terrains by hydraulic erosion. It efficiently couples fluid simulation using a Lagrangian approach, namely the Smoothed Particle Hydrodynamics (SPH) method, and a physically-based erosion model adopted from an Eulerian approach. The eroded sediment is associated with the SPH particles and is advected both implicitly, due to the particle motion, and explicitly, through an additional velocity field, which accounts for the sediment transfer between the particles. We propose a new donor-acceptor scheme for the explicit advection in SPH. Boundary particles associated to the terrain are used to mediate sediment exchange between the SPH particles and the terrain itself. Our results show that this particle-based method is efficient for the erosion of dense, large, and sparse fluid. Our implementation provides interactive results for scenes with up to 25,000 particles. \textcopyright{} 2008 The Eurographics Association and Blackwell Publishing Ltd.},
	issue        = 2
}
@article{Benes2009,
	title        = {Interactive modeling of virtual ecosystems},
	author       = {Bed\v{r}ich Bene\v{s} and Nathan Andrysco and Ond\v{r}ej \v{S}t'ava},
	year         = 2009,
	journal      = {Natural Phenomena},
	pages        = {9--16},
	issn         = 18160867,
	url          = {https://diglib.eg.org/xmlui/bitstream/handle/10.2312/EG.DL.conf.EG2009.nph.009-016/009-016.pdf?sequence=1},
	abstract     = {We present a novel technique for interactive, intuitive, and efficient modeling of virtual plants and plant ecosystems. Our approach is biologically-based, but shades the user from overwhelming input parameters by simplifying them to intuitive controls. Users are able to create scenes that are populated by virtual plants. Plants communicate actively with the environment and attempt to generate an optimal spatial distribution that dynamically adapts to neighboring plants, to user defined obstacles, light, and gravity. We demonstrate simulations of ecosystems composed of up to 140 trees that are computed in less than two minutes. Various phenomena previously available for non-realtime procedural approaches are created interactively, such as plants competing for space, topiary, plant lighting, virtual forests, etc. Results are aimed at architectural modeling, the entertainment industry, and everywhere that quick and fast creation of believable biological plant models is necessary.\textcopyright{} The Eurographics Association 2009.}
}
@phdthesis{Allegre2009,
	title        = {Contributions \`{a} l'introduction de flexibilit\'{e} dans la reconstruction et l'\'{e}dition de mod\`{e}les 3D},
	author       = {R\'{e}mi All\`{e}gre},
	year         = 2009,
	journal      = {Recherche},
	volume       = 1,
	pages        = {2009--2010},
	url          = {https://perso.liris.cnrs.fr/raphaelle.chaine/DOCUMENTS/these_Remi_Allegre_2006.pdf},
	abstract     = {This thesis deals with geometric modeling of complex 3D free-form shapes. In the context of the Art3D project (ACI Masses de Donn\'{e}es), we have investigated two research directions related to the representation of digitized objects, with a flexibility goal : dynamic surface reconstruction and multirepresentation modeling. In the first part of the thesis, we introduce a flexible combinatorial approach to surface reconstruction that makes it possible to directly generate a simplified triangulated surface from a dense input point set. The reconstructed surface can be next locally refined or coarsened in a dynamic fashion. The second part presents a hybrid modeling framework for creating complex shapes from scanned models or simple primitives. We have developed an extended CSG tree that mixes implicit surfaces, polygonal meshes, and point set models in a coherent fashion.}
}
@article{Wither2009,
	title        = {Structure from silhouettes: A new paradigm for fast sketch-based design of trees},
	author       = {Jamie Wither and Fr\'{e}d\'{e}ric Boudon and Marie-Paule Cani and Christophe Godin},
	year         = 2009,
	journal      = {Computer Graphics Forum},
	volume       = 28,
	pages        = {541--550},
	doi          = {10.1111/j.1467-8659.2009.01394.x},
	issn         = 14678659,
	url          = {https://hal.archives-ouvertes.fr/hal-00366289/document},
	abstract     = {Modeling natural elements such as trees in a plausible way, while offering simple and rapid user control, is a challenge. This paper presents a method based on a new structure from silhouettes paradigm. We claim that sketching the silhouettes of foliage at multiple scales is quicker and more intuitive for a user than having to sketch each branch of a tree. This choice allows us to incorporate botanical knowledge, enabling us to infer branches that connect in a plausible way to their parent branch and have a correct distribution in 3D. We illustrate these ideas by presenting a seamless sketch-based interface, used for sketching foliage silhouettes from the scale of an entire tree to the scale of a leaf. Each sketch serves for inferring both the branches at that level and construction lines to serve as support for sub-silhouette refinement. When the user finally zooms out, the style inferred for the branching systems he has refined (in terms of branch density, angle, length distribution and shape) is duplicated to the unspecified branching systems at the same level. Meanwhile, knowledge from botany is again used for extending the branch distribution to 3D, resulting in a full, plausible 3D tree that fits the user-sketched contours. As our results show, this system can be of interest to both experts and novice users. While experts can fully specify all parts of a tree and over-sketch specific branches if required, any user can design a basic 3D tree in one or two minutes, as easily as sketching it with paper and pen. \textcopyright{} 2008 The Eurographics Association and Blackwell Publishing Ltd.},
	issue        = 2
}
@book{Kampis2009,
	title        = {Advances in Artificial Life, Darwin Meets von Neumann},
	author       = {George Kampis and Istavan Karsai},
	year         = 2009,
	journal      = {Media},
	pages        = 524,
	doi          = {10.1007/978-3-642-21314-4},
	isbn         = 9783642208317,
	url          = {http://books.google.com/books?hl=en&amp;lr=&amp;id=tWsy_aPMjVcC&amp;oi=fnd&amp;pg=PP2&amp;dq=Multi-Agent-Based+Simulation+XI+InternationalWorkshop,+MABS+2010+Toronto,+Canada,+May+11,+2010+Revised+Selected+Papers&amp;ots=6I26mOjTGO&amp;sig=NjOhain2FrF8zFti},
	note         = {Read at p. 278},
	abstract     = {10th Europian Conference, ECAL 2009, Budapest, Hungary September 2009}
}
@inproceedings{Balzer2009,
	title        = {Capacity-constrained point distributions},
	author       = {Michael Balzer and Thomas Schl\"{o}mer and Oliver Deussen},
	year         = 2009,
	month        = 7,
	booktitle    = {ACM SIGGRAPH 2009 papers},
	publisher    = {ACM},
	volume       = 28,
	pages        = {1--8},
	doi          = {10.1145/1576246.1531392},
	isbn         = 9781605587264,
	url          = {https://dl.acm.org/doi/10.1145/1576246.1531392},
	city         = {New York, NY, USA},
	keywords     = {blue noise,ca-,density,function in the sense,importance sampling,is proportional to the,lloyd,pacity constraint,points in an area,poisson disk point sets,s method,that point distributions adapt,that the number of,to a given density,voronoi tessellations}
}
@article{Horna2009,
	title        = {Consistency constraints and 3D building reconstruction},
	author       = {S. Horna and Daniel Meneveaux and Guillaume Damiand and Yves Bertrand},
	year         = 2009,
	journal      = {CAD Computer Aided Design},
	publisher    = {Elsevier Ltd},
	volume       = 41,
	pages        = {13--27},
	doi          = {10.1016/j.cad.2008.11.006},
	issn         = {00104485},
	url          = {http://dx.doi.org/10.1016/j.cad.2008.11.006 https://hal.archives-ouvertes.fr/hal-00440844/file/CAD_consistency constraints and 3D buildings reconstruction.pdf},
	abstract     = {Virtual architectural (indoor) scenes are often modeled in 3D for various types of simulation systems. For instance, some authors propose methods dedicated to lighting, heat transfer, acoustic or radio-wave propagation simulations. These methods rely in most cases on a volumetric representation of the environment, with adjacency and incidence relationships. Unfortunately, many buildings data are only given by 2D plans and the 3D needs varies from one application to another. To face these problems, we propose a formal representation of consistency constraints dedicated to building interiors and associated with a topological model. We show that such a representation can be used for: (i) reconstructing 3D models from 2D architectural plans (ii) detecting automatically geometrical, topological and semantical inconsistencies (iii) designing automatic and semi-automatic operations to correct and enrich a 2D plan. All our constraints are homogeneously defined in 2D and 3D, implemented with generalized maps and used in modeling operations. We explain how this model can be successfully used for lighting and radio-wave propagation simulations. \textcopyright{} 2008 Elsevier Ltd. All rights reserved.},
	issue        = 1,
	keywords     = {3D modeling,Architecture,G-maps,Indoor building,Reconstruction,Topological model}
}
@article{Peytavie2009a,
	title        = {Procedural Generation of Rock Piles using Aperiodic Tiling},
	author       = {Adrien Peytavie and Eric Galin and J. Grosjean and S. Merillou},
	year         = 2009,
	month        = 10,
	journal      = {Computer Graphics Forum},
	volume       = 28,
	pages        = {1801--1809},
	doi          = {10.1111/j.1467-8659.2009.01557.x},
	issn         = {0167-7055},
	url          = {https://onlinelibrary.wiley.com/doi/10.1111/j.1467-8659.2009.01557.x},
	abstract     = {<p>In this paper, we present a tiling method for generating piles of rocks without any computationally demanding physically-based simulation. Previous techniques rely on a periodic tiling of rocks and generate unrealistic repetitive patterns. In contrast, our approach relies on a modified corner cube algorithm to generate a set of aperiodic tiles. We generalize the construction method so that the geometry of rocks should straddle corner cubes with a view to avoiding unrealistic gaps in the arrangement of rocks. Moreover, we propose an original technique to control the shape of rocks into contact by computing the Vorono\"{\i} cells using a parameterized anisotropic distance. Our method has been successfully used to generate landscapes and stone huts and walls with thousands of rocks piled together.</p>},
	issue        = 7
}
@article{Rusnell2009,
	title        = {Feature-Rich Distance-Based Terrain Synthesis},
	author       = {Brennan Rusnell},
	year         = 2009,
	journal      = {Information Visualization},
	issue        = {May}
}
@inproceedings{DeCarpentier,
	title        = {Interactive GPU-based procedural heightfield brushes},
	author       = {Giliam J. P. de Carpentier and Rafael Bidarra},
	year         = 2009,
	month        = 4,
	booktitle    = {Proceedings of the 4th International Conference on Foundations of Digital Games},
	publisher    = {ACM},
	volume       = 8,
	pages        = {55--62},
	doi          = {10.1145/1536513.1536532},
	isbn         = 9781605584379,
	url          = {https://dl.acm.org/doi/10.1145/1536513.1536532},
	city         = {New York, NY, USA}
}
@article{Gain2009,
	title        = {Terrain sketching},
	author       = {James Gain and Patrick Marais and Wolfgang Stra\ss{}er},
	year         = 2009,
	journal      = {Proceedings of I3D 2009: The 2009 ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games},
	volume       = 1,
	pages        = {31--38},
	doi          = {10.1145/1507149.1507155},
	isbn         = 9781605584294,
	abstract     = {Procedural methods for terrain synthesis are capable of creating realistic depictions of heightfield terrains with little user intervention. However, users often do wish to intervene in controlling the placement and shape of landforms, but without sacrificing realism. In this paper, we present a sketching interface to procedural terrain generation. This system enables users to draw the silhouette, spine and bounding curves of both extruding (hills and mountains) and embedding landforms (river courses and canyons). Terrain is interactively generated to match the sketched constraints using multiresolution surface deformation. In addition, the wavelet noise characteristics of silhouette strokes are propagated to the surrounding terrain. With terrain sketching users can interactively create or modify landscapes incorporating varied and complex land-forms. Copyright \textcopyright{} 2009 by the Association for Computing Machinery, Inc.},
	issue        = 212
}
@article{Baojun2009,
	title        = {A simple approach to 3D geological modelling and visualization},
	author       = {Wang Baojun and Shi Bin and Song Zhen},
	year         = 2009,
	journal      = {Bulletin of Engineering Geology and the Environment},
	volume       = 68,
	pages        = {559--565},
	doi          = {10.1007/s10064-009-0233-y},
	issn         = 14359529,
	abstract     = {3D geological modeling has become one of the most reliable and effective means of displaying geological structures, but most commercial software products for 3D geological modeling need special techniques and much pre-processing work as well as being expensive and complicated to operate. In this paper, a simple approach to building a 3D geological model is proposed, integrating such popular software packages as 3D Studio Max (3DSMax), ArcGIS, and Virtual Reality Modeling Language (VRML). The approach can be used to build accurate 3D geological structures and to model stratigraphy at almost any level of complexity. Moreover, the resulting model can be operated interactively, including zooming in or out, rotating and moving. The paper demonstrates how this new approach can be a very effective method for 3D geological modeling. \textcopyright{} Springer-Verlag 2009.},
	issue        = 4,
	keywords     = {3D geological modeling,Interactive operation,Visualization}
}
@article{Caumon2009,
	title        = {Surface-based 3D modeling of geological structures},
	author       = {G. Caumon and P. Collon-Drouaillet and C. Le Carlier De Veslud and S. Viseur and J. Sausse},
	year         = 2009,
	journal      = {Mathematical Geosciences},
	volume       = 41,
	pages        = {927--945},
	doi          = {10.1007/s11004-009-9244-2},
	issn         = 18748961,
	abstract     = {Building a 3D geological model from field and subsurface data is a typical task in geological studies involving natural resource evaluation and hazard assessment. However, there is quite often a gap between research papers presenting case studies or specific innovations in 3D modeling and the objectives of a typical class in 3D structural modeling, as more and more is implemented at universities. In this paper, we present general procedures and guidelines to effectively build a structural model made of faults and horizons from typical sparse data. Then we describe a typical 3D structural modeling workflow based on triangulated surfaces. Our goal is not to replace software user guides, but to provide key concepts, principles, and procedures to be applied during geomodeling tasks, with a specific focus on quality control. \textcopyright{} International Association for Mathematical Geosciences 2009.},
	issue        = 8,
	keywords     = {3D earth modeling,Geomodeling,Interpretation,Structural geology,Visualization}
}
@article{Parks2009,
	title        = {Freeform modeling of faulted surfaces in seismic images},
	author       = {Derek Parks},
	year         = 2009,
	journal      = {79th Society of Exploration Geophysicists International Exposition and Annual Meeting 2009, SEG 2009},
	pages        = {2702--2706},
	isbn         = 9781615675661,
	url          = {https://web.archive.org/web/20170808195119id_/http://www.cwp.mines.edu/Meetings/Project09/cwp-633.pdf},
	abstract     = {An interactive surface editing framework that is well suited to the needs of geophysical modelers and interpreters is described. This surface editing framework allows a non-expert user to quickly create complicated surfaces by combining two simple concepts: deformation and cutting. Deformations change the geometry of a surface and allow a user to model continuous geologic horizons. Cutting changes the topology of the surface to model geologic faults.},
	keywords     = {cutting,surface modeling freeform deformation}
}
@inproceedings{Yersin2011,
	title        = {Crowd patches},
	author       = {Barbara Yersin and Jonathan Maim and Julien Pettr\'{e} and Daniel Thalmann},
	year         = 2009,
	month        = 2,
	booktitle    = {Proceedings of the 2009 symposium on Interactive 3D graphics and games},
	publisher    = {ACM},
	pages        = {207--214},
	doi          = {10.1145/1507149.1507184},
	isbn         = 9781605584294,
	url          = {https://dl.acm.org/doi/10.1145/1507149.1507184},
	city         = {New York, NY, USA},
	keywords     = {a typical approach is,able,densely inhabited worlds,efficient crowd rendering engines,have been de-,interactive crowd,of in-,to display thousands of,to store pre-computed images,veloped,virtual environment population,virtual humans in real-time}
}
@article{Gelas2009,
	title        = {Variational implicit surface meshing},
	author       = {Arnaud Gelas and S\'{e}bastien Valette and R\'{e}my Prost and Wieslaw L. Nowinski},
	year         = 2009,
	month        = 6,
	journal      = {Computers \& Graphics},
	volume       = 33,
	pages        = {312--320},
	doi          = {10.1016/j.cag.2009.03.016},
	issn         = {00978493},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0097849309000326},
	issue        = 3,
	keywords     = {implicit surface,meshing,restricted delaunay,variational approach}
}
@article{Griffiths2009,
	title        = {Towards a generalized biogeography of the Southern Ocean benthos},
	author       = {Huw J. Griffiths and David K.A. Barnes and Katrin Linse},
	year         = 2009,
	journal      = {Journal of Biogeography},
	volume       = 36,
	pages        = {162--177},
	doi          = {10.1111/j.1365-2699.2008.01979.x},
	issn         = {03050270},
	abstract     = {Aim: To investigate whether the biogeographical regions proposed by J. W. Hedgpeth and widely adopted by other authors hold true, are an oversimplification or with further data might show a unified Antarctic province. Location: Southern Hemisphere. Methods: The distributions of 1318 species of bivalves, 4656 species of gastropods, 1465 species of cheilostome and 167 species of cyclostome bryozoans were analysed for 29 regions in the Southern Hemisphere, including South American, South African, Tasmanian, New Zealand, sub-Antarctic and Antarctic regions. We present data on species richness, rates of endemism, patterns of radiation, faunal similarities and multivariate biogeographical analyses. Results: The most striking pattern to emerge from our data set of species counts per region was a strong east-west hemispheric asymmetry, with high species numbers in New Zealand, Tasmania and South Africa and low numbers in South America. In contrast, no difference was found in richness between the east and west parts of the Southern Ocean. We compared findings in our model taxa with published data on ascidians, cephalopods and pycnogonids. Further evidence of strong faunal links between the Antarctic and South America is reported in this study, although we found little evidence for a biogeographical relationship between the Antarctic or South America and New Zealand/Tasmania. Strong evidence exists for a long-term influence of the Antarctic Circumpolar Current upon the distribution of Southern Ocean benthos. This is demonstrated by the reduced prevalence of South American species in the Antarctic and sub-Antarctic with increasing distance from South America in the direction of the current. Three of our four study taxa (bivalves, cheilostomes and cyclostomes) show the Southern Ocean as a 'single functional unit' with no evidence for a biogeographical split between east and west. Main conclusions: Unlike the biogeographical schemes previously proposed, we show that biogeographical regions in the Southern Ocean differ depending upon the class of animals being considered. Despite this we suggest that some general rules are viable, including species endemism rates of around 50\%, a single Antarctic province and a definite distinction between the sub-Antarctic islands influenced by South America and those of New Zealand. \textcopyright{} 2008 British Antarctic Survey.},
	issue        = 1,
	keywords     = {Antarctic,Bryozoa,Continental shelf,Continental slope,Endemism,Magellanic,Mollusca,Pycnogonida,Richness,Zoogeography}
}
@article{Webster2009,
	title        = {Coral reef evolution on rapidly subsiding margins},
	author       = {Jody M Webster and Juan Carlos and David A Clague and Christina Gallup and James R Hein and Donald C Potts and Willem Renema and Robert Riding and Kristin Riker-coleman and Eli Silver and Laura M Wallace},
	year         = 2009,
	journal      = {Global and Planetary Change},
	publisher    = {Elsevier B.V.},
	volume       = 66,
	pages        = {129--148},
	doi          = {10.1016/j.gloplacha.2008.07.010},
	issn         = {0921-8181},
	url          = {http://dx.doi.org/10.1016/j.gloplacha.2008.07.010},
	issue        = {1-2}
}
@article{Koelling2009,
	title        = {SEALEX -- Internal reef chronology and virtual drill logs from a spreadsheet-based reef growth model},
	author       = {Martin Koelling and Jody Michael and Gilbert Camoin and Yasufumi Iryu and Edouard Bard and Claire Seard},
	year         = 2009,
	journal      = {Global and Planetary Change},
	publisher    = {Elsevier B.V.},
	volume       = 66,
	pages        = {149--159},
	doi          = {10.1016/j.gloplacha.2008.07.011},
	issn         = {0921-8181},
	url          = {http://dx.doi.org/10.1016/j.gloplacha.2008.07.011},
	issue        = {1-2}
}
@phdthesis{Orzan2009,
	title        = {Contour-Based Images: Representation, Creation and Manipulation},
	author       = {Alexandrina Orzan},
	year         = 2009,
	pages        = 136,
	url          = {http://maverick.inria.fr/Publications/2009/Orz09},
	abstract     = {This thesis proposes a novel image primitive--the diffusion curve. This primitive relies on the principle that images can be defined via their discontinuities, and concentrates image features along contours. The diffusion curve can be defined in vector graphics, as well as in raster graphics, to increase user control during the process of art creation. The vectorial diffusion curve primitive augments the expressive powers of vector images by capturing complex spatial appearance behaviors. Diffusion curves represent a simple and easy- to-manipulate support for complex content representation and edition. In raster images, diffusion curves define a higher level structural organization of the pixel image. This structure is used to create simplified or exaggerated representations ofphotographs in a way consistent with the original image content. Finally, a fully automatic vectorization method is presented, that converts raster diffusion curve to vector diffusion curve.},
	institution  = {INPG},
	keywords     = {expressive rendering,image processing,vector graphics}
}
@article{Lenaerts2009,
	title        = {Mixing fluids and granular materials},
	author       = {Toon Lenaerts and Philip Dutr\'{e}},
	year         = 2009,
	journal      = {Computer Graphics Forum},
	volume       = 28,
	pages        = {213--218},
	doi          = {10.1111/j.1467-8659.2009.01360.x},
	issn         = 14678659,
	abstract     = {Fluid animations in computer graphics show interactions with various kinds of objects. However, fluid flowing through a granular material such as sand is still not possible within current frameworks. In this paper, we present the simulation of fine granular materials interacting with fluids. We propose a unified Smoothed Particle Hydrodynamics framework for the simulation of both fluid and granular material. The granular volume is simulated as a continuous material sampled by particles. By incorporating previous work on porous flow in this simulation framework we are able to fully couple fluid and sand. Fluid can now percolate between sand grains and influence the physical properties of the sand volume. Our method demonstrates various new effects such as dry soil transforming into mud pools by rain or rigid sand structures being eroded by waves. \textcopyright{} 2008 The Eurographics Association and Blackwell Publishing Ltd.},
	issue        = 2
}
@misc{Andric2009,
	title        = {Lagrangian Particle Tracking},
	author       = {Jelena Andric},
	year         = 2009,
	url          = {https://www.tfd.chalmers.se/~hani/kurser/OS_CFD_2009/JelenaAndric/presentationJelenaAndric.pdf},
	issue        = {December}
}
@article{Wampler2009,
	title        = {Optimal gait and form for animal locomotion},
	author       = {Kevin Wampler and Zoran Popovi},
	year         = 2009,
	journal      = {ACM Transactions on Graphics},
	volume       = 28,
	doi          = {10.1145/1531326.1531366},
	issn         = {07300301},
	abstract     = {We present a fully automatic method for generating gaits and morphologies for legged animal locomotion. Given a specific animal's shape we can determine an efficient gait with which it can move. Similarly, we can also adapt the animal's morphology to be optimal for a specific locomotion task. We show that determining such gaits is possible without the need to specify a good initial motion, and without manually restricting the allowed gaits of each animal. Our approach is based on a hybrid optimization method which combines an efficient derivative-aware spacetime constraints optimization with a derivative-free approach able to find non-local solutions in high-dimensional discontinuous spaces. We demonstrate the effectiveness of this approach by synthesizing dynamic locomotions of bipeds, a quadruped, and an imaginary five-legged creature. \textcopyright{} 2009 ACM.},
	issue        = 3,
	keywords     = {Animation,Character dynamics,Gait,Spacetime optimization}
}
@article{Boldea2009,
	title        = {A Particle Cellular Automata Model for Fluid Simulations},
	author       = {Costin-Radu Boldea},
	year         = 2009,
	journal      = {Math. Comp. Sci. Ser},
	volume       = 36,
	pages        = {35--41},
	issn         = {1223-6934},
	abstract     = {A new cellular-automaton model for fluid dynamics is introduced in this paper, that focus on discrete models based on point particles moving on a lattice in order to mimic a fully molecular dynamics. The CA model uses an easily implementable, deterministic pair of interaction rules. Therefore, we combine the advantage of the low computational cost of CA and its ability to mimic the realistic fluid dynamics to develop a new animating framework for computer graphics applications.},
	issue        = 2,
	keywords     = {2000 Mathematics Subject Classification Primary 68Q80; Secondary 37B15 Key words and phrases Cellular automata,Lattice gas models,Navier-Stokes equation}
}
@article{ElAmawy2009,
	title        = {Karst development and structural relationship in the tertiary rocks of the Al Jabal Al Akhdar, NE Libya: A case study in Qasr Libya area},
	author       = {Maher El Amawy and Ahmed M. Muftah},
	year         = 2009,
	month        = 3,
	journal      = {3rd International Symposium Karst Evolution in the South Mediterranean Area},
	volume       = 14,
	pages        = {173--189},
	abstract     = {The Structural pattern, in the western part of Al Jabal Al Akhdar, reflects inversion during late-Cretaceous-Miocene times, in response to the influence by dextral shear of the Alpine orogeny. It is themed by the formation of NE-SW to ENE-WSW principle displacement(or deformational) zones (PDZs) that confine inside a system of ENE-WSW trending folds and array of secondary faults conformable with the geometry and progressive evolution in wrench tectonic model. These structures are dominated with folds in the Upper Cretaceous and revealed a main factor of brittle structural elements (faults and joints) upwards in the Tertiary sediments. Qasr Libya area exposes wide exposures of Tertiary carbonate sediments and distinctively clarified the main effect of structures on the morphology, distribution and development of karst features. The structural configuration represents a development of concurrent assemblage of WNW-ESE dextral strike slip faults, N-S sinistral strike slip faults and unmappable flower structures and NNW-SSE normal fault within ENE-WSW principle dextral shear zone. The movement within the whole structure induced zones of broken and crushed rock fragments of varying sizes by which the dissolution becomes easier by the surface and underground water. Among the Tertiary sediments are Darnah Formation (Middle-Late Eocene) and Al Bayda Algal Limestone Member (the upper part of Early Oligocene) that display prominent and spectacular different shapes and sizes of karst (lapies, caves and dolines). In Apollonia Formation (Early-Middle Eocene), Al Shahhat Marl Member (the lower part of Early Oligocene) and Al Abraq Formation (Late Oligocene), these features are lacking and essentially represented by bogaz features .Commonly, karst (caves and dolines, in particular)are structurally controlled and formed in the phreatic zone, while the accompanied collapse in the dolines has been taken place in advance stage of the karst cycle (or in vadose zone).}
}
@techreport{Lagae2009,
	title        = {Procedural Noise using Sparse Gabor Convolution Procedural Noise using Sparse Gabor Convolution \textasteriskcentered},
	author       = {Ares Lagae and Sylvain Lefebvre and George Drettakis and Philip Dutr\'{e}},
	year         = 2009,
	journal      = {ACM Transactions on Graphics},
	volume       = 28,
	pages        = {54--64},
	url          = {https://inria.hal.science/inria-00606821},
	abstract     = {Figure 1: (Left) We present a procedural noise that offers accurate spectral control. The user can interactively manipulate the power spectrum. (Middle) We apply the noise to a surface without the need for texture coordinates, and provide high-quality anisotropic filtering. Thanks to increased expressiveness of the noise, a simple colormap is enough to produce visually interesting textures. (Right) Since our surface noise does not require a texture parameterization, the surface can evolve dynamically and even sustain topology changes. Abstract Noise is an essential tool for texturing and modeling. Designing interesting textures with noise calls for accurate spectral control, since noise is best described in terms of spectral content. Textur-ing requires that noise can be easily mapped to a surface, while high-quality rendering requires anisotropic filtering. A noise function that is procedural and fast to evaluate offers several additional advantages. Unfortunately, no existing noise combines all of these properties. In this paper we introduce a noise based on sparse convolution and the Gabor kernel that enables all of these properties. Our noise offers accurate spectral control with intuitive parameters such as orientation, principal frequency and bandwidth. Our noise supports two-dimensional and solid noise, but we also introduce setup-free surface noise. This is a method for mapping noise onto a surface, complementary to solid noise, that maintains the appearance of the noise pattern along the object and does not require a texture pa-rameterization. Our approach requires only a few bytes of storage, does not use discretely sampled data, and is nonperiodic. It supports anisotropy and anisotropic filtering. We demonstrate our noise using an interactive tool for noise design.},
	issue        = 3,
	keywords     = {()}
}
@inproceedings{Tutenel2009,
	title        = {Rule-based layout solving and its application to procedural interior generation},
	author       = {Tim Tutenel and Rafael Bidarra and Ruben Michael Smelik and Klaas Jan De Kraker},
	year         = 2009,
	booktitle    = {Proceedings of the CASA Workshop on 3D Advanced Media in Gaming and Simulation (3AMIGAS)},
	url          = {https://www.researchgate.net/publication/228922424},
	abstract     = {Due to the recent advancement in procedural generation techniques, games are presenting players with ever growing cities and terrains to explore. However most sandbox-style games situated in cities, do not allow players to wander into buildings. In past research, space planning techniques have already been utilized to generate suitable layouts for both building floor plans and room layouts. We introduce a novel rule-based layout solving approach, especially suited for use in conjunction with procedural generation methods. We show how this solving approach can be used for procedural generation by providing the solver with a user-defined plan. In this plan, users can specify objects to be placed as instances of classes, which in turn contain rules about how instances should be placed. This approach gives us the opportunity to use our generic solver in different procedural generation scenarios. In this paper, we will illustrate mainly with interior generation examples.},
	keywords     = {Procedural generation,constraint solving}
}
@article{Aksu2009,
	title        = {Miocene-Recent evolution of Anaximander Mountains and Finike Basin at the junction of Hellenic and Cyprus Arcs, eastern Mediterranean},
	author       = {A. E. Aksu and J. Hall and C. Yaltirak},
	year         = 2009,
	month        = 3,
	journal      = {Marine Geology},
	volume       = 258,
	pages        = {24--47},
	doi          = {10.1016/j.margeo.2008.04.008},
	issn         = {00253227},
	abstract     = {Interpretation of ~ 1750~km of multi-channel seismic reflection profiles shows that the region of Anaximander Mountains (sensu lato) experienced a protracted Miocene contractional tectonic phase characterised by a nearly E-W trending and S-verging fold-thrust belt. This tectonic phase culminated during the latest Miocene and was replaced in the early-mid Pliocene by a tectonic regime dominated by transpression and rotation. We postulate that during the Pliocene-Quaternary the Anaximander Mountain (sensu stricto) and the Anaximenes Mountain developed as the result of reactivation and uplift and rotation of a linked, thick-skinned pre-Messinian imbricate thrust fan. In both regions, the development of back thrusts accentuated the morphology of these submarine mountains. At this time, the Anaximenes Mountain experienced a progressive counterclockwise rotation, while the Anaxagoras Mountain and the Florence Rise experienced a clockwise rotation creating the present present-day arrowhead-shaped morphology of the Anaximander Mountains (sensu lato). The Si\{dotless\}rri\{dotless\} Erin\c{c} Plateau represents a former Miocene fold-thrust belt that is transected during the Pliocene-Quaternary by a major transpressional fault system, which created a series of closely-spaced high-angle faults that cut the seafloor, creating a corrugated topography. A major transfer fault is developed between the Anaximander Mountain (sensu stricto) and the Si\{dotless\}rri\{dotless\} Erin\c{c} Plateau which displays ~ 2~km of contractional stratigraphic separation and as much as 40~km of sinistral strike-slip. The Finike Basin evolved during the Pliocene-Quaternary as the result of accelerated subsidence, caused by the lithospheric loading of the western Tauride Mountains. \textcopyright{} 2008 Elsevier B.V. All rights reserved.},
	issue        = {1-4},
	keywords     = {Anaxagoras Mountains,Anaximander,Anaximenes,Finike Basin,Florence Rise,basin evolution,eastern Mediterranean,tectonics}
}
@article{Peytavie2009b,
	title        = {Arches: A framework for modeling complex terrains},
	author       = {Adrien Peytavie and E. Galin and J. Grosjean and S. Merillou},
	year         = 2009,
	journal      = {Computer Graphics Forum},
	publisher    = {Blackwell Publishing Ltd},
	volume       = 28,
	pages        = {457--467},
	doi          = {10.1111/j.1467-8659.2009.01385.x},
	issn         = 14678659,
	abstract     = {In this paper, we present a framework for representing complex terrains with such features as overhangs, arches and caves and including different materials such as sand and rocks. Our hybrid model combines a volumetric discrete data structure that stores the different materials and an implicit representation for sculpting and reconstructing the surface of the terrain. Complex scenes can be edited and sculpted interactively with high level tools. We also propose an original rock generation technique that enables us to automatically generate complex rocky sceneries with piles of rocks without any computationally demanding physically-based simulation. \textcopyright{} 2008 The Eurographics Association and Blackwell Publishing Ltd.},
	issue        = 2
}
@article{Tan2009,
	title        = {Physically-based fluid animation: A survey},
	author       = {Jie Tan and Xubo Yang},
	year         = 2009,
	month        = 5,
	journal      = {Science in China, Series F: Information Sciences},
	volume       = 52,
	pages        = {723--740},
	doi          = {10.1007/s11432-009-0091-z},
	issn         = 10092757,
	abstract     = {In this paper, we give an up-to-date survey on physically-based fluid animation research. As one of the most popular approaches to simulate realistic fluid effects, physically-based fluid animation has spurred a large number of new results in recent years. We classify and discuss the existing methods within three categories: Lagrangian method, Eulerian method and Lattice-Boltzmann method. We then introduce techniques for seven different kinds of special fluid effects. Finally we review the latest hot research areas and point out some future research trends, including surface tracking, fluid control, hybrid method, model reduction, etc. \textcopyright{} 2009 Science in China Press and Springer-Verlag GmbH.},
	issue        = 5,
	keywords     = {Finite difference method,Lattice-Boltzmann method,Navier-Stokes equations,Particle level set,Physically-based animation,Smoothed particle hydrodynamics}
}
@article{Cui2009,
	title        = {Boid particle swarm optimisation},
	author       = {Zhihua Cui and Zhongzhi Shi},
	year         = 2009,
	month        = 5,
	journal      = {International Journal of Innovative Computing and Applications},
	publisher    = {ECMS},
	volume       = 2,
	pages        = 77,
	doi          = {10.1504/IJICA.2009.031778},
	isbn         = 9780956494481,
	issn         = {1751-648X},
	url          = {http://www.inderscience.com/link.php?id=31778},
	abstract     = {Particle swarm optimisation (PSO) is a novel population-based stochastic optimisation algorithm inspired by the Reynolds' boid model. The original biological background of boid obeys three basic simple steering rules: separation, alignment and cohesion. However, to promote a simple update equation, none of these rules of boid model is employed by PSO methodology. Due to the weakness of biological background of PSO, in this paper, a new variant of PSO, boid particle swarm optimisation (BPSO), is designed in which cohesion rule and alignment rule are both employed to improve the performance. In BPSO, each particle has two motions: divergent motion and convergent motion. For divergent motion, each particle adjusts its moving direction according to the alignment direction and the cohesion direction, as well as in convergent motion, the original update equation of the standard version of PSO is used. To make a motion transition, a threshold is introduced to make the divergent motion is employed in the first period, whereas the convergent motion is used in the final stage. To testify the efficiency, several unconstrained benchmarks are used to compare. Simulation results show the proposed variant is more effective and efficient than other two variants of PSO when solving multi-modal high-dimensional numerical problems.},
	issue        = 2,
	keywords     = {BPSO,alignment rule,boid particle swarm optimisation,cohesion rule,separation rule}
}
@article{Marinakis2009,
	title        = {Ant colony and particle swarm optimization for financial classification problems},
	author       = {Yannis Marinakis and Magdalene Marinaki and Michael Doumpos and Constantin Zopounidis},
	year         = 2009,
	month        = 9,
	journal      = {Expert Systems with Applications},
	volume       = 36,
	pages        = {10604--10611},
	doi          = {10.1016/j.eswa.2009.02.055},
	issn         = {09574174},
	abstract     = {Financial decisions are often based on classification models which are used to assign a set of observations into predefined groups. Such models ought to be as accurate as possible. One important step towards the development of accurate financial classification models involves the selection of the appropriate independent variables (features) which are relevant for the problem at hand. This is known as the feature selection problem in the machine learning/data mining field. In financial decisions, feature selection is often based on the subjective judgment of the experts. Nevertheless, automated feature selection algorithms could be of great help to the decision-makers providing the means to explore efficiently the solution space. This study uses two nature-inspired methods, namely ant colony optimization and particle swarm optimization, for this problem. The modelling context is developed and the performance of the methods is tested in two financial classification tasks, involving credit risk assessment and audit qualifications. \textcopyright{} 2009 Elsevier Ltd. All rights reserved.},
	issue        = 7,
	keywords     = {Ant colony optimization,Auditing,Credit risk assessment,Feature selection,Nearest neighbour classifiers,Particle swarm optimization}
}
@inproceedings{Godoy2009,
	title        = {A Complex Neighborhood based Particle Swarm Optimization},
	author       = {Alan Godoy and Fernando J. Von Zuben},
	year         = 2009,
	month        = 5,
	booktitle    = {2009 IEEE Congress on Evolutionary Computation},
	publisher    = {IEEE},
	pages        = {720--727},
	doi          = {10.1109/CEC.2009.4983016},
	isbn         = {978-1-4244-2958-5},
	url          = {http://ieeexplore.ieee.org/document/4983016/}
}
@article{Luo2010,
	title        = {Edge adaptive image steganography based on lsb matching revisited},
	author       = {Weiqi Luo and Fangjun Huang and Jiwu Huang},
	year         = 2010,
	month        = 6,
	journal      = {IEEE Transactions on Information Forensics and Security},
	volume       = 5,
	pages        = {201--214},
	doi          = {10.1109/TIFS.2010.2041812},
	issn         = 15566013,
	url          = {http://ieeexplore.ieee.org/document/5411758/},
	abstract     = {The least-significant-bit (LSB)-based approach is a popular type of steganographic algorithms in the spatial domain. However, we find that in most existing approaches, the choice of embedding positions within a cover image mainly depends on a pseudorandom number generator without considering the relationship between the image content itself and the size of the secret message. Thus the smooth/flat regions in the cover images will inevitably be contaminated after data hiding even at a low embedding rate, and this will lead to poor visual quality and low security based on our analysis and extensive experiments, especially for those images with many smooth regions. In this paper, we expand the LSB matching revisited image steganography and propose an edge adaptive scheme which can select the embedding regions according to the size of secret message and the difference between two consecutive pixels in the cover image. For lower embedding rates, only sharper edge regions are used while keeping the other smoother regions as they are. When the embedding rate increases, more edge regions can be released adaptively for data hiding by adjusting just a few parameters. The experimental results evaluated on 6000 natural images with three specific and four universal steganalytic algorithms show that the new scheme can enhance the security significantly compared with typical LSB-based approaches as well as their edge adaptive ones, such as pixel-value-differencing-based approaches, while preserving higher visual quality of stego images at the same time. \textcopyright{} 2010 IEEE.},
	issue        = 2,
	keywords     = {Content-based steganography,Least-significant-bit (LSB)-based steganography,Pixel-value differencing (PVD),Security}
}
@article{Carenini2010,
	title        = {Visual structured summaries of human conversations},
	author       = {Giuseppe Carenini and Gabriel Murray},
	year         = 2010,
	journal      = {International Conference on Intelligent User Interfaces, Proceedings IUI},
	pages        = {37--40},
	doi          = {10.1145/2002353.2002366},
	isbn         = 9781605589961,
	abstract     = {This paper presents an interactive interface to create visually structured summaries of human conversations via ontology mapping. We have built highly accurate classifiers for mapping the sentences of a conversation in an ontology, which includes nodes for the Dialog Acts (DA) properties such as decision and subjective, along with nodes for the conversation participants. In contrast with previous work, our classifiers do not rely on features specific to any particular conversational modality. We are currently developing an interactive interface that allows the user to generate visual structured summaries by searching a conversation for sentences according to the ontology mapping. Our first prototype comprises two panels. The right panel displays the ontology, while the left panel of the our prototype displays the whole conversation, where sentences are temporally ordered. Given the information displayed in the two panels, the user can generate visual, structured summaries by selecting nodes in the ontology. As a result, the sentences that were mapped in the selected nodes will be highlighted. Our initial prototype builds on a component of the GATE system, which was originally developed as a tool for text annotation. \textcopyright{} 2010 ACM.},
	keywords     = {conversation,human,structured summaries,visual}
}
@article{Galin2010,
	title        = {Procedural generation of roads},
	author       = {\'{E}ric Galin and Adrien Peytavie and N. Mar\'{e}chal and \'{E}ric Gu\'{e}rin},
	year         = 2010,
	month        = 5,
	journal      = {Computer Graphics Forum},
	publisher    = {Blackwell Publishing Ltd},
	volume       = 29,
	pages        = {429--438},
	doi          = {10.1111/j.1467-8659.2009.01612.x},
	issn         = 14678659,
	url          = {https://onlinelibrary.wiley.com/doi/full/10.1111/j.1467-8659.2009.01612.x https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8659.2009.01612.x https://onlinelibrary.wiley.com/doi/10.1111/j.1467-8659.2009.01612.x},
	note         = {Peut-\^{e}tre pour cr\'{e}er des \&quot;chemins\&quot; pour le robot (voir presentation ppt de Karen)},
	abstract     = {In this paper, we propose an automatic method for generating roads based on a weighted anisotropic shortest path algorithm. Given an input scene, we automatically create a path connecting an initial and a final point. The trajectory of the road minimizes a cost function that takes into account the different parameters of the scene including the slope of the terrain, natural obstacles such as rivers, lakes, mountains and forests. The road is generated by excavating the terrain along the path and instantiating generic parameterized models. \textcopyright{} 2010 The Eurographics Association and Blackwell Publishing Ltd.},
	issue        = 2,
	keywords     = {Discrete anisotropic shortest path,Procedural modeling,Road generation}
}
@phdthesis{Lengyel2010a,
	title        = {Voxel-based terrain for real-time virtual simulations},
	author       = {E.S. Lengyel},
	year         = 2010,
	pages        = 148,
	url          = {http://gradworks.umi.com/34/04/3404919.html},
	abstract     = {This dissertation provides the theoretical basis and implementation details for a complete and practical real-time voxel-based terrain rendering system. We first present a modified Marching Cubes algorithm designed to eliminate choices arising from ambiguities in the original algorithm and its successors in order to facilitate a faster implementation and to simplify the design of a level-of-detail algorithm. The modified Marching Cubes algorithm is extended to operate on voxel data at multiple resolutions in such a way that triangle meshes produced at all levels of detail correctly match geometrical features. We introduce a robust method for seamlessly joining voxel-based terrain meshes of different levels of detail and establish a transition structure that both simplifies the triangulation problem and eliminates the potential for shading artifacts. Finally, we discuss methods for applying texture maps and advanced shading techniques to voxel-based terrain meshes. These methods are designed to be fast and compatible with the widest possible range of graphics hardware across multiple platforms.},
	keywords     = {marching cubes,rendering,terrain,voxel}
}
@article{Congote2010,
	title        = {Extending marching cubes with adaptative methods to obtain more accurate iso-surfaces},
	author       = {John Congote and Aitor Moreno and I\~{n}igo Barandiaran and Javier Barandiaran and Oscar Ruiz},
	year         = 2010,
	journal      = {Communications in Computer and Information Science},
	volume       = {68 CCIS},
	pages        = {35--44},
	doi          = {10.1007/978-3-642-11840-1_3},
	isbn         = 3642118399,
	issn         = 18650929,
	abstract     = {This work proposes an extension of the Marching Cubes algorithm, where the goal is to represent implicit functions with higher accuracy using the same grid size. The proposed algorithm displaces the vertices of the cubes iteratively until the stop condition is achieved. After each iteration, the difference between the implicit and the explicit representations is reduced, and when the algorithm finishes, the implicit surface representation using the modified cubical grid is more accurate, as the results shall confirm. The proposed algorithm corrects some topological problems that may appear in the discretization process using the original grid. \textcopyright{} 2010 Springer-Verlag Berlin Heidelberg.},
	issue        = {January}
}
@article{Doran2010,
	title        = {Using Software Agents},
	author       = {Jonathon Doran and Ian Parberry},
	year         = 2010,
	journal      = {IEEE Transactions on Computational Intelligence and AI in Games},
	volume       = 2,
	pages        = {111--119},
	issue        = 2
}
@article{Walsh2010,
	title        = {Terrain generation using an interactive genetic algorithm},
	author       = {Paul Walsh and Prasad Gade},
	year         = 2010,
	journal      = {2010 IEEE World Congress on Computational Intelligence, WCCI 2010 - 2010 IEEE Congress on Evolutionary Computation, CEC 2010},
	publisher    = {IEEE},
	doi          = {10.1109/CEC.2010.5585913},
	isbn         = 9781424469109,
	abstract     = {This paper introduces the Auto Terrain Generation System (ATGS), which is based on an Interactive Genetic Algorithm (IGA) that enables non-specialist users to rapidly generate terrains. The motivation for using an IGA is discussed, existing terrain generation techniques are described and a new approach, based on a fractal terrain engine, is outlined. Graphics engines allow terrains to be specified with over 800 floating point parameters, which can overwhelm non-specialist users. These parameters also create a vast search space for auto-terrain generation systems that can complicate procedural techniques. ATGS addresses these issues via interaction with the user, which is implemented in ATGS by a web based user interface that allows users to rapidly indicate terrain preferences. These user preferences are used by a genetic algorithm to explore a multi-dimensional parameter space that satisfies the user's intuition and aesthetics. Proof of concept experiments are outlined, results are presented and future research work is projected. \textcopyright{} 2010 IEEE.}
}
@article{Merrell2010,
	title        = {Computer-generated residential building layouts},
	author       = {Paul Merrell and Eric Schkufza and Vladlen Koltun},
	year         = 2010,
	journal      = {ACM Transactions on Graphics},
	volume       = 29,
	pages        = {1--12},
	doi          = {10.1145/1866158.1866203},
	isbn         = 9781450304399,
	issn         = {07300301},
	abstract     = {We present a method for automated generation of building layouts for computer graphics applications. Our approach is motivated by the layout design process developed in architecture. Given a set of high-level requirements, an architectural program is synthesized using a Bayesian network trained on real-world data. The architectural program is realized in a set of floor plans, obtained through stochastic optimization. The floor plans are used to construct a complete three-dimensional building with internal structure. We demonstrate a variety of computer-generated buildings produced by the presented approach. \textcopyright{} 2010 ACM.},
	issue        = 6,
	keywords     = {architectural modeling,computer-aided architectural design,data-driven 3D modeling,procedural modeling,spatial allocation}
}
@article{Dormans2010,
	title        = {Adventures in level design: Generating missions and spaces for action adventure games},
	author       = {Joris Dormans},
	year         = 2010,
	journal      = {Workshop on Procedural Content Generation in Games, PC Games 2010, Co-located with the 5th International Conference on the Foundations of Digital Games},
	doi          = {10.1145/1814256.1814257},
	isbn         = 9781450300230,
	abstract     = {This paper investigates strategies to generate levels for action adventure games. This genre relies more strongly on well-designed levels than rule-driven genres such as strategy or roleplaying games for which procedural level generation has been successful in the past. The approach outlined by this paper distinguishes between missions and spaces as two separate structures that need to be generated in two individual steps. It discusses the merits of different types of generative grammars for each individual step in the process. Copyright 2010 ACM.},
	keywords     = {Action adventure games,Level design,Procedural generation}
}
@article{Togelius2010,
	title        = {Towards multiobjective procedural map generation},
	author       = {Julian Togelius and Mike Preuss and Georgios N. Yannakakis},
	year         = 2010,
	journal      = {Workshop on Procedural Content Generation in Games, PC Games 2010, Co-located with the 5th International Conference on the Foundations of Digital Games},
	doi          = {10.1145/1814256.1814259},
	isbn         = 9781450300230,
	abstract     = {A search-based procedural content generation (SBPCG) algorithm for strategy game maps is proposed. Two representations for strategy game maps are devised, along with a number of objectives relating to predicted player experience. A multiobjective evolutionary algorithm is used for searching the space of maps for candidates that satisfy pairs of these objectives. As the objectives are inherently partially conicting, the algorithm generates Pareto fronts showing how these objectives can be balanced. Such fronts are argued to be a valuable tool for designers looking to balance various design needs. Choosing appropriate points (manually or automatically) on the Pareto fronts, maps can be found that exhibit good map design according to specified criteria, and could either be used directly in e.g. an RTS game or form the basis for further human design. Copyright 2010 ACM.}
}
@article{Fukao2010,
	title        = {Seafloor topography, ocean infragravity waves, and background Love and Rayleigh waves},
	author       = {Yoshio Fukao and Kiwamu Nishida and Naoki Kobayashi},
	year         = 2010,
	journal      = {Journal of Geophysical Research: Solid Earth},
	volume       = 115,
	pages        = {1--10},
	doi          = {10.1029/2009JB006678},
	issn         = 21699356,
	abstract     = {We propose that background Love and Rayleigh waves in a frequency range 5-20 mHz are generated primarily by ocean infragravity waves in the same frequency range by a linear coupling process with seafloor topography. Wavelengths of infragravity waves in this frequency range are on the order of 10 to 40 km in the deep ocean. The seafloor topography with wavelengths of this order is dominated by abyssal hills, which are the most widespread physiographic forms on Earth, covering as much as 85\% of the Pacific floor. Interaction of infragravity waves in the deep ocean with these hills generates a random distribution of point-like tangential forces on the seafloor which may be large enough to excite Love and Rayleigh waves simultaneously. We quantify this idea by using the known statistical property of hills distribution in the Pacific and by noting that heights of abyssal hills are an order of magnitude smaller than depths of the deep ocean, so that the topography-related phase velocity change can be neglected. The model is reasonably consistent with the Love to Rayleigh wave amplitude ratio reported at 10-20 mHz and the observed background Rayleigh wave spectrum with a characteristic plateau around 8 mHz. Contribution of topographic coupling in shallow, coastal seas is not included in our simple model but should be important, especially at frequencies above 20 mHz. \textcopyright{} 2010 by the American Geophysical Union.},
	issue        = 4,
	keywords     = {http://dx.doi.org/10.1029/2009JB006678, doi:10.102}
}
@article{Hnaidi2010,
	title        = {Feature based terrain generation using diffusion equation},
	author       = {Houssam Hnaidi and Eric Gu\'{e}rin and Samir Akkouche and Adrien Peytavie and Eric Galin},
	year         = 2010,
	month        = 9,
	journal      = {Computer Graphics Forum},
	volume       = 29,
	pages        = {2179--2186},
	doi          = {10.1111/j.1467-8659.2010.01806.x},
	issn         = {0167-7055},
	url          = {https://onlinelibrary.wiley.com/doi/10.1111/j.1467-8659.2010.01806.x},
	abstract     = {<p>This paper presents a diffusion method for generating terrains from a set of parameterized curves that characterize the landform features such as ridge lines, riverbeds or cliffs. Our approach provides the user with an intuitive vector-based feature-oriented control over the terrain. Different types of constraints (such as elevation, slope angle and roughness) can be attached to the curves so as to define the shape of the terrain. The terrain is generated from the curve representation by using an efficient multigrid diffusion algorithm. The algorithm can be efficiently implemented on the GPU, which allows the user to interactively create a vast variety of landscapes.</p>},
	issue        = 7,
	keywords     = {Terrain modeling,gradient and height field diffusion,vector graphics}
}
@article{Smelik2010b,
	title        = {Integrating procedural generation and manual editing of virtual worlds},
	author       = {Ruben M. Smelik and Tim Tutenel and Klaas Jan De Kraker and Rafael Bidarra},
	year         = 2010,
	journal      = {Workshop on Procedural Content Generation in Games, PC Games 2010, Co-located with the 5th International Conference on the Foundations of Digital Games},
	doi          = {10.1145/1814256.1814258},
	isbn         = 9781450300230,
	url          = {https://d1wqtxts1xzle7.cloudfront.net/36779011/FDGWorkshopPaper_final_rc1-with-cover-page-v2.pdf?Expires=1642695458&Signature=LvUwj6x8fYomPWljJ9TjFWohVXPTtSTw3PlARTq1uwqGdQu3ilMDZYngI-qAvc5492XGjWe0FpAyVZWKV0HRi0hHIkZ5IX8~adYOE0R2RwVEMR8q5NW~xXg6knDS5BQwt},
	abstract     = {Because of the increasing detail and size of virtual worlds, designers are more and more urged to consider employing procedural methods to alleviate part of their modeling work. However, such methods are often unintuitive to use, difficult to integrate, and provide little user control, making their application far from straightforward. In our declarative modeling approach, designers are provided with a more productive and simplified virtual world modeling workow that matches better with their iterative way of working. Using interactive procedural sketching, they can quickly layout a virtual world, while having proper user control at the level of large terrain features. However, in practice, designers require a finer level of control. Integrating procedural techniques with manual editing in an iterative modeling workow is an important topic that has remained relatively unaddressed until now. This paper identifies challenges of this integration and discusses approaches to combine these methods in such a way that designers can freely mix them, while the virtual world model is kept consistent during all modifications. We conclude that overcoming the challenges mentioned, for example in a declarative modeling context, is instrumental to achieve the much desired adoption of procedural modeling in mainstream virtual world modeling. Copyright 2010 ACM.},
	keywords     = {Declarative modeling,Manual modelling,Procedural methods,Virtual worlds}
}
@article{Smith2010,
	title        = {Tanagra: A mixed-initiative level design tool},
	author       = {Gillian Smith and Jim Whitehead and Michael Mateas},
	year         = 2010,
	journal      = {FDG 2010 - Proceedings of the 5th International Conference on the Foundations of Digital Games},
	pages        = {209--216},
	doi          = {10.1145/1822348.1822376},
	isbn         = 9781605589374,
	url          = {https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.190.1116&rep=rep1&type=pdf},
	abstract     = {Tanagra is a prototype mixed-initiative design tool for 2D plat-former level design, in which a human and computer can work together to produce a level. The human designer can place constraints on a continuously running level generator, in the form of exact geometry placement and manipulation of the level's pacing. The computer then flls in the rest of the level with geometry that guarantees playability, or informs the designer that there is no level that meets their requirements. This paper presents the design of Tanagra, a discussion of the editing operations it provides to the designer, and an evaluation of the expressivity of its generator. \textcopyright{} 2010 ACM.},
	keywords     = {AI-assisted design,Games,Level design,Procedural content generation}
}
@article{Ylmaz2010,
	title        = {A new version of Bishop frame and an application to spherical images},
	author       = {S\"{u}ha Ylmaz and Melih Turgut},
	year         = 2010,
	journal      = {Journal of Mathematical Analysis and Applications},
	publisher    = {Elsevier Inc.},
	volume       = 371,
	pages        = {764--776},
	doi          = {10.1016/j.jmaa.2010.06.012},
	issn         = {0022247X},
	url          = {http://dx.doi.org/10.1016/j.jmaa.2010.06.012 https://core.ac.uk/download/pdf/82572186.pdf},
	abstract     = {In this work, we introduce a new version of Bishop frame using a common vector field as binormal vector field of a regular curve and call this frame as "Type-2 Bishop Frame". Thereafter, by translating type-2 Bishop frame vectors to the center of unit sphere of three-dimensional Euclidean space, we introduce new spherical images and call them as type-2 Bishop spherical images. Frenet-Serret apparatus of these new spherical images are obtained in terms of base curve's type-2 Bishop invariants. Additionally, we express some interesting relations and illustrate two examples of our main results. \textcopyright{} 2010 Elsevier Inc.},
	issue        = 2,
	keywords     = {Bishop frame,Classical differential geometry,Euclidean space,General helix,Slant helix,Spherical images}
}
@article{Stava2010,
	title        = {Inverse procedural modeling by automatic generation of L-systems},
	author       = {Ond\v{r}ej \v{S}t'ava and Bed\v{r}ich Bene\v{s} and Radomir M\v{e}ch and Daniel G. Aliaga and Peter Kri\v{s}tof},
	year         = 2010,
	journal      = {Computer Graphics Forum},
	volume       = 29,
	pages        = {665--674},
	doi          = {10.1111/j.1467-8659.2009.01636.x},
	issn         = 14678659,
	url          = {https://www.cs.jhu.edu/~misha/ReadingSeminar/Papers/Stava10.pdf},
	abstract     = {We present an important step towards the solution of the problem of inverse procedural modeling by generating parametric context-free L-systems that represent an input 2D model. The L-system rules efficiently code the regular structures and the parameters represent the properties of the structure transformations. The algorithm takes as input a 2D vector image that is composed of atomic elements, such as curves and poly-lines. Similar elements are recognized and assigned terminal symbols of an L-system alphabet. The terminal symbols' position and orientation are pair-wise compared and the transformations are stored as points in multiple 4D transformation spaces. By careful analysis of the clusters in the transformation spaces, we detect sequences of elements and code them as L-system rules. The coded elements are then removed from the clusters, the clusters are updated, and then the analysis attempts to code groups of elements in (hierarchies) the same way. The analysis ends with a single group of elements that is coded as an L-system axiom. We recognize and code branching sequences of linearly translated, scaled, and rotated elements and their hierarchies. The L-system not only represents the input image, but it can also be used for various editing operations. By changing the L-system parameters, the image can be randomized, symmetrized, and groups of elements and regular structures can be edited. By changing the terminal and non-terminal symbols, elements or groups of elements can be replaced. \textcopyright{} 2010 The Eurographics Association and Blackwell Publishing Ltd.},
	issue        = 2,
	keywords     = {Computer Graphics [I.3.5]: Computational Geometry,Mathematical Logic and Formal Languages [F.4.2]: G}
}
@article{Jones2010,
	title        = {Directable weathering of concave rock using curvature estimation},
	author       = {Matthew Beardall and Joseph Butler and McKay Farley and Michael D. Jones},
	year         = 2010,
	journal      = {IEEE Transactions on Visualization and Computer Graphics},
	volume       = 16,
	pages        = {81--94},
	doi          = {10.1109/TVCG.2009.39},
	isbn         = 2008050068,
	issn         = 10772626,
	url          = {https://scholarsarchive.byu.edu/cgi/viewcontent.cgi?article=1109&context=facpub},
	abstract     = {We address the problem of directable weathering of exposed concave rock for use in computer-generated animation or games. Previous weathering models that admit concave surfaces are computationally inefficient and difficult to control. In nature, the spheroidal and cavernous weathering rates depend on the surface curvature. Spheroidal weathering is fastest in areas with large positive mean curvature and cavernous weathering is fastest in areas with large negative mean curvature. We simulate both processes using an approximation of mean curvature on a voxel grid. Both weathering rates are also influenced by rock durability. The user controls rock durability by editing a durability graph before and during weathering simulation. Simulations of rockfall and colluvium deposition further improve realism. The profile of the final weathered rock matches the shape of the durability graph up to the effects of weathering and colluvium deposition. We demonstrate the top-down directability and visual plausibility of the resulting model through a series of screenshots and rendered images. The results include the weathering of a cube into a sphere and of a sheltered inside corner into a cavern as predicted by the underlying geomorphological models. \textcopyright{} 2010 IEEE.},
	issue        = 1,
	keywords     = {Modeling packages,Physically based modeling},
	pmid         = 19910663
}
@article{Doran2010a,
	title        = {Controlled procedural terrain generation using software agents},
	author       = {Jonathon Doran and Ian Parberry},
	year         = 2010,
	journal      = {IEEE Transactions on Computational Intelligence and AI in Games},
	volume       = 2,
	pages        = {111--119},
	doi          = {10.1109/TCIAIG.2010.2049020},
	issn         = {1943068X},
	url          = {https://ianparberry.com/pubs/terrain.pdf},
	abstract     = {Procedural terrain generation is used to create landforms for applications such as computer games and flight simulators. While most of the existing work has concentrated on algorithms that generate terrain without input from the user, we explore a more controllable system that uses intelligent agents to generate terrain elevation heightmaps according to designer-defined constraints. This allows the designer to create procedural terrain that has specific properties. \textcopyright{} 2010 IEEE.},
	issue        = 2,
	keywords     = {Agents,procedural content generation,terrain}
}
@article{Huijser2010,
	title        = {Procedural natural systems for game level design},
	author       = {Remco Huijser and Jeroen Dobbe and Willem F. Bronsvoort and Rafael Bidarra},
	year         = 2010,
	journal      = {Proceedings - 2010 Brazilian Symposium on Games and Digital Entertainment, SBGames 2010},
	publisher    = {IEEE},
	pages        = {189--198},
	doi          = {10.1109/SBGAMES.2010.31},
	isbn         = 9780769543598,
	abstract     = {Due to the increase in magnitude and level of detail of next-gen games, the time required to manually design a game level has increased dramatically. This paper introduces procedural natural systems, a novel approach aimed at reducing the time needed to design large-scale natural phenomena for game levels. The concept of natural systems separates the shape of a natural phenomenon from its footprint, allowing a designer to edit either of them separately. Various procedural techniques are used to combine the shape and footprint of a natural system, as well as to tweak these in real-time in a game world. We conclude that natural systems provide a solid foundation for intuitive, flexible and efficient procedural generation of significant portions of a game level. \textcopyright{} 2010 IEEE.},
	keywords     = {Game level design,Natural systems,Procedural content generation}
}
@phdthesis{Martinet2010,
	title        = {Drawing Planar Graphs},
	author       = {Lucie Martinet},
	year         = 2010,
	volume       = 1,
	pages        = {1--16}
}
@article{Caumon2010,
	title        = {Towards stochastic time-varying geological modeling},
	author       = {Guillaume Caumon},
	year         = 2010,
	journal      = {Mathematical Geosciences},
	volume       = 42,
	pages        = {555--569},
	doi          = {10.1007/s11004-010-9280-y},
	issn         = 18748961,
	abstract     = {The modeling of subsurface geometry and properties is a key element to understand Earth processes and manage natural hazards and resources. In this paper, we suggest this field should evolve beyond pure data fitting approaches by integrating geological concepts to constrain interpretations or test their consistency. This process necessarily calls for adding the time dimension to 3D modeling, both at the geological and human time scales. Also, instead of striving for one single best model, it is appropriate to generate several possible subsurface models in order to convey a quantitative sense of uncertainty. Depending on the modeling objective (e.g., quantification of natural resources, production forecast), this population of models can be ranked. Inverse theory then provides a framework to validate (or rather invalidate) models which are not compatible with certain types of observations. We review recent methods to better achieve both stochastic and time-varying geomodeling and advocate that the application of inversion should rely not only on random field models, but also on geological concepts and parameters. \textcopyright{} 2010 International Association for Mathematical Geosciences.},
	issue        = 5,
	keywords     = {Geomodeling,Geostatistics,Inverse methods,Structural restoration,Uncertainty}
}
@article{Doran2010b,
	title        = {Controlled Procedural Terrain Generation Using Software Agents},
	author       = {Jonathon Doran and Ian Parberry},
	year         = 2010,
	journal      = {IEEE Transactions on Computational Intelligence and AI in Games},
	volume       = 2,
	pages        = {111--119},
	issue        = 2
}
@article{Takayama2010,
	title        = {Volumetric modeling with diffusion surfaces},
	author       = {Kenshi Takayama and Olga Sorkine and Andrew Nealen and Takeo Igarashi},
	year         = 2010,
	journal      = {ACM Transactions on Graphics},
	volume       = 29,
	doi          = {10.1145/1866158.1866202},
	isbn         = 9781450304399,
	issn         = {07300301},
	abstract     = {The modeling of volumetric objects is still a difficult problem. Solid texture synthesis methods enable the design of volumes with homogeneous textures, but global features such as smoothly varying colors seen in vegetables and fruits are difficult to model. In this paper, we propose a representation called diffusion surfaces (DSs) to enable modeling such objects. DSs consist of 3D surfaces with colors defined on both sides, such that the interior colors in the volume are obtained by diffusing colors from nearby surfaces. A straightforward way to compute color diffusion is to solve a volumetric Poisson equation with the colors of the DSs as boundary conditions, but it requires expensive volumetric meshing which is not appropriate for interactive modeling. We therefore propose to interpolate colors only locally at user-defined cross-sections using a modified version of the positive mean value coordinates algorithm to avoid volumetric meshing. DSs are generally applicable to model many different kinds of objects with internal structures. As a case study, we present a simple sketch-based interface for modeling objects with rotational symmetries that can also generate random variations of models. We demonstrate the effectiveness of our approach through various DSs models with simple non-photorealistic rendering techniques enabled by DSs. \textcopyright{} 2010 ACM.},
	issue        = 6,
	keywords     = {color diffusion,sketching interface,volumetric modeling}
}
@article{VitalBrazil2010,
	title        = {Sketching Variational Hermite-RBF Implicits},
	author       = {Emilio Vital Brazil and Ives Macedo and Mario Costa Sousa and Luiz Henrique de Figueiredo and L Velho},
	year         = 2010,
	journal      = {Proceedings of the Seventh Sketch-Based Interfaces and Modeling Symposium},
	pages        = {1--8},
	doi          = {10.2312/SBM/SBM10/001-008},
	url          = {https://diglib.eg.org/bitstream/handle/10.2312/SBM.SBM10.001-008/001-008.pdf?sequence=1&isAllowed=n},
	abstract     = {We present techniques for modeling Variational Hermite Radial Basis Function (VHRBF) Implicits using a set of sketch-based interface and modeling (SBIM) operators. VHRBF Implicits is a simple and compact representation well suited for SBIM. It provides quality reconstructions, preserving the intended shape from a coarse and non-uniform number of point-normal samples extracted directly from the input strokes. In addition, it has a number of desirable properties such as parameter-free modeling, invariance under geometric similarities on the input strokes, suitable estimation of differential quantities, good behavior near close sheets, and both linear fitting and reproduction. Our approach uses these properties of VHRBF Implicits to quickly and robustly generate the overall shape of 3D models. We present examples of implicit models obtained from a set of SBIM language operators for contouring, cross-editing, kneading, oversketching and merging.}
}
@article{Ji2010,
	title        = {B-Mesh: A modeling system for base meshes of 3D articulated shapes},
	author       = {Zhongping Ji and Ligang Liu and Yigang Wang},
	year         = 2010,
	journal      = {Computer Graphics Forum},
	volume       = 29,
	pages        = {2169--2177},
	doi          = {10.1111/j.1467-8659.2010.01805.x},
	issn         = 14678659,
	abstract     = {This paper presents a novel modeling system, called B-Mesh, for generating base meshes of 3D articulated shapes. The user only needs to draw a one-dimensional skeleton and to specify key balls at the skeletal nodes. The system then automatically generates a quad dominant initial mesh. Further subdivision and evolution are performed to refine the initial mesh and generate a quad mesh which has good edge flow along the skeleton directions. The user can also modify and manipulate the shape by editing the skeleton and the key balls and can easily compose new shapes by cutting and pasting existing models in our system. The mesh models generated in our system greatly benefit the sculpting operators for sculpting modeling and skeleton-based animation. \textcopyright{} 2010 The Eurographics Association and Blackwell Publishing Ltd.},
	issue        = 7
}
@article{Bernhardt2010,
	title        = {Implicit Blending Revisited},
	author       = {Adrien Bernhardt and Loic Barthe and Marie-Paule Cani and Brian Wyvill},
	year         = 2010,
	month        = 5,
	journal      = {Computer Graphics Forum},
	volume       = 29,
	pages        = {367--375},
	doi          = {10.1111/j.1467-8659.2009.01606.x},
	issn         = {0167-7055},
	url          = {https://onlinelibrary.wiley.com/doi/10.1111/j.1467-8659.2009.01606.x},
	abstract     = {Blending is both the strength and the weakness of functionally based implicit surfaces (such as F-reps or soft-objects). While it gives them the unique ability to smoothly merge into a single, arbitrary shape, it makes implicit modelling hard to control since implicit surfaces blend at a distance, in a way that heavily depends on the slope of the field functions that define them. This paper presents a novel, generic solution to blending of functionally-based implicit surfaces: the insight is that to be intuitive and easy to control, blends should be located where two objects overlap, while enabling other parts of the objects to come as close to each other as desired without being deformed. Our solution relies on automatically defined blending regions around the intersection curves between two objects. Outside of these volumes, a clean union of the objects is computed thanks to a new operator that guarantees the smoothness of the resulting field function; meanwhile, a smooth blend is generated inside the blending regions. Parameters can automatically be tuned in order to prevent small objects from blurring out when blended into larger ones, and to generate a progressive blend when two animated objects come in contact.},
	issue        = 2
}
@article{Turk2010,
	title        = {Sticky feet: Evolution in a multi-creature physical simulation},
	author       = {Greg Turk},
	year         = 2010,
	journal      = {Artificial Life XII: Proceedings of the 12th International Conference on the Synthesis and Simulation of Living Systems, ALIFE 2010},
	pages        = {496--503},
	isbn         = 9780262290753,
	url          = {https://www.cc.gatech.edu/home/turk/my_papers/sticky_feet.pdf},
	abstract     = {We demonstrate artificial evolution in a system that combines physical simulation with competition between creatures. The simulated creatures are constructed using point masses that are connected by oscillating springs. The creatures pull themselves across their 2D environment by varying the amount of friction at different point masses, giving them sticky feet. Creatures combat one another, and the victor of such an encounter earns the right to reproduce, possibly with mutation. Rather than testing one individual against another in pairs, as many as 100 creatures move and interact with each other in the same 2D environment. Over time, the initial creatures are replaced by new creatures that are more agile and better at combating others. The evolved creatures from such simulations exhibit a wide array of body plans, locomotion styles, and interaction behaviors.}
}
@article{Jobling2010,
	title        = {J. Morrissey and J. L. Sumich: Introduction to the Biology of Marine Life, 9th edn.},
	author       = {Malcolm Jobling},
	year         = 2010,
	journal      = {Aquaculture International},
	volume       = 18,
	pages        = {709--710},
	doi          = {10.1007/s10499-009-9275-1},
	isbn         = 9780763753696,
	issn         = {0967-6120},
	abstract     = {The book closes with two special-topic chapters;   and mammals in Polar Seas, and harvesting living  resources. These two chapters, although containing some interesting material, may be considered a bit of an anomaly.},
	issue        = 4
}
@article{Prusinkiewicz2010,
	title        = {Constraints of space in plant development},
	author       = {Przemyslaw Prusinkiewicz and Pierre Barbier De Reuille},
	year         = 2010,
	journal      = {Journal of Experimental Botany},
	volume       = 61,
	pages        = {2117--2129},
	doi          = {10.1093/jxb/erq081},
	issn         = {00220957},
	url          = {http://algorithmicbotany.org/papers/constraints-of-space-in-plant-development.pdf},
	abstract     = {Like all forms in nature, plants are subject to the properties of space. On the one hand, space prevents configurations that would place more than one component in the same location at the same time. A generalization of this constraint limits proximity and density of organs. On the other hand, space provides a means for a plant to create three-dimensional forms by differentially controlling their growth. This results from a connection between the metric properties of surfaces and their Gaussian curvature. Three strategies used by plants to develop within the constraints of space are presented: expansion to another dimension, egalitarian partitioning of space, and competition for space. These strategies are illustrated with examples of curved surfaces of leaves and petals, self-similar branching structures of compound leaves and inflorescences, and tree architecture. The examples highlight the fundamental role of the constraints of space in plant development, and the complementary role of genetic regulation and space-dependent emergent phenomena in shaping a plant. \textcopyright{} 2010 The Author.},
	issue        = 8,
	keywords     = {Competition for space,Curvature,Dimension,Fractal,Genetic regulation of form,Leaf margin,Metric,Plant modelling,Tree architecture},
	pmid         = 20388746
}
@article{Iwasaki2010,
	title        = {Fast particle-based visual simulation of ice melting},
	author       = {K. Iwasaki and H. Uchida and Y. Dobashi and T. Nishita},
	year         = 2010,
	journal      = {Computer Graphics Forum},
	volume       = 29,
	pages        = {2215--2223},
	doi          = {10.1111/j.1467-8659.2010.01810.x},
	issn         = 14678659,
	abstract     = {The visual simulation of natural phenomena has been widely studied. Although several methods have been proposed to simulate melting, the flows of meltwater drops on the surfaces of objects are not taken into account. In this paper, we propose a particle-based method for the simulation of the melting and freezing of ice objects and the interactions between ice and fluids. To simulate the flow of meltwater on ice and the formation of water droplets, a simple interfacial tension is proposed, which can be easily incorporated into common particle-based simulation methods such as Smoothed Particle Hydrodynamics. The computations of heat transfer, the phase transition between ice and water, the interactions between ice and fluids, and the separation of ice due to melting are further accelerated by implementing our method using CUDA. We demonstrate our simulation and rendering method for depicting melting ice at interactive frame-rates. \textcopyright{} 2010 The Eurographics Association and Blackwell Publishing Ltd.},
	issue        = 7
}
@article{Tychonievich2010,
	title        = {Delaunay deformable mesh for the weathering and erosion of 3D terrain},
	author       = {L. A. Tychonievich and M. D. Jones},
	year         = 2010,
	journal      = {Visual Computer},
	volume       = 26,
	pages        = {1485--1495},
	doi          = {10.1007/s00371-010-0506-2},
	isbn         = {0037101005},
	issn         = {01782789},
	abstract     = {Computer-generated erosion and weathering are important to convey setting and mood in computer generated images. Heightmap based landforms are good for distant scenes, but inadequate for scenes containing concave rock formations. Voxel based terrain editing algorithms do admit concave surfaces but do not scale. We introduce weathering on triangulated surface meshes, using a memory efficient modification of the Delaunay deformable model. This structure allows the freedom of an unorganized point cloud, the geometric information and visualization of a surface mesh, and the topological freedom of volumetric approaches-all while scaling linearly with surface complexity. We implement both spheroidal weathering and hydraulic erosion algorithms on this structure and demonstrate that the resulting terrain is visually plausible at modest computational cost. \textcopyright{} 2010 Springer-Verlag.},
	issue        = 12,
	keywords     = {Geometry,Terrain,Weathering}
}
@article{Ferraris2010,
	title        = {Automating Terrain Texturing in Real-Time Using a Rule-Based Approach},
	author       = {John Ferraris and Christos Gatzidis and Feng Tian},
	year         = 2010,
	journal      = {International Journal of Virtual Reality},
	volume       = 9,
	pages        = {21--28},
	doi          = {10.20870/ijvr.2010.9.4.2787},
	issn         = {1081-1451},
	abstract     = {This publication proposes a novel approach to automatically colour and texture a given terrain mesh in real time. Through the use of weighting rules, a simple syntax allows for the generation of texture and colour values based on the elevation and angle of a given vertex. It is through this combination of elevation and angle that complex features such as ridges, hills and mountains can be described, with the mesh coloured and textured accordingly. The implementation of the approach is done entirely on the GPU using 2D lookup textures, delivering a great performance increase over typical approaches that pass colour and weighting information in the fragment shader. In fact, the rule set is abstracted enough to be used in conjunction with any colouring/texturing approach that uses weighting values to dictate which surfaces are depicted on the mesh},
	issue        = 4
}
@article{Park2010,
	title        = {Guiding flows for controlling crowds},
	author       = {Min Je Park},
	year         = 2010,
	journal      = {Visual Computer},
	volume       = 26,
	pages        = {1383--1391},
	doi          = {10.1007/s00371-009-0415-4},
	isbn         = {0037100904},
	issn         = {01782789},
	url          = {https://link.springer.com/content/pdf/10.1007/s00371-009-0415-4.pdf},
	abstract     = {In this paper, we present a novel method for controlling massive crowds by using control particles. Our method differs from previous ones that generate attraction (or repelling) forces around the control particles. Instead of doing this, we create a steady-state, flow-like control field that guides the crowd to move along with the control particles. Our control field can be naturally incorporated into the original simulation by using density-based weighted blending. Although we focus on simulation methods that use dynamic potential functions, our method can also be used to improve the controllability of agent-based simulation methods. Since the control particles can be easily manipulated by traditional key-framing, our method provides animators with an intuitive interface for manipulating the position of crowd over time. We illustrate the effectiveness of our method on several examples. \textcopyright{} Springer-Verlag 2009.},
	issue        = 11,
	keywords     = {Crowd simulation,Interactive control,Key-frame animation}
}
@article{Cowart2010,
	title        = {Analyzing Estuarine Shoreline Change: A Case Study of Cedar Island, North Carolina},
	author       = {Lisa Cowart and J. P. Walsh and D. Reide Corbett},
	year         = 2010,
	journal      = {Journal of Coastal Research},
	volume       = 265,
	pages        = {817--830},
	doi          = {10.2112/jcoastres-d-09-00117.1},
	issn         = {0749-0208},
	abstract     = {Continued climate change, sea-level rise, and coastal development have lead to concern about shoreline dynamics beyond oceanfront areas, encompassing more sheltered coastal water bodies such as estuaries. Because estuaries are critically important ecosystems, understanding coastline changes in these areas is necessary to evaluating resource risks. A transect-based approach is commonly used to quantify shoreline change on linear (i.e., ocean) shorelines; however, due to the complex morphology of the study area, a point-based approach was developed and applied in this study. Shoreline-change rates and additional parameters (i.e., wave energy and shoreline composition) were determined using 1958 and 1998 aerial photography and available datasets. From this data, the average shoreline change in the study area is -0.24 m yr(-1), with 88\% of the shoreline eroding. Of the parameters analyzed, shoreline composition appears to have an important control on shoreline erosion, whereas wave energy is not significantly correlated with shoreline-change rates.},
	issue        = {September}
}
@inproceedings{Rivest2010,
	title        = {Length increasing active contour for the segmentation of small blood vessels},
	author       = {D. Rivest-H\'{e}nault and M. Cheriet and S. Desch\^{e}nes and C. Lapierre},
	year         = 2010,
	booktitle    = {Proceedings - International Conference on Pattern Recognition},
	pages        = {2796--2799},
	doi          = {10.1109/ICPR.2010.685},
	isbn         = 9780769541099,
	issn         = 10514651,
	abstract     = {A new level-set based active contour method for the segmentation of small blood vessels and other elongated structures is presented. Its main particularity is the presence of a length increasing force in the contour driving equation. The effect of this force is to push the active contour in the direction of thin elongated shapes. Although the proposed force is not stable in general, our experiments show that with few precautions it can successfully be integrated in a practical segmentation scheme and that it helps to segment a longer part of the structures of interest. For the segmentation of blood vessels, this may reduce the amount of user interactivity needed: only a small region inside the structure of interest need to be specified. \textcopyright{} 2010 IEEE.}
}
@inproceedings{Laine2010,
	title        = {Efficient sparse voxel octrees},
	author       = {Samuli Laine and Tero Karras},
	year         = 2010,
	month        = 2,
	booktitle    = {Proceedings of the 2010 ACM SIGGRAPH symposium on Interactive 3D Graphics and Games},
	publisher    = {ACM},
	pages        = {55--63},
	doi          = {10.1145/1730804.1730814},
	isbn         = 9781605589398,
	url          = {https://dl.acm.org/doi/10.1145/1730804.1730814},
	abstract     = {This technical report extends our previous paper on sparse voxel octrees. We first discuss the benefits and drawbacks of voxel representations and how the storage space requirements behave for different kinds of content. Then, we explain in detail our compact data structure for storing voxels and an efficient ray cast algorithm that utilizes this structure, including the contributions of the original paper: additional voxel contour information, normal compression format for storing high-precision object-space normals, post-process filtering technique for smoothing out blockiness of shading, and beam optimization for accelerating ray casts. Management of voxel data in memory and on disk is covered in more detail, as well as the construction of voxel hierarchy. We extend the results section considerably, providing detailed statistics of our test cases. Finally, we discuss the technological barriers and problems that would need to be overcome before voxels could be widely adopted as a generic content format. Our voxel codebase is open sourced and available at},
	city         = {New York, NY, USA}
}
@phdthesis{PeytavieThesis,
	title        = {G\'{e}n\'{e}ration proc\'{e}durale de monde},
	author       = {Adrien Peytavie},
	year         = 2010,
	month        = 7,
	url          = {https://theses.hal.science/tel-00841373},
	city         = {Lyon},
	institution  = {Universit\'{e} Claude Bernard Lyon 1},
	keywords     = {()}
}
@inproceedings{Reinhard2010,
	title        = {State of the Art in Procedural Noise Functions},
	author       = {E Reinhard and A Lagae and S Lefebvre and R Cook and T DeRose and G Drettakis and DS Ebert and JP Lewis and K Perlin and M Zwicker},
	year         = 2010,
	booktitle    = {Eurographics 2010 - State of the Art Reports},
	publisher    = {The Eurographics Association},
	doi          = {https://doi.org/10.2312/egst.20101059},
	abstract     = {Procedural noise functions are widely used in Computer Graphics, from off-line rendering in movie production to interactive video games. The ability to add complex and intricate details at low memory and authoring cost is one of its main attractions. This state-of-the-art report is motivated by the inherent importance of noise in graphics, the widespread use of noise in industry, and the fact that many recent research developments justify the need for an up-to-date survey. Our goal is to provide both a valuable entry point into the field of procedural noise functions, as well as a comprehensive view of the field to the informed reader. In this report, we cover procedural noise functions in all their aspects. We outline recent advances in research on this topic, discussing and comparing recent and well established methods. We first formally define procedural noise functions based on stochastic processes and then classify and review existing procedural noise functions. We discuss how procedural noise functions are used for modeling and how they are applied on surfaces. We then introduce analysis tools and apply them to evaluate and compare the major approaches to noise generation. We finally identify several directions for future work.},
	editor       = {Helwig Hauser and Erik Reinhard},
	keywords     = {Gabor noise,Perlin noise,and texture,anisotropic noise,anti-aliasing,filtering,noise,power spectrum estimation Categories and Subject Descriptors (according to ACM CCS): I33 [Computer Graphics]: Picture/Image Generation-I37 [Computer Graphics]: Three-Dimensional Graphics and Realism-Color,procedural,procedural modeling,procedural noise function,procedural texture,shading,shadowing,solid noise,solid texture,sparse convolution noise,spectral analysis,spot noise,stochastic modeling,stochastic process,surface noise,texture synthesis,wavelet noise}
}
@article{Smelik2010a,
	title        = {Interactive Creation of Virtual Worlds Using Procedural Sketching},
	author       = {Ruben M Smelik and Tim Tutenel and Klass Jan De Kraker and Rafael Bidarra},
	year         = 2010,
	journal      = {Eurographics},
	abstract     = {Procedural modelling is an attractive alternative to cut down the costs of manual content creation for virtual worlds. We discuss our declarative modelling approach to the creation of 3D virtual worlds, which integrates a variety of procedural techniques in order to enable a non-specialist user to interactively create a complete 3D virtual world in minutes. In particular, we introduce procedural sketching, a novel paradigm which allows designers to quickly specify and see the effects of their procedural modelling operations, and describe its main features as implemented in our prototype system SketchaWorld. Two main interaction modes are described, for specifying the landscape and terrain features, respectively. Our approach automatically fits all generated terrain features with their surroundings, for example by smoothing out rough terrain for roads, or creating a bridge to cross a river. It is concluded that this approach provides designers with the productivity gain of procedural methods, while still allowing for fine user control and actively supporting iterative modelling.},
	keywords     = {Computer Graphics Forum,EUROGRAPHICS}
}
@article{Bronsvoort2010,
	title        = {The increasing role of semantics in object modeling},
	author       = {Willem F. Bronsvoort and Rafael Bidarra and Hilderick A. van der Meiden and Tim Tutenel},
	year         = 2010,
	journal      = {Computer-Aided Design and Applications},
	volume       = 7,
	pages        = {431--440},
	doi          = {10.3722/cadaps.2010.431-440},
	issn         = 16864360,
	abstract     = {Object modeling for applications like CAD/CAM, simulation and computer games, has traditionally been limited to the shape of objects. Currently, a trend can be observed to add several types of semantics to object models. This observation is discussed in some detail for three modeling approaches worked on in our research group: feature modeling, including recent advances for freeform features, modeling families of objects, and modeling virtual worlds. The use of semantics in some other modeling approaches is briefly discussed. Adding semantics can ease specification and modification of an object model, help to guarantee its validity, and be useful for applications which use the model, such as process planning for manufacturing or gameplay. Much work remains to be done to determine the types of semantics most useful in practice. \textcopyright{} 2010 CAD Solutions, LLC.},
	issue        = 3,
	keywords     = {Constraints,Families of objects,Feature modeling,Object modeling}
}
@inproceedings{Bidarra2010,
	title        = {Integrating semantics and procedural generation: key enabling factors for declarative modeling of virtual worlds},
	author       = {R Bidarra and Klass Jan de Kraker and Ruben M. Smelik and Tim Tutenel},
	year         = 2010,
	booktitle    = {FOCUS K3D Conference on Semantic 3D Media and Content}
}
@article{Marechal2010,
	title        = {Heat transfer simulation for modeling realistic winter sceneries},
	author       = {N. Mar\'{e}chal and E. Gu\'{e}rin and E. Galin and S. M\'{e}rillou and N. M\'{e}rillou},
	year         = 2010,
	journal      = {Computer Graphics Forum},
	publisher    = {Blackwell Publishing Ltd},
	volume       = 29,
	pages        = {449--458},
	doi          = {10.1111/j.1467-8659.2009.01614.x},
	issn         = 14678659,
	abstract     = {This paper presents a physically based method for simulating the heat transfers between the different environmental elements to synthesize realistic winter sceneries. We simulate the snow fall over the ground, as well as the conductive, convective and radiative thermal transfers using a finite volume method according to the variations of air and dew point temperatures, the amount of snow, cloud cover and day-night cycles. Our approach takes into account phase changes such as snow melting into water or water freezing into ice. \textcopyright{} 2010 The Eurographics Association and Blackwell Publishing Ltd.},
	issue        = 2,
	keywords     = {Ice,Natural phenomena,Snow,Thermal transfers,Winter landscapes}
}
@techreport{Amawy2010,
	title        = {Karst Evolution in the South Mediterranean Area: KARST DEVELOPMENT AND STRUCTURAL RELATIONSHIP IN THE TERTIARY ROCKS OF THE WESTERN PART OF AL JABAL AL AKHDAR, NE LIBYA: A CASE STUDY IN QASR LIBYA AREA},
	author       = {Maher El Amawy and Ahmed Muftah},
	year         = 2010,
	volume       = 14,
	pages        = {173--189},
	abstract     = {The Structural pattern, in the western part of Al Jabal Al Akhdar, reflects inversion during late-Cretaceous-Miocene times, in response to the influence by dextral shear of the Alpine orogeny. It is themed by the formation of NE-SW to ENE-WSW principle displacement(or deformational) zones (PDZs) that confine inside a system of ENE-WSW trending folds and array of secondary faults conformable with the geometry and progressive evolution in wrench tectonic model. These structures are dominated with folds in the Upper Cretaceous and revealed a main factor of brittle structural elements (faults and joints) upwards in the Tertiary sediments. Qasr Libya area exposes wide exposures of Tertiary carbonate sediments and distinctively clarified the main effect of structures on the morphology, distribution and development of karst features. The structural configuration represents a development of concurrent assemblage of WNW-ESE dextral strike slip faults, N-S sinistral strike slip faults and unmappable flower structures and NNW-SSE normal fault within ENE-WSW principle dextral shear zone. The movement within the whole structure induced zones of broken and crushed rock fragments of varying sizes by which the dissolution becomes easier by the surface and underground water. Among the Tertiary sediments are Darnah Formation (Middle-Late Eocene) and Al Bayda Algal Limestone Member (the upper part of Early Oligocene) that display prominent and spectacular different shapes and sizes of karst (lapies, caves and dolines). In Apollonia Formation (Early-Middle Eocene), Al Shahhat Marl Member (the lower part of Early Oligocene) and Al Abraq Formation (Late Oligocene), these features are lacking and essentially represented by bogaz features .Commonly, karst (caves and dolines, in particular)are structurally controlled and formed in the phreatic zone, while the accompanied collapse in the dolines has been taken place in advance stage of the karst cycle (or in vadose zone).}
}
@article{Smelik2010,
	title        = {A Declarative Approach to Procedural Modeling of Virtual Worlds},
	author       = {R M Smelik and T Tutenel and K J De Kraker and R Bidarra},
	year         = 2010,
	journal      = {Computers and Graphics},
	abstract     = {With the ever increasing costs of manual content creation for virtual worlds, the potential of creating it automatically becomes too attractive to ignore. However, for most designers, traditional procedural content generation methods are complex and unintuitive to use, hard to control, and generated results are not easily integrated into a complete and consistent virtual world. We introduce a novel declarative modeling approach that enables designers to concentrate on stating what they want to create instead of on describing how they should model it. It aims at reducing the complexity of virtual world modeling by combining the strengths of semantics-based modeling with manual and procedural approaches. This article describes two of its main contributions to procedural modeling of virtual worlds: interactive procedural sketching and virtual world consistency maintenance. We discuss how these techniques, integrated in our modeling framework SketchaWorld, build up to enable designers to create a complete 3D virtual world in minutes. Procedural sketching provides a fast and more intuitive way to model virtual worlds, by letting designers interactively sketch their virtual world using high-level terrain features, which are then procedurally expanded using a variety of integrated procedural methods. Consistency maintenance guarantees that the semantics of all terrain features is preserved throughout the modeling process. In particular, it automatically solves conflicts possibly emerging from interactions between terrain features. We believe that these contributions together represent a significant step towards providing more user control and flexibility in procedural modeling of virtual worlds. It can therefore be expected that by further reducing its complexity, virtual world modeling will become accessible to an increasingly broad group of users.},
	keywords     = {consistency maintenance,declarative modeling,procedural methods,procedural sketching,semantic modeling,virtual worlds}
}
@inbook{Geertsema2010,
	title        = {Hillslope processes},
	author       = {Marteen Geertsema and James W. Schwab and Peter, Jordan and Thomas H. Millard and Terrence P. Rollerson},
	year         = 2010,
	month        = 1,
	booktitle    = {Compendium of forest hydrology and geomorphology in British Columbia}
}
@inproceedings{Bossavit2011,
	title        = {An immersive multitouch workspace},
	author       = {Benoit Bossavit and Jean-Baptiste de la Rivi\`{e}re and Toni Da Luz and Mathieu Courtois and C\'{e}dric Kervegant and Martin Hachet},
	year         = 2011,
	booktitle    = {ACM SIGGRAPH 2011 Emerging Technologies on - SIGGRAPH '11},
	publisher    = {ACM Press},
	pages        = {1--1},
	doi          = {10.1145/2048259.2048266},
	isbn         = 9781450309691,
	url          = {http://dl.acm.org/citation.cfm?doid=2048259.2048266},
	abstract     = {Multitouch interaction has some unique strengths, one of them being that direct touch on 2D screens makes it fast and easy. Unfortunately, because of stereo disparity and content occlusion, direct touch interaction becomes an issue as soon as 3D stereoscopic content is visualized. We propose a new system that combines efficient direct multitouch interaction with co-located 3D stereoscopic visualization. In our approach, users benefit from well-known 2D metaphors and widgets displayed on a monoscopic touchscreen while visualizing 3D objects floating above the surface at an optically correct distance (see Figure 1(a)).},
	city         = {New York, New York, USA}
}
@phdthesis{ArasDarganzany2011,
	title        = {Human Body Parts Tracking: Applications to Activity Recognition},
	author       = {Aras Darganzany},
	year         = 2011,
	institution  = {University of Nevada, Reno}
}
@inproceedings{SeanSchumer,
	title        = {Analysis of human footsteps utilizing multi-axial seismic fusion},
	author       = {Sean Schumer},
	year         = 2011,
	month        = 5,
	booktitle    = {2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	publisher    = {IEEE},
	pages        = {697--700},
	doi          = {10.1109/ICASSP.2011.5946499},
	isbn         = {978-1-4577-0538-0},
	url          = {http://ieeexplore.ieee.org/document/5946499/}
}
@inproceedings{Varpa2011,
	title        = {Applying one-vs-one and one-vs-all classifiers in k-nearest neighbour method and support vector machines to an otoneurological multi-class problem},
	author       = {Kirsi Varpa and Henry Joutsijoki and Kati Iltanen and Martti Juhola},
	year         = 2011,
	booktitle    = {Studies in Health Technology and Informatics},
	publisher    = {IOS Press},
	volume       = 169,
	pages        = {579--583},
	doi          = {10.3233/978-1-60750-806-9-579},
	isbn         = 9781607508052,
	issn         = 18798365,
	url          = {https://ebooks.iospress.nl/doi/10.3233/978-1-60750-806-9-579},
	abstract     = {We studied how the splitting of a multi-class classification problem into multiple binary classification tasks, like One-vs-One (OVO) and One-vs-All (OVA), affects the predictive accuracy of disease classes. Classifiers were tested with an otoneurological data using 10-fold cross-validation 10 times with k-Nearest Neighbour (k-NN) method and Support Vector Machines (SVM). The results showed that the use of multiple binary classifiers improves the classification accuracies of disease classes compared to one multi-class classifier. In general, OVO classifiers worked out better with this data than OVA classifiers. Especially, the OVO with k-NN yielded the highest total classification accuracies. \textcopyright{} 2011 European Federation for Medical Informatics. All rights reserved.},
	keywords     = {Binary classifiers,K-nearest neighbour method,Multi-class classification,Otoneurology,Support vector machines}
}
@article{Dormans2011b,
	title        = {Level design as model transformation: A strategy for automated content generation},
	author       = {Joris Dormans},
	year         = 2011,
	journal      = {ACM International Conference Proceeding Series},
	doi          = {10.1145/2000919.2000921},
	isbn         = 9781450308724,
	abstract     = {This paper frames the process of designing a level in a game as a series of model transformations. The transformations correspond to the application of particular design principles, such as the use of locks and keys to transform a linear mission into a branching space. It shows that by using rewrite systems, these transformations can be formalized and automated. The resulting automated process is highly controllable: it is a perfect match for a mixed-initiative approach to level generation where human and computer collaborate in designing levels. An experimental prototype that implements these ideas is presented. \textcopyright{} ACM.}
}
@article{Buhler2011,
	title        = {Decay of an internal tide due to random topography in the ocean},
	author       = {Oliver B\"{u}hler and Miranda Holmes-Cerfon},
	year         = 2011,
	journal      = {Journal of Fluid Mechanics},
	volume       = 678,
	pages        = {271--293},
	doi          = {10.1017/jfm.2011.115},
	issn         = {00221120},
	abstract     = {We present a theoretical and numerical study of the decay of an internal wave caused by scattering at undulating sea-floor topography, with an eye towards building a simple model in which the decay of internal tides in the ocean can be estimated. As is well known, the interactions of internal waves with irregular boundary shapes lead to a mathematically ill-posed problem, so care needs to be taken to extract meaningful information from this problem. Here, we restrict the problem to two spatial dimensions and build a numerical tool that combines a real-space computation based on the characteristics of the underlying partial differential equation with a spectral computation that satisfies the relevant radiation conditions. Our tool works for finite-amplitude topography but is restricted to subcritical topography slopes. Detailed results are presented for the decay of the gravest vertical internal wave mode as it encounters finite stretches of either sinusoidal topography or random topography defined as a Gaussian random process with a simple power spectrum. A number of scaling laws are identified and a simple expression for the decay rate in terms of the power spectrum is given. Finally, the resulting formulae are applied to an idealized model of sea-floor topography in the ocean, which seems to indicate that this scattering process can provide a rapid decay mechanism for internal tides. However, the present results are restricted to linear fluid dynamics in two spatial dimensions and to uniform stratification, which restricts their direct application to the real ocean. \textcopyright{} 2011 Cambridge University Press.},
	keywords     = {Internal waves,topographic effects,wave scattering}
}
@article{Yannakakis2011a,
	title        = {Experience-driven procedural content generation},
	author       = {Georgios N. Yannakakis and Julian Togelius},
	year         = 2011,
	journal      = {IEEE Transactions on Affective Computing},
	publisher    = {IEEE},
	volume       = 2,
	pages        = {147--161},
	doi          = {10.1109/T-AFFC.2011.6},
	issn         = 19493045,
	abstract     = {Procedural content generation (PCG) is an increasingly important area of technology within modern human-computer interaction (HCI) design. Personalization of user experience via affective and cognitive modeling, coupled with real-time adjustment of the content according to user needs and preferences are important steps toward effective and meaningful PCG. Games, Web 2.0, interface, and software design are among the most popular applications of automated content generation. The paper provides a taxonomy of PCG algorithms and introduces a framework for PCG driven by computational models of user experience. This approach, which we call Experience-Driven Procedural Content Generation (EDPCG), is generic and applicable to various subareas of HCI. We employ games as an example indicative of rich HCI and complex affect elicitation, and demonstrate the approach's effectiveness via dissimilar successful studies. \textcopyright{} 2011 IEEE.},
	issue        = 3,
	keywords     = {Procedural content generation,adaptation,computer games.,personalization,user affect,user experience}
}
@article{Dormans2011f,
	title        = {Generating missions and spaces for adaptable play experiences},
	author       = {Joris Dormans and Sander Bakkes},
	year         = 2011,
	journal      = {IEEE Transactions on Computational Intelligence and AI in Games},
	publisher    = {IEEE},
	volume       = 3,
	pages        = {216--228},
	doi          = {10.1109/TCIAIG.2011.2149523},
	issn         = {1943068X},
	note         = {This paper is really focused on action games, considering keeping the player in the action. Most of the parts are not interesting in our case. Need to focus on small parts:},
	abstract     = {This paper investigates strategies to generate levels for action-adventure games. For this genre, level design is more critical than for rule-driven genres such as simulation or rogue-like role-playing games, for which procedural level generation has been successful in the past. The approach outlined by this article distinguishes between missions and spaces as two separate structures that need to be generated in two individual steps. It discusses the merits of different types of generative grammars for each individual step in the process. Notably, the approach acknowledges that the online generation of levels needs to be tailored strictly to the actual experience of a player. Therefore, the approach incorporates techniques to establish and exploit player models in actual play. \textcopyright{} 2011 IEEE.},
	issue        = 3,
	keywords     = {Game AI,game design,generative grammars,real-time generated game environments}
}
@article{Bohannon2011,
	title        = {Systematic review Normal walking speed: a descriptive meta-analysis},
	author       = {Richard W Bohannon and A Williams Andrews},
	year         = 2011,
	journal      = {Physiotherapy},
	volume       = 97,
	pages        = {182--189},
	doi          = {10.1016/j.physio.2010.12.004},
	abstract     = {Background Walking speed has implications for community functioning and is predictive of important outcomes. Determining whether an individual's walking speed is limited requires normal values for comparison. Objectives To use meta-analysis to describe normal gait speed for healthy individuals within age and gender strata. Data sources PubMed, the Cumulative Index of Nursing and Allied Health (CINAHL), Scopus, Science Citation Index and articles identified by hand searches. Study selection criteria Inclusion required that the gait speed of apparently healthy adults was documented as they walked at a normal pace over a course of 3 to 30 m. Summary data were excluded unless obtained from at least 10 participants within a gender and decade stratum. Study appraisal and synthesis methods The two authors independently reviewed articles and extracted data. Accuracy was confirmed by the other author. Data were grouped within gender and decade strata. A meta-analysis macro was used to consolidate data by strata and to determine homogeneity. Results Forty-one articles contributed data to the analysis. Combined, they provided data from 23 111 subjects. The gait speed was homogeneous within strata and ranged from a mean of 143.4 cm/second for men aged 40 to 49 years to a mean of 94.3 cm/second for women aged 80 to 99 years. Limitations The data presented herein may not be useful as a standard of normal if gait is measured over short distances from the command 'go' or if a turn is involved. Conclusions and implications The consolidation of data from multiple studies reported in this meta-analysis provides normative data that can serve as a standard against which individuals can be compared. Doing so will aid the interpretation of their performance.}
}
@article{Winberg2011,
	title        = {Examining Automatic Texture Mapping of Arbitrary Terrains},
	author       = {Olov Winberg},
	year         = 2011,
	journal      = {Masterthesis},
	url          = {https://www.diva-portal.org/smash/get/diva2:422722/FULLTEXT01.pdf#page=51&zoom=100,166,605},
	issue        = {April},
	keywords     = {()}
}
@article{DeWitt2011,
	title        = {Fluid Simulation using Laplacian Eigenfunctions},
	author       = {Tyler De Witt and Christian Lessig and Eugene Fiume},
	year         = 2011,
	journal      = {ACM Trans. Graph},
	volume       = {VV},
	doi          = {10.1145/XXXXXXX.YYYYYYY}
}
@article{Chentanez2011,
	title        = {Real-Time Eulerian Water Simulation Using a Restricted Tall Cell Grid},
	author       = {Nuttapong Chentanez and Matthias M\"{u}ller},
	year         = 2011,
	journal      = {ACM Transactions on Graphics},
	volume       = 30,
	pages        = {1--10},
	doi          = {10.1145/2010324.1964977},
	issn         = 15577368,
	abstract     = {We present a new Eulerian fluid simulation method, which allows real-time simulations of large scale three dimensional liquids. Such scenarios have hitherto been restricted to the domain of off-line computation. To reduce computation time we use a hybrid grid representation composed of regular cubic cells on top of a layer of tall cells. With this layout water above an arbitrary terrain can be represented without consuming an excessive amount of memory and compute power, while focusing effort on the area near the surface where it most matters. Additionally, we optimized the grid representation for a GPU implementation of the fluid solver. To further accelerate the simulation, we introduce a specialized multigrid algorithm for solving the Poisson equation and propose solver modifications to keep the simulation stable for large time steps. We demonstrate the efficiency of our approach in several real-world scenarios, all running above 30 frames per second on a modern GPU. Some scenes include additional features such as two-way rigid body coupling as well as particle representations of sub-grid detail. \textcopyright{} 2011, ACM. All rights reserved.},
	issue        = 4,
	keywords     = {fluid simulation,multigrid,real time,tall cell grid}
}
@article{Vasa2011,
	title        = {A Perception Correlated Comparison Method for Dynamic Meshes},
	author       = {Libor V\'{a}\v{s}a and V\'{a}clav Skala},
	year         = 2011,
	journal      = {IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS},
	volume       = 17,
	doi          = {10.1109/TVCG.2010.38},
	abstract     = {There are multiple areas of computer graphics where triangular meshes are being altered in order to reduce their size or complexity, while attempting to preserve the original shape of the mesh as closely as possible. Recently, this area of research has been extended to cover even a dynamic case, i.e., surface animations which are compressed and simplified. However, to date very little effort has been made to develop methods for evaluating the results, namely the amount of distortion introduced by the processing. Even the most sophisticated compression methods use distortion evaluation by some kind of mean squared error while the actual relevance of such measure has not been verified so far. In this paper, we point out some serious drawbacks of the existing error measures. We present results of the subjective testing that we have performed, and we derive a new measure called Spatiotemporal edge difference (STED) which is shown to provide much better correlation with subjective opinions on mesh distortion.},
	issue        = 2,
	keywords     = {Animation,discrepancy,distortion,dynamic mesh.,error,evaluation,measure}
}
@phdthesis{Jako2011,
	title        = {Fast Hydraulic and Thermal Erosion on GPU},
	author       = {Bal\'{a}zs J\'{a}k\'{o} and Bal\'{a}zs T\'{o}th},
	year         = 2011,
	pages        = 4,
	abstract     = {Computer games, TV series, movies, simulators and many other computer graphics applications are using external scenes where a realistic looking terrain is a vital part of the view. Creating such terrains are not a simple task neither manually nor automatically. In this paper we propose a method that generates realistic virtual terrainsby simulation of hydraulic and thermal erosion on a predefined height field terrain. The model is designed to beexecuted interactively on parallel architectures like graphics processors.},
	issue        = {July},
	keywords     = {GLSL,GPU,erosion,hydraulic erosion,navier-stokes,terrain,thermal erosion}
}
@article{Goffe2011,
	title        = {Tiled top-down combinatorial pyramids for large images representation},
	author       = {Romain Goffe and Luc Brun and Guillaume Damiand},
	year         = 2011,
	journal      = {International Journal of Imaging Systems and Technology},
	volume       = 21,
	pages        = {28--36},
	doi          = {10.1002/ima.20270},
	issn         = 10981098,
	url          = {https://hal.archives-ouvertes.fr/hal-00567701v2/document},
	abstract     = {The uprising number of applications that involve very large images with resolutions greater than 30,000 \texttimes{} 30,000 raises major memory management issues. Firstly, the amount of data usually prevents such images from being processed globally and therefore, designing a global image partition raises several issues. Secondly, a multiresolution approach is necessary since an analysis only based on the highest resolution may miss global features revealed at lower resolutions. This article introduces the tiled top-down pyramidal framework which addresses these two main constraints. Our model provides a full representation of multiresolution images with both geometrical and topological relationships. The advantage of a top-down construction scheme is twofold: the focus of attention only refines regions of interest which results in a reduction of the amount of required memory and in a refinement process that may take into account hierarchical features from previous segmentations. Moreover, the top-down model is combined with decomposition in tiles to provide an accurate memory bounding while allowing global analysis of large images. \textcopyright{} 2011 Wiley Periodicals, Inc.},
	issue        = 1,
	keywords     = {combinatorial map,irregular pyramid,tiled data structure,topological model}
}
@phdthesis{Faraj2011,
	title        = {Expressive rendering of animated hair},
	author       = {Noura Faraj},
	year         = 2011
}
@article{Given2011,
	title        = {Introduction},
	author       = {Barbara A. Given and Marcia Grant},
	year         = 2011,
	journal      = {Seminars in Oncology Nursing},
	volume       = 27,
	pages        = {91--92},
	doi          = {10.1016/j.soncn.2011.02.001},
	issn         = {07492081},
	url          = {https://cs.brown.edu/people/rtamassi/gdhandbook/chapters/force-directed.pdf},
	issue        = 2,
	pmid         = 21514478
}
@article{Wang2011,
	title        = {Multiscale vector volumes},
	author       = {L Wang and Y Yu and K Zhou and B Guo},
	year         = 2011,
	journal      = {ACM SIGGRAPH Asia},
	volume       = 30,
	pages        = {12--15},
	doi          = {doi.acm.org/10.1145/2024156.2024201},
	url          = {https://core.ac.uk/download/pdf/37973373.pdf},
	abstract     = {We introduce multiscale vector volumes, a compact vector repre- sentation for volumetric objects with complex internal structures spanning a wide range of scales. With our representation, an object is decomposed into components and each component is modeled as an SDF tree, a novel data structure that uses multiple signed dis- tance functions (SDFs) to further decompose the volumetric com- ponent into regions. Multiple signed distance functions collectively can represent non-manifold surfaces and deliver a powerful vector representation for complex volumetric features. We use multiscale embedding to combine object components at different scales into one complex volumetric object. As a result, regions with dramat- ically different scales and complexities can co-exist in an object. To facilitate volumetric object authoring and editing, we have also developed a scripting language and a GUI prototype. With the help of a recursively defined spatial indexing structure, our vector repre- sentation supports fast random access, and arbitrary cross sections of complex volumetric objects can be visualized in real time.},
	issue        = 6,
	keywords     = {multiscale representations,volumetric modeling}
}
@article{Berry2011,
	title        = {A simple algorithm to generate the minimal separators and the maximal cliques of a chordal graph},
	author       = {Anne Berry and Romain Pogorelcnik},
	year         = 2011,
	journal      = {Information Processing Letters},
	volume       = 111,
	pages        = {508--511},
	doi          = {10.1016/j.ipl.2011.02.013},
	issn         = {00200190},
	abstract     = {We present a simple unified algorithmic process which uses either LexBFS or MCS on a chordal graph to generate the minimal separators and the maximal cliques in linear time in a single pass. \textcopyright{} 2011 Elsevier B.V. All rights reserved.},
	issue        = 11,
	keywords     = {Graph algorithms,LexBFS,MCS,Maximal clique,Minimal separator,Moplex ordering}
}
@article{Hollander2011,
	title        = {ManyLoDs: Parallel many-view level-of-detail selection for real-time global illumination},
	author       = {Matthias Holl\"{a}nder and Tobias Ritschel and Elmar Eisemann and Tamy Boubekeur},
	year         = 2011,
	journal      = {Computer Graphics Forum},
	volume       = 30,
	pages        = {1233--1240},
	doi          = {10.1111/j.1467-8659.2011.01982.x},
	issn         = 14678659,
	url          = {https://perso.telecom-paristech.fr/boubek/papers/ManyLoDs/ManyLoDs.pdf},
	abstract     = {Level-of-Detail structures are a key component for scalable rendering. Built from raw 3D data, these structures are often defined as Bounding Volume Hierarchies, providing coarse-to-fine adaptive approximations that are well-adapted for many-view rasterization. Here, the total number of pixels in each view is usually low, while the cost of choosing the appropriate LoD for each view is high. This task represents a challenge for existing GPU algorithms. We propose ManyLoDs, a new GPU algorithm to efficiently compute many LoDs from a Bounding Volume Hierarchy in parallel by balancing the workload within and among LoDs. Our approach is not specific to a particular rendering technique, can be used on lazy representations such as polygon soups, and can handle dynamic scenes. We apply our method to various many-view rasterization applications, including Instant Radiosity, Point-Based Global Illumination, and reflection / refraction mapping. For each of these, we achieve real-time performance in complex scenes at high resolutions.},
	issue        = 4,
	keywords     = {GPU,Level-of-detail,Many-view,Multi-view,Real-time}
}
@article{LeBorgne2011,
	title        = {Vulnerability of open ocean food webs in the tropical Pacific to climate change Val\'{e}rie Allain Pacific Community},
	author       = {Robert Le Borgne and Richard Matear},
	year         = 2011,
	journal      = {Vulnerability of tropical Pacific fisheries and aquaculture to climate change},
	pages        = {189--250},
	url          = {https://www.researchgate.net/publication/236597538},
	issue        = {January 2014}
}
@article{Toyokawa2011,
	title        = {Distribution of ephyrae and polyps of jellyfish Aurelia aurita (Linnaeus 1758) sensu lato in Mikawa Bay, Japan},
	author       = {Masaya Toyokawa and Kaoru Aoki and Satoshi Yamada and Akira Yasuda and Yusuke Murata and Tomohiko Kikuchi},
	year         = 2011,
	journal      = {Journal of Oceanography},
	volume       = 67,
	pages        = {209--218},
	doi          = {10.1007/s10872-011-0021-8},
	issn         = {09168370},
	abstract     = {We surveyed the distribution of colonies of polyps of Aureliaaurita sensu lato (s.l.) in Mikawa Bay, Japan. First, we surveyed the distribution of ephyrae of A. aurita s.l. at 75 stations encompassing the whole of Mikawa Bay in early 2008. A total of 37 ephyrae were sampled mostly from fishing ports. Ephyrae were most abundant around the islands located near the mouth of the bay, and decreased from the western part to the eastern part of Mikawa Bay. Next, we selected five fishing ports in Mikawa Bay where ephyrae occurred and surveyed the underside of floating piers and underwater overhangs of wharfs. We found dense colonies of polyps of A. aurita s. l. under nearly all of the floating piers at the two islands located near the mouth of the bay. Fitting a logistic regression model to the dataset showed that the percentage coverage of Aurelia polyps was significantly greater at the two islands compared with the other locations. In addition, the coverage of Aurelia polyps was greater when the coverage of other fouling organisms was in the range of 65-90\%, and the coverage of Aurelia polyps was lower on floating piers with a vinyl surface and on concrete wharfs. The combined distribution of polyp colonies of A. aurita s.l. in Ise Bay and Mikawa Bay suggested that A. aurita s.l. in the two bays probably forms a single population and shoals of medusae mainly originate from protected harbors along the mouth-part of the bays. \textcopyright{} 2011 The Oceanographic Society of Japan and Springer.},
	issue        = 2,
	keywords     = {Benthos,Cnidaria,Coastal,Fishing port,Fouling,Model selection,Plankton,Polyp,Population,Semaeostomeae}
}
@article{Teske2011,
	title        = {A review of marine phylogeography in southern Africa},
	author       = {Peter R. Teske and Sophie Von Der Heyden and Christopher D. McQuaid and Nigel P. Barker},
	year         = 2011,
	journal      = {South African Journal of Science},
	volume       = 107,
	pages        = {43--53},
	doi          = {10.4102/sajs.v107i5/6.514},
	issn         = 19967489,
	abstract     = {The southern African marine realm is located at the transition zone between the Atlantic and Indo-Pacific biomes. Its biodiversity is particularly rich and comprises faunal and floral elements from the two major oceanic regions, as well as a large number of endemics. Within this realm, strikingly different biota occur in close geographic proximity to each other, and many of the species with distributions spanning two or more of the region's marine biogeographic provinces are divided into evolutionary units that can often only be distinguished on the basis of genetic data. In this review, we describe the state of marine phylogeography in southern Africa, that is, the study of evolutionary relationships at the species level, or amongst closely related species, in relation to the region's marine environment. We focus particularly on coastal phylogeography, where much progress has recently been made in identifying phylogeographic breaks and explaining how they originated and are maintained. We also highlight numerous shortcomings that should be addressed in the near future. These include: the limited data available for commercially important organisms, particularly offshore species; the paucity of oceanographic data for nearshore areas; a dearth of studies based on multilocus data; and the fact that studying the role of diversifying selection in speciation has been limited to physiological approaches to the exclusion of genetics. It is becoming apparent that the southern African marine realm is one of the world's most interesting environments in which to study the evolutionary processes that shape not only regional, but also global patterns of marine biodiversity.},
	issue        = {5-6}
}
@article{Lehman2011,
	title        = {Evolving a diversity of creatures through novelty search and local competition},
	author       = {Joel Lehman and Kenneth O. Stanley},
	year         = 2011,
	journal      = {Genetic and Evolutionary Computation Conference, GECCO'11},
	pages        = {211--218},
	doi          = {10.1145/2001576.2001606},
	isbn         = 9781450305570,
	abstract     = {An ambitious challenge in artificial life is to craft an evolutionary process that discovers a wide diversity of well-adapted virtual creatures within a single run. Unlike in nature, evolving creatures in virtual worlds tend to converge to a single morphology because selection therein greedily rewards the morphology that is easiest to exploit. However, novelty search, a technique that explicitly rewards diverging, can potentially mitigate such convergence. Thus in this paper an existing creature evolution platform is extended with multi-objective search that balances drives for both novelty and performance. However, there are different ways to combine performance-driven search and novelty search. The suggested approach is to provide evolution with both a novelty objective that encourages diverse morphologies and a local competition objective that rewards individuals outperforming those most similar in morphology. The results in an experiment evolving locomoting virtual creatures show that novelty search with local competition discovers more functional morphological diversity within a single run than models with global competition, which are more predisposed to converge. The conclusions are that novelty search with local competition may complement recent advances in evolving virtual creatures and may in general be a principled approach to combining novelty search with pressure to achieve. Copyright 2011 ACM.},
	keywords     = {Artificial life,Natural evolution,Novelty search,Virtual creatures}
}
@article{BMPG11,
	title        = {Layered surface fluid simulation for surgical training},
	author       = {Louis Borgeat and Philippe Massicotte and Guillaume Poirier and Guy Godin},
	year         = 2011,
	journal      = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume       = {6891 LNCS},
	pages        = {323--330},
	doi          = {10.1007/978-3-642-23623-5_41},
	isbn         = 9783642236228,
	issn         = {03029743},
	url          = {https://publications-cnrc.canada.ca/fra/voir/accepté/?id=ed339668-26bb-4efc-8301-69f0f5e3fc54},
	abstract     = {We present a novel approach to fluid simulation over complex dynamic geometry designed for the specific context of virtual surgery simulation. The method combines a surface-based fluid simulation model with a multi-layer depth peeling representation to allow realistic yet efficient simulation of bleeding on complex surfaces undergoing geometry and topology modifications. Our implementation allows for fast fluid propagation and accumulation over the entire scene, and runs on the GPU at a constant low cost that is independent of the amount of blood in the scene. The proposed bleeding simulation is integrated in a complete simulator for brain tumor resection, where trainees have to manage blood aspiration and tissue/vessel cauterization while they perform virtual surgery tasks. \textcopyright{} 2011 Springer-Verlag.},
	issue        = {PART 1},
	keywords     = {GPU,aspiration,bleeding,cauterization,depth peeling,fluid simulation,neurosurgery,surgery,visual simulation},
	pmid         = 22003633
}
@article{Benes2011,
	title        = {Guided procedural modeling},
	author       = {B. Bene\v{s} and O. \v{S}t'ava and R. M\v{e}ch and G. Miller},
	year         = 2011,
	journal      = {Computer Graphics Forum},
	volume       = 30,
	pages        = {325--334},
	doi          = {10.1111/j.1467-8659.2011.01886.x},
	issn         = 14678659,
	abstract     = {Procedural methods present one of the most powerful techniques for authoring a vast variety of computer graphics models. However, their massive applicability is hindered by the lack of control and a low predictability of the results. In the classical procedural modeling pipeline, the user usually defines a set of rules, executes the procedural system, and by examining the results attempts to infer what should be changed in the system definition in order to achieve the desired output. We present guided procedural modeling, a new approach that allows a high level of top-down control by breaking the system into smaller building blocks that communicate. In our work we generalize the concept of the environment. The user creates a set of guides. Each guide defines a region in which a specific procedural model operates. These guides are connected by a set of links that serve for message passing between the procedural models attached to each guide. The entire model consists of a set of guides with procedural models, a graph representing their connection, and the method in which the guides interact. The modeling process is performed by modifying each of the described elements. The user can control the high-level description by editing the guides or manipulate the low-level description by changing the procedural rules. Changing the connectivity allows the user to create new complex forms in an easy and intuitive way. We show several examples of procedural structures, including an ornamental pattern, a street layout, a bridge, and a model of trees. We also demonstrate interactive examples for quick and intuitive editing using physics-based mass-spring system. \textcopyright{} 2010 The Author(s).},
	issue        = 2
}
@phdthesis{Narain2011,
	title        = {Visual modeling and visualisation of multiscale phenomena},
	author       = {Rahul Narain},
	year         = 2011,
	abstract     = {Many large-scale systems such as human crowds, fluids, and granular materials exhibit complicated motion at many different scales, from a characteristic global behavior to important small-scale detail. Such multiscale systems are computationally expensive for traditional simulation techniques to capture over the full range of scales. I present novel techniques for scalable simulation of these large, complex phenomena for visual computing applications. These techniques achieve their efficiency by coupling together separate models for the large-scale and fine-scale dynamics of a complex system. In fluid simulation, it remains a challenge to efficiently simulate fine details such as foam, ripples, and turbulence without compromising the accuracy of the large-scale flow. I present two techniques for this problem that combine physically-based numerical simulation for the global flow with efficient local models for detail. For surface features, I propose the use of texture synthesis, guided by the physical characteristics of the macroscopic flow. For turbulence in the fluid motion itself, I present a technique that tracks the transfer of energy from the mean flow to the turbulent fluctuations and synthesizes these fluctuations procedurally, allowing extremely efficient visual simulation of turbulent fluids. Another large class of problems which are not easily handled by traditional approaches is the simulation of very large aggregates of discrete entities, such as dense pedestrian crowds and granular materials. I present a technique for crowd simulation that couples a discrete model of individual navigation with a novel continuum formulation for the collective motion of pedestrians, enabling simulation of extremely large crowds at nearreal-time rates on commodity hardware. I also present a technique for simulating granular materials which generalizes this model and introduces a novel computational scheme for friction, thus efficiently reproducing a wide range of granular behavior. In all these cases, the proposed techniques are typically an order of magnitude faster than comparable existing methods. Through these applications to a diverse set of challenging simulation problems, I demonstrate that the proposed approach is a powerful and versatile technique for the simulation of a broad range of large, complex systems.}
}
@article{Hudak2011,
	title        = {Terrain models for mass movement erosion},
	author       = {M. Hud\'{a}k and R. \v{D}urikovi\v{c}},
	year         = 2011,
	journal      = {Theory and Practice of Computer Graphics 2011, TPCG 2011 - Eurographics UK Chapter Proceedings},
	pages        = {9--16},
	doi          = {10.2312/LocalChapterEvents/TPCG/TPCG11/009-016},
	isbn         = 9783905673838,
	url          = {https://diglib.eg.org/bitstream/handle/10.2312/LocalChapterEvents.TPCG.TPCG11.009-016/009-016.pdf?sequence=1},
	abstract     = {In this paper we present a particle-based method for large scale long time progressive simulation of terrain erosion containing wet granular particles. The wetting process and the propagation through granular material is based on defining the wetness value for each particle representing the amount of water absorbed by granular particles and stored between them, as was originally proposed by Rungjiratananon [RSKN08]. We extend this model by adding a non homogeneous material to simulate differences between different types of soil-like granular material, based on physical constants like stability, plasticity and wetness. With this approach we can create a physical animation of erosion process like mass movement or mass wasting. \textcopyright{} The Eurographics Association 2011.}
}
@inproceedings{Chen2011,
	title        = {Analyses, Simulations, and Physical Modeling Validation of Levee and Embankment Erosion},
	author       = {Zhongxian Chen and Christopher S. Stuetzle and Barbara M. Cutler and Jared A. Gross and W. Randolph Franklin and Thomas F. Zimmie},
	year         = 2011,
	month        = 3,
	booktitle    = {Geo-Frontiers 2011},
	publisher    = {American Society of Civil Engineers},
	pages        = {1503--1513},
	doi          = {10.1061/41165(397)154},
	isbn         = 9780784411650,
	url          = {https://ascelibrary.org/doi/10.1061/41165%28397%29154},
	city         = {Reston, VA}
}
@misc{Nikooyan2011,
	title        = {Mass-spring-damper modelling of the human body to study running and hopping-an overview},
	author       = {A. A. Nikooyan and A. A. Zadpoor},
	year         = 2011,
	month        = 12,
	journal      = {Proceedings of the Institution of Mechanical Engineers, Part H: Journal of Engineering in Medicine},
	volume       = 225,
	pages        = {1121--1135},
	doi          = {10.1177/0954411911424210},
	issn         = {09544119},
	abstract     = {Several mass-spring-damper models have been developed to study the response of the human body to the collision with the ground during hopping, trotting, or running. The mass, spring, and damper elements represent the masses, stiffness properties, and damping properties of hard and soft tissues. The masses that models are composed of are connected to each other via springs and dampers. The present paper reviews the various types of mass-spring-damper models including one-body and multi-body models. The models are further categorized as being either passive or active. In passive models, the mechanical properties (stiffness and damping) of soft tissues remain constant regardless of the type of footwear, ground stiffness, etc. In active models, the mechanical properties adapt to external loads. The governing equations of motion of all models as well as their parameters are presented. The specific ways that the models take account of the shoe-ground interactions are discussed as well. The methods used for determination of different modelling parameters are briefly surveyed. The advantages and disadvantages of the different types of mass-spring-damper models are also discussed. The paper concludes with a brief discussion of possible future research trends in the area of mass-spring-damper modelling. \textcopyright{} IMechE 2011.},
	issue        = 12,
	keywords     = {damping,ground reaction force,mechanical modelling,passive and active models,shoe-ground model,stiffness},
	pmid         = 22320052
}
@techreport{Roose2011,
	title        = {Dynamic refinement for fluid flow simulations with SPH Particle refinement for fluid flow simulations with SPH},
	author       = {Dirk Roose and K U Leuven and Yaidel Reyes L\'{o}pez},
	year         = 2011,
	journal      = {Computer Methods in Mechanics},
	url          = {https://www.researchgate.net/publication/228531954},
	abstract     = {In this paper, we present a refinement algorithm for the SPH method. A particle is refined by replacing it with smaller daughter particles. The position of the new particles is calculated by using a square pattern centered at the position of the refined particle. We study the possibility of scaling and rotating this pattern according to the local distribution of the particles to reduce the overlap with the newly created daughter particles. The results of the simulations using the fully refined domain and the simulations using the dynamic refinement starting from the unrefined domain are compared and are in a good agreement. Kinetic energy as well as linear and angular momentum are conserved by the refinement procedure. The algorithm is presented in 2D, but its extension to 3D is straightforward.},
	keywords     = {Smoothed Particle Hydrodynamics,adaptivity,meshless methods,particle refinement}
}
@article{Nikiel2011,
	title        = {Game-logic simulation based on cellular automata and flocking techniques},
	author       = {S\l{}awomir Nikiel},
	year         = 2011,
	journal      = {Proceedings 25th European Conference on Modelling and Simulation (ECMS)},
	isbn         = 9780956494429
}
@inproceedings{Jafari2011,
	title        = {Terrain effects on wind flow: simulations with an immersed boundary method},
	author       = {S Jafari and N Chokani and R S Abhari},
	year         = 2011,
	booktitle    = {Proceedings of ASME Turbo Expo},
	doi          = {10.1115/GT2011-46240},
	url          = {http://asme.org/terms},
	abstract     = {The modelling of the wind resource over arbitrary topography is required to optimize the micrositing of wind turbines. Most solvers use classical body-fitted grid for simulations. In such an approach, to cover the wind rose using a rectangular domain, a dedicated mesh must be generated for each direction. Moreover, over complex terrain, additional numerical errors are introduced in the solver due to coordinate transformations. To overcome these challenges and to facilitate the grid generation process, an immersed boundary method is developed in connection with a RANS solver in order to simulate turbulent atmospheric flows over arbitrary topography. In this method, a Cartesian grid is used and the boundary condition on the terrain surface is modelled within the solver using a "direct forcing" approach. With the immersed boundary method a rectangular grid can be used to simulate the flow field for all wind directions and only a rotation of the digital elevation map is required. Ghost cells are used to enforce the desired boundary condition at the immersed surface. The immersed boundary method developed in this work is used to simulate the flow in connection with both Baldwin-Lomax and k\ensuremath{\omega} turbulence models. The performance of the method is examined for the flow over a two-dimensional hill. Results are compared with experimental data as well as a classical body-fitted grid to isolate the effect of the boundary conditions. The comparisons show good agreement among all the results. The results for the three-dimensional wind flow simulation over the Askervein Hill test case are also presented, and show the capability of the immersed boundary method in a full-scale scenario.},
	keywords     = {GT2011-46240}
}
@misc{McLane2011,
	title        = {The role of agent-based models in wildlife ecology and management},
	author       = {Adam J. McLane and Christina Semeniuk and Gregory J. McDermid and Danielle J. Marceau},
	year         = 2011,
	month        = 4,
	journal      = {Ecological Modelling},
	volume       = 222,
	pages        = {1544--1556},
	doi          = {10.1016/j.ecolmodel.2011.01.020},
	issn         = {03043800},
	abstract     = {Conservation planning of critical habitats for wildlife species at risk is a priority topic that requires the knowledge of how animals select and use their habitat, and how they respond to future developmental changes in their environment. This paper explores the role of a habitat-modeling methodological approach, agent-based modeling, which we advocate as a promising approach for ecological research. Agent-based models (ABMs) are capable of simultaneously distinguishing animal densities from habitat quality, can explicitly represent the environment and its dynamism, can accommodate spatial patterns of inter- and intra-species mechanisms, and can explore feedbacks and adaptations inherent in these systems. ABMs comprise autonomous, individual entities; each with dynamic, adaptive behaviors and heterogeneous characteristics that interact with each other and with their environment. These interactions result in emergent outcomes that can be used to quantitatively examine critical habitats from the individual- to population-level. ABMs can also explore how wildlife will respond to potential changes in environmental conditions, since they can readily incorporate adaptive animal-movement ecology in a changing landscape. This paper describes the necessary elements of an ABM developed specifically for understanding wildlife habitat selection, reviews the current empirical literature on ABMs in wildlife ecology and management, and evaluates the current and future roles these ABMs can play, specifically with regards to scenario planning of designated critical habitats. \textcopyright{} 2011 Elsevier B.V.},
	issue        = 8,
	keywords     = {Agent-based model,Animal learning,Conservation planning,Environmental representation,Habitat modeling,Movement ecology}
}
@article{Chng2011a,
	title        = {Realistic Placement of Plants for Virtual Environments},
	author       = {Eugene Ch'ng},
	year         = 2011,
	month        = 7,
	journal      = {IEEE Computer Graphics and Applications},
	volume       = 31,
	pages        = {66--77},
	doi          = {10.1109/MCG.2010.42},
	issn         = {0272-1716},
	url          = {http://ieeexplore.ieee.org/document/5445060/},
	issue        = 4
}
@inproceedings{Vergne2011,
	title        = {Implicit brushes for stylized line-based rendering},
	author       = {Romain Vergne and David Vanderhaeghe and Jiazhou Chen and Pascal Barla and Xavier Granier and Christophe Schlick},
	year         = 2011,
	booktitle    = {Computer Graphics Forum},
	publisher    = {Blackwell Publishing Ltd},
	volume       = 30,
	pages        = {513--522},
	doi          = {10.1111/j.1467-8659.2011.01892.x},
	issn         = 14678659,
	abstract     = {We introduce a new technique called Implicit Brushes to render animated 3D scenes with stylized lines in realtime with temporal coherence. An Implicit Brush is defined at a given pixel by the convolution of a brush footprint along a feature skeleton; the skeleton itself is obtained by locating surface features in the pixel neighborhood. Features are identified via image-space fitting techniques that not only extract their location, but also their profile, which permits to distinguish between sharp and smooth features. Profile parameters are then mapped to stylistic parameters such as brush orientation, size or opacity to give rise to a wide range of line-based styles. \textcopyright{} 2011 The Author(s).},
	issue        = 2
}
@misc{Minecraft2011,
	title        = {Minecraft},
	author       = {"Mojang Studios"},
	year         = 2011
}
@article{Smelik2011a,
	title        = {A declarative approach to procedural modeling of virtual worlds},
	author       = {Ruben M. Smelik and Tim Tutenel and Klass Jan de Kraker and Rafael Bidarra},
	year         = 2011,
	month        = 4,
	journal      = {Computers \& Graphics},
	volume       = 35,
	pages        = {352--363},
	doi          = {10.1016/j.cag.2010.11.011},
	issn         = {00978493},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0097849310001809},
	abstract     = {With the ever increasing costs of manual content creation for virtual worlds, the potential of creating it automatically becomes too attractive to ignore. However, for most designers, traditional procedural content generation methods are complex and unintuitive to use, hard to control, and generated results are not easily integrated into a complete and consistent virtual world. We introduce a novel declarative modeling approach that enables designers to concentrate on stating what they want to create instead of on describing how they should model it. It aims at reducing the complexity of virtual world modeling by combining the strengths of semantics-based modeling with manual and procedural approaches. This article describes two of its main contributions to procedural modeling of virtual worlds: interactive procedural sketching and virtual world consistency maintenance. We discuss how these techniques, integrated in our modeling framework SketchaWorld, build up to enable designers to create a complete 3D virtual world in minutes. Procedural sketching provides a fast and more intuitive way to model virtual worlds, by letting designers interactively sketch their virtual world using high-level terrain features, which are then procedurally expanded using a variety of integrated procedural methods. Consistency maintenance guarantees that the semantics of all terrain features is preserved throughout the modeling process. In particular, it automatically solves conflicts possibly emerging from interactions between terrain features. We believe that these contributions together represent a significant step towards providing more user control and flexibility in procedural modeling of virtual worlds. It can therefore be expected that by further reducing its complexity, virtual world modeling will become accessible to an increasingly broad group of users.},
	issue        = 2,
	keywords     = {consistency maintenance,declarative modeling,procedural methods,procedural sketching,semantic modeling,virtual worlds}
}
@inproceedings{Smelik2011b,
	title        = {Semantic constraints for procedural generation of virtual worlds},
	author       = {Ruben Smelik and Krzysztof Galka and Klaas Jan de Kraker and Frido Kuijper and Rafael Bidarra},
	year         = 2011,
	month        = 6,
	booktitle    = {Proceedings of the 2nd International Workshop on Procedural Content Generation in Games},
	publisher    = {ACM},
	pages        = {1--4},
	doi          = {10.1145/2000919.2000928},
	isbn         = 9781450308724,
	url          = {https://dl.acm.org/doi/10.1145/2000919.2000928},
	city         = {New York, NY, USA}
}
@inproceedings{Tutenel2011a,
	title        = {Procedural filters for customization of virtual worlds},
	author       = {Tim Tutenel and Roland van der Linden and Marnix Kraus and Bart Bollen and Rafael Bidarra},
	year         = 2011,
	month        = 6,
	booktitle    = {Proceedings of the 2nd International Workshop on Procedural Content Generation in Games},
	publisher    = {ACM},
	pages        = {1--8},
	doi          = {10.1145/2000919.2000924},
	isbn         = 9781450308724,
	url          = {https://dl.acm.org/doi/10.1145/2000919.2000924},
	city         = {New York, NY, USA}
}
@inproceedings{Tutenel2011b,
	title        = {Generating consistent buildings: A semantic approach for integrating procedural techniques},
	author       = {Tim Tutenel and Ruben M. Smelik and Ricardo Lopes and Klaas Jan De Kraker and Rafael Bidarra},
	year         = 2011,
	month        = 9,
	booktitle    = {IEEE Transactions on Computational Intelligence and AI in Games},
	volume       = 3,
	pages        = {274--288},
	doi          = {10.1109/TCIAIG.2011.2162842},
	issn         = {1943068X},
	abstract     = {Computer games often take place in extensive virtual worlds, attractive for roaming and exploring. Unfortunately, current virtual cities can strongly hinder this kind of gameplay, since the buildings they feature typically have replicated interiors, or no interiors at all. Procedural content generation is becoming more established, with many techniques for automatically creating specific building elements. However, the integration of these techniques to form complete buildings is still largely unexplored, limiting their application to open game worlds. We propose a novel approach that integrates existing procedural techniques to generate such buildings. With minimal extensions, individual techniques can be coordinated to create buildings with consistently interrelated exteriors and interiors, as in the real world. Our solution offers a framework where various procedural techniques communicate with a moderator, which is responsible for negotiating the placement of building elements, making use of a library of semantic classes and constraints. We demonstrate the applicability of our approach by presenting several examples featuring the integration of a fa\c{c}ade shape grammar, two different floor plan layout generation techniques, and furniture placement techniques. We conclude that this approach allows one to preserve the individual qualities of existing procedural techniques, while assisting the consistency maintenance of the generated buildings. \textcopyright{} 2011 IEEE.},
	issue        = 3,
	keywords     = {Fa\c{c}ade shape grammars,floor plan generation techniques,procedural modeling of buildings,semantic modeling}
}
@techreport{Kindler2011,
	title        = {Modern and quaternary carbonate environments},
	author       = {Pascal Kindler and Fabienne Godefroid and H. Allen Curran and Christophe Dupraz and John E Mylroie and Andr\'{e} Strasser and Eric P. Verrecchia},
	year         = 2011,
	month        = 2,
	institution  = {Gerace Research Center}
}
@book{Bertin2011,
	title        = {Semiology of Graphics},
	author       = {Jacques Bertin},
	year         = 2011,
	publisher    = {Esri Press},
	editor       = {Editions Gauthier-Villars and Editions Mouton \& Cie and Ecole Pratique des Hautes Etudes}
}
@misc{Seidl2011,
	title        = {Modelling natural disturbances in forest ecosystems: A review},
	author       = {Rupert Seidl and Paulo M. Fernandes and Teresa F. Fonseca and Fran\c{c}ois Gillet and Anna Maria J\"{o}nsson and Katar\'{\i}na Mergani\v{c}ov\'{a} and Sigrid Netherer and Alexander Arpaci and Jean Daniel Bontemps and Harald Bugmann and Jose Ramon Gonz\'{a}lez-Olabarria and Petra Lasch and C\'{e}line Meredieu and Francisco Moreira and Mart Jan Schelhaas and Frits Mohren},
	year         = 2011,
	month        = 2,
	journal      = {Ecological Modelling},
	volume       = 222,
	pages        = {903--924},
	doi          = {10.1016/j.ecolmodel.2010.09.040},
	issn         = {03043800},
	abstract     = {Natural disturbances play a key role in ecosystem dynamics and are important factors for sustainable forest ecosystem management. Quantitative models are frequently employed to tackle the complexities associated with disturbance processes. Here we review the wide variety of approaches to modelling natural disturbances in forest ecosystems, addressing the full spectrum of disturbance modelling from single events to integrated disturbance regimes. We applied a general, process-based framework founded in disturbance ecology to analyze modelling approaches for drought, wind, forest fires, insect pests and ungulate browsing. Modelling approaches were reviewed by disturbance agent and mechanism, and a set of general disturbance modelling concepts was deduced. We found that although the number of disturbance modelling approaches emerging over the last 15 years has increased strongly, statistical concepts for descriptive modelling are still largely prevalent over mechanistic concepts for explanatory and predictive applications. Yet, considering the increasing importance of disturbances for forest dynamics and ecosystem stewardship under anthropogenic climate change, the latter concepts are crucial tool for understanding and coping with change in forest ecosystems. Current challenges for disturbance modelling in forest ecosystems are thus (i) to overcome remaining limits in process understanding, (ii) to further a mechanistic foundation in disturbance modelling, (iii) to integrate multiple disturbance processes in dynamic ecosystem models for decision support in forest management, and (iv) to bring together scaling capabilities across several levels of organization with a representation of system complexity that captures the emergent behaviour of disturbance regimes. \textcopyright{} 2010 Elsevier B.V.},
	issue        = 4,
	keywords     = {Browsing,Disturbance modelling,Drought,Insect herbivory,Wildfire,Wind storm}
}
@inproceedings{Bernhardt2011,
	title        = {Real-time terrain modeling using CPU-GPU coupled computation},
	author       = {Adrien Bernhardt and Andr\'{e} Maximo and Luiz Velho and Houssam Hnaidi and Marie Paule Cani},
	year         = 2011,
	booktitle    = {Proceedings - 24th SIBGRAPI Conference on Graphics, Patterns and Images},
	pages        = {64--71},
	doi          = {10.1109/SIBGRAPI.2011.28},
	isbn         = 9780769545486,
	abstract     = {Motivated by the importance of having real-time feedback in sketch-based modeling tools, we present a framework for terrain edition capable of generating and displaying complex and high-resolution terrains. Our system is efficient and fast enough to allow the user to see the terrain morphing at the same time the drawing editing occurs. We have two types of editing interactions: the user can draw strokes creating elevations and crevices; and previous strokes can be interactively moved to different regions of the terrain. One interesting feature of our tool is that terrain primitives can be interactively manipulated similarly to primitives in vector-graphics tools. We achieve real-time performance in both modeling and rendering using a hybrid CPU-GPU coupled solution. We maintain a coarse version of the terrain geometry in the CPU by using a quadtree, while a fine version is produced in the GPU using tessellation shaders. \textcopyright{} 2011 IEEE.},
	keywords     = {Coupled computation,GPU tessellation,Sketch-based modeling,Terrain modeling}
}
@inbook{Chng2011b,
	title        = {An Artificial Life-Based Vegetation Modelling Approach for Biodiversity Research},
	author       = {Eugene Ch'ng},
	year         = 2011,
	booktitle    = {Nature-Inspired Informatics for Intelligent Applications and Knowledge Discovery},
	publisher    = {IGI Global},
	pages        = {68--118},
	doi          = {10.4018/978-1-60566-705-8.ch004},
	url          = {http://services.igi-global.com/resolvedoi/resolve.aspx?doi=10.4018/978-1-60566-705-8.ch004}
}
@article{Rasmus2011,
	title        = {Interactions between snow, canopy, and vegetation in a boreal coniferous forest},
	author       = {Sirpa Rasmus and Robin Lundell and Timo Saarinen},
	year         = 2011,
	month        = 3,
	journal      = {Plant Ecology and Diversity},
	volume       = 4,
	pages        = {55--65},
	doi          = {10.1080/17550874.2011.558126},
	issn         = 17550874,
	abstract     = {Background: Snow is known to have a major impact on the distribution of plants in arctic and alpine ecosystems; however, its impact on understorey vegetation in boreal forests is little reported. Aims: To study the effects of trees on the distribution of snow and examine the small-scale spatial relation between snow distribution and ground vegetation. Methods: Detailed spatial variation in snow depth and summer precipitation, canopy dimensions and locations of individual trees, and ground vegetation cover were observed in a coniferous forest, and the spatial correlations between these variables were examined. Results: Spatial patterns of snow remained unchanged throughout the winter and across two different winters. Snow depth showed significant correlations with different tree influence indices calculated based on the distance to the trunk, height, diameter or canopy extent. Dwarf shrub cover correlated positively with snow, and moss cover correlated negatively with the tree influence indices. The highest covers of Vaccinium myrtillus, V. vitis-idaea and Hylocomium splendens were observed on patches with thick snow cover. Linnaea borealis, in contrast, was absent from these patches. Pleurozium schreberi and Dicranum polysetum were most abundant on patches with moderate snow. Conclusions: Trees do not only affect ground vegetation through competition, but also have indirect effects associated with uneven snow cover. Our results suggest that, like arctic and alpine species, boreal forest understorey species show differences in their snow affinity. \textcopyright{} 2011 Botanical Society of Scotland and Taylor \& Francis.},
	issue        = 1,
	keywords     = {Dwarf shrubs,Mosses,Snow,Spatial distribution,Trees,Vegetation}
}
@techreport{Stork2012,
	title        = {Camera pose estimation with circular markers},
	author       = {Joris Stork},
	year         = 2012
}
@article{Annegarn2012,
	title        = {Differences in walking pattern during 6-min walk test between patients with COPD and healthy subjects},
	author       = {Janneke Annegarn and Martijn A. Spruit and Hans H.C.M. Savelberg and Paul J.B. Willems and Coby van de Bool and Annemie M.W.J. Schols and Emiel F.M. Wouters and Kenneth Meijer},
	year         = 2012,
	month        = 5,
	journal      = {PLoS ONE},
	publisher    = {Public Library of Science},
	volume       = 7,
	pages        = {e37329},
	doi          = {10.1371/journal.pone.0037329},
	issn         = 19326203,
	url          = {www.plosone.org},
	abstract     = {Background: To date, detailed analyses of walking patterns using accelerometers during the 6-min walk test (6MWT) have not been performed in patients with chronic obstructive pulmonary disease (COPD). Therefore, it remains unclear whether and to what extent COPD patients have an altered walking pattern during the 6MWT compared to healthy elderly subjects. Methodology/Principal Findings: 79 COPD patients and 24 healthy elderly subjects performed the 6MWT wearing an accelerometer attached to the trunk. The accelerometer features (walking intensity, cadence, and walking variability) and subject characteristics were assessed and compared between groups. Moreover, associations were sought with 6-min walk distance (6MWD) using multiple ordinary least squares (OLS) regression models. COPD patients walked with a significantly lower walking intensity, lower cadence and increased walking variability compared to healthy subjects. Walking intensity and height were the only two significant determinants of 6MWD in healthy subjects, explaining 85\% of the variance in 6MWD. In COPD patients also age, cadence, walking variability measures and their interactions were included were significant determinants of 6MWD (total variance in 6MWD explained: 88\%). Conclusions/Significance: COPD patients have an altered walking pattern during 6MWT compared to healthy subjects. These differences in walking pattern partially explain the lower 6MWD in patients with COPD. \textcopyright{} 2012 Annegarn et al.},
	issue        = 5,
	keywords     = {Accelerometers,Autocorrelation,Body weight,Chronic obstructive pulmonary disease,Dyspnea,Gait analysis,Geriatric care,Walking},
	pmid         = 22624017
}
@article{Lobello2012,
	title        = {Multi-Resolution Dual contouring from volumetric data},
	author       = {Ricardo Uribe Lobello and Florent Dupont and Florence Denis},
	year         = 2012,
	journal      = {GRAPP 2012 IVAPP 2012 - Proceedings of the International Conference on Computer Graphics Theory and Applications and International Conference on Information Visualization Theory and Applications},
	pages        = {163--168},
	doi          = {10.5220/0003858801630168},
	isbn         = 9789898565020,
	abstract     = {We present a Multi-Resolution Dual method based on an incremental octree-based refinement strategy. Our solution is able to generate multi-resolution surfaces from segmented volumetric data. It extends the Dual Marching Cubes algorithm over a generalized octree and guarantees that the produced surfaces are always manifold by introducing a new cell-based criterion for dual vertices generation. Moreover, we propose a top-bottom refinement algorithm that is able to locally adapt the mesh resolution according to a curvature parameter. Our algorithm is suitable to process volumetric data sets and we show on different volumes that the produced surfaces are manifold and approximate well the original object.},
	issue        = {February},
	keywords     = {Image-based modeling,Multi-resolution modeling,Surface modeling}
}
@article{Togelius2012,
	title        = {Compositional procedural content generation},
	author       = {Julian Togelius and Tr\'{o}ndur Justinussen and Anders Hartzen},
	year         = 2012,
	journal      = {3rd Workshop on Procedural Content Generation in Games, PCG 2012, Organized in Conjunction with the Foundations of Digital Games Conference, FDG 2012},
	pages        = {66--69},
	doi          = {10.1145/2538528.2538541},
	note         = {Can be useful for specific tests of the robot (start with many waterflows, have sharp edges, start inside a gallery, etc...)},
	abstract     = {We consider the strengths and drawbacks of various procedural content generation methods, and how they could be combined to hybrid methods that retain the advantages and avoid the disadvantages of their constituent methods. One answer is composition, where one method is nestled inside another. As an example, we present a hybrid evolutionary-ASP dungeon generator.}
}
@article{Kessing2012,
	title        = {Designing semantic game worlds},
	author       = {Jassin Kessing and Tim Tutenel and Rafael Bidarra},
	year         = 2012,
	journal      = {3rd Workshop on Procedural Content Generation in Games, PCG 2012, Organized in Conjunction with the Foundations of Digital Games Conference, FDG 2012},
	pages        = {40--48},
	doi          = {10.1145/2538528.2538530},
	abstract     = {Current game worlds often fall short in providing consistency between the visual representation of the world and the way it feels, behaves, and reacts. This problem partly originates from the goal-oriented and cost-effective nature of the game development process, which mostly favors ad hoc solutions for one particular game, rather than investing in concepts like reusability and emergent gameplay. In broader terms, we observe that game worlds miss semantics, and we argue that its deployment has the potential to bring about the consistency missing in their content. Therefore, we present a novel approach aimed at enriching virtual entities in game worlds with information about their roles, how they relate to others, and how they can affect and interact with players, NPCs, and with each other. We discuss several requirements to achieve these goals, and introduce a semantic model to represent game worlds. In order to support and validate this model, we have developed Entika, a framework to facilitate the deployment of semantics during game development, as well as its maintenance during run-time. Furthermore, we briefly discuss several applications that demonstrate the power of this semantic model for game worlds. After careful evaluation of our semantic game world model and framework, we conclude that a semantically rich world representation can substantially assist designers in creating much more consistent game worlds.},
	keywords     = {Game worlds,Object interaction,Semantics}
}
@article{Valtchanov2012a,
	title        = {Evolving dungeon crawler levels with relative placement},
	author       = {Valtchan Valtchanov and Joseph Alexander Brown},
	year         = 2012,
	journal      = {ACM International Conference Proceeding Series},
	pages        = {27--35},
	doi          = {10.1145/2347583.2347587},
	isbn         = 9781450310840,
	abstract     = {Procedural Content Generation (PCG) is the process of automating the construction of media types for use in game development, the movie industry, and other creative fields. By approaching the process of media creation as a search for content which is evaluated to express desirable features in a well-defined manner, we are able to apply evolutionary techniques such as genetic programming. This can greatly decrease the effort required to bring a project to completion by allowing artists and developers to focus on guiding the creation process. The specific generation process addressed is that of map creation for dungeon crawler video games. The search method proposed allows artists and developers to guide the generation process by specifying a set of tiles that define the composition of each map, and a fitness function that defines its structure. \textcopyright{} 2012 ACM.},
	keywords     = {evolutionary computation,level generation,procedural content generation}
}
@article{Shao2012c,
	title        = {Human action segmentation and recognition via motion and shape analysis},
	author       = {Ling Shao and Ling Ji and Yan Liu and Jianguo Zhang},
	year         = 2012,
	month        = 3,
	journal      = {Pattern Recognition Letters},
	publisher    = {North-Holland},
	volume       = 33,
	pages        = {438--445},
	doi          = {10.1016/j.patrec.2011.05.015},
	issn         = {01678655},
	abstract     = {In this paper, we present an automated video analysis system which addresses segmentation and detection of human actions in an indoor environment, such as a gym. The system aims at segmenting different movements from the input video and recognizing the action types simultaneously. Two action segmentation techniques, namely color intensity based and motion based, are proposed. Both methods can efficiently segment periodic human movements into temporal cycles. We also apply a novel approach for human action recognition by describing human actions using motion and shape features. The descriptor contains both the local shape and its spatial layout information, therefore is more effective for action modeling and is suitable for detecting and recognizing a variety of actions. Experimental results show that the proposed action segmentation and detection algorithms are highly effective. \textcopyright{} 2011 Published by Elsevier B.V. All rights reserved.},
	issue        = 4,
	keywords     = {Human action recognition,Human action segmentation,Motion analysis,Motion history image,PCOG}
}
@article{Prats2012,
	title        = {An open source tool for simulation and supervision of underwater intervention missions},
	author       = {Mario Prats and Javier Perez and J. Javier Fernandez and Pedro J. Sanz},
	year         = 2012,
	journal      = {IEEE International Conference on Intelligent Robots and Systems},
	pages        = {2577--2582},
	doi          = {10.1109/IROS.2012.6385788},
	isbn         = 9781467317375,
	issn         = 21530858,
	abstract     = {This paper presents UWSim: a new software tool for visualization and simulation of underwater robotic missions. The software visualizes an underwater virtual scenario that can be configured using standard modeling software. Controllable underwater vehicles, surface vessels and robotic manipulators, as well as simulated sensors, can be added to the scene and accessed externally through network interfaces. This allows to easily integrate the simulation and visualization tool with existing control architectures, thus allowing hardware-in-the-loop simulations (HIL). UWSim has been successfully used for simulating the logics of underwater intervention missions and for reproducing real missions from the captured logs. The software is offered as open source, thus filling a gap in the underwater robotics community, where commercial simulators oriented to ROV pilot training predominate. \textcopyright{} 2012 IEEE.}
}
@article{Gaucherel2012,
	title        = {Understanding Patchy Landscape Dynamics: Towards a Landscape Language},
	author       = {C\'{e}dric Gaucherel and Fr\'{e}d\'{e}ric Boudon and Thomas Houet and Mathieu Castets and Christophe Godin},
	year         = 2012,
	journal      = {PLoS ONE},
	volume       = 7,
	doi          = {10.1371/journal.pone.0046064},
	issn         = 19326203,
	url          = {https://halshs.archives-ouvertes.fr/halshs-00750971/file/Gaucherel_al-PONE.pdf},
	abstract     = {Patchy landscapes driven by human decisions and/or natural forces are still a challenge to be understood and modelled. No attempt has been made up to now to describe them by a coherent framework and to formalize landscape changing rules. Overcoming this lacuna was our first objective here, and this was largely based on the notion of Rewriting Systems, also called Formal Grammars. We used complicated scenarios of agricultural dynamics to model landscapes and to write their corresponding driving rule equations. Our second objective was to illustrate the relevance of this landscape language concept for landscape modelling through various grassland managements, with the final aim to assess their respective impacts on biological conservation. For this purpose, we made the assumptions that a higher grassland appearance frequency and higher land cover connectivity are favourable to species conservation. Ecological results revealed that dairy and beef livestock production systems are more favourable to wild species than is hog farming, although in different ways. Methodological results allowed us to efficiently model and formalize these landscape dynamics. This study demonstrates the applicability of the Rewriting System framework to the modelling of agricultural landscapes and, hopefully, to other patchy landscapes. The newly defined grammar is able to explain changes that are neither necessarily local nor Markovian, and opens a way to analytical modelling of landscape dynamics. \textcopyright{} 2012 Gaucherel et al.},
	issue        = 9,
	pmid         = 23049935
}
@article{Prasad2012,
	title        = {A novel framework for making dominant point detection methods non-parametric},
	author       = {Dilip K. Prasad and Maylor K.H. Leung and Chai Quek and Siu Yeung Cho},
	year         = 2012,
	journal      = {Image and Vision Computing},
	publisher    = {Elsevier B.V.},
	volume       = 30,
	pages        = {843--859},
	doi          = {10.1016/j.imavis.2012.06.010},
	issn         = {02628856},
	url          = {http://dx.doi.org/10.1016/j.imavis.2012.06.010 https://pdf.sciencedirectassets.com/271526/1-s2.0-S0262885612X00106/1-s2.0-S0262885612000984/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEDUaCXVzLWVhc3QtMSJGMEQCIEvFwJ9%2BlZhaD6vGKO22HFRdVP5iZukCZszz%2B1%2F},
	abstract     = {Most dominant point detection methods require heuristically chosen control parameters. One of the commonly used control parameter is maximum deviation. This paper uses a theoretical bound of the maximum deviation of pixels obtained by digitization of a line segment for constructing a general framework to make most dominant point detection methods non-parametric. The derived analytical bound of the maximum deviation can be used as a natural bench mark for the line fitting algorithms and thus dominant point detection methods can be made parameter-independent and non-heuristic. Most methods can easily incorporate the bound. This is demonstrated using three categorically different dominant point detection methods. Such non-parametric approach retains the characteristics of the digital curve while providing good fitting performance and compression ratio for all the three methods using a variety of digital, non-digital, and noisy curves. \textcopyright{} 2012 Elsevier B.V.},
	issue        = 11,
	keywords     = {Digital curves,Dominant points,Line fitting,Non-parametric,Polygonal approximation}
}
@article{Bazeille2012,
	title        = {Color-based underwater object recognition using water light attenuation},
	author       = {St\'{e}phane Bazeille and Isabelle Quidu and Luc Jaulin},
	year         = 2012,
	journal      = {Intelligent Service Robotics},
	volume       = 5,
	pages        = {109--118},
	doi          = {10.1007/s11370-012-0105-3},
	issn         = 18612776,
	url          = {https://www.ensta-bretagne.fr/jaulin/paper_isr_bazeille.pdf},
	abstract     = {In this article we present a new approach for object recognition in a robotic underwater context. Color is an attractive feature because of its simplicity and its robustness to scale changes, object positions and partial occlusions. Unfortunately, in the underwater medium, the colors are modified by attenuation and are not constant with the distance. To perform a color-based recognition of an object, we develop an algorithm robust with respect to the attenuation which takes into account the light modification during its path between the light source and the camera. Therefore, a given underwater object can be identified in an image by detecting all the colors compatible with its prior known color. Our method is fast, robust and needs a very few computers resources. We successfully used it when experimenting in the sea using a system we built. It is suitable for robotic applications where computers resources are limited and shared between various embedded devices. This novel concept enables the use of the color in many applications such as target interception, object tracking or obstacle detection. \textcopyright{} 2012 Springer-Verlag.},
	issue        = 2,
	keywords     = {Color,Light attenuation,Underwater robot,Vision}
}
@article{Raffe2012a,
	title        = {A survey of procedural terrain generation techniques using evolutionary algorithms},
	author       = {William L. Raffe and Fabio Zambetta and Xiaodong Li},
	year         = 2012,
	journal      = {2012 IEEE Congress on Evolutionary Computation, CEC 2012},
	pages        = {2090--2097},
	doi          = {10.1109/CEC.2012.6256610},
	isbn         = 9781467315098,
	url          = {https://ap-st01.ext.exlibrisgroup.com/61RMIT_INST/upload/1654105000990_n2006034557.pdf?Expires=1654105121&Signature=FrlTT4vBpkq~nbL9nxnPRu4SV6tegL~9cBpjuIslucfR2pzwyy8oZ4su--Qd13yzcWwQMhP2nJAtJpb5gRqsYXTbnLDwjRd69O5V1WyWcrX6riggwjkBZ2fKrTNYVH3KDlCY~fDBCp8},
	abstract     = {This paper provides a review of existing approaches to using evolutionary algorithms (EA) during procedural terrain generation (PTG) processes in video games. A reliable PTG algorithm would allow game maps to be created partially or completely autonomously, reducing the development cost of a game and providing players with more content. Specifically, the use of EA raises possibilities of more control over the terrain generation process, as well as the ability to tailor maps for individual users. In this paper we outline the prominent algorithms that use EA in terrain generation, describing their individual advantages and disadvantages. This is followed by a comparison of the core features of these approaches and an analysis of their appropriateness for generating game terrain. This survey concludes with open challenges for future research. \textcopyright{} 2012 IEEE.},
	issue        = {Cec}
}
@phdthesis{Guerin2012,
	title        = {Mod\'{e}lisation de terrains virtuels Sp\'{e}cialit\'{e}},
	author       = {\'{E}ric Gu\'{e}rin},
	year         = 2012,
	url          = {https://hal.archives-ouvertes.fr/tel-01635126/file/HDR-EricGuerin-Finale.pdf}
}
@inbook{Brun2012,
	title        = {Image Processing and Analysing With Graphs : Theory and Practice Chapter 1},
	author       = {Luc Brun and Walter Kropatsch},
	year         = 2012,
	issue        = {June}
}
@article{Rocca2012,
	title        = {Patchwork terrains},
	author       = {Luigi Rocca and Daniele Panozzo and Enrico Puppo},
	year         = 2012,
	journal      = {GRAPP 2012 IVAPP 2012 - Proceedings of the International Conference on Computer Graphics Theory and Applications and International Conference on Information Visualization Theory and Applications},
	pages        = {67--76},
	doi          = {10.5220/0003848500670076},
	isbn         = 9789898565020,
	url          = {https://cims.nyu.edu/gcl/papers/GRAPP12-RocPanPup.pdf},
	abstract     = {We present a radically new method for the management, multi-resolution representation and rendering of large terrain databases. Our method has two main benefits: it provides a C \ensuremath{\kappa} representation of terrain, with \ensuremath{\kappa} depending on the type of base patches; and it supports efficient updates of the database as new data come in. We assume terrain data to come as a collection of regularly sampled overlapping grids, with arbitrary spacing and orientation. A multi-resolution model is built and updated dynamically off-line from such grids, which can be queried on-line to obtain a suitable collection of patches to cover a given domain with a given, possibly view-dependent, level of detail. Patches are combined to obtain a C \ensuremath{\kappa} surface. The whole framework can is designed to take advantage of the parallel computing power of modern GPUs.},
	keywords     = {Multiresolution modeling,Terrain modeling,Terrain rendering}
}
@article{Zanni2012,
	title        = {Geometric Details on Skeleton-based Implicit Surfaces},
	author       = {C\'{e}dric Zanni and Paul Bares and Ares Lagae and Maxime Quiblier and Marie-paule Cani and C\'{e}dric Zanni and Paul Bares and Ares Lagae and Maxime Quiblier and Marie-paule Cani Geometric},
	year         = 2012,
	journal      = {Eurographics 2012-33rd Annual Conference of the European Association for Computer Graphics},
	pages        = {49--52}
}
@article{Natali2012,
	title        = {Rapid visualization of geological concepts},
	author       = {Mattia Natali and Ivan Viola and Daniel Patel},
	year         = 2012,
	journal      = {Brazilian Symposium of Computer Graphic and Image Processing},
	publisher    = {IEEE},
	pages        = {150--157},
	doi          = {10.1109/SIBGRAPI.2012.29},
	isbn         = 9780769548296,
	issn         = 15301834,
	abstract     = {We describe a sketch-based system for constructing an illustrative visualization of the subsurface. An intuitive and rapid modelling tool is defined, which takes as input user's strokes and creates a 3D layer-cake model of the earth. Our tool enables users to quickly express and communicate their ideas directly using a 3D model. For sketching, we have created geometric operators that capture the domain specific modelling requirements. We have devised sketching operators for expressing folding and faulting processes. This makes it possible to produce a large span of scenarios. Moreover, for communicating layer properties such as rock type and grain size, our system allows for associating user defined texture to each layer which can be deformed with a few sketch strokes. \textcopyright{} 2012 IEEE.},
	keywords     = {illustrative visualization,layer-cake model,sketch-based technique,stratigraphy,structural geology}
}
@article{Seidl2012,
	title        = {An individual-based process model to simulate landscape-scale forest ecosystem dynamics},
	author       = {Rupert Seidl and Werner Rammer and Robert M. Scheller and Thomas A. Spies},
	year         = 2012,
	month        = 4,
	journal      = {Ecological Modelling},
	volume       = 231,
	pages        = {87--100},
	doi          = {10.1016/j.ecolmodel.2012.02.015},
	issn         = {03043800},
	abstract     = {Forest ecosystem dynamics emerges from nonlinear interactions between adaptive biotic agents (i.e., individual trees) and their relationship with a spatially and temporally heterogeneous abiotic environment. Understanding and predicting the dynamics resulting from these complex interactions is crucial for the sustainable stewardship of ecosystems, particularly in the context of rapidly changing environmental conditions. Here we present iLand (the individual-based forest landscape and disturbance model), a novel approach to simulating forest dynamics as an emergent property of environmental drivers, ecosystem processes and dynamic interactions across scales. Our specific objectives were (i) to describe the model, in particular its novel approach to simulate spatially explicit individual-tree competition for resources over large scales within a process-based framework of physiological resource use, and (ii) to present a suite of evaluation experiments assessing iLands ability to simulate tree growth and mortality for a wide range of forest ecosystems. Adopting an approach rooted in ecological field theory, iLand calculates a continuous field of light availability over the landscape, with every tree represented by a mechanistically derived, size- and species-dependent pattern of light interference. Within a hierarchical multi-scale framework productivity is derived at stand-level by means of a light-use efficiency approach, and downscaled to individuals via local light availability. Allocation (based on allometric ratios) and mortality (resulting from carbon starvation) are modeled at the individual-tree level, accounting for adaptive behavior of trees in response to their environment. To evaluate the model we conducted simulations over the extended environmental gradient of a longitudinal transect in Oregon, USA, and successfully compared results against independently observed productivity estimates (63.4\% of variation explained) and mortality patterns in even-aged stands. This transect experiment was furthermore replicated for a different set of species and ecosystems in the Austrian Alps, documenting the robustness and generality of our approach. Model performance was also successfully evaluated for structurally and compositionally complex old-growth forests in the western Cascades of Oregon. Finally, the ability of our approach to address forest ecosystem dynamics at landscape scales was demonstrated by a computational scaling experiment. In simulating the emergence of ecosystem patterns and dynamics as a result of complex process interactions across scales our approach has the potential to contribute crucial capacities to understanding and fostering forest ecosystem resilience under changing climatic conditions. \textcopyright{} 2012 Elsevier B.V.},
	keywords     = {Complex adaptive systems,Ecological field theory,Forest ecosystem dynamics,Forest structure and functioning,Hierarchical multi-scale modeling,Individual-based modeling}
}
@article{Heppell2012,
	title        = {Documenting recovery of a spawning aggregation through size frequency analysis from underwater laser calipers measurements},
	author       = {Scott A. Heppell and Brice X. Semmens and Stephanie K. Archer and Christy V. Pattengill-Semmens and Philippe G. Bush and Croy M. McCoy and Selina S. Heppell and Bradley C. Johnson},
	year         = 2012,
	journal      = {Biological Conservation},
	publisher    = {Elsevier Ltd},
	volume       = 155,
	pages        = {119--127},
	doi          = {10.1016/j.biocon.2012.06.002},
	issn         = {00063207},
	url          = {http://dx.doi.org/10.1016/j.biocon.2012.06.002},
	abstract     = {Many spawning aggregations of marine fishes have been fished beyond the point of sustainability, leading to increased calls for protection through seasonal and/or site-specific fishery closures. Once a closure has been put in place, monitoring the aggregation is imperative in order to learn whether protection leads to the recovery of the population. Current methods for monitoring the status of spawning aggregations rely largely on counts, either subsample or census, usually combined with capturing a subset of the fish to assess individual traits such as length and weight. Handling fish during the spawning aggregation can be stressful for the fish, and can ultimately lead to decreased spawning success, increased susceptibility to predators, or increased mortality through capture trauma or infection. Here we present a novel analysis for monitoring fish on a spawning aggregation that does not require the capture and handling of fish. Following a recovering aggregation of Nassau grouper (. Epinephelus striatus) over seven spawning seasons, we show that length-distribution data can be collected by divers using a video-based system with parallel lasers calibrated to a specific distance apart, and subsequently use those data to monitor changes in the size distribution over time. We detected recruitment of new fish to the grouper spawning aggregation in the fourth year of monitoring. In addition to tracking size distribution trends over time, the length distribution information could be combined with an established length-weight regression and an estimate of total abundance to estimate spawning stock biomass. We qualitatively cross-validate this method with census data to evaluate its effectiveness in monitoring the recovery or decline of aggregating species that can be visually observed. \textcopyright{} 2012 Elsevier Ltd.},
	keywords     = {Length analysis,Length distribution,Marine protected area,Monitoring,Nassau grouper,Population recovery,Spawning aggregation}
}
@article{Longay2012,
	title        = {TreeSketch : Interactive Procedural Modeling of Trees on a Tablet},
	author       = {Steven Longay and Adam Runions and Fr\'{e}d\'{e}ric Boudon and Przemyslaw Prusinkiewicz},
	year         = 2012,
	journal      = {The proceedings of the Eurographics Symposium on Sketch-Based Interfaces and Modeling},
	pages        = {107--120},
	url          = {http://algorithmicbotany.org/papers/TreeSketch.SBM2012.large.pdf},
	abstract     = {TreeSketch is a system for modeling complex trees that look natural yet are creatively designed. The system inte- grates procedural tree generation with a multi-touch tablet interface that provides detailed control of tree form. The procedural component is based on the concept of tree self-organization and simulates competition of branches for space and light as the tree develops from a seedling. The modeler can control this process by directing growth with a procedural brush, changing parameters as the tree grows, interleaving controlled and autonomous growth, and editing generated forms. Complex trees can be created in a matter of seconds.}
}
@inbook{Ouannes2012,
	title        = {Following Food Sources by Artificial Creatures in a Virtual Ecosystem},
	author       = {Nesrine Ouannes and Noureddine Djedi and Yves Duthen and Herv\'{e} Luga},
	year         = 2012,
	booktitle    = {Virtual Worlds},
	pages        = {99--116},
	abstract     = {In this chapter a virtual ecosystem environment with basic physical law and energy concept has been proposed, this ecosystem is populated with 3D virtual creatures that are living in this environment in order to forage food. Artificial behaviors are developed in order to control artificial creatures. Initially, we study the behavior of herbivore's creatures, which feed resources available in their environment. A genetic algorithm with an artificial neural network were implemented together to guarantee some of these behaviors like searching food. Foods are presented in different locations in the virtual ecosystem. The evolutionary process uses the physical properties of the virtual creatures and an external fitness function with several objectives that will conduct to the expected behaviors. The experiment evolving locomoting virtual creatures shows that these virtual creatures try to obtain at least one of the food sources presented in their trajectories. Our best-evolved creatures are able to reach multiple food sources during the simulation time.}
}
@article{Yeh2012,
	title        = {Synthesizing open worlds with constraints using locally annealed reversible jump MCMC},
	author       = {Yi Ting Yeh and Lingfeng Yang and Matthew Watson and Noah D. Goodman and Pat Hanrahan},
	year         = 2012,
	journal      = {ACM Transactions on Graphics},
	volume       = 31,
	doi          = {10.1145/2185520.2185552},
	issn         = {07300301},
	url          = {https://graphics.stanford.edu/~lfyg/owl.pdf},
	abstract     = {We present a novel Markov chain Monte Carlo (MCMC) algorithm that generates samples from transdimensional distributions encoding complex constraints. We use factor graphs, a type of graphical model, to encode constraints as factors. Our proposed MCMC method, called locally annealed reversible jump MCMC, exploits knowledge of how dimension changes affect the structure of the factor graph. We employ a sequence of annealed distributions during the sampling process, allowing us to explore the state space across different dimensionalities more freely. This approach is motivated by the application of layout synthesis where relationships between objects are characterized as constraints. In particular, our method addresses the challenge of synthesizing open world layouts where the number of objects are not fixed and optimal configurations for different numbers of objects may be drastically different. We demonstrate the applicability of our approach on two open world layout synthesis problems: coffee shops and golf courses. \textcopyright{} 2012 ACM 0730-0301/2012/08-ART56.},
	issue        = 4,
	keywords     = {Constrained synthesis,Factor graphs,Open worlds}
}
@phdthesis{Oyundolgor2012,
	title        = {A Study on Efficient Algorithms for Generating Virtual Wind Field Usable for Real-time Animation},
	author       = {Khorloo Oyundolgor},
	year         = 2012,
	issue        = {March},
	institution  = {Graduate School of Engineering Iwate University}
}
@article{Jiang2012,
	title        = {Image Segmentation Based on Level Set Method},
	author       = {Xin Jiang and Renjie Zhang and Shengdong Nie},
	year         = 2012,
	journal      = {Physics Procedia},
	publisher    = {Elsevier BV},
	volume       = 33,
	pages        = {840--845},
	doi          = {10.1016/j.phpro.2012.05.143},
	issn         = 18753892,
	abstract     = {Level set method can be effectively used to solve topology problems during the evolution of curves while the previous algorithms cannot deal with them. In recent years, there are many image segmentation algorithms based on level set method. For different applications of image processing, people have put forward the corresponding solutions, and a large number of researchers also continue to improve and enhance the efficiency and effectiveness of these algorithms. In this article, according to the development of the image segmentation methods based on level set, an overview is given for readers of different backgrounds in this field to use, and their characteristics are discussed.}
}
@article{Getreuer2012,
	title        = {Chan-Vese Segmentation},
	author       = {Pascal Getreuer},
	year         = 2012,
	month        = 8,
	journal      = {Image Processing On Line},
	publisher    = {Image Processing On Line},
	volume       = 2,
	pages        = {214--224},
	doi          = {10.5201/ipol.2012.g-cv},
	abstract     = {While many segmentation methods rely heavily in some way on edge detection, the "Active Contours Without Edges" method by Chan and Vese ignores edges completely. Instead, the method optimally fits a two-phase piecewise constant model to the given image. The segmentation boundary is represented implicitly with a level set function, which allows the segmentation to handle topological changes more easily than explicit snake methods. This article describes the level set formulation of the Chan–Vese model and its numerical solution using a semi-implicit gradient descent. We also discuss the Chan–Sandberg–Vese method, a straightforward extension of Chan–Vese for vector-valued images.}
}
@article{Pirk2012,
	title        = {Plastic trees: Interactive self-adapting botanical tree models},
	author       = {S\"{o}ren Pirk and Ondrej Stava and Julian Kratt and Michel Abdul Massih Said and Boris Neubert and Radom\'{\i}r M\v{e}ch and Bedrich Benes and Oliver Deussen},
	year         = 2012,
	month        = 7,
	journal      = {ACM Transactions on Graphics},
	volume       = 31,
	doi          = {10.1145/2185520.2185546},
	issn         = {07300301},
	abstract     = {We present a dynamic tree modeling and representation technique that allows complex tree models to interact with their environment. Our method uses changes in the light distribution and proximity to solid obstacles and other trees as approximations of biologically motivated transformations on a skeletal representation of the tree's main branches and its procedurally generated foliage. Parts of the tree are transformed only when required, thus our approach is much faster than common algorithms such as Open L-Systems or space colonization methods. Input is a skeleton-based tree geometry that can be computed from common tree production systems or from reconstructed laser scanning models. Our approach enables content creators to directly interact with trees and to create visually convincing ecosystems interactively. We present different interaction types and evaluate our method by comparing our transformations to biologically based growth simulation techniques. \textcopyright{} 2012 ACM 0730-0301/2012/08-ART50.},
	issue        = 4,
	keywords     = {Generative Tree Modeling,Interactive Procedural Modeling,Visual Models of Trees}
}
@phdthesis{TuntelThesis,
	title        = {Semantic Game Worlds},
	author       = {Tim Tutenel},
	year         = 2012,
	city         = {Hasselt},
	institution  = {Universiteit Hasselt},
	keywords     = {Semantic game worlds,declarative modeling,procedural content generation}
}
@article{Pardo2012,
	title        = {Stochastic simulation of karst conduit networks},
	author       = {Eulogio Pardo-Ig\'{u}zquiza and Peter A. Dowd and Chaoshui Xu and Juan Jos\'{e} Dur\'{a}n-Valsero},
	year         = 2012,
	month        = 1,
	journal      = {Advances in Water Resources},
	volume       = 35,
	pages        = {141--150},
	doi          = {10.1016/j.advwatres.2011.09.014},
	issn         = {03091708},
	abstract     = {Karst aquifers have very high spatial heterogeneity. Essentially, they comprise a system of pipes (i.e., the network of conduits) superimposed on rock porosity and on a network of stratigraphic surfaces and fractures. This heterogeneity strongly influences the hydraulic behavior of the karst and it must be reproduced in any realistic numerical model of the karst system that is used as input to flow and transport modeling. However, the directly observed karst conduits are only a small part of the complete karst conduit system and knowledge of the complete conduit geometry and topology remains spatially limited and uncertain. Thus, there is a special interest in the stochastic simulation of networks of conduits that can be combined with fracture and rock porosity models to provide a realistic numerical model of the karst system. Furthermore, the simulated model may be of interest per se and other uses could be envisaged. The purpose of this paper is to present an efficient method for conditional and non-conditional stochastic simulation of karst conduit networks. The method comprises two stages: generation of conduit geometry and generation of topology. The approach adopted is a combination of a resampling method for generating conduit geometries from templates and a modified diffusion-limited aggregation method for generating the network topology. The authors show that the 3D karst conduit networks generated by the proposed method are statistically similar to observed karst conduit networks or to a hypothesized network model. The statistical similarity is in the sense of reproducing the tortuosity index of conduits, the fractal dimension of the network, the direction rose of directions, the Z-histogram and Ripley's K-function of the bifurcation points (which differs from a random allocation of those bifurcation points). The proposed method (1) is very flexible, (2) incorporates any experimental data (conditioning information) and (3) can easily be modified when implemented in a hydraulic inverse modeling procedure. Several synthetic examples are given to illustrate the methodology and real conduit network data are used to generate simulated networks that mimic real geometries and topology. \textcopyright{} 2011 Elsevier Ltd.},
	keywords     = {Conduit geometry,Diffusion-limited aggregation,Inception horizon,Network topology,Rose diagram,Z-histogram}
}
@article{Yuan2012,
	title        = {Object-space multiphase implicit functions},
	author       = {Zhan Yuan and Yizhou Yu and Wenping Wang},
	year         = 2012,
	month        = 7,
	journal      = {ACM Transactions on Graphics},
	volume       = 31,
	doi          = {10.1145/2185520.2185610},
	issn         = {07300301},
	abstract     = {Implicit functions have a wide range of applications in entertainment, engineering and medical imaging. A standard two-phase implicit function only represents the interior and exterior of a single object. To facilitate solid modeling of heterogeneous objects with multiple internal regions, object-space multiphase implicit functions are much desired. Multiphase implicit functions have much potential in modeling natural organisms, heterogeneous mechanical parts and anatomical atlases. In this paper, we introduce a novel class of object-space multiphase implicit functions that are capable of accurately and compactly representing objects with multiple internal regions. Our proposed multiphase implicit functions facilitate true object-space geometric modeling of heterogeneous objects with non-manifold features. We present multiple methods to create object-space multiphase implicit functions from existing data, including meshes and segmented medical images. Our algorithms are inspired by machine learning algorithms for training multicategory max-margin classifiers. Comparisons demonstrate that our method achieves an error rate one order of magnitude smaller than alternative techniques. \textcopyright{} 2012 ACM 0730-0301/2012/08-ART114.},
	issue        = 4,
	keywords     = {Implicit Surfaces,Linear Programming,Non-Manifold Surfaces,Piecewise Polynomial Surfaces,Support Vector Machines}
}
@inproceedings{Li2012,
	title        = {2D shape manipulations with holomorphic coordinates},
	author       = {Zheng Li and Chengming Liu},
	year         = 2012,
	booktitle    = {Proceedings - 4th International Conference on Digital Home, ICDH 2012},
	pages        = {443--448},
	doi          = {10.1109/ICDH.2012.26},
	abstract     = {Cage-based deformation methods require an enclosing cage to deform a shape, which is not user-friendly. In this paper, we propose holomorphic coordinates that directly take user-specified shape points as handles to produce visually promising conformal deformations for 2D shapes. Based on the theory of holomorphic functions, holomorphic coordinates promise the interpolation and smoothness properties on the shape. Namely, handle points can be moved to the exact locations that the user specifies, and the deformations are smooth all over the shape. We also suggest an algorithm to solve holomorphic coordinates on a grid in a least-squares sense by constructing harmonic and conjugate constraints. Experiments have shown that the numerical errors are close to zero, and deformed shapes can be obtained at an interactive rate. \textcopyright{} 2012 IEEE.},
	keywords     = {conformal deformations,coordinates,holomorphic functions,shape manipulations}
}
@techreport{Loiret2012,
	title        = {La Biosph\`{e}re selon Vernadsky : Contradiction du principe de Carnot},
	author       = {Richard Loiret},
	year         = 2012,
	url          = {https://hal.science/hal-00911684v2},
	abstract     = {To cite this version: Richard Loiret. La Biosph\`{e}re selon Vernadsky : Contradiction du principe de Carnot : Rendre compte de la biodiversit\'{e} dans le bilan des relations homme-nature (Cahier de recherche n\textdegree{}1). [Rapport de recherche] REEDS; Centre international de Recherches en Economie \'{e}cologique, Eco-innovation et ing\'{e}nierie du D\'{e}veloppement Soutenable; Universit\'{e} de Versailles Saint-Quentin-en-Yvelines. 2012. \"{\i}\textquestiondown{}\textquestiondown{}hal-00911684v2\"{\i}\textquestiondown{}\textquestiondown{}},
	keywords     = {()}
}
@article{Wang2013,
	title        = {A computational model of stereoscopic 3D visual saliency A computational model of stereoscopic 3D visual saliency A computational model of stereoscopic 3D visual saliency},
	author       = {Junle Wang and Matthieu Perreira da Silva and Patrick Le Callet and Vincent Ricordel and Matthieu Perreira Da Silva},
	year         = 2013,
	journal      = {IEEE Transactions on Image Processing},
	publisher    = {Institute of Electrical and Electronics Engineers},
	volume       = 22,
	doi          = {10.1109/TIP.2013.2246176ï},
	issn         = {2151-2165},
	url          = {https://hal.archives-ouvertes.fr/hal-00788847},
	abstract     = {Many computational models of visual attention performing well in predicting salient areas of 2D images have been proposed in the literature. The emerging applications of stereoscopic 3D display bring additional depth information affecting the human viewing behavior, and require extensions of the efforts made in 2D visual modeling. In this paper, we propose a new computational model of visual attention for stereoscopic 3D still image. Apart from detecting salient areas based on 2D visual features, the proposed model takes depth as an additional visual dimension. The measure of depth saliency is derived from the eye movement data obtained from an eye-tracking experiment using synthetic stimuli. Two different ways of integrating depth information in the modeling of 3D visual attention are then proposed and examined. For the performance evaluation of 3D visual attention models, we have created an eye-tracking database which contains stereoscopic images of natural content and is publicly available along with this paper. The proposed model gives a good performance, compared to that of state-of-the-art 2D models on 2D images. The results also suggest that a better performance is obtained when depth information is taken into account through the creation of a depth saliency map rather than when it is integrated by a weighting method.},
	issue        = 6,
	keywords     = {3DTV,Index Terms-Visual attention,depth saliency,eye-tracking,saliency map,stereoscopy}
}
@article{Zmuda2013,
	title        = {Optimizing constrained-environment redirected walking instructions using search techniques},
	author       = {Michael A. Zmuda and Joshua L. Wonser and Eric R. Bachmann and Eric Hodgson},
	year         = 2013,
	journal      = {IEEE Transactions on Visualization and Computer Graphics},
	volume       = 19,
	pages        = {1872--1884},
	doi          = {10.1109/TVCG.2013.88},
	issn         = 10772626,
	abstract     = {A goal of redirected walking (RDW) is to allow large virtual worlds to be explored within small tracking areas. Generalized steering algorithms, such as steer-to-center, simply move the user toward locations that are considered to be collision free in most cases. The algorithm developed here, FORCE, identifies collision-free paths by using a map of the tracking area's shape and obstacles, in addition to a multistep, probabilistic prediction of the user's virtual path through a known virtual environment. In the present implementation, the path predictions describe a user's possible movements through a virtual store with aisles. Based on both the user's physical and virtual location/orientation, a search-based optimization technique identifies the optimal steering instruction given the possible user paths. Path prediction uses the map of the virtual world; consequently, the search may propose steering instructions that put the user close to walls if the user's future actions eventually lead away from the wall. Results from both simulated and real users are presented. FORCE identifies collision-free paths in 55.0 percent of the starting conditions compared to 46.1 percent for generalized methods. When considering only the conditions that result in different outcomes, redirection based on FORCE produces collision-free path 94.5 percent of the time. \textcopyright{} 2013 IEEE.},
	issue        = 11,
	keywords     = {Backtracking,motion compression,redirected walking,virtual reality},
	pmid         = 24029907
}
@article{Iosa2013,
	title        = {The Golden Ratio of Gait Harmony: Repetitive Proportions of Repetitive Gait Phases},
	author       = {Marco Iosa and Augusto Fusco and Fabio Marchetti and Giovanni Morone and Carlo Caltagirone and Stefano Paolucci and Antonella Peppe},
	year         = 2013,
	journal      = {BioMed Research International},
	publisher    = {Hindawi Publishing Corporation},
	volume       = 2013,
	doi          = {10.1155/2013/918642},
	url          = {http://dx.},
	abstract     = {In nature, many physical and biological systems have structures showing harmonic properties. Some of them were found related to the irrational number \'{\i} \mathrm{\mu}\'{\i}\textonequarter{} known as the golden ratio that has important symmetric and harmonic properties. In this study, the spatiotemporal gait parameters of 25 healthy subjects were analyzed using a stereophotogrammetric system with 25 retroreflective markers located on their skin. The proportions of gait phases were compared with \'{\i} \mathrm{\mu}\'{\i}\textonequarter{}, the value of which is about 1.6180. The ratio between the entire gait cycle and stance phase resulted in 1.620 \pm{} 0.058, that between stance and the swing phase was 1.629 \pm{} 0.173, and that between swing and the double support phase was 1.684 \pm{} 0.357. All these ratios did not differ significantly from each other (\'{\i} \mathrm{\mu}\'{\i}\textdegree{}\ensuremath{^1} = 0.870, \'{\i} \mathrm{\mu}\'{\i}\pm{} = 0.422, repeated measure analysis of variance) or from \'{\i} \mathrm{\mu}\'{\i}\textonequarter{} (\'{\i} \mathrm{\mu}\'{\i}\pm{} = 0.670, 0.820, 0.422, resp., t-tests). The repetitive gait phases of physiological walking were found in turn in repetitive proportions with each other, revealing an intrinsic harmonic structure. Harmony could be the key for facilitating the control of repetitive walking. Harmony is a powerful unifying factor between seemingly disparate fields of nature, including human gait.}
}
@techreport{Fanello2013,
	title        = {Keep It Simple And Sparse: Real-Time Action Recognition Giorgio Metta},
	author       = {Sean Ryan Fanello and Ilaria Gori and Giorgio Metta and Francesca Odone},
	year         = 2013,
	journal      = {Journal of Machine Learning Research},
	volume       = 14,
	pages        = {2617--2640},
	abstract     = {Sparsity has been showed to be one of the most important properties for visual recognition purposes. In this paper we show that sparse representation plays a fundamental role in achieving one-shot learning and real-time recognition of actions. We start off from RGBD images, combine motion and appearance cues and extract state-of-the-art features in a computationally efficient way. The proposed method relies on descriptors based on 3D Histograms of Scene Flow (3DHOFs) and Global Histograms of Oriented Gradient (GHOGs); adaptive sparse coding is applied to capture high-level patterns from data. We then propose a simultaneous on-line video segmentation and recognition of actions using linear SVMs. The main contribution of the paper is an effective real-time system for one-shot action modeling and recognition; the paper highlights the effectiveness of sparse coding techniques to represent 3D actions. We obtain very good results on three different data sets: a benchmark data set for one-shot action learning (the ChaLearn Gesture Data Set), an in-house data set acquired by a Kinect sensor including complex actions and gestures differing by small details, and a data set created for human-robot interaction purposes. Finally we demonstrate that our system is effective also in a human-robot interaction setting and propose a memory game, "All Gestures You Can", to be played against a humanoid robot.},
	keywords     = {human robot interaction,one-shot action learning,real-time action recognition,sparse representation}
}
@article{Stone2013,
	title        = {Unobtrusive, continuous, in-home gait measurement using the microsoft kinect},
	author       = {Erik E. Stone and Marjorie Skubic},
	year         = 2013,
	journal      = {IEEE Transactions on Biomedical Engineering},
	volume       = 60,
	pages        = {2925--2932},
	doi          = {10.1109/TBME.2013.2266341},
	issn         = {00189294},
	abstract     = {A system for capturing habitual, in-home gait measurements using an environmentally mounted depth camera, the Microsoft Kinect, is presented. Previous work evaluating the use of the Kinect sensor for in-home gait measurement in a lab setting has shown the potential of this approach. In this paper, a single Kinect sensor and computer were deployed in the apartments of older adults in an independent living facility for the purpose of continuous, in-home gait measurement. In addition, a monthly fall risk assessment protocol was conducted for each resident by a clinician, which included traditional tools such as the timed up a go and habitual gait speed tests. A probabilistic methodology for generating automated gait estimates over time for the residents of the apartments from the Kinect data is described, along with results from the apartments as compared to two of the traditionally measured fall risk assessment tools. Potential applications and future work are discussed. \textcopyright{} 1964-2012 IEEE.},
	issue        = 10,
	keywords     = {Depth camera,Kinect,fall risk,gait},
	pmid         = 23744661
}
@article{Liapis2013,
	title        = {Sentient Sketchbook : Computer-Assisted Game Level Authoring},
	author       = {Antonio Liapis and Georgios N. Yannakakis and Julian Togelius},
	year         = 2013,
	journal      = {8th International Conference on the Foundations of Digital Games}
}
@article{Watling2013,
	title        = {A proposed biogeography of the deep ocean floor},
	author       = {Les Watling and John Guinotte and Malcolm R. Clark and Craig R. Smith},
	year         = 2013,
	journal      = {Progress in Oceanography},
	publisher    = {Elsevier Ltd},
	volume       = 111,
	pages        = {91--112},
	doi          = {10.1016/j.pocean.2012.11.003},
	issn         = {00796611},
	url          = {http://dx.doi.org/10.1016/j.pocean.2012.11.003},
	note         = {Can be useful for later (faune/flore)},
	abstract     = {While there are many generalized schemes representing the biogeographic distribution of life in the deep sea, reviewed here, a comprehensive analysis has not been undertaken since Vinogradova (1979, 1997) for the abyssal and Belyaev (1989) for the hadal. The purpose of this paper is to propose global biogeographic provinces for the lower bathyal and abyssal benthos (>800. m depths) in order to aid high seas management efforts. Biological samples from these depths are sparse so delineation of biogeographic provinces was initially hypothesized using oceanographic proxies, and examined with documented locations of select benthic marine species. These biogeographic provinces were first developed in 2009 via an expert consultation workshop to delineate biogeographic provinces in offshore regions - the Global Open Ocean and Deep Sea (GOODS) classification. We have refined the GOODS deep-sea classification by incorporating additional high-resolution hydrographic and organic-matter flux data for the seafloor. Water mass characteristics (temperature and salinity) and particulate organic flux to the seafloor were the strongest determinants in the final delineation of provincial boundaries. This process resulted in the delineation of 14 lower bathyal and 14 abyssal provinces. The bathyal and abyssal classifications presented here should be used with other management tools and analyses (e.g., predictive habitat modeling, seamount classifications, etc.) to help determine where marine protected areas should be placed and to minimize the negative impacts of commercial activities in the high seas. \textcopyright{} 2012 Elsevier Ltd.}
}
@article{Turnewitsch2013,
	title        = {Deep-sea fluid and sediment dynamics-Influence of hill- to seamount-scale seafloor topography},
	author       = {Robert Turnewitsch and Saeed Falahat and Jonas Nycander and Andrew Dale and Robert B. Scott and Darran Furnival},
	year         = 2013,
	journal      = {Earth-Science Reviews},
	volume       = 127,
	pages        = {203--241},
	doi          = {10.1016/j.earscirev.2013.10.005},
	issn         = {00128252},
	abstract     = {Deep-sea sediments play a central role in a wide range of subject areas. A number of important controls on the formation of sedimentary deposits have been studied. However, to date, the impact of submarine landscape geometry as a possible control has received comparatively little attention. This seems to be particularly true for intermediate-scale topographic features such as abyssal hills, knolls and seamounts that can be found in many regions of the global seafloor: recent estimates suggest that in the deep open oceans, away from continental margins, there might be as many as ~25\texttimes{}106 abyssal hills, knolls and seamounts. Despite this large number very little is known about how they influence environmental complexity and patchiness, biogeochemical fluxes and the formation of sedimentary records. This paper reviews the currently known types of fluid-flow interactions with abyssal hills, knolls and seamounts that could potentially influence the way sediments are formed. The main types of relevant flow components are: quasi-steady to eddying background flow; internal lee and near-inertial waves; barotropic and baroclinic tides; and seamount-trapped waves. Previous studies looking into systematic links between fluid dynamics and sediments at hills, knolls and seamounts are reviewed. Finally, a case study is presented which aims to combine our current knowledge and investigate whether a given combination of recent fluid-flow components leaves a detectable imprint in the recent sediments on and around a short seamount. The main conclusions and implications are as follows. (1) Topographically generated flow-field geometries that are composed of a number of different prevailing fluid-flow components can be reflected and detected in properties of the underlying sediments. (2) Tidal and other higher-frequency (lee-wave, near-inertial) components of deep-ocean currents can be essential for locally driving total current velocities across threshold values for non-deposition/erosion/resuspension of freshly deposited deep-sea sediments. Moreover, there is evidence suggesting that not only maximum current speeds but also intensities of higher-frequency (tidal and/or (near-)inertial) current-direction variability might control sediment dynamics and sediment formation. This relativises the view that current speed is the main, or even only, controlling factor for sediment dynamics and sediment formation. (3) When it comes to the reconstruction of paleo-flows, these findings imply that certain sedimentary records may well reveal more about variability in the higher-frequency flow components than about variability in the basin-scale net flow component that often is the focus of paleoceanographic studies. (4) Single-core paleo-records from hill-, seamount- or similarly controlled sediment deposits may be biased due to the asymmetry of flow fields around these topographic features. To arrive at unbiased paleo-records for non-fluid-dynamic parameters, the influence of the flow-field geometry would have to be removed from the record first. (5) It seems the mechanistic understanding of hill- and seamount-related flow/topography interactions and their links to sediment dynamics is approaching a level that may (a) facilitate improved interpretation of topographically controlled sedimentary paleo-records, (b) help fill in the knowledge gap that exists for functional deep-sea biodiversity at intermediate space scales, and (c) improve predictive capabilities for exploration of economically relevant iron-manganese (Fe-Mn) crusts on seamounts. \textcopyright{} 2013 Elsevier B.V.},
	keywords     = {Abyssal hill,Erosion,Non-deposition,Seamount,Sediment,Tides}
}
@article{Genevaux2013,
	title        = {Terrain generation using procedural models based on hydrology},
	author       = {Jean-David G\'{e}nevaux and \'{E}ric Galin and Eric Gu\'{e}rin and Adrien Peytavie and Bedrich Benes},
	year         = 2013,
	month        = 7,
	journal      = {ACM Transactions on Graphics},
	volume       = 32,
	pages        = {1--13},
	doi          = {10.1145/2461912.2461996},
	issn         = {0730-0301},
	url          = {https://dl.acm.org/doi/10.1145/2461912.2461996},
	abstract     = {<p>We present a framework that allows quick and intuitive modeling of terrains using concepts inspired by hydrology. The terrain is generated from a simple initial sketch, and its generation is controlled by a few parameters. Our terrain representation is both analytic and continuous and can be rendered by using varying levels of detail. The terrain data are stored in a novel data structure: a construction tree whose internal nodes define a combination of operations, and whose leaves represent terrain features. The framework uses rivers as modeling elements, and it first creates a hierarchical drainage network that is represented as a geometric graph over a given input domain. The network is then analyzed to construct watersheds and to characterize the different types and trajectories of rivers. The terrain is finally generated by combining procedural terrain and river patches with blending and carving operators.</p>},
	issue        = 4
}
@phdthesis{Cosmin2013,
	title        = {3D mesh morphing},
	author       = {Bogdan Cosmin},
	year         = 2013
}
@article{Niesner2013,
	title        = {Real-time 3D reconstruction at scale using voxel hashing},
	author       = {Matthias Niesner and Michael Zollh\"{o}fer and Shahram Izadi and Marc Stamminger},
	year         = 2013,
	journal      = {ACM Transactions on Graphics},
	volume       = 32,
	doi          = {10.1145/2508363.2508374},
	issn         = {07300301},
	url          = {https://niessnerlab.org/papers/2013/4hashing/niessner2013hashing.pdf},
	abstract     = {Online 3D reconstruction is gaining newfound interest due to the availability of real-time consumer depth cameras. The basic problem takes live overlapping depth maps as input and incrementally fuses these into a single 3D model. This is challenging particularly when real-time performance is desired without trading quality or scale. We contribute an online system for large and fine scale volumetric reconstruction based on a memory and speed efficient data structure. Our system uses a simple spatial hashing scheme that compresses space, and allows for real-time access and updates of implicit surface data, without the need for a regular or hierarchical grid data structure. Surface data is only stored densely where measurements are observed. Additionally, data can be streamed efficiently in or out of the hash table, allowing for further scalability during sensor motion. We show interactive reconstructions of a variety of scenes, reconstructing both fine-grained details and large scale environments. We illustrate how all parts of our pipeline from depth map pre-processing, camera pose estimation, depth map fusion, and surface rendering are performed at real-time rates on commodity graphics hardware. We conclude with a comparison to current state-of-the-art online systems, illustrating improved performance and reconstruction quality.},
	issue        = 6,
	keywords     = {Data structure,GPU,Real-time reconstruction,Scalable}
}
@phdthesis{Zanni2013,
	title        = {Skeleton-based Implicit Modeling \& Applications},
	author       = {C\'{e}dric Zanni},
	year         = 2013,
	pages        = 168,
	abstract     = {Modeling with skeleton is an attractive alternative to "control points" usually placed outside a shape in order to model it : this paradigm, similar to a wire inside the modeled shape, enables model of arbitrary geometry and topology. In order to do so, shapes defined by skeletons should be able to smoothly blend together. Introduced in computer graphics in the 70's, implicit surfaces are one of the main solution to this problem. They are powerful both for the modeling of 3D models and their animations : their construction from a skeleton and their blending capacity by simply summing their scalar field provide an easy way to incrementally create shapes and store them in a compact way, it also facilitates animation containing changes in topology. Implicit surfaces, and more specifically Convolution surfaces, are therefore particularly well adapted to skeleton-based modeling. However, they present a number of drawback that make them difficult to use in practice. This thesis propose new skeleton-based implicit models, inspired not only by convolution but also from space deformations. They enable : - an easier generation of shape along curve skeletons (arcs of helix), - a better control of generated shape both in term of thickness and blending, in particular our model are scale-invariant that make them more intuitive, - the generation of shape which topology better reflects the topology of its skeleton, - the generation of small details from a procedural texture, the details behave in a coherent way with the underlying surface (and its skeleton).}
}
@article{Hong2013,
	title        = {A skeleton-based technique for modelling implicit surfaces},
	author       = {Qingqi Hong},
	year         = 2013,
	journal      = {Proceedings of the 2013 6th International Congress on Image and Signal Processing, CISP 2013},
	publisher    = {IEEE},
	volume       = 2,
	pages        = {686--691},
	doi          = {10.1109/CISP.2013.6745253},
	isbn         = 9781479927647,
	abstract     = {In this paper, we develop a skeleton-based technique to model implicit surfaces using 2-D piecewise algebraic splines, which allows the construction of generalized cylinders with arbitrary cross-sections. Our method is based on smooth blending of a set of locally constructed general cylinders corresponding to different cross-sections along a given skeleton. Firstly, freeform cross-sections are reconstructed implicitly using the 2-D piecewise algebraic splines, and then, different cross-section profiles are weighted and summed up along the skeleton using the Partial Shape Preserving (PSP) spline basis functions. In addition, the smooth piecewise polynomial blending operations is employed to blend the branches of implicitly constructed generalized cylinders together. The implicit generalized cylinders constructed using our method is model free, and can achieve extremely high smoothness and accuracy. \textcopyright{} 2013 IEEE.},
	issue        = {Cisp},
	keywords     = {Generalized cylinders,Implicit surfaces,Modelling,Skeleton}
}
@article{Carroll2013,
	title        = {Improving Frenet's Frame Using Bishop's Frame},
	author       = {Daniel Carroll and Emek Kose and Ivan Sterling},
	year         = 2013,
	journal      = {Journal of Mathematics Research},
	volume       = 5,
	doi          = {10.5539/jmr.v5n4p97},
	issn         = {1916-9795},
	url          = {https://www.researchgate.net/profile/Ivan-Sterling-2/publication/258840016_Improving_Frenet's_Frame_Using_Bishop's_Frame/links/54dcebbc0cf282895a3b3375/Improving-Frenets-Frame-Using-Bishops-Frame.pdf},
	abstract     = {The main drawback of the Frenet frame is that it is undefined at those points where the curvature is zero. Further- more, in the case of planar curves, the Frenet frame does not agree with the standard framing of curves in the plane. The main drawback of the Bishop frame is that the principle normal vector N is not in it. Our new frame, which we call the Beta frame, combines, on a large set of curves, the best aspects of the Bishop frames and the Frenet frames. It yields a globally defined normal, a globally defined signed curvature, and a globally defined torsion. For planar curves it agrees with the standard framing of curves in the plane.},
	issue        = 4,
	keywords     = {bishop frames,frenet frames}
}
@article{Laurent2013,
	title        = {A parametric method to model 3D displacements around faults with volumetric vector fields},
	author       = {Gautier Laurent and Guillaume Caumon and Antoine Bouziat and Mark Jessell},
	year         = 2013,
	month        = 4,
	journal      = {Tectonophysics},
	volume       = 590,
	pages        = {83--93},
	doi          = {10.1016/J.TECTO.2013.01.015},
	issn         = {00401951},
	abstract     = {This paper presents a 3D parametric fault representation for modeling the displacement field associated with faults in accordance with their geometry. The displacements are modeled in a canonical fault space where the near-field displacement is defined by a small set of parameters consisting of the maximum displacement amplitude and the profiles of attenuation in the surrounding space. The particular geometry and the orientation of the slip of each fault are then taken into account by mapping the actual fault onto its canonical representation. This mapping is obtained with the help of a curvilinear frame aligned both on the fault surface and slip direction.This formulation helps us to include more geological concepts in quantitative subsurface models during 3D structural modeling tasks. Its applicability is demonstrated in the framework of forward modeling and stochastic sequential fault simulations, and the results of our model are compared to observations of natural objects described in the literature. \textcopyright{} 2013 Elsevier B.V.},
	keywords     = {Fault,Kinematics,Parameterization,Structural modeling,Time integration}
}
@article{Lisle2013,
	title        = {A critical look at the Wallace-Bott hypothesis in fault-slip analysis},
	author       = {Richard J. Lisle},
	year         = 2013,
	journal      = {Bulletin de la Societe Geologique de France},
	volume       = 184,
	pages        = {299--306},
	doi          = {10.2113/gssgfbull.184.4-5.299},
	issn         = {00379409},
	url          = {https://d1wqtxts1xzle7.cloudfront.net/32558932/Pub_122_2013_angelier_tribute-with-cover-page-v2.pdf?Expires=1648732786&Signature=L0M4r0k0mzuwSpbQrCnV5op3YzXa51zSUXhbtNgSpGjVyrOteljWOK3cbUeoK7Gi1dAKvV78~KsAKtvGeJ2DeikDSP07ugb1zD7k6i6ouk-biIr8m4B8AG14M3-b4K},
	abstract     = {The assumption is widely made that slip on faults occurs in the direction of maximum resolved shear stress, an assumption known as the Wallace-Bott hypothesis. This assumption is used to theoretically predict slip directions from known in situ stresses, and also as the basis of palaeostress inversion from fault-slip data. This paper examines different situations in relation to the appropriateness of this assumption. Firstly, it is shown that the magnitude of the shear stress resolved within a plane is a function with a poorly defined maximum direction, so that shear stress values greater than 90\% of the maximum occur within a wide angular range (\ss{} 26\textdegree{}) degrees. The situation of simultaneous movement on pairs of faults requires slip on each fault to be parallel to their mutual line of intersection. However, the resolved shear stresses arising from a homogeneous state of stress do not accord with such a slip arrangement except in the case of pairs of perpendicular faults. Where fault surfaces are non-planar, the directions of resolved shear stress in general give, according to the Wallace-Bott hypothesis, a set of slip directions of rigid fault blocks, which is generally kinematically incompatible. Finally, a simple model of a corrugated fault suggests that any anisotropy of the shear strength of the fault such as that arising from fault surface topography, can lead to a significant angular difference between the directions of maximum shear stress and the slip direction. These findings have relevance to the design of procedures used to estimate palaeostresses and the amount of data required for this type of analysis.},
	issue        = {4-5},
	keywords     = {Brittle tectonics,Corrugated fault surfaces,Paleostresses,Slickenlines,Structural analysis}
}
@article{Dunyach2013,
	title        = {Adaptive remeshing for real-time mesh deformation},
	author       = {Marion Dunyach},
	year         = 2013,
	journal      = {Eurographics short \ldots{}},
	pages        = {1--4},
	url          = {http://www.graphics.uni-bielefeld.de/publications/eg13-remeshing.pdf},
	abstract     = {We present an adaptive isotropic remeshing technique that is fast enough to be used in interactive applications, such as mesh deformation or mesh sculpting. Previous real-time remeshing techniques are either not adaptive, hence requiring too many triangles, or make compromises in terms of triangle quality. High quality adaptive remeshing techniques are too slow for interactive applications. In this short paper we present a simple extension of a uniform remeshing approach that results in an efficient, yet high quality, curvature-adaptive remeshing.}
}
@phdthesis{Burt2013,
	title        = {Interactive Evolutionary Computation by Duplication and Diversification of L-Systems},
	author       = {Thomas Burt},
	year         = 2013,
	url          = {http://algorithmicbotany.org/papers/tburt.th2013.small.pdf},
	abstract     = {Buildings with intermittent occupancy may not perform thermally the same as typical commercial and residential facilities. Thermal comfort requirements require careful envelope design coupled with the appropriate air-conditioning system operation strategies. One of the most prominent examples of such buildings is mosques. Mosques are usually occupied five intermittent times day and night all year round. Like any other building, they have to be mechanically air-conditioned to achieve the required thermal comfort for worshippers especially in harsh climatic regions. This paper describes the physical and operating characteristics typical for the intermittently occupied mosques as well as the results of the thermal optimization of a medium size mosque in the two hot-dry and hot-humid Saudi Arabian cities of Riyadh and Jeddah. The analysis utilizes a direct search optimization technique that is coupled to an hourly energy simulation program. Based on that, design guidelines are presented for the optimum thermal performance of mosques in these two cities in addition to other design and operating factors that need to be considered for mosques in general. \textcopyright{} 2009 The Author(s).},
	institution  = {University of Calgary}
}
@article{Yin2013,
	title        = {A practical terrain generation method using sketch map and simple parameters},
	author       = {Hua Fei Yin and Chang Wen Zheng},
	year         = 2013,
	journal      = {IEICE Transactions on Information and Systems},
	volume       = {E96-D},
	pages        = {1836--1844},
	doi          = {10.1587/transinf.E96.D.1836},
	issn         = 17451361,
	url          = {https://www.jstage.jst.go.jp/article/transinf/E96.D/8/E96.D_1836/_pdf/-char/en},
	abstract     = {A procedural terrain generation method is presented in this paper. It uses a user-drawn sketch map, which is a raster image with lines and polygons painted by different colors to represent sketches of different terrain features, as input to control the placement of terrain features. Some simple parameters which can be easily understood and adjusted by users are used to control the generation process. To further automatically generate terrains, a mechanism that automatically generates sketches is also put forward. The method is implemented in a PC, and experiments show that terrains are generated efficiently. This method provides users a controllable way to generate terrains. Copyright \textcopyright{} 2013 The Institute of Electronics, Information and Communication Engineers.},
	issue        = 8,
	keywords     = {Automatic generation,Procedural methods,Terrain generation,Terrain sketch}
}
@article{Dembogurski2013,
	title        = {Interactive Virtual Terrain Generation using Augmented Reality Markers},
	author       = {Renan Augusto Dembogurski and Bruno Jos\'{e} Dembogurski and Jos\'{e} Luiz Ribeiro De Souza Filho and Dhiego Oliveira Sad and Rodrigo De Souza Silva and Marcelo Bernardes Vieira},
	year         = 2013,
	journal      = {Journal on Interactive Systems},
	volume       = 3,
	pages        = 1,
	doi          = {10.5753/jis.2012.619},
	abstract     = {This paper presents an application that allows the generation of virtual terrains interactively, using augmented reality markers. This application also allows the user to navigate in the generated virtual environment. To demonstrate how the process is done, a terrain generation scenario was chosen. Virtual objects were augmented using markers and the detection is done through the ARToolKit framework. A particle system was used to simulate deformation to better incorporate the needs of terrain generation. The deformation itself follows an interparticle force between the particles attached to a movable physical marker and the particles attached to a fixed multi-marker representing the mesh. A viscous force is also used to generate a plastic material effect ensuring permanent deformation. The resulting application although conceptually simple and easy to use, can produce an immersive output environment that the user can freely navigate.},
	issue        = 3,
	keywords     = {2014,a evas\~{a}o em cursos,all content following this,de gamifica\c{c}\~{a}o para diminuir,de gradua\c{c}\~{a}o view project,enhancement of the downloaded,file,page was uploaded by,rodrigo l,s,silva on 25 june,the user has requested}
}
@article{Dobrin2013,
	title        = {A Review of Properties and Variations of Voronoi Diagrams},
	author       = {Adam Dobrin},
	year         = 2013,
	journal      = {World Applied Sciences Journal},
	volume       = 21,
	pages        = {21--29},
	doi          = {10.5829/idosi.wasj.2013.21.1.71197},
	issn         = 18184952,
	url          = {https://www.whitman.edu/documents/academics/mathematics/dobrinat.pdf},
	abstract     = {The aims of this study were to detect the presence of impacted lower mandibular third molars (IW) and the medical complications among outpatients at Taif Uni. KSA, throughout (2012). The study was concerned with the determination of type of impaction, physical signs and predominant microorganisms. The examined complained students (No.=113) with age (18-26yrs.), were subjected for clinical, dental and microbial examinations. Total impacted wisdoms (IW) were 49.6\%. According to the site, (Uni. and Bi.) had prevalence of 67.9 and 32.1\%, respectively. According to the position, (MA. and V.) displayed incidence of 64.3 and 35.7\%, respectively. The most common complaints were pain 76.8\%, pericoronitis 62.5\%, periodontal pocketing 57.1\%, trismus 51.8\%, cheek biting 39.3\%, cellulitis 32.1\% and abscess formation 19.6\%. The accompanied vital signs were septic S.T. 55.4\%, lymphadenitis 76.8\% and fever 66.1\%. The aerobic and facultative anaerobic isolates were Strept. Viridans, Corynebacterium spp. Haemophilus spp. Strept. mutans, CNS, Staph. aureus, Strept. pneumoniae, E. coli, Strept. pyogenes and Pseudomonas spp.. with incidence of 90.5, 60.8, 56.8, 52.7, 45.9, 25.7, 23, 23, 14.9 and 10.8\% and anaerobic isolates were Prevotella spp. Fusobacterium spp. Actinomyces spp. Bacteroides spp. Lactobacillus spp. Campylobacter spp. and Clostridium spp. had incidence of 98.6, 90.5, 81.1, 81.1, 70.3, 54 and 41.9\% respectively. \textcopyright{} IDOSI Publications, 2013.},
	issue        = 1,
	keywords     = {Fever,Impacted Wisdom,Pericoronitis,Periodontal,Septic S. T. Lymphadenitis,Trismus}
}
@article{Ni2013,
	title        = {A new logistic dynamic particle swarm optimization algorithm based on random topology},
	author       = {Qingjian Ni and Jianming Deng},
	year         = 2013,
	journal      = {The Scientific World Journal},
	volume       = 2013,
	doi          = {10.1155/2013/409167},
	issn         = {1537744X},
	abstract     = {Population topology of particle swarm optimization (PSO) will directly affect the dissemination of optimal information during the evolutionary process and will have a significant impact on the performance of PSO. Classic static population topologies are usually used in PSO, such as fully connected topology, ring topology, star topology, and square topology. In this paper, the performance of PSO with the proposed random topologies is analyzed, and the relationship between population topology and the performance of PSO is also explored from the perspective of graph theory characteristics in population topologies. Further, in a relatively new PSO variant which named logistic dynamic particle optimization, an extensive simulation study is presented to discuss the effectiveness of the random topology and the design strategies of population topology. Finally, the experimental data are analyzed and discussed. And about the design and use of population topology on PSO, some useful conclusions are proposed which can provide a basis for further discussion and research. \textcopyright{} 2013 Qingjian Ni and Jianming Deng.},
	pmid         = 23818820
}
@article{Lidal2013,
	title        = {Geological storytelling},
	author       = {Endre M. Lidal and Mattia Natali and Daniel Patel and Helwig Hauser and Ivan Viola},
	year         = 2013,
	journal      = {Computers and Graphics (Pergamon)},
	publisher    = {Elsevier},
	volume       = 37,
	pages        = {445--459},
	doi          = {10.1016/j.cag.2013.01.010},
	issn         = {00978493},
	url          = {http://dx.doi.org/10.1016/j.cag.2013.01.010},
	abstract     = {Developing structural geological models from exploratory subsea imaging is difficult and an ill-posed process. The structural geological processes that take place in the subsurface are both complex and time-dependent. We present Geological Storytelling, a novel graphical system for performing rapid and expressive geomodeling. Geologists can convey geological stories that externalize both their model and the reasoning process behind it through our simple, yet expressive sketch-based, flip-over canvases. This rapid modeling interface makes it easy to construct a large variety of geological stories, and our story tree concept facilitates easy management and the exploration of these alternatives. The stories are then animated and the geologists can examine and compare them to identify the most plausible models. Finally, the geological stories can be presented as illustrative animations of automatically synthesized 3D models, which efficiently communicate the complex geological evolution to non-experts and decision makers. Geological storytelling provides a complete pipeline from the ideas and knowledge in the mind of the geologist, through externalized artifacts specialized for discussion and knowledge dissemination among peer-experts, to automatically rendered illustrative 3D animations for communication to lay audience. We have developed geological storytelling in collaboration with domain experts that work with the modeling challenges on a daily basis. For evaluation, we have developed a geological storytelling prototype and presented it to experts and academics from the geosciences. In their feedback, they acknowledge that the rapid and expressive sketching of stories can make them explore more alternatives and that the 3D illustrative animations assist in communicating their models. \textcopyright{} 2013 Elsevier Ltd.},
	issue        = 5,
	keywords     = {3D model synthesis,Alternatives exploration,Animation,Externalization of mental processes,Geology,Sketch-based modeling,Storytelling,Structural geological models}
}
@article{Gourmel2013,
	title        = {A gradient-based implicit blend},
	author       = {Olivier Gourmel and Loic Barthe and Marie-Paule Cani and Brian Wyvill and Adrien Bernhardt and Mathias Paulin and Herbert Grasberger},
	year         = 2013,
	month        = 4,
	journal      = {ACM Transactions on Graphics},
	volume       = 32,
	pages        = {1--12},
	doi          = {10.1145/2451236.2451238},
	issn         = {0730-0301},
	url          = {https://dl.acm.org/doi/10.1145/2451236.2451238},
	abstract     = {<p> We introduce a new family of binary composition operators that solves four major problems of constructive implicit modeling: suppressing bulges when two shapes merge, avoiding unwanted blending at a distance, ensuring that the resulting shape keeps the topology of the union, and enabling sharp details to be added without being blown up. The key idea is that field functions should not only be combined based on their values, but also on their <italic>gradients</italic> . We implement this idea through a family of <italic>C</italic> <sup>\infty{}</sup> composition operators evaluated on the GPU for efficiency, and illustrate it by applications to constructive modeling and animation. </p>},
	issue        = 2
}
@article{Huang2013,
	title        = {Intersection-free and topologically faithful slicing of implicit solid},
	author       = {Pu Huang and Charlie C.L. Wang and Yong Chen},
	year         = 2013,
	journal      = {Journal of Computing and Information Science in Engineering},
	volume       = 13,
	doi          = {10.1115/1.4024067},
	issn         = 15309827,
	url          = {https://mewangcl.github.io/pubs/JCISEImpSlicing.pdf},
	abstract     = {We present a robust and efficient approach to directly slicing implicit solids. Different from prior slicing techniques that reconstruct contours on the slicing plane by tracing the topology of intersected line segments, which is actually not robust, we generate contours by a topology guaranteed contour extraction on binary images sampled from given solids and a subsequent contour simplification algorithm which has the topology preserved and the geometric error controlled. The resultant contours are free of self-intersection, topologically faithful to the given r-regular solids and with shape error bounded. Therefore, correct objects can be fabricated from them by rapid prototyping. Moreover, since we do not need to generate the tessellated B-rep of given solids, the memory cost our approach is low - only the binary image and the finest contours on one particular slicing plane need to be stored in-core. Our method is general and can be applied to any implicit representations of solids. Copyright \textcopyright{} 2013 by ASME.},
	issue        = 2,
	keywords     = {Direct slicing,Implicit representation,Self-intersection free,Solid,Topologically faithful}
}
@article{Canezin2013,
	title        = {Adequate inner bound for geometric modeling with compact field functions},
	author       = {Florian Canezin and Ga\"{e}l Guennebaud and Lo\"{\i}c Barthe},
	year         = 2013,
	journal      = {Computers and Graphics (Pergamon)},
	volume       = 37,
	pages        = {565--573},
	doi          = {10.1016/j.cag.2013.05.024},
	issn         = {00978493},
	url          = {https://www.irit.fr/recherches/VORTEX/publications/rendu-geometrie/SMI2013_Canezin_et_al.pdf},
	abstract     = {Recent advances in implicit surface modeling now provide highly controllable blending effects. These effects rely on the field functions of R3\rightarrow{}R in which the implicit surfaces are defined. In these fields, there is an outside part in which blending is defined and an inside part. The implicit surface is the interface between these two parts. As recent operators often focus on blending, most efforts have been made on the outer part of field functions and little attention has been paid on the inner part. Yet, the inner fields are important as soon as difference and intersection operators are used. This makes its quality as crucial as the quality of the outside. In this paper, we analyze these shortcomings, and deduce new constraints on field functions such that differences and intersections can be seamlessly applied without introducing discontinuities or field distortions. In particular, we show how to adapt state of the art gradient-based union and blending operators to our new constraints. Our approach enables a precise control of the shape of both the inner or outer field boundaries. We also introduce a new set of asymmetric operators tailored for the modeling of fine details while preserving the integrity of the resulting fields. \textcopyright{} 2013 Elsevier Ltd.},
	issue        = 6,
	keywords     = {Blending,CSG,Composition operators,Details,Field functions,Geometric modeling,Implicit surfaces}
}
@article{Vaillant2013,
	title        = {Implicit skinning: Real-time skin deformation with contact modeling},
	author       = {Rodolphe Vaillant and Lo\"{\i}c Barthe and Ga\"{e}l Guennebaud and Marie Paule Cani and Damien Rohmer and Brian Wyvill and Olivier Gourmel and Mathias Paulin},
	year         = 2013,
	journal      = {ACM Transactions on Graphics},
	volume       = 32,
	doi          = {10.1145/2461912.2461960},
	issn         = {07300301},
	url          = {http://rodolphe-vaillant.fr/pivotx/templates/projects/implicit_skinning/implicit_skinning.pdf},
	abstract     = {Geometric skinning techniques, such as smooth blending or dualquaternions, are very popular in the industry for their high performances, but fail to mimic realistic deformations. Other methods make use of physical simulation or control volume to better capture the skin behavior, yet they cannot deliver real-time feedback. In this paper, we present the first purely geometric method handling skin contact effects and muscular bulges in real-time. The insight is to exploit the advanced composition mechanism of volumetric, implicit representations for correcting the results of geometric skinning techniques. The mesh is first approximated by a set of implicit surfaces. At each animation step, these surfaces are combined in real-time and used to adjust the position of mesh vertices, starting from their smooth skinning position. This deformation step is done without any loss of detail and seamlessly handles contacts between skin parts. As it acts as a post-process, our method fits well into the standard animation pipeline. Moreover, it requires no intensive computation step such as collision detection, and therefore provides real-time performances. Copyright \textcopyright{} ACM. Copyright \textcopyright{} ACM 2013.},
	issue        = 4,
	keywords     = {Mesh deformation with contact,Skinning}
}
@article{Teh2013,
	title        = {A Global Estimate of the Number of Coral Reef Fishers},
	author       = {Louise S.L. Teh and Lydia C.L. Teh and U. Rashid Sumaila},
	year         = 2013,
	journal      = {PLoS ONE},
	volume       = 8,
	doi          = {10.1371/journal.pone.0065397},
	issn         = 19326203,
	abstract     = {Overfishing threatens coral reefs worldwide, yet there is no reliable estimate on the number of reef fishers globally. We address this data gap by quantifying the number of reef fishers on a global scale, using two approaches - the first estimates reef fishers as a proportion of the total number of marine fishers in a country, based on the ratio of reef-related to total marine fish landed values. The second estimates reef fishers as a function of coral reef area, rural coastal population, and fishing pressure. In total, we find that there are 6 million reef fishers in 99 reef countries and territories worldwide, of which at least 25\% are reef gleaners. Our estimates are an improvement over most existing fisher population statistics, which tend to omit accounting for gleaners and reef fishers. Our results suggest that slightly over a quarter of the world's small-scale fishers fish on coral reefs, and half of all coral reef fishers are in Southeast Asia. Coral reefs evidently support the socio-economic well-being of numerous coastal communities. By quantifying the number of people who are employed as reef fishers, we provide decision-makers with an important input into planning for sustainable coral reef fisheries at the appropriate scale. \textcopyright{} 2013 Teh et al.},
	issue        = 6,
	pmid         = 23840327
}
@article{Terry2013,
	title        = {One hundred and thirty years since Darwin: `Reshaping' the theory of atoll formation},
	author       = {James P Terry and James Goff},
	year         = 2013,
	month        = 4,
	journal      = {The Holocene},
	volume       = 23,
	pages        = {615--619},
	doi          = {10.1177/0959683612463101},
	issn         = {0959-6836},
	url          = {http://journals.sagepub.com/doi/10.1177/0959683612463101},
	abstract     = {<p>April 2012 marked the 130th anniversary of the death of Charles Darwin. One of many significant contributions he made to science was the subsidence theory of atoll formation, which he penned on 12 April 1836 during the voyage of the Beagle through the Pacific. Darwin's elegant theory, founded on the premise of a subsiding volcano and the corresponding upward growth of coral reef, was astonishing for the time considering the absence of an underpinning awareness of plate tectonics. His theory has endured until modern times in spite of a number of opposing ideas and permutations and has an enviable longevity amongst paradigms in geomorphology. Darwin frequently alluded to the generally circular morphology of the atoll shape, yet the reality is that many atolls are neither circular nor elliptical, instead possessing irregular morphologies. In particular, many exhibit major arcuate `bight-like' structures (ABLS) in their plan form. These departures from the circular form are indicative of geomorphological processes that cannot be ignored. ABLS are the morphological expression of large submarine failures that are common on the slopes of volcanic edifices. Such failures can occur during any stage of atoll formation and are a valuable addition to Darwin's theory because they indicate the instability of the volcanic foundations. Moreover, ABLS have fundamental implications for hazard research in the context of oceanic islands. Not only does our extension to the theory explain the diversity of atoll shape, but it also provides a mechanism for identifying a vast number of potential local tsunamigenic sources, which is critical for advancing modern understanding of tsunami hazards in oceanic environments.</p>},
	issue        = 4
}
@article{Rogers2013,
	title        = {Hydrodynamics of spur and groove formations on a coral reef},
	author       = {Justin S. Rogers and Stephen G. Monismith and Falk Feddersen and Curt D. Storlazzi},
	year         = 2013,
	month        = 6,
	journal      = {Journal of Geophysical Research: Oceans},
	volume       = 118,
	pages        = {3059--3073},
	doi          = {10.1002/jgrc.20225},
	issn         = {2169-9275},
	url          = {https://agupubs.onlinelibrary.wiley.com/doi/10.1002/jgrc.20225},
	abstract     = {Spur and groove (SAG) formations are found on the fore reefs of many coral reefs worldwide. Although these formations are primarily present in wave-dominated environments, their effect on wave-driven hydrodynamics is not well understood. A two-dimensional, depth-averaged, phase-resolving nonlinear Boussinesq model ( funwaveC) was used to model hydrodynamics on a simplified SAG system. The modeling results show that the SAG formations together with shoaling waves induce a nearshore Lagrangian circulation pattern of counter-rotating circulation cells. The mechanism driving the modeled flow is an alongshore imbalance between the pressure gradient (PG) and nonlinear wave (NLW) terms in the momentum balance. Variations in model parameters suggest the strongest factors affecting circulation include spur-normal waves, increased wave height, weak alongshore currents, increased spur height, and decreased bottom drag. The modeled circulation is consistent with a simple scaling analysis based on the dynamical balance of NLW, PG, and bottom stress terms. Model results indicate that the SAG formations efficiently drive circulation cells when the alongshore SAG wavelength allows for the effects of diffraction to create alongshore differences in wave height without changing the mean wave angle.},
	issue        = 6
}
@article{Prusinkiewicz2013,
	title        = {Modeling morphogenesis in multicellular structures with cell complexes and L-systems},
	author       = {Przemyslaw Prusinkiewicz and Brendan Lane},
	year         = 2013,
	journal      = {Springer Proceedings in Mathematics},
	volume       = 15,
	pages        = {137--151},
	doi          = {10.1007/978-3-642-20164-6_12},
	issn         = 21905614,
	url          = {http://algorithmicbotany.org/papers/complexes.pfm2012.pdf},
	abstract     = {We consider computational modeling of biological systems that consist of discrete components arranged into linear structures. As time advances, these components may process information, communicate and divide. We show that: (1) the topological notion of cell complexes provides a useful framework for simulating information processing and flow between components; (2) an indexfree notation exploiting topological adjacencies in the structure is needed to conveniently model structures in which the number of components changes (for example, due to cell division); and (3) Lindenmayer systems operating on cell complexes combine the above elements in the case of linear structures. These observations provide guidance for constructing L-systems and explain their modeling power. Lsystems operating on cell complexes are illustrated by revisiting models of heterocyst formation in Anabaena and by presenting a simple model of leaf development focused on the morphogenetic role of the leaf margin. \textcopyright{} Springer-Verlag Berlin Heidelberg 2013.},
	issue        = 1
}
@phdthesis{Kingon2013,
	title        = {Mapping, classification, and spatial variation of hardbottom habitats in the northeastern Gulf of Mexico},
	author       = {Kelly Kingon},
	year         = 2013,
	isbn         = 9781303433153,
	url          = {https://search.proquest.com/docview/1468443256?accountid=6180%0Ahttp://dw2zn6fm9z.search.serialssolution.com?ctx_ver=Z39.88-2004&ctx_enc=info:ofi/enc:UTF-8&rfr_id=info:sid/ProQuest+Dissertations+%26+Theses+Global&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertat},
	abstract     = {This dissertation starts by evaluating the applicability of using a commercially available, cost-effective, sidescan sonar system to detect benthic habitats, in particular hardbottom habitats, in the nearshore northeastern Gulf of Mexico. To illustrate the capability of low-cost devices in mapping benthic habitats, I tested the Humminbird 997c SI unit marketed to fishermen at a cost of approximately ,000) Marine Sonic system. This analysis verified that the classification results of sand and hardbottom habitats based on data collected using the Humminbird sidescan system were similar to those produced using the traditional and more expensive Marine Sonic sidescan equipment. Thirty-three sites in total were then mapped with the Humminbird system and sampled using dive surveys. Seascape pattern metrics were calculated from the classified Humminbird sidescan maps. The dive survey data included measurements of the geomorphology, physical attributes of the water column (e.g. temperature, depth, and visibility), and coverage and heights of the benthic biota. The coverage and heights of the biota were compared to the geomorphology, seascape, and water column variables to identify patterns in the distribution and community composition of the sessile organisms. Within the study area, visibility was found to vary with longitude. Sites in the east showed higher visibility than sites in the west and this may be driving the community patterns that were identified. Relationships were identified between the four most abundant taxa (sponges, hard corals, brown algae, and red algae) and the geomorphology, physical, and seascape variables. However, the relationships were often complicated and the biota did not strictly follow gradients or boundaries in substrate or geoform (physical feature or landform), even though these features are often used to classify habitats and biotopes. The percent cover of rock was a significant geomorphology variable for red algae and hard coral coverage while geoforms were related to the heights of sponges and brown algae. Seascape metrics also had significant effects on the sessile biota particularly related to patch edges, heterogeneity, core areas, nearest neighbor distances, and the percent cover of hardbottom. Despite the fact that sessile organisms do not move much, if at all following their planktonic larval stage, the surrounding seascape contributes to the patterns we see in their distribution, coverage, and heights. The third chapter focuses on applying a new classification standard to the benthic habitats in the nearshore northeastern Gulf of Mexico. The United States Geological Survey (USGS) has a standardized system for classifying terrestrial and aquatic habitats found across the U.S. which has been in place for almost 40 years. This classification standard does not include marine and most coastal habitats. Therefore, marine researchers developed a number of classification systems for coastal and marine habitats relevant to their local or regional studies in U.S. waters. A national standardized method for classifying marine and coastal habitats was not adopted until recently. The Coastal and Marine Ecological Classification Standard (CMECS) developed by the Federal Geographic Data Committee was approved last year and is intended to fill the gap in U.S. marine habitat classification standards. Since the classification standard is in its infancy, it has not been applied in many geographic areas. My third chapter is the first study to apply the CMECS to the benthic habitats in the nearshore northeastern Gulf of Mexico off the coast of northwest Florida. Hardbottom and sand habitats are characteristic of this area. In the previous chapter, the underwater surveys revealed that the dominant taxa at the sites within the study area were hard corals, sponges, and macroalgae. I used CMECS to broadly classify the sites where the surveys were completed. I found that habitat heterogeneity and a wide variety of environmental characteristics influenced the distribution of taxa at the local scale. This made applying CMECS at scales finer than the composite study area unfeasible without major modifications. CMECS worked well for classifying the broad scale in this region but was not appropriate for classifying complex fine-scale biotopes. (Abstract shortened by UMI.)},
	institution  = {Florida State University},
	keywords     = {0329:Ecology,0368:Physical geography,0799:Remote sensing,Biological sciences,Classification systems,Earth sciences,Ecology,Gulf of Mexico,Hardbottom,Physical geography,Remote sensing,Sessile biota,Sidescan sonar,Spatial analysis}
}
@article{Pytel2013,
	title        = {Self-organized approach to modeling hydraulic erosion features},
	author       = {Alexei Pytel and Stephen Mann},
	year         = 2013,
	journal      = {Computers and Graphics (Pergamon)},
	publisher    = {Elsevier},
	volume       = 37,
	pages        = {280--292},
	doi          = {10.1016/j.cag.2013.01.006},
	issn         = {00978493},
	url          = {http://dx.doi.org/10.1016/j.cag.2013.01.006},
	abstract     = {A simulation of the effects of hydraulic erosion should generate realistic fractal character and exhibit certain high-level behavior, such as tributary capture. Our simulation method is able to achieve these goals in an emergent way by using a variant of avalanching, which is a principle followed by many physical self-organized systems. We also use the same approach to generate initial conditions for the erosion, so that the combined algorithm is a complete terrain modeling method based only on self-organization.},
	issue        = 4,
	keywords     = {Hydraulic erosion,Procedural modeling,Terrain modeling}
}
@techreport{Pfeifer2013,
	title        = {Cellular automata - Dynamical systems},
	author       = {Rolf Pfeifer and Rudolf M F\"{u}chslin},
	year         = 2013
}
@article{Chng2013,
	title        = {Model resolution in complex systems simulation: Agent preferences, behavior, dynamics and n-tiered networks},
	author       = {Eugene Ch'ng},
	year         = 2013,
	month        = 5,
	journal      = {SIMULATION},
	volume       = 89,
	pages        = {635--659},
	doi          = {10.1177/0037549712470582},
	issn         = {0037-5497},
	url          = {http://journals.sagepub.com/doi/10.1177/0037549712470582},
	abstract     = {Agent-based modeling is a process of representing and simulating the intentions, behaviors and actions of complex systems with the goal of understanding specific phenomena related to the communications within complex systems that produce emergent behavior and self-organization, or for predicting spatial or behavioral patterns of individuals or groups of interacting entities. Agent-based modeling, also termed multi-agent systems, or in ecological simulation, individual-based models, spans simple to highly complex systems; their interactions can be difficult to implement and optimize programmatically, particularly when there could be hundreds of thousands of agents within a community that have multiple levels of communication. The resolution and the scale of simulation is an especially important component that could determine the accuracy of the models. This article focuses on the model resolution of complex systems, facilitated by an object-oriented communications framework, a foundation for the simulation of the fine resolution of the dynamics, behavior, preferences, interaction and n-tiered trophic networks, including the simulated environments they inhabit. It dissects individual agents with a view to modeling and simulating fine behaviors amongst a population of agent types in n-tiered networks, scalable to hundreds of thousands of species using mathematically defined behavior, efficient algorithms and adaptive data structures as support for the simulations.},
	issue        = 5,
	keywords     = {agent-based systems,artificial life,complexity,modeling and simulation environments,simulation system architecture}
}
@inproceedings{VanDerLinden2013,
	title        = {Designing Procedurally Generated Levels},
	author       = {Roland Van Der Linden and Ricardo Lopes and Rafael Bidarra},
	year         = 2013,
	booktitle    = {Proceedings of IDPv2 2013 - Workshop on Artificial Intelligence in the Game Design Process, co-located with the Ninth AAAI Conference on Artificial Intelligence in Interactive Digital Entertainment},
	url          = {www.aaai.org},
	abstract     = {There is an increasing demand to improve the procedural generation of game levels. Our approach empowers game designers to author and control level generators, by expressing gameplay-related design constraints. Graph grammars, resulting from these designer-expressed constraints, can generate sequences of desired player actions as well as their associated target content. These action graphs are used to determine layouts and content for game levels. We showcase this approach with a case study on a dungeon crawler game. Results allow us to conclude that our control mechanisms are both expressive and powerful, effectively supporting designers to procedurally generate levels.},
	keywords     = {AAAI Technical Report WS-13-20}
}
@article{Musialski2013,
	title        = {A Survey of Urban Reconstruction},
	author       = {P. Musialski and P. Wonka and D. G. Aliaga and M. Wimmer and L. van Gool and W. Purgathofer},
	year         = 2013,
	month        = 9,
	journal      = {Computer Graphics Forum},
	volume       = 32,
	pages        = {146--177},
	doi          = {10.1111/cgf.12077},
	issn         = {0167-7055},
	url          = {https://onlinelibrary.wiley.com/doi/10.1111/cgf.12077},
	abstract     = {<p>This paper provides a comprehensive overview of urban reconstruction. While there exists a considerable body of literature, this topic is still under active research. The work reviewed in this survey stems from the following three research communities: computer graphics, computer vision and photogrammetry and remote sensing. Our goal is to provide a survey that will help researchers to better position their own work in the context of existing solutions, and to help newcomers and practitioners in computer graphics to quickly gain an overview of this vast field. Further, we would like to bring the mentioned research communities to even more interdisciplinary work, since the reconstruction problem itself is by far not solved.</p>},
	issue        = 6
}
@book{Bertin2013,
	title        = {S\'{e}miologie graphique: Les diagrammes, les r\'{e}seaux, les cartes},
	author       = {Jacques Bertin},
	year         = 2013,
	pages        = 452,
	isbn         = {978-2713224171},
	editor       = {Editions de l'Ecole des Hautes Etudes en Sciences Sociales}
}
@misc{Ramalho2013,
	title        = {Coastal evolution on volcanic oceanic islands: A complex interplay between volcanism, erosion, sedimentation, sea-level change and biogenic production},
	author       = {Ricardo S. Ramalho and Rui Quartau and Alan S. Trenhaile and Neil C. Mitchell and Colin D. Woodroffe and S\'{e}rgio P. \'{A}vila},
	year         = 2013,
	month        = 12,
	journal      = {Earth-Science Reviews},
	volume       = 127,
	pages        = {140--170},
	doi          = {10.1016/j.earscirev.2013.10.007},
	issn         = {00128252},
	abstract     = {The growth and decay of oceanic hotspot volcanoes are intrinsically related to a competition between volcanic construction and erosive destruction, and coastlines are at the forefront of such confrontation. In this paper, we review the several mechanisms that interact and contribute to the development of coastlines on oceanic island volcanoes, and how these processes evolve throughout the islands' lifetime. Volcanic constructional processes dominate during the emergent island and subaerial shield-building stages. During the emergent island stage, surtseyan activity prevails and hydroclastic and pyroclastic structures form; these structures are generally ephemeral because they can be rapidly obliterated by marine erosion. With the onset of the subaerial shield-building stage, coastal evolution is essentially characterized by rapid but intermittent lateral growth through the formation of lava deltas, largely expanding the coastlines until they, typically, reach their maximum extension. With the post-shield quiescence in volcanic activity, destructive processes gradually take over and coastlines retreat, adopting a more prominent profile; mass wasting and marine and fluvial erosion reshape the landscape and, if conditions are favorable, biogenic processes assume a prominent role. Post-erosional volcanic activity may temporarily reverse the balance by renewing coastline expansion, but islands inexorably enter in a long battle for survival above sea level. Reef growth and/or uplift may also prolong the island's lifetime above the waves. The ultimate fate of most islands, however, is to be drowned through subsidence and/or truncation by marine erosion. \textcopyright{} 2013 Elsevier B.V.},
	keywords     = {Coastal evolution,Erosion,Oceanic island volcanoes,Sea-level change,Sedimentation,Volcanism}
}
@techreport{Cline2013,
	title        = {Fluid flow for the rest of us: Tutorial of the marker and cell method in computer graphics},
	author       = {David Cline and Parris K Egbert and David Cardon},
	year         = 2013,
	url          = {https://www.researchgate.net/publication/228964362},
	abstract     = {Understanding how fluid is modeled for computer graphics can be a challenge. This is especially true for students who have not taken courses in vector calculus and differential equations, or are rusty in these subjects. Beginning students tend to get bogged down in the notation of the Navier-Stokes equations and the inevitable difficulties that arise when trying to discretize them. Despite this fact, we will attempt to show that, given a little instruction, building a complete fluid simulator is actually fairly straightforward.}
}
@article{Weier2013,
	title        = {Generating and Rendering Large Scale Tiled Plant Populations},
	author       = {Martin Weier and Andr\'{e} Hinkenjann and Georg Demme and Philipp Slusallek},
	year         = 2013,
	journal      = {Journal of Virtual Reality and Broadcasting},
	volume       = 10,
	doi          = {10.20385/1860-2037/10.2013.1},
	isbn         = {1860-2037},
	url          = {www:http://vc.inf.h-brs.de†www:http://www.dfki.de/‡www:http://www.dfki.de/},
	abstract     = {Generating and visualizing large areas of vegetation that look natural makes terrain surfaces much more realistic. However, this is a challenging field in computer graphics, because ecological systems are complex and visually appealing plant models are geometrically detailed. This work presents Silva (System for the Instantiation of Large Vegetated Areas), a system to generate and visualize large vegetated areas based on the ecological surrounding. Silva generates vegetation on Wang-tiles with associated reusable distri},
	issue        = 1,
	keywords     = {Ecosystem,In-stantiation,Poisson Disc Distribution,Ray Tracing,Terrain render-ing,Wang-tiles,simulation}
}
@techreport{Weier2013,
	title        = {Generating and Rendering Large Scale Tiled Plant Populations},
	author       = {Martin Weier and Andr\'{e} Hinkenjann and Georg Demme and Philipp Slusallek},
	year         = 2013,
	journal      = {Journal of Virtual Reality and Broadcasting},
	volume       = 10,
	doi          = {https://doi.org/10.20385/1860-2037/10.2013.1},
	url          = {www:http://vc.inf.h-brs.de†www:http://www.dfki.de/‡www:http://www.dfki.de/},
	abstract     = {Generating and visualizing large areas of vegetation that look natural makes terrain surfaces much more realistic. However, this is a challenging field in computer graphics, because ecological systems are complex and visually appealing plant models are geometrically detailed. This work presents Silva (System for the Instantiation of Large Vegetated Areas), a system to generate and visualize large vegetated areas based on the ecological surrounding. Silva generates vegetation on Wang-tiles with associated reusable distri},
	issue        = 1,
	keywords     = {Ecosystem,In-stantiation,Poisson Disc Distribution,Ray Tracing,Terrain render-ing,Wang-tiles,simulation}
}
@inproceedings{Nescher2014,
	title        = {Planning redirection techniques for optimal free walking experience using model predictive control},
	author       = {Thomas Nescher and Ying Yin Huang and Andreas Kunz},
	year         = 2014,
	booktitle    = {IEEE Symposium on 3D User Interfaces 2014, 3DUI 2014 - Proceedings},
	publisher    = {IEEE Computer Society},
	pages        = {111--118},
	doi          = {10.1109/3DUI.2014.6798851},
	abstract     = {RedirectedWalking (RDW) is a technique that allows exploring immersive virtual environments by real walking in a small physical room. RDW employs so-called redirection techniques (RETs) to manipulate the user's real world trajectory in such a way that he remains within the boundaries of the physical room. Different RETs were suggested and evaluated in the past. In addition, steering algorithms were proposed that apply a limited set of RETs to redirect a user away from the physical room's boundaries. \textcopyright{} 2014 IEEE.},
	keywords     = {Redirected walking,Virtual reality,locomotion,model predictive control,optimal control,redirection techniques}
}
@article{Buys2014,
	title        = {An adaptable system for RGB-D based human body detection and pose estimation},
	author       = {Koen Buys and Cedric Cagniart and Anatoly Baksheev and Tinne De Laet and Joris De Schutter and Caroline Pantofaru},
	year         = 2014,
	month        = 1,
	journal      = {Journal of Visual Communication and Image Representation},
	volume       = 25,
	pages        = {39--52},
	doi          = {10.1016/j.jvcir.2013.03.011},
	issn         = 10473203,
	abstract     = {Human body detection and pose estimation is useful for a wide variety of applications and environments. Therefore a human body detection and pose estimation system must be adaptable and customizable. This paper presents such a system that extracts skeletons from RGB-D sensor data. The system adapts on-line to difficult unstructured scenes taken from a moving camera (since it does not require background subtraction) and benefits from using both color and depth data. It is customizable by virtue of requiring less training data, having a clearly described training method, and a customizable human kinematic model. Results show successful application to data from a moving camera in cluttered indoor environments. This system is open-source, encouraging reuse, comparison, and future research. \textcopyright{} 2013 Elsevier Inc. All rights reserved.},
	issue        = 1,
	keywords     = {Body part recognition,Joint locations,Motion capture,Open source,Person detection,Pose detection,RGB-D data,Random decision forest,Real-time}
}
@article{Guan2014,
	title        = {Compressive classification of human motion using pyroelectric infrared sensors},
	author       = {Qiuju Guan and Caiyong Li and Xuemei Guo and Guoli Wang},
	year         = 2014,
	month        = 11,
	journal      = {Pattern Recognition Letters},
	publisher    = {Elsevier},
	volume       = 49,
	pages        = {231--237},
	doi          = {10.1016/j.patrec.2014.07.018},
	issn         = {01678655},
	abstract     = {Vision-based approaches have been widely applied in motion classification. However, their applicability is often limited by much higher data-loads and computational costs, particularly in the case of constrained recourses. In this paper, a compressive sensing based approach is investigated for motion classification by using pyroelectric infrared (PIR) sensors. We represent a human motion as a spatio-temporal energy sequence (STES) and extract it from an infrared radiation domain. To generate this sequence, a mask is used to divide the object space into small meshes, from which the human-motion induced variances in the infrared radiation will be used to construct a feature. Because of the sparsity of STES, a hardware prototype that is composed of a PIR sensor array and a visibility mask is designed for measuring STES compressively, and a nearest neighbor classifier is then used for classification in the compressive measurement domain. To evaluate the proposed approach, we recorded 360 compressive STESs of ten aerobic exercises performed by six persons. Encouraging experimental results validate the feasibility and efficacy of our approach. \textcopyright{} 2014 Elsevier B.V. All rights reserved.},
	keywords     = {Compressive sensing,Human behavior understanding,Motion classification,Pyroelectric infrared sensors}
}
@article{VanderLinden2014,
	title        = {Procedural Generation of Dungeons},
	author       = {Roland van der Linden and Ricardo Lopes and Rafael Bidarra},
	year         = 2014,
	journal      = {IEEE Transactions on Computational Intelligence and AI in Games},
	volume       = 6,
	url          = {https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8782107},
	issue        = 1
}
@article{Sloot2014,
	title        = {Self-paced versus fixed speed treadmill walking},
	author       = {L. H. Sloot and M. M. van der Krogt and J. Harlaar},
	year         = 2014,
	month        = 1,
	journal      = {Gait and Posture},
	publisher    = {Elsevier},
	volume       = 39,
	pages        = {478--484},
	doi          = {10.1016/j.gaitpost.2013.08.022},
	issn         = {09666362},
	abstract     = {Instrumented treadmills are increasingly used in gait research, although the imposed walking speed is suggested to affect gait performance. A feedback-controlled treadmill that allows subjects to walk at their preferred speed, i.e. functioning in a self-paced (SP) mode, might be an attractive alternative, but could disturb gait through accelerations of the belt. We compared SP with fixed speed (FS) treadmill walking, and also considered various feedback modes. Nineteen healthy subjects walked on a dual-belt instrumented treadmill. Spatio-temporal, kinematic and kinetic gait parameters were derived from both the average stride patterns and stride-to-stride variability. For 15 out of 70 parameters significant differences were found between SP and FS. These differences were smaller than 1. cm, 1\textdegree{}, 0.2. N. m and 0.2. W/kg for respectively stride length and width, joint kinematics, moments and powers. Since this is well within the normal stride variability, these differences were not considered to be clinically relevant, indicating that SP walking is not notably affected by belt accelerations. The long-term components of walking speed variability increased during SP walking (43\%, p< 0.01), suggesting that SP allows for more natural stride variability. Differences between SP feedback modes were predominantly found in the timescales of walking speed variability, while the gait pattern was similar between modes. Overall, the lack of clinically significant differences in gait pattern suggests that SP walking is a suitable alternative to fixed speed treadmill walking in gait analysis. \textcopyright{} 2013 Elsevier B.V.},
	issue        = 1,
	keywords     = {Biomechanics,Feedback-controlled treadmill,Fixed speed,Self-paced walking},
	pmid         = 24055003
}
@article{Parberry2014,
	title        = {Designer Worlds: Procedural Generation of Infinite Terrain from Real-World Elevation Data},
	author       = {Ian Parberry},
	year         = 2014,
	journal      = {Journal of Computer Graphics Techniques (JCGT)},
	volume       = 3,
	pages        = {74--85},
	issn         = {2331-7418},
	url          = {http://jcgt.org/published/0003/01/04/},
	note         = {height maps only},
	abstract     = {The standard way to procedurally generate random terrain for video games and other applications is to post-process the output of a fast noise generator such as Perlin noise. Tuning the post-processing to achieve particular types of terrain requires game designers to be reasonably well-trained in mathematics. A well-known variant of Perlin noise called value noise is used in a process accessible to designers trained in geography to generate geotypical terrain based on elevation statistics drawn from widely available sources such as the United States Geographical Service. A step-by-step process for downloading and creating terrain from real-world USGS elevation data is described, and an implementation in C++ is given.},
	issue        = 1
}
@article{Nasr-Azadani2014,
	title        = {Turbidity currents interacting with three-dimensional seafloor topography},
	author       = {M. M. Nasr-Azadani and E. Meiburg},
	year         = 2014,
	journal      = {Journal of Fluid Mechanics},
	volume       = 745,
	pages        = {409--443},
	doi          = {10.1017/jfm.2014.47},
	issn         = 14697645,
	abstract     = {Direct numerical simulations are employed to investigate the interactions of bidisperse turbidity currents with three-dimensional seafloor topography in the form of Gaussian bumps. Results for two different bump heights are compared against currents propagating over a flat surface. The bump heights are chosen such that the current largely flows over the smaller bump, while it primarily flows around the taller bump. Furthermore, the effects of the settling velocity are investigated by comparing turbidity currents with corresponding compositional gravity currents. The influence of the bottom topography on the front velocity of turbidity currents is seen to be much weaker than the influence of the particle settling velocity. Consistent with earlier work on gravity currents propagating over flat boundaries, the influence of the Reynolds number on the front velocity of currents interacting with three-dimensional bottom topography is found to be small, as long as Re\geq{}O(1000). The lobe-and-cleft structures, on the other hand, exhibit a stronger influence of the Reynolds number. The current/bump interaction deforms the bottom boundary-layer vorticity into traditional horseshoe vortices, with a downwash region in the centre of the wake. At the same time, the vorticity originating in the mixing layer between the current and the ambient interacts with the bump in such a way as to form 'inverted horseshoe vortices', with an upwash region in the wake centre. Additional streamwise vortical structures form as a result of baroclinic vorticity generation. The dependence of the sedimentation rate and streamwise vorticity generation on the height of the bump are discussed, and detailed analyses are presented of the energy budget and bottom wall-shear stress. It is shown that for typical laboratory-scale experiments, the range of parameters explored in the present investigation will not give rise to bedload transport or sediment resuspension. Based on balance arguments for the kinetic and potential energy components, a scaling law is obtained for the maximum bump height over which gravity currents can travel. This scaling law is validated by simulation results, and it provides a criterion for distinguishing between 'short' and 'tall' topographical features. For turbidity currents, this scaling result represents an upper limit. An interesting non-monotonic influence of the bump height is observed on the long-term propagation velocity of the current. On the one hand, the lateral deflection of the current by the bump leads to an effective increase in the current height and its front velocity in the region away from the bump. At the same time, taller bumps result in a more vigorous three-dimensional evolution of the current, accompanied by increased levels of dissipation, which slows the current down. For small bumps, the former mechanism dominates, so that on average the current front propagates faster than its flat bottom counterpart. For currents interacting with larger bumps, however, the increased dissipation becomes dominant, so that they exhibit a reduced front velocity as compared to currents propagating over flat surfaces.},
	issue        = 2,
	keywords     = {gravity currents,stratified flows,topographic effect}
}
@article{Rongier2014,
	title        = {Simulation of 3D karst conduits with an object-distance based method integrating geological knowledge},
	author       = {Guillaume Rongier and Pauline Collon-Drouaillet and Marco Filipponi},
	year         = 2014,
	journal      = {Geomorphology},
	volume       = 217,
	pages        = {152--164},
	doi          = {10.1016/j.geomorph.2014.04.024},
	issn         = {0169555X},
	url          = {https://hal.archives-ouvertes.fr/hal-01304938/document},
	abstract     = {Karst conduit shapes have a high influence on fluid flows. As these underground hidden systems are partially inaccessible, their stochastic simulation is an essential tool to assess the uncertainties related to these highly exploited water resources. The object-distance simulation method (ODSIM) is a hybrid dual-scale approach that has been recently proposed to model geological underground structures due to late processes such as dolomitized rocks, mineralized veins or karsts. Using a perturbed Euclidean distance field around a curve representing roughly the conduit centre and called a skeleton, the resulting shapes are globally cylindrical-like 3D envelopes. But at a drain scale, karstic conduits are elongated along weakness planes such as lithostratigraphic horizons, bedding planes, fractures or faults. In addition to those planes the influence of the water table is added. This work presents different improvements of ODSIM methodology for simulating more realistic shapes in the particular case of karst. Firstly, we propose using a custom distance field computed with a fast marching method. Considering the "velocity" field to be proportional to the permeability allows the resulting features to be elongated along the weakness planes. Secondly, to handle specific shapes due to the proximity of the water table, such as trenches or notches, we impose areas of higher velocity between the skeleton and the water table. Finally, we generate a custom random threshold with several variograms and/or distributions depending on the different features integrated in the "velocity" field. Applied on different models, it is shown that the resulting karst conduits have more realistic shapes than those obtained with the previous workflow, while the variability of structures which can be modelled with ODSIM is preserved. \textcopyright{} 2014 Elsevier B.V.},
	keywords     = {Inception feature,Karst conduit,Shape,Skeleton,Stochastic simulation}
}
@article{Merland2014,
	title        = {Voronoi grids conforming to 3D structural features},
	author       = {Romain Merland and Guillaume Caumon and Bruno L\'{e}vy and Pauline Collon-Drouaillet},
	year         = 2014,
	journal      = {Computational Geosciences},
	volume       = 18,
	pages        = {373--383},
	doi          = {10.1007/s10596-014-9408-0},
	isbn         = 1059601494,
	issn         = 14200597,
	url          = {https://www.researchgate.net/profile/Romain-Merland/publication/263558668_Voronoi_Grids_Conformal_to_3D_Structural_Features/links/5acf42120f7e9b18965b1364/Voronoi-Grids-Conformal-to-3D-Structural-Features.pdf},
	abstract     = {Flow simulation in a reservoir can be highly impacted by upscaling errors. These errors can be reduced by using simulation grids with cells as homogeneous as possible, hence conformable to horizons and faults. In this paper, the coordinates of 3D Voronoi seeds are optimized so that Voronoi cell facets honor the structural features. These features are modeled by piecewise linear complex (PLC). The optimization minimizes a function made of two parts: (1) a barycentric function, which ensures that the cells will be of good quality by maximizing their compactness; and (2) a conformity function, which allows to minimize the volume of cells that is isolated from the Voronoi seed w.r.t., a structural feature. To determine the isolated volume, a local approximation of the structural feature inside the Voronoi cells is used to cut the cells. It improves the algorithm efficiency and robustness compared to an exact cutting procedure. This method, used jointly with an adaptive gradient solver to minimize the function, allows dealing with complex 3D geological cases. It always produces a Voronoi simulation grid with the desired number of cells. \textcopyright{} 2014 Springer International Publishing Switzerland.},
	issue        = {3-4},
	keywords     = {Conform,Reservoir grid,Structural features,Voronoi}
}
@article{Le2014,
	title        = {Siggraph course (skinning). Part IV: Mesh Animation Decomposition and Compression},
	author       = {Binh H Le and Zhigang Deng},
	year         = 2014,
	journal      = {SIGGRAPH Course 2014},
	pages        = {1--35},
	url          = {https://skinning.org/decomposition-methods.pdf},
	abstract     = {With the development of advanced computer vision and tracking techniques, deformed mesh sequences can be soundly reconstructed by markerless performance capture [De Aguiar et al. 2008b; Vlasic et al. 2008; Vlasic et al. 2009; Stoll et al. 2010], or by motion capture with dense markers [Park and Hodgins 2006; De Aguiar et al. 2007]. With the maturity of these high-quality capture techniques, researchers in computer graphics community have also explored the concept of using example poses (i.e., a sequence of deformed mesh frames) for character skinning, rigging and animation, which has become increasingly practical and useful in entertainment practice. For example, proxy bones (or called bones for simplicity) and corresponding skinning weights can be automatically extracted from a set of example poses [James and Twigg 2005; Kavan et al. 2010; Le and Deng 2012], and the resulting bones and skinning weights can be potentially used for many applications including mesh animation compression, hardware-accelerated skinning animation, collision detection, animation editing, and so on [James and Twigg 2005; Kavan et al. 2010]. Furthermore, different from a set of disconnected proxy bones, a skeletal rigging model can also be automatically extracted from example poses [Schaefer and Yuksel 2007; Hasler et al. 2010; Le and Deng 2014]. Since the skeleton extracted from example poses is compatible with game engines and popular animation software such as Maya and Blender, it can be directly used for various animation editing, compression, and rendering applications, which could help to substantially reduce production cost in industry practice. In linear blend skinning (LBS) model (or cage-based deformation), the deformed position of a surface vertex is influenced by a set of bones (or control points). Often, the number of bones that affect a vertex of the target mesh varies significantly, such as from one to tens of them. Meanwhile, with the availability and affordability of high-precision 3D scanning and acquisition devices, dense 3D mesh models with thousands or even millions of vertices have being commonly used in movie special effects, video games, and other entertainment industry practices. Therefore, skinning high-resolution 3D meshes on off-the-shelf computers has become an expensive computational task, in particular, for real-time graphics applications (such as video games) due to their real-time response requirement. Fortunately, modern GPU hardware can provide an unprecedented computing capability to handle massive parallel data processing. Researchers have strived to efficiently exploit the GPU computing power to accelerate skinning animation on GPU. In particular, one intensively studied solution is to impose the sparseness constraint on the skinning weights [James and Twigg 2005; Landreneau and Schaefer 2010; Le and Deng 2013] (that is, enforce no more than a fixed number of non-zero skinning weights for any vertex), while maximally retaining the visual quality of the reduced skinning animation. This process is called skinning weight reduction and compression. In the remainder of the course note, we will first describe a number of recent example-based skinning decomposition techniques that automatically extract proxy bones (flexible or rigid) and corresponding skinning weights from a set of example poses (Section 1). Then, we will further describe recent skeleton extraction algorithms that automatically extract skeletal rigging models from example poses (Section 2). Finally, we will describe a number of skinning weight reduction and compression approaches to balance the trade-off between skinning efficiency and quality (Section 3).}
}
@article{Lewis2014,
	title        = {Siggraph course 2014 (skinning). Part III: Example-based Shape Deformation},
	author       = {J P Lewis},
	year         = 2014,
	journal      = {Siggraph 2014},
	pages        = {1--20},
	url          = {https://skinning.org/example-based.pdf},
	issue        = {Figure 1}
}
@article{Kavan2014,
	title        = {Part I: Direct Skinning Methods and Deformation Primitives},
	author       = {Ladislav Kavan},
	year         = 2014,
	journal      = {SIGGRAPH Course 2014 -- Skinning: Real-time Shape Deformation},
	pages        = {1--11},
	url          = {https://skinning.org/direct-methods.pdf},
	issue        = 3
}
@article{Solomon2014,
	title        = {A General Framework for Bilateral and Mean Shift Filtering},
	author       = {Justin Solomon and Keenan Crane and Adrian Butscher and Chris Wojtan},
	year         = 2014,
	pages        = {1--11},
	doi          = {https://doi.org/10.48550/arXiv.1405.4734},
	url          = {http://arxiv.org/abs/1405.4734},
	abstract     = {We present a generalization of the bilateral filter that can be applied to feature-preserving smoothing of signals on images, meshes, and other domains within a single unified framework. Our discretization is competitive with state-of-the-art smoothing techniques in terms of both accuracy and speed, is easy to implement, and has parameters that are straightforward to understand. Unlike previous bilateral filters developed for meshes and other irregular domains, our construction reduces exactly to the image bilateral on rectangular domains and comes with a rigorous foundation in both the smooth and discrete settings. These guarantees allow us to construct unconditionally convergent mean-shift schemes that handle a variety of extremely noisy signals. We also apply our framework to geometric edge-preserving effects like feature enhancement and show how it is related to local histogram techniques.}
}
@article{Stava2014,
	title        = {Inverse procedural modelling of trees},
	author       = {Ond\v{r}ej \v{S}t'ava and Julian Kratt and Baoquan Chen and Radomir M\v{e}ch and Oliver Deussen and Bed\v{r}ich Bene\v{s}},
	year         = 2014,
	journal      = {Computer Graphics Forum},
	volume       = 33,
	pages        = {118--131},
	doi          = {10.1111/cgf.12282},
	issn         = 14678659,
	url          = {https://cfcs.pku.edu.cn/baoquan/docs/20180621170343624947.pdf},
	abstract     = {Procedural tree models have been popular in computer graphics for their ability to generate a variety of output trees from a set of input parameters and to simulate plant interaction with the environment for a realistic placement of trees in virtual scenes. However, defining such models and their parameters is a difficult task. We propose an inverse modelling approach for stochastic trees that takes polygonal tree models as input and estimates the parameters of a procedural model so that it produces trees similar to the input. Our framework is based on a novel parametric model for tree generation and uses Monte Carlo Markov Chains to find the optimal set of parameters. We demonstrate our approach on a variety of input models obtained from different sources, such as interactive modelling systems, reconstructed scans of real trees and developmental models. Procedural tree models have been popular in computer graphics for their ability to generate a variety of output trees from a set of input parameters and to simulate plant interaction with the environment for a realistic placement of trees in virtual scenes. However, defining such models and their parameters is a difficult task. We propose an inverse modeling approach for stochastic trees that takes polygonal tree models as input and estimates the parameters of a procedural model so that it produces trees similar to the input.},
	issue        = 6,
	keywords     = {biological modeling,mesh generation,natural phenomena}
}
@article{Tasse2015,
	title        = {Feature-based terrain editing from complex sketches},
	author       = {Flora Ponjou Tasse and Arnaud Emilien and Marie-Paule Cani and Stefanie Hahmann and Neil Dodgson},
	year         = 2014,
	month        = 12,
	journal      = {Computers \& Graphics},
	volume       = 45,
	pages        = {101--115},
	doi          = {10.1016/j.cag.2014.09.001},
	issn         = {00978493},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0097849314000818},
	keywords     = {first person editing,silhouettes,sketch-based modelling,terrain}
}
@inbook{Tasse2014,
	title        = {First Person Sketch-based Terrain Editing},
	author       = {Flora Ponjou Tasse and Arnaud Emilien and Marie-Paule Cani and Stefanie Hahmann and Adrien Bernhardt},
	year         = 2014,
	booktitle    = {Graphics Interface},
	url          = {https://hal.inria.fr/hal-00976689/file/FirstPersonSketchBasedTerrainEditing_GI2014.pdf},
	keywords     = {first person editing,sketch-based modelling,terrain}
}
@article{Henry2014,
	title        = {Interactive Formation Control in Complex Environments},
	author       = {Joseph Henry and Hubert P. H. Shum and Taku Komura},
	year         = 2014,
	month        = 2,
	journal      = {IEEE Transactions on Visualization and Computer Graphics},
	publisher    = {IEEE},
	volume       = 20,
	pages        = {211--222},
	doi          = {10.1109/TVCG.2013.116},
	issn         = {1077-2626},
	url          = {http://ieeexplore.ieee.org/document/6582419/},
	issue        = 2
}
@phdthesis{Andereck2014,
	title        = {Procedural Terrain Generation Based on Constraint Paths},
	author       = {Micheal Andereck},
	year         = 2014,
	url          = {https://etd.ohiolink.edu/!etd.send_file?accession=osu1388357258&disposition=attachment},
	abstract     = {Procedural terrain generation is a highly popular topic in computer science today with applications in video games, medical rehabilitation, land planning, and even military training. Many algorithms exist to create these terrains including fractal designs, physical simulations, and applying real-world data. These systems offer various levels of interactivity and user control. We introduce a constraint-based system for procedurally generating virtual terrains. The first constraint is based on user-designed paths which can be customized for the various needs of patients experiencing medical rehabilitation. Due to the specific needs of this application, we require that our terrain shape should not manipulate the heights specified by these paths. Additional constraints may be applied from real-world data, user-painted heights, and tile borders. Given a set of constraints our generative algorithm iteratively finds the best fitting terrain shape, interpolating between and beyond the specified points. With a combination of user interaction and faithful fitting of data, our algorithm provides a more friendly system for constrained virtual terrain generation.}
}
@article{Koca2014,
	title        = {A hybrid representation for modeling, interactive editing, and real-time visualization of terrains with volumetric features},
	author       = {\c{C}etin Koca and U\u{g}ur G\"{u}d\"{u}kbay},
	year         = 2014,
	journal      = {International Journal of Geographical Information Science},
	publisher    = {Taylor \& Francis},
	volume       = 28,
	pages        = {1821--1847},
	doi          = {10.1080/13658816.2014.900560},
	issn         = 13623087,
	url          = {http://dx.doi.org/10.1080/13658816.2014.900560 http://repository.bilkent.edu.tr/bitstream/handle/11693/26473/A hybrid representation for modeling%2C interactive editing%2C and real-time visualization of terrains with volumetric features.pdf?sequence=1},
	abstract     = {Terrain rendering is a crucial part of many real-time applications. The easiest way to process and visualize terrain data in real time is to constrain the terrain model in several ways. This decreases the amount of data to be processed and the amount of processing power needed, but at the cost of expressivity and the ability to create complex terrains. The most popular terrain representation is a regular 2D grid, where the vertices are displaced in a third dimension by a displacement map, called a heightmap. This is the simplest way to represent terrain, and although it allows fast processing, it cannot model terrains with volumetric features. Volumetric approaches sample the 3D space by subdividing it into a 3D grid and represent the terrain as occupied voxels. They can represent volumetric features but they require computationally intensive algorithms for rendering, and their memory requirements are high. We propose a novel representation that combines the voxel and heightmap approaches, and is expressive enough to allow creating terrains with caves, overhangs, cliffs, and arches, and efficient enough to allow terrain editing, deformations, and rendering in real time.},
	issue        = 9,
	keywords     = {caves,cliffs,heightmap,overhangs,terrain editing,terrain representation,terrain visualization,voxel}
}
@inbook{Peltonen2014,
	title        = {Part 5 : Layout for general- structured graphs},
	author       = {Jaakko Peltonen},
	year         = 2014,
	url          = {https://coursepages2.tuni.fi/mttts17/wp-content/uploads/sites/136/2020/04/drv_2020_lecture13.pdf}
}
@article{Snodgrass2014,
	title        = {A hierarchical approach to generating maps using Markov chains},
	author       = {Sam Snodgrass and Santiago Onta\~{n}\'{o}n},
	year         = 2014,
	journal      = {Proceedings of the 10th AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment, AIIDE 2014},
	pages        = {59--65},
	isbn         = 9781577356813,
	abstract     = {In this paper we describe a hierarchical method for procedurally generating maps using Markov chains. Our method takes as input a collection of human-authored two-dimensional maps, and splits them into high-level tiles which capture large structures. Markov chains are then learned from those maps to capture the structure of both the high-level tiles, as well as the low-level tiles. Then, the learned Markov chains are used to generate new maps by first generating the high-level structure of the map using high-level tiles, and then generating the low-level layout of the map. We validate our approach using the game Super Mario Bros., by evaluating the quality of maps produced using different configurations for training and generation.},
	issue        = {Aiide}
}
@article{Emilien2013,
	title        = {Design de cascades r\'{e}alistes : une m\'{e}thode pour combiner contr\^{o}le interactif et mod\`{e}le proc\'{e}dural},
	author       = {Arnaud Emilien and Pierre Poulin and Marie-paule Cani and Ulysse Vimont},
	year         = 2014,
	journal      = {Revue Electronique Francophone d'Informatique Graphique},
	volume       = 8,
	pages        = {1--12},
	url          = {http://liris.cnrs.fr/~egfr/BestPapers/Troisieme2013_Arnaud-Emilien.pdf},
	issue        = 1
}
@article{DeGroot2014,
	title        = {Implicit decals: Interactive editing of repetitive patterns on surfaces},
	author       = {Erwin De Groot and Brian Wyvill and Lo\"{\i}c Barthe and Ahmad Nasri and Paul Lalonde},
	year         = 2014,
	journal      = {Computer Graphics Forum},
	volume       = 33,
	pages        = {141--151},
	doi          = {10.1111/cgf.12260},
	issn         = 14678659,
	url          = {https://hal.archives-ouvertes.fr/hal-00876004/document},
	abstract     = {Texture mapping is an essential component for creating 3D models and is widely used in both the game and the movie industries. Creating texture maps has always been a complex task and existing methods carefully balance flexibility with ease of use. One difficulty in using texturing is the repeated placement of individual textures over larger areas. In this paper, we propose a method which uses decals to place images onto a model. Our method allows the decals to compete for space and to deform as they are being pushed by other decals. A spherical field function is used to determine the position and the size of each decal and the deformation applied to fit the decals. The decals may span multiple objects with heterogeneous representations. Our method does not require an explicit parametrization of the model. As such, varieties of patterns, including repeated patterns like rocks, tiles and scales can be mapped. We have implemented the method using the GPU where placement, size and orientation of thousands of decals are manipulated in real time. \textcopyright{} 2013 The Authors Computer Graphics Forum \textcopyright{} 2013 The Eurographics Association and John Wiley \& Sons Ltd.},
	issue        = 1,
	keywords     = {GPU,decals,implicit surfaces,parameterization,texture mapping}
}
@misc{CourseImplicitSurfaces2014,
	title        = {Implicit Surfaces \& Solid Representations 3D Object Representations},
	author       = {Princeton University},
	year         = 2014,
	url          = {https://www.cs.princeton.edu/courses/archive/spring14/cos426/lectures/09-implicit.pdf}
}
@article{Krause-Jensen2014,
	title        = {Expansion of vegetated coastal ecosystems in the future Arctic},
	author       = {Dorte Krause-Jensen and Carlos M. Duarte},
	year         = 2014,
	journal      = {Frontiers in Marine Science},
	volume       = 1,
	pages        = {1--10},
	doi          = {10.3389/fmars.2014.00077},
	issn         = 22967745,
	abstract     = {Warming occurs particularly fast in the Arctic and exerts profound effects on arctic ecosystems. Sea ice-associated ecosystems are projected to decline but reduced arctic sea ice cover also increases the solar radiation reaching the coastal seafloors with the potential for expansion of vegetated habitats, i.e., kelp forests and seagrass meadows. These habitats support key ecosystem functions, some of which may mitigate effects of climate change. Therefore, the likely expansion of vegetated coastal habitats in the Arctic will generate new productive ecosystems, offer habitat for a number of invertebrate and vertebrate species, including provision of refugia for calcifiers from possible threats from ocean acidification, contribute to enhance CO2 sequestration and protect the shoreline from erosion. The development of models allowing quantitative forecasts of the future of vegetated arctic ecosystems requires that key hypotheses underlying such forecasts be tested. Here we propose a set of three key testable hypotheses along with a research agenda for testing them using a broad diversity of approaches, including analyses of paleo-records, space-for-time substitutions and experimental studies. The research agenda proposed would provide a solid underpinning to guide forecasts on the spread of marine macrophytes onto the Arctic with climate change and contribute to balance our understanding of climate change impacts on the arctic ecosystem through a focus on the role of engineering species. Anticipating these changes in ecosystem structure and function is key to develop managerial strategies to maximize these ecosystem services in a future warmer Arctic.},
	issue        = {DEC},
	keywords     = {Arctic,Climate change,Ecological function,Macroalgae,Marine vegetation,Sea-ice,Seagrasses,Warming}
}
@article{Valle2014,
	title        = {Seagrass meadows under a changing climate: habitat modelling, restoration and monitoring},
	author       = {Mireia Valle},
	year         = 2014,
	journal      = {Department of Plant Biology and Ecology},
	pages        = 220,
	doi          = {10.13140/2.1.2235.3606},
	issue        = {November}
}
@article{Roger2014,
	title        = {Discussion about tsunami interaction with fringing coral reef},
	author       = {Jean Roger and Bernard Dudon and Yann Krien and Narcisse Zahibo},
	year         = 2014,
	journal      = {Advances in Natural and Technological Hazards Research},
	volume       = 35,
	pages        = {161--176},
	doi          = {10.1007/978-94-007-7269-4_8},
	isbn         = 9789400772694,
	issn         = 22136959,
	abstract     = {The recent catastrophic tsunamis show that it is now more than ever necessary to assess tsunami hazard for all coastal communities. In fact, facing the dangerous increase of population in low-lying coastal areas during the last decades directly linked to the reduction of the natural defences against sea assaults, including tsunamis, and considering the economy of most of the concerned countries, solutions should be found quickly to protect those populations and/or mitigate the hazard. In that way, recent studies and post-event field observations have highlighted the protective role played by coral reefs and the consequences of their destructions on the tsunami amplitudes. In this study previous results about the effect of fringing coral reef geometry on the tsunami amplitude are discussed using numerical modeling of nonlinear shallow water equations (NAMI-DANCE code). For this purpose, a set of different artificial Digital Elevation Models has been prepared in agreement with real bathymetric profiles and results of simulations are compared and discussed together with the conclusions obtained by the other authors.},
	issue        = {September},
	keywords     = {Coral fringing reef,Numerical modeling,Tsunami}
}
@article{Smelik2014,
	title        = {A survey on procedural modelling for virtual worlds},
	author       = {Ruben M. Smelik and Tim Tutenel and Rafael Bidarra and Bedrich Benes},
	year         = 2014,
	journal      = {Computer Graphics Forum},
	volume       = 33,
	pages        = {31--50},
	doi          = {10.1111/cgf.12276},
	issn         = 14678659,
	abstract     = {Procedural modelling deals with (semi-)automatic content generation by means of a program or procedure. Among other advantages, its data compression and the potential to generate a large variety of detailed content with reduced human intervention, have made procedural modelling attractive for creating virtual environments increasingly used in movies, games and simulations. We survey procedural methods that are useful to generate features of virtual worlds, including terrains, vegetation, rivers, roads, buildings and entire cities. In this survey, we focus particularly on the degree of intuitive control and of interactivity offered by each procedural method, because these properties are instrumental for their typical users: designers and artists. We identify the most promising research results that have been recently achieved, but we also realize that there is far from widespread acceptance of procedural methods among non-technical, creative professionals. We conclude by discussing some of the most important challenges of procedural modelling. Procedural modeling deals with (semi-)automatic content generation by means of a procedure. This article surveys procedural methods that generate features of virtual worlds, including terrain, vegetation and cities. Promising results are identified, and the most salient challenges are discussed. A special focus is put on their degree of control and interactivity, essential for a more widespread use by creative professionals.},
	issue        = 6,
	keywords     = {procedural content generation,procedural modeling methods,virtual worlds}
}
@article{Stomakhin2014,
	title        = {Augmented MPM for phase-change and varied materials},
	author       = {Alexey Stomakhin and Craig Schroeder and Chenfanfu Jiang and Lawrence Chai and Joseph Teran and Andrew Selle},
	year         = 2014,
	journal      = {ACM Transactions on Graphics},
	volume       = 33,
	doi          = {10.1145/2601097.2601176},
	issn         = 15577333,
	abstract     = {In this paper, we introduce a novel material point method for heat transport, melting and solidifying materials. This brings a wider range of material behaviors into reach of the already versatile material point method. This is in contrast to best-of-breed fluid, solid or rigid body solvers that are difficult to adapt to a wide range of materials. Extending the material point method requires several contributions. We introduce a dilational/deviatoric splitting of the constitutive model and show that an implicit treatment of the Eulerian evolution of the dilational part can be used to simulate arbitrarily incompressible materials. Furthermore, we show that this treatment reduces to a parabolic equation for moderate compressibility and an elliptic, Chorin-style projection at the incompressible limit. Since projections are naturally done on marker and cell (MAC) grids, we devise a staggered grid MPM method. Lastly, to generate varying material parameters, we adapt a heat-equation solver to a material point framework. Copyright \textcopyright{} ACM.},
	issue        = 4,
	keywords     = {Freezing,Lava,Material point,Melting,Physically-based modeling}
}
@article{Hawick2014,
	title        = {Modelling flood incursion and coastal erosion using cellular automata simulations},
	author       = {Ken A. Hawick},
	year         = 2014,
	journal      = {Proceedings of the IASTED International Conference on Environmental Management and Engineering, EME 2014},
	pages        = {158--165},
	doi          = {10.2316/P.2014.821-005},
	abstract     = {Coastal flooding and associated land erosion are important environmental issues that are difficult to model for large scale systems. Cellular automaton models are attractive as computational simple and inexpensive individual cell calculations can be scaled up to model relatively large area models. We explore combinations of diffusional and injective cellular automaton models for water/land incursion and erosion problems. The Kawasaki site exchange automaton and the Invasion Percolation models form the basis of our hybrid automaton model. We explore some quantitative statistical metrics and discuss development directions of a hybrid model that supports both steady erosion as well as rapid water incursion and soil/land removal.},
	keywords     = {Beach area transport,Complex systems,Emergence,Flooding,Soil erosion,Water incursion}
}
@article{Abdi2014,
	title        = {Wind flow simulations on idealized and real complex terrain using various turbulence models},
	author       = {Daniel S. Abdi and Girma T. Bitsuamlak},
	year         = 2014,
	journal      = {Advances in Engineering Software},
	publisher    = {Elsevier Ltd},
	volume       = 75,
	pages        = {30--41},
	doi          = {10.1016/j.advengsoft.2014.05.002},
	issn         = 18735339,
	abstract     = {The effect of topographic features on wind speed and wake turbulence is evaluated by conducting Computational Fluid Dynamics (CFD) simulations using an in-house CFD program that features various turbulence models. The simulation results are assessed by computing Fractional Speed Up Ratio (FSUR) along longitudinal lines at different elevations. Such information is useful for evaluating wind loads on long span structures and micro-siting of wind turbines on complex terrain. Simulations are conducted on both idealized and real topographic features in both 2D and 3D domain. The turbulence structure behind hills is examined using several turbulence models such as the mixing-length, standard k-\ensuremath{\epsilon}, RNG k-\ensuremath{\epsilon}, realizable k-\ensuremath{\epsilon} and Smagorinsky LES models. All turbulence models predicted FSUR values on upstream side of hills adequately; however, the performance of simple turbulence models, such as mixing length, is found to be insufficient for characterizing wakes behind hills. RANS turbulence models gave results close to one another; however, those models that incorporate modifications to account for adverse pressure gradient conditions performed better at wakes behind hills. LES conducted at full scale dimensions, and using wall functions, failed to give results that are comparable to the other turbulence models. Re-conducting the simulations at model scale dimensions, hence at relatively small Reynolds number, and without using wall functions gave results that are comparable to those found in the literature. Therefore, use of wall functions can degrade quality of results in LES of high Reynolds number flows of practical interest. \textcopyright{} 2014 Published by Elsevier Ltd. All rights reserved.},
	keywords     = {Complex terrain,Computational fluid dynamics,FSUR,LES,RANS,Topography,Turbulence models}
}
@article{Huang2014,
	title        = {Classification of submarine canyons of the Australian continental margin},
	author       = {Zhi Huang and Scott L. Nichol and Peter T. Harris and M. Julian Caley},
	year         = 2014,
	month        = 11,
	journal      = {Marine Geology},
	publisher    = {Elsevier},
	volume       = 357,
	pages        = {362--383},
	doi          = {10.1016/j.margeo.2014.07.007},
	issn         = {00253227},
	abstract     = {Submarine canyons influence oceanographic processes, sediment transport, productivity and benthic biodiversity from the continental shelf to the slope and beyond. However, not all canyons perform the same function. The relative influence of an individual canyon on these processes will, in part, be determined by its form, shape and position on the continental margin. Here we present an analysis of canyon geomorphic metrics using an updated national dataset of 713 submarine canyons surrounding mainland Australia. These metrics (attributes) for each canyon are used to classify them into canyon types across a hierarchy of physical characteristics separately for shelf-incising (n. =. 95) and slope-confined (blind; n. =. 618) canyons. We find that the canyon metrics describe a wide variety of canyon form and complexity that is consistent with a population of canyons that has evolved at different rates around the Australian margin since the break-up of Gondwana. The large number of slope-confined canyons is interpreted to reflect dominance of slope mass-wasting processes over erosive turbidity flows from fluvial and shelf sources on an arid continent. The distribution of submarine canyons around the Australian margin is not regular, with clusters occurring in the east, southeast, west and southwest where the margin is steepest. The classification result provides a quantitative framework for describing canyon heterogeneity for application in studies of geological controls on individual canyons, canyon oceanography and canyon biodiversity.},
	keywords     = {Australia,Bathymetry,Hierarchical classification,Morphometrics,Submarine canyons}
}
@phdthesis{EmilienThesis,
	title        = {Interactive design of virtual worlds : Combining procedural modeling with intuitive user control},
	author       = {Arnaud Emilien},
	year         = 2014,
	month        = 12,
	url          = {https://theses.hal.science/tel-01147917v2},
	city         = {Grenoble},
	institution  = {Universit\'{e} de Grenoble},
	keywords     = {()}
}
@inproceedings{Gilet2014,
	title        = {Local random-phase noise for procedural texturing},
	author       = {Guillaume Gilet and Basile Sauvage and Kenneth Vanhoey and Jean Michel Dischler and Djamchid Ghazanfarpour},
	year         = 2014,
	month        = 11,
	booktitle    = {ACM Transactions on Graphics},
	publisher    = {Association for Computing Machinery},
	volume       = 33,
	doi          = {10.1145/2661229.2661249},
	issn         = 15577368,
	abstract     = {(Figure Presented) Local random-phase noise is a noise model for procedural texturing. It is defined on a regular spatial grid by local noises, which are sums of cosines with random phase. Our model is versatile thanks to separate sampling in the spatial and spectral domains. Therefore, it encompasses Gabor noise and noise by Fourier series. A stratified spectral sampling allows for a faithful yet compact and efficient reproduction of an arbitrary power spectrum. Noise by example is therefore obtained faster than state-of-the-art techniques. As a second contribution we address texture by example and generate not only Gaussian patterns but also structured features present in the input. This is achieved by fixing the phase on some part of the spectrum. Generated textures are continuous and non-repetitive. Results show unprecedented framerates and a flexible visual result: users can control with one parameter the blending between noise by example and structured texture synthesis.},
	issue        = 6,
	keywords     = {By-example texturing,Noise synthesis,Procedural texturing}
}
@article{McCauley2014,
	title        = {Positive and Negative Effects of a Threatened Parrotfish on Reef Ecosystems},
	author       = {Douglas J. McCauley and Hillary S. Young and Roger Guevara and Gareth J. Williams and Eleanor A. Power and Robert B. Dunbar and Douglas W. Bird and William H. Durham and Fiorenza Micheli},
	year         = 2014,
	month        = 10,
	journal      = {Conservation Biology},
	volume       = 28,
	pages        = {1312--1321},
	doi          = {10.1111/cobi.12314},
	issn         = 15231739,
	abstract     = {Species that are strong interactors play disproportionately important roles in the dynamics of natural ecosystems. It has been proposed that their presence is necessary for positively shaping the structure and functioning of ecosystems. We evaluated this hypothesis using the case of the world's largest parrotfish (Bolbometopon muricatum), a globally imperiled species. We used direct observation, animal tracking, and computer simulations to examine the diverse routes through which B. muricatum affects the diversity, dispersal, relative abundance, and survival of the corals that comprise the foundation of reef ecosystems. Our results suggest that this species can influence reef building corals in both positive and negative ways. Field observation and simulation outputs indicated that B. muricatum reduced the abundance of macroalgae that can outcompete corals, but they also feed directly on corals, decreasing coral abundance, diversity, and colony size. B. muricatum appeared to facilitate coral advancement by mechanically dispersing coral fragments and opening up bare space for coral settlement, but they also damaged adult corals and remobilized a large volume of potentially stressful carbonate sediment. The impacts this species has on reefs appears to be regulated in part by its abundance-the effects of B. muricatum were more intense in simulation scenarios populated with high densities of these fish. Observations conducted in regions with high and low predator (e.g., sharks) abundance generated results that are consistent with the hypothesis that these predators of B. muricatum may play a role in governing their abundance; thus, predation may modulate the intensity of the effects they have on reef dynamics. Overall our results illustrate that functionally unique and threatened species may not have universally positive impacts on ecosystems and that it may be necessary for environmental managers to consider the diverse effects of such species and the forces that mediate the strength of their influence.},
	issue        = 5,
	keywords     = {Benthic,Bolbometopon,Coral,Diversity,Function,Management,Simulation,Threatened species},
	pmid         = 25065396
}
@article{Kraayenbrink2014,
	title        = {Semantic crowds},
	author       = {Nick Kraayenbrink and Jassin Kessing and Tim Tutenel and Gerwin de Haan and Rafael Bidarra},
	year         = 2014,
	month        = 12,
	journal      = {Entertainment Computing},
	publisher    = {Elsevier B.V.},
	volume       = 5,
	pages        = {297--312},
	doi          = {10.1016/j.entcom.2013.12.002},
	issn         = 18759521,
	abstract     = {Recent advances in crowd simulation techniques have led to increasingly realistic agent and group behavior. As many crowd simulation solutions typically target only specific types of environments and scenarios, numerous special-purpose methods and systems have emerged that are unsuitable for other contexts. Solving this situation demands a higher-level approach that takes re-use and re-configuration of crowds as a priority, for adequate application in a broad variety of scenarios, virtual environments and interaction with the entities present in that environment. In this article, we propose semantic crowds, a novel approach that allows one to specify and re-use the same crowds for virtually any environment, and have them use the objects available in it in a meaningful manner. To have the agents autonomously interact within any virtual world, we avoid in them explicit object-related information. Instead, this knowledge is stored in the objects themselves, which can then be queried, according to an agent's needs. To facilitate creating such crowds, we developed an interactive crowd editor that provides high-level editing parameters for defining crowd templates. We illustrate the flexibility of semantic crowds by means of three cases, in which we let the same crowd populate quite differently configured airport terminal environments. These examples also highlight that this modular approach easily combines with your custom implementations of agent behavior model and/or motion planner.},
	issue        = 4,
	keywords     = {Agent behavior,Crowd simulation,Crowd specification,Reusable crowds,Semantic virtual worlds}
}
@article{Dong2014,
	title        = {Image Super-Resolution Using Deep Convolutional Networks},
	author       = {Chao Dong and Chen Change Loy and Kaiming He and Xiaoou Tang},
	year         = 2014,
	month        = 12,
	url          = {http://arxiv.org/abs/1501.00092},
	abstract     = {We propose a deep learning method for single image super-resolution (SR). Our method directly learns an end-to-end mapping between the low/high-resolution images. The mapping is represented as a deep convolutional neural network (CNN) that takes the low-resolution image as the input and outputs the high-resolution one. We further show that traditional sparse-coding-based SR methods can also be viewed as a deep convolutional network. But unlike traditional methods that handle each component separately, our method jointly optimizes all layers. Our deep CNN has a lightweight structure, yet demonstrates state-of-the-art restoration quality, and achieves fast speed for practical on-line usage. We explore different network structures and parameter settings to achieve trade-offs between performance and speed. Moreover, we extend our network to cope with three color channels simultaneously, and show better overall reconstruction quality.}
}
@article{DeLellis2014,
	title        = {A note on the Hausdorff dimension of the singular set for minimizers of the Mumford-Shah energy},
	author       = {Camillo De Lellis and Matteo Focardi and Berardo Ruffini},
	year         = 2014,
	month        = 10,
	journal      = {Advances in Calculus of Variations},
	publisher    = {Walter de Gruyter GmbH},
	volume       = 7,
	pages        = {539--545},
	doi          = {10.1515/acv-2013-0107},
	issn         = 18648266,
	abstract     = {We give a more elementary proof of a result by Ambrosio, Fusco and Hutchinson to estimate the Hausdorff dimension of the singular set of minimizers of the Mumford-Shah energy (see [1, Theorem 5.6]). On the one hand, we follow the strategy of the above mentioned paper; but on the other hand our analysis greatly simplifies the argument since it relies on the compactness result proved by the first two authors in [4, Theorem 13] for sequences of local minimizers with vanishing gradient energy, and the regularity theory of minimal Caccioppoli partitions, rather than on the corresponding results for Almgren's area minimizing sets.},
	issue        = 4,
	keywords     = {Local minimizer,Mumford-Shah energy,Singular set}
}
@book{Hopley2014,
	title        = {Encyclopedia of modern coral reefs : structure, form and process},
	author       = {David. Hopley},
	year         = 2014,
	publisher    = {Springer, Credo Reference},
	isbn         = 9789048126385,
	abstract     = {[Enhanced Credo edition]. "Coral reefs are the largest landforms built by plants and animals. Their study therefore incorporates a wide range of disciplines. This encyclopedia approaches coral reefs from an earth science perspective, concentrating especially on modern reefs. Currently coral reefs are under high stress, most prominently from climate change with changes to water temperature, sea level and ocean acidification particularly damaging. Modern reefs have evolved through the massive environmental changes of the Quaternary with long periods of exposure during glacially lowered sea level periods and short periods of interglacial growth. The entries in this encyclopedia condense the large amount of work carried out since Charles Darwin first attempted to understand reef evolution. Leading authorities from many countries have contributed to the entries covering areas of geology, geography and ecology, providing comprehensive access to the most up-to-date research on the structure, form and processes operating on Quaternary coral reefs."--Publisher's website. .About the Encyclopedia of earth sciences series -- Contributors -- Preface -- Acknowledgments -- Topical entries A to Z.}
}
@article{Andujar2014,
	title        = {Inexpensive reconstruction and rendering of realistic roadside landscapes},
	author       = {C. And\'{u}jar and A. Chica and M. A. Vico and S. Moya and P. Brunet},
	year         = 2014,
	month        = 9,
	journal      = {Computer Graphics Forum},
	publisher    = {Blackwell Publishing Ltd},
	volume       = 33,
	pages        = {101--117},
	doi          = {10.1111/cgf.12281},
	issn         = 14678659,
	abstract     = {In this paper, we present an inexpensive approach to create highly detailed reconstructions of the landscape surrounding a road. Our method is based on a space-efficient semi-procedural representation of the terrain and vegetation supporting high-quality real-time rendering not only for aerial views but also at road level. We can integrate photographs along selected road stretches. We merge the point clouds extracted from these photographs with a low-resolution digital terrain model through a novel algorithm which is robust against noise and missing data. We pre-compute plausible locations for trees through an algorithm which takes into account perceptual cues. At runtime we render the reconstructed terrain along with plants generated procedurally according to pre-computed parameters. Our rendering algorithm ensures visual consistency with aerial imagery and thus it can be integrated seamlessly with current virtual globes. In this paper, we present an inexpensive approach to create highly detailed reconstructions of the landscape surrounding a road. Our method is based on a space-efficient semi-procedural representation of the terrain and vegetation supporting high-quality real-time rendering not only for aerial views but also at road level. We use a vehicle-mounted camera to capture a collection of photographs along selected road stretches. We integrate the point clouds extracted from these photographs with a low-resolution digital terrain model through a novel algorithm which is robust against noise and missing data. We pre-compute plausible locations for trees through an algorithm which takes into account perceptual cues.},
	issue        = 6,
	keywords     = {I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism,real-time rendering,rendering}
}
@techreport{EcologyCurriculum2014,
	title        = {Coral Reef: Ecology Curriculum},
	author       = {Khaled bin Sultan Living Oceans Foundation},
	year         = 2014,
	url          = {www.lof.org.}
}
@inbook{Soare2014,
	title        = {Thermokarst Landforms},
	author       = {Richard Soare},
	year         = 2014,
	booktitle    = {Encyclopedia of Planetary Landforms},
	publisher    = {Springer New York},
	pages        = {1--5},
	doi          = {10.1007/978-1-4614-9213-9_370-1},
	url          = {http://link.springer.com/10.1007/978-1-4614-9213-9_370-1},
	city         = {New York, NY}
}
@techreport{Shit2014,
	title        = {Gully Erosion Control: Lateritic Soil Region of West Bengal},
	author       = {Pravat Kumar Shit and Ramrishna Maiti},
	year         = 2014,
	month        = 3,
	volume       = 28,
	pages        = {54--61},
	url          = {https://www.researchgate.net/publication/268152349},
	abstract     = {Gully erosion management on lateritic soil is a critical issue in West Bengal. In this paper, have been used in combination with vegetation and check dams, for all aspects of lateritic soil erosion management. A program for controlling gully erosion was carried out in Rangamati in lateritic soil region of western part of West Bengal from 2011 to 2012 that includes two approaches "Check dam" and "Vegetation cover". Results indicated that at the initial stage, the percent of sand was the maximum in the upper catchment of each gully basin and the concentration of silt and clay was the least. Gradually as vegetation started trapping, the sediment composition of soil changed registering higher percentage of finer particles. Again, the nutrients detached from the upper catchment were arrested by check dams that induced nutrients supply and water storage, which in turn, increased the growth of vegetation. This proved the significance of vegetation cover with check dams to curb soil erosion. The results obtained may help the planners and managers to take proper decision for the conservation of lateritic soil.},
	issue        = 3,
	institution  = {Departmentof Geography and Environment Management, Vidyasagar University, Medinipur},
	keywords     = {Rill-gully erosion,check dam,vegetation cover}
}
@article{Bian2015,
	title        = {Fall detection based on body part tracking using a depth camera},
	author       = {Zhen Peng Bian and Junhui Hou and Lap Pui Chau and Nadia Magnenat-Thalmann},
	year         = 2015,
	month        = 3,
	journal      = {IEEE Journal of Biomedical and Health Informatics},
	publisher    = {Institute of Electrical and Electronics Engineers Inc.},
	volume       = 19,
	pages        = {430--439},
	doi          = {10.1109/JBHI.2014.2319372},
	issn         = 21682194,
	abstract     = {The elderly population is increasing rapidly all over the world. One major risk for elderly people is fall accidents, especially for those living alone. In this paper, we propose a robust fall detection approach by analyzing the tracked key joints of the human body using a single depth camera. Compared to the rivals that rely on the RGB inputs, the proposed scheme is independent of illumination of the lights and can work even in a dark room. In our scheme, a pose-invariant randomized decision tree algorithm is proposed for the key joint extraction, which requires low computational cost during the training and test. Then, the support vector machine classifier is employed to determine whether a fall motion occurs, whose input is the 3-D trajectory of the head joint. The experimental results demonstrate that the proposed fall detection method is more accurate and robust compared with the state-of-the-art methods.},
	issue        = 2,
	keywords     = {3-D,Computer vision,fall detection,head tracking,monocular,video surveillance},
	pmid         = 24771601
}
@techreport{MariaDiazBarros2015,
	title        = {Real-Time Human Pose Estimation from Body-Scanned Point Clouds},
	author       = {Jilliam Mar\'{\i}a Diaz Barros and Frederic Garcia and D\'{e}sir\'{e} Sidib\'{e}},
	year         = 2015,
	url          = {https://hal-univ-bourgogne.archives-ouvertes.fr/hal-01145637},
	abstract     = {This paper presents a novel approach to estimate the human pose from a body-scanned point cloud. To do so, a predefined skeleton model is first initialized according to both the skeleton base point and its torso limb obtained by Principal Component Analysis (PCA). Then, the body parts are iteratively clustered and the skeleton limb fitting is performed, based on Expectation Maximization (EM). The human pose is given by the location of each skeletal node in the fitted skeleton model. Experimental results show the ability of the method to estimate the human pose from multiple point cloud video sequences representing the external surface of a scanned human body; being robust, precise and handling large portions of missing data due to occlusions, acquisition hindrances or registration inaccuracies.},
	keywords     = {Human pose estimation,point cloud,skeleton model}
}
@article{DaCosta2015,
	title        = {Application of the physical habitat simulation for fish species to assess environmental flows in an Atlantic Forest Stream in South-eastern Brazil},
	author       = {Marcus Rodrigues da Costa and Tailan Moretti Mattos and Victor Hugo Fernandes and Francisco Mart\'{\i}nez-Capel and Rafael Mu\~{n}oz-Mas and Francisco Gerson Ara\'{u}jo},
	year         = 2015,
	month        = 10,
	journal      = {Neotropical Ichthyology},
	publisher    = {Sociedade Brasileira de Ictiologia},
	volume       = 13,
	pages        = {685--698},
	doi          = {10.1590/1982-0224-20140170},
	issn         = 19820224,
	abstract     = {The physical habitat simulation sub-routine of the Instream Flow Incremental Methodology (IFIM) uses hydraulic modeling and suitability indices of target fish species to predict how differences in-stream flows affect the microhabitat occupation by fish species. This habitat modelling approach was adopted to assess the ecological effects of running flows on three neotropical fish species of different orders (Bryconamericus ornaticeps, Ancistrus multispinis and Geophagus brasiliensis).The study encompassed two reaches of an Atlantic Forest stream in Southeastern Brazil where topographic and hydraulic (depth, velocity and type of substrate) characteristics were measured to implement one-dimensional hydraulic simulation. Sub aquatic observation of fish was performed to collect data on microhabitat use and these data were used to develop habitat suitability curves that were used in the habitat simulation to obtain the habitat suitability index (HSI) and weighted usable area (WUA) versus flow curves. Upon these curves minimum and optimum environmental flows for the target fish species were proposed. Bryconamericus ornaticeps and A. multispinis selected microhabitats around 0.6 m depth, whereas G. brasiliensis showed a wider suitable range (0.35-0.9 m). All the three species were mainly observed in microhabitat with low flow velocity (0.1 m/s). Bryconamericus ornaticeps selected more frequently coarse substrate (e.g. boulders) but it appeared also over sandy substrate, whereas A. multispinis and G. brasiliensis selected preferably boulders. The range of 0.65-0.85 m3/s was found as the optimum to meet the needs of the three fish species. Our results agree with the necessary objective information to perform grounded management actions in the frame of a management program aiming at ecosystem conservation. Thereby it can be considered a successful pilot study in environmental flow assessment in an Atlantic Forest stream of Brazil.},
	issue        = 4,
	keywords     = {Habitat modeling,Habitat suitability curves,Neotropical fish}
}
@article{Plotnik2015,
	title        = {Self-selected gait speed - Over ground versus self-paced treadmill walking, a solution for a paradox},
	author       = {Meir Plotnik and Tamar Azrad and Moshe Bondi and Yotam Bahat and Yoav Gimmon and Gabriel Zeilig and Rivka Inzelberg and Itzhak Siev-Ner},
	year         = 2015,
	month        = 2,
	journal      = {Journal of NeuroEngineering and Rehabilitation},
	publisher    = {BioMed Central Ltd.},
	volume       = 12,
	pages        = 20,
	doi          = {10.1186/s12984-015-0002-z},
	issn         = 17430003,
	url          = {https://jneuroengrehab.biomedcentral.com/articles/10.1186/s12984-015-0002-z},
	abstract     = {Background: The study of gait at self-selected speed is important. Traditional gait laboratories being relatively limited in space provide insufficient path length, while treadmill (TM) walking compromises natural gait by imposing speed variables. Self-paced (SP) walking can be realized on TM using feedback-controlled belt speed. We compared over ground walking vs. SP TM in two self-selected gait speed experiments: without visual flow, and while subjects were immersed in a virtual reality (VR) environment inducing natural visual flow. Methods: Young healthy subjects walked 96 meters at self-selected comfortable speed, first over ground and then on the SP TM without (n=15), and with VR visual flow (n=11). Gait speed was compared across conditions for four 10 m long segments (7.5 - 17.5, 30.5 - 40.5, 55.5 - 65.5 and 78.5-88.5 m). Results: During over ground walking mean (\pm{} SD) gait speed was equal for both experimental groups (1.50 \pm{} 0.13 m/s). Without visual flow, gait speed over SP TM was smaller in the first and second epochs as compared to over ground (first: 1.15 \pm{}0.18 vs. second: 1.53 \pm{} 0.13 m/s; p<0.05), and was comparable in the third and fourth (1.45 \pm{} 0.19 vs. 1.49 \pm{} 0.15 m/s; p>0.3). With visual flow, gait speed became comparable to that of over ground performance already in the first epoch (1.43 \pm{} 0.22 m/s; p>0.17). Curve fitting analyses estimated that steady state velocity in SP TM walking is reached after shorter distanced passed with visual flow (24.6 \pm{} 14.7 m) versus without (36.5 \pm{} 18.7 m, not statistically significant; p=0.097). Steady state velocity was estimated to be higher in the presence of visual flow (1.61 \pm{} 0.17 m/s) versus its absence (1.42 \pm{} 1.19 m/s; p<0.05). Conclusions: The SP TM walking is a reliable method for recording typical self-selected gait speed, provided that sufficient distance is first passed for reaching steady state. Seemingly, in the presence of VR visual flow, steady state of gait speed is reached faster. We propose that the gait research community joins forces to standardize the use of SP TMs, e.g., by unifying protocols or gathering normative data.},
	issue        = 1,
	keywords     = {Gait speed,Over ground walking,Self- paced treadmill,Virtual reality,Visual flow},
	pmid         = 25881130
}
@inproceedings{Kingma2015,
	title        = {Adam: A method for stochastic optimization},
	author       = {Diederik P. Kingma and Jimmy Lei Ba},
	year         = 2015,
	month        = 12,
	booktitle    = {3rd International Conference on Learning Representations, ICLR 2015 - Conference Track Proceedings},
	publisher    = {International Conference on Learning Representations, ICLR},
	url          = {https://arxiv.org/abs/1412.6980v9},
	abstract     = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.}
}
@article{Orthuber2015,
	title        = {3D building reconstruction from lidar point clouds by adaptive dual contouring},
	author       = {E. Orthuber and J. Avbelj},
	year         = 2015,
	journal      = {ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
	volume       = 2,
	pages        = {157--164},
	doi          = {10.5194/isprsannals-II-3-W4-157-2015},
	issn         = 21949050,
	abstract     = {This paper presents a novel workflow for data-driven building reconstruction from Light Detection and Ranging (LiDAR) point clouds. The method comprises building extraction, a detailed roof segmentation using region growing with adaptive thresholds, segment boundary creation, and a structural 3D building reconstruction approach using adaptive 2.5D Dual Contouring. First, a 2D-grid is overlain on the segmented point cloud. Second, in each grid cell 3D vertices of the building model are estimated from the corresponding LiDAR points. Then, the number of 3D vertices is reduced in a quad-tree collapsing procedure, and the remaining vertices are connected according to their adjacency in the grid. Roof segments are represented by a Triangular Irregular Network (TIN) and are connected to each other by common vertices or - at height discrepancies - by vertical walls. Resulting 3D building models show a very high accuracy and level of detail, including roof superstructures such as dormers. The workflow is tested and evaluated for two data sets, using the evaluation method and test data of the "ISPRS Test Project on Urban Classification and 3D Building Reconstruction" (Rottensteiner et al., 2012). Results show that the proposed method is comparable with the state of the art approaches, and outperforms them regarding undersegmentation and completeness of the scene reconstruction.},
	issue        = {3W4},
	keywords     = {Building,City,Computer,LIDAR,Model,Photogrammetry,Reconstruction,Vision}
}
@article{Mark2015,
	title        = {Procedural Generation of 3D Caves for Games on the GPU},
	author       = {Benjamin Mark and Tudor Berechet and Tobias Mahlmann and Julian Togelius},
	year         = 2015,
	journal      = {Foundations of Digital Games},
	isbn         = 9780991398249,
	url          = {http://lup.lub.lu.se/record/5464981/file/5464988.pdf},
	abstract     = {Procedural Content Generation in Games (PCG) is a thriv-\r\ning field of research and application. Recent presented ex-\r\namples range from levels, stories and race tracks to complete\r\nrulesets for games. However, there is not much research to\r\ndate on procedural 3D modeling of caves, and similar en-\r\nclosed natural spaces. In this paper, we present a modular\r\npipeline to procedurally generate underground caves in real-\r\ntime, to be used as part of larger landscapes in game worlds.\r\nWe propose a three step approach, which can be fully im-\r\nplemented using General-Purpose Computing on Graphics\r\nProcessing (GPGPU) technology: 1) an L-System to em-\r\nulate the expanded cracks and passages which form cave\r\nstructures in nature, 2) a noise-perturbed metaball approach\r\nfor virtual 3D carving, and 3) a rendering component for\r\nisosurface extraction of the modeled voxel data, and fur-\r\nther mesh enhancement through shader programming. We\r\ndemonstrate how the interaction between these components\r\nproduce results comparable to real world caves, and show\r\nthat the solution is viable for video game environments. For\r\nthis, we present the findings of a user study we conducted\r\namong indie-game developers and players, using our results.},
	keywords     = {Filosofi}
}
@article{Chen2015a,
	title        = {Actively Controllable Switching for Tree Topology Seafloor Observation Networks},
	author       = {Yanhu Chen and Bruce M. Howe and Canjun Yang},
	year         = 2015,
	journal      = {IEEE Journal of Oceanic Engineering},
	publisher    = {IEEE},
	volume       = 40,
	pages        = {993--1002},
	doi          = {10.1109/JOE.2014.2362830},
	issn         = {03649059},
	abstract     = {Cabled ocean observatory systems that provide abundant power and broad bandwidth communication enabling undersea science have been evolving during the last decade. To establish such permanent infrastructure in the ocean, the technology of cable network switching and fault isolation with very high reliability is essential. In this paper, we review existing switching methods as applied to a constant voltage tree topology network. We propose an actively controllable method that can configure each branch of the network only by changing the feeding current; the current level implicitly conveys the switching information. A laboratory prototype demonstrated the features of backbone switching with zero current and low voltage (less than 20 V), and active controllability of the switch.},
	issue        = 4,
	keywords     = {Cable switching,constant current,high voltage,ocean observation network}
}
@article{Genevaux2015,
	title        = {Terrain Modelling from Feature Primitives},
	author       = {Jean-David G\'{e}nevaux and \'{E}ric Galin and Adrien Peytavie and \'{E}ric Gu\'{e}rin and Cyril Briquet and Fran\c{c}ois Grosbellet and Bed\v{r}ich Bene\v{s}},
	year         = 2015,
	doi          = {https://doi.org/10.1111/cgf.12530},
	abstract     = {We introduce a compact hierarchical procedural model that combines feature-based primitives to describe complex terrains with varying level of detail. Our model is inspired by skeletal implicit surfaces and defines the terrain elevation function by using a construction tree. Leaves represent terrain features and they are generic parametrized skeletal primitives, such as mountains, ridges, valleys, rivers, lakes or roads. Inner nodes combine the leaves and subtrees by carving, blending or warping operators. The elevation of the terrain at a given point is evaluated by traversing the tree and by combining the contributions of the primitives. The definition of the tree leaves and operators guarantees that the resulting elevation function is Lipschitz, which speeds up the sphere tracing used to render the terrain. Our model is compact and allows for the creation oflarge terrains with a high level of detail using a reduced set of primitives. We show the creation of different kinds of landscapes and demonstrate that our model allows to efficiently control the shape and distribution oflandform features. Keywords:},
	keywords     = {Computational geometry and Object modeling surface,Interaction techniques,Methodology and Techniques Graphics data structure,object representations}
}
@article{Prokhorov2015,
	title        = {On the problem of reconstructing the floor topography of a fluctuating ocean},
	author       = {I. V. Prokhorov and A. A. Sushchenko and V. A. Kan},
	year         = 2015,
	journal      = {Journal of Applied and Industrial Mathematics},
	volume       = 9,
	pages        = {412--422},
	doi          = {10.1134/S1990478915030126},
	issn         = 19904797,
	abstract     = {We formulate and study the inverse problem for the nonstationary radiative transfer equation related to an acoustic mapping of the ocean floor using side-scan sonars. In the single-scattering approximation we obtain a formula for determining the function that describes small deviations of the floor surface from a middle level.},
	issue        = 3,
	keywords     = {inverse problem,radiative transfer equation,sea floor topography,single-scattering approximation}
}
@inbook{Lee2015,
	title        = {Fluid simulation overview},
	author       = {Richard Lee},
	year         = 2015,
	pages        = {1--10},
	note         = {Nice way to explain the Eulerian method (Jos Stam 2003)}
}
@article{Collon2015,
	title        = {3D geomodelling combining implicit surfaces and Voronoi-based remeshing: A case study in the Lorraine Coal Basin (France)},
	author       = {Pauline Collon and Wendy Steckiewicz-Laurent and Jeanne Pellerin and Gautier Laurent and Guillaume Caumon and Guillaume Reichart and Laurent Vaute},
	year         = 2015,
	journal      = {Computers and Geosciences},
	volume       = 77,
	pages        = {29--43},
	doi          = {10.1016/j.cageo.2015.01.009},
	issn         = {00983004},
	url          = {https://hal.univ-lorraine.fr/hal-01276842/file/2015Pap_Collon_CaGeo_PreprintV.pdf},
	abstract     = {In this paper we demonstrate how recent geomodelling techniques can be combined and used to build a 3D geological model on a real case study: the former coal mine of Merlebach (France), that is targeted to be exploited for low-temperature geothermal energy production. From geological maps, cross-sections, borehole and mine exploitation data, we build a 3D model in which are identified the rocks and infrastructures having significantly different permeabilities. First, a structural model of the main geological interfaces in our area of interest (2 horizons and 13 faults) is built with classical geomodelling techniques. Then, we propose to model by surfaces the 71 irregularly stacked, very close and very thin, sub-vertical coal beds. To ease their construction, we use an implicit method which represents 3D surfaces as isovalues of a scalar field defined in a 3D tetrahedral grid of the area. The corresponding triangulated surfaces are remeshed with a recently proposed method based on Voronoi diagrams so that the exploited parts of the coal beds, now filled by sand, can be computed. The 3D surface-based geological model, in which infrastructures can be inserted as piecewise lines, can be volumetrically meshed. It is available for download as supplemental material, as well as a volumetric grid.},
	keywords     = {3D surface-based model,Geomodelling,Geothermics,Implicit modelling,Post-mining,Surface remeshing}
}
@article{Bonneel2015,
	title        = {Sliced and Radon Wasserstein Barycenters of Measures},
	author       = {Nicolas Bonneel and Julien Rabin and Gabriel Peyr\'{e} and Hanspeter Pfister},
	year         = 2015,
	month        = 1,
	journal      = {Journal of Mathematical Imaging and Vision},
	volume       = 51,
	pages        = {22--45},
	doi          = {10.1007/s10851-014-0506-3},
	issn         = {0924-9907},
	url          = {http://link.springer.com/10.1007/s10851-014-0506-3},
	issue        = 1,
	keywords     = {barycenter of measures,optimal transport,radon transform,stein distance,wasser-}
}
@article{Korpinar2015,
	title        = {A characterization for Bishop equations of parallel curves according to Bishop frame in E^3},
	author       = {Talat K\"{o}rpinar and Vedat Asil and Muhammed T. Sariaydin and Muhsin Incesu},
	year         = 2015,
	journal      = {Boletim da Sociedade Paranaense de Matematica},
	volume       = 33,
	pages        = {33--39},
	doi          = {10.5269/bspm.v33i1.21712},
	issn         = 21751188,
	url          = {https://pdfs.semanticscholar.org/15a9/48a43730f644f23489796a8598018c2dcfab.pdf},
	abstract     = {In this paper, we study Bishop equations of parallel curves according to Bishop frame in Euclidean 3-space. We obtain a new characterization of parallel curve by using Bishop frame in E\{double-struck\}3.},
	issue        = 1,
	keywords     = {Bishop frame,Curves,Euclidean 3-space,Parallel curves}
}
@article{Jacobson2015,
	title        = {Skinning: Real-time Shape Deformationart II: Automatic Skinning via Constrained Energy Optimization},
	author       = {Alec Jacobson},
	year         = 2015,
	journal      = {SIGGRAPH Course 2014},
	pages        = {1--28},
	url          = {http://skinning.org/automatic-methods.pdf}
}
@phdthesis{Rieux2015,
	title        = {Processus de Diffusion Discret Op\'{e}rateur Laplacien appliqu\'{e} \`{a} l'\'{e}tude de surfaces},
	author       = {Fr\'{e}d\'{e}ric Rieux},
	year         = 2015,
	url          = {https://tel.archives-ouvertes.fr/tel-01174715/file/these.pdf}
}
@article{Emilien2015a,
	title        = {WorldBrush},
	author       = {Arnaud Emilien and Ulysse Vimont and Marie-Paule Cani and Pierre Poulin and Bedrich Benes},
	year         = 2015,
	month        = 7,
	journal      = {ACM Transactions on Graphics},
	volume       = 34,
	pages        = {1--11},
	doi          = {10.1145/2766975},
	issn         = {0730-0301},
	url          = {https://dl.acm.org/doi/10.1145/2766975},
	abstract     = {We present a novel approach for the interactive synthesis and editing of virtual worlds. Our method is inspired by painting operations and uses methods for statistical example-based synthesis to automate content synthesis and deformation. Our real-time approach takes a form of local inverse procedural modeling based on intermediate statistical models: selected regions of procedurally and manually constructed example scenes are analyzed, and their parameters are stored as <italic>distributions</italic> in a palette, similar to colors on a painter's palette. These <italic>distributions</italic> can then be interactively applied with brushes and combined in various ways, like in painting systems. Selected regions can also be moved or stretched while maintaining the consistency of their content. Our method captures both distributions of elements and structured objects, and models their interactions. Results range from the interactive editing of 2D artwork maps to the design of 3D virtual worlds, where constraints set by the terrain's slope are also taken into account.},
	issue        = 4,
	keywords     = {Computer graphics,Interactive modeling,Inverse procedural modeling,Painting systems,Virtual worlds}
}
@article{Bradbury2015,
	title        = {Guided Ecological Simulation for Artistic Editing of Plant Distributions in Natural Scenes},
	author       = {Gwyneth A Bradbury and Kartic Subr and Charalampos Koniaris and Kenny Mitchell and Tim Weyrich},
	year         = 2015,
	journal      = {The Journal of Computer Graphics Techniques},
	volume       = 4,
	pages        = {28--53},
	url          = {https://pure.hw.ac.uk/ws/portalfiles/portal/10342646/Bradbury2015Guided_lowres.pdf},
	abstract     = {In this paper we present a novel approach to author vegetation cover of large natural scenes. Unlike stochastic scatter-instancing tools for plant placement (such as multi-class blue noise generators), we use a simulation based on ecological processes to produce layouts of plant distributions. In contrast to previous work on ecosystem simulation, however, we propose a framework of global and local editing operators that can be used to interact directly with the live simulation. The result facilitates an artist-directed workflow with both spatially and temporally-varying control over the simulation's output. We compare our result against random-scatter solutions, also employing such approaches as a seed to our algorithm. We demonstrate the versatility of our approach within an iterative authoring workflow, comparing it to typical artistic methods.},
	issue        = 4
}
@article{Michel2016,
	title        = {Generation of Folded Terrains from Simple Vector Maps},
	author       = {Elie Michel and Arnaud Emilien and Marie-Paule Cani},
	year         = 2015,
	journal      = {Eurographics 2015 short paper proceedings},
	pages        = {4--8},
	doi          = {10.2312/egsh.20151019},
	url          = {https://hal.inria.fr/hal-01147920/file/2015__Michel__Generation_of_Folded_Terrains_from_Simple_Vector_Maps.pdf}
}
@article{Gain2015,
	title        = {Parallel, Realistic and Controllable Terrain Synthesis},
	author       = {James Gain and B. Merry and Patrick Marais},
	year         = 2015,
	journal      = {Computer Graphics Forum},
	volume       = 34,
	pages        = {105--116},
	doi          = {10.1111/cgf.12545},
	issn         = 14678659,
	abstract     = {The challenge in terrain synthesis for virtual environments is to provide a combination of precise user control over landscape form, with interactive response and visually realistic results. We present a system that builds on parallel pixel-based texture synthesis to enable interactive creation of an output terrain from a database of heightfield exemplars. We also provide modelers with control over height and surrounding slope by means of constraint points and curves; a paint-by-numbers interface for specifying the local character of terrain; coherence controls that allow localization of changes to the synthesized terrain; and copy-paste functionality to directly transplant terrain regions. Together these contributions provide a level of realism that, based on user experiments, is indistinguishable from real source terrains; user control sufficient for precise placement of a variety of landforms, such as cliffs, ravines and mesas; and synthesis times of 165ms for a 10242 terrain grid.},
	issue        = 2
}
@article{Khan2015,
	title        = {Adaptive rectangular cuboids for 3D mapping},
	author       = {Sheraz Khan and Dirk Wollherr and Martin Buss},
	year         = 2015,
	journal      = {Proceedings - IEEE International Conference on Robotics and Automation},
	volume       = {2015-June},
	pages        = {2132--2139},
	doi          = {10.1109/ICRA.2015.7139480},
	isbn         = 9781479969234,
	issn         = 10504729,
	url          = {https://mediatum.ub.tum.de/doc/1271436/1271436.pdf},
	abstract     = {This paper presents an extension of the standard occupancy grid for 3D environment mapping. The presented approach adds a fusion process after the occupancy update which modifies the resolution of the grid cells in an incremental manner. Consequently, the proposed approach requires fewer grid cells for 3D representation in comparison to a standard occupancy grid. The resolution adaptation process is based on the occupancy probabilities of the grid cells and leads to the relaxation of the cubic grid cell assumption common to most 3D occupancy grids. The aim of this paper is to show the advantage of the proposed incremental fusion process which leads to the approximation of the 3D environment using rectangular cuboids. Evaluation on a large scale dataset and comparison to the state of the art shows that the proposed approach has faster access time for all occupied grid cells and requires a smaller number of cells for 3D environment representation.},
	issue        = {June}
}
@inproceedings{Abela2015,
	title        = {A Constructive Approach for the Generation of Underwater Environments},
	author       = {Ryan Abela and Antonios Liapis and Georgios N Yannakakis},
	year         = 2015,
	booktitle    = {Proceedings of the FDG workshop on Procedural Content Generation in Games},
	url          = {https://code.google.com/p/lsystems-csharp-lib},
	abstract     = {This paper introduces Coralize, a library of generators for marine organisms such as corals and sponges. Using constructive algorithms, Coralize can generate stony corals via L-system grammars, soft corals via leaf venation algorithms and sponges via nutrient-based mesh growth. The genera-tive algorithms are parameterizable, allowing a user to adjust the parameters in order to create visually appealing 3D meshes. Such meshes can be used to automatically populate a seabed or reef, in order to create a biologically realistic and aesthetically pleasing underwater environment.}
}
@article{Emilien2015,
	title        = {Interactive Procedural Modelling of Coherent Waterfall Scenes},
	author       = {Arnaud Emilien and Pierre Poulin and Marie-Paule Cani and Ulysse Vimont},
	year         = 2015,
	month        = 9,
	journal      = {Computer Graphics Forum},
	volume       = 34,
	pages        = {22--35},
	doi          = {10.1111/cgf.12515},
	issn         = {0167-7055},
	url          = {https://onlinelibrary.wiley.com/doi/10.1111/cgf.12515},
	abstract     = {Combining procedural generation and user control is a fundamental challenge for the interactive design of natural scenery. This is particularly true for modelling complex waterfall scenes where, in addition to taking charge of geometric details, an ideal tool should also provide a user with the freedom to shape the running streams and falls, while automatically maintaining physical plausibility in terms of flow network, embedding into the terrain, and visual aspects of the waterfalls. We present the first solution for the interactive procedural design of coherent waterfall scenes. Our system combines vectorial editing, where the user assembles elements to create a waterfall network over an existing terrain, with a procedural model that parametrizes these elements from hydraulic exchanges; enforces consistency between the terrain and the flow; and generates detailed geometry, animated textures and shaders for the waterfalls and their surroundings. The tool is interactive, yielding visual feedback after each edit.},
	issue        = 6,
	keywords     = {3,5,acm ccs,computational geometry and object,computer graphics,i,mesh generation,modelling-physically based modelling,natural phenomena}
}
@article{Mahdavi-Amiri2015,
	title        = {A Survey of Digital Earth},
	author       = {Ali Mahdavi-Amiri and Troy Alderson and Faramarz Samavati},
	year         = 2015,
	journal      = {Computers and Graphics (Pergamon)},
	volume       = 53,
	pages        = {95--117},
	doi          = {10.1016/j.cag.2015.08.005},
	issn         = {00978493},
	url          = {https://www.sfu.ca/~amahdavi/files/survey_C_G-min.pdf},
	abstract     = {The creation of a digital representation of the Earth and its associated data is a complex and difficult task. The incredible size of geospatial data and differences between data sets pose challenges related to big data, data creation, and data integration. Advances in globe representation and visualization have made use of Discrete Global Grid Systems (DGGSs) that discretize the globe into a set of cells to which data are assigned. DGGSs are well studied and important in the GIS, OGC, and Digital Earth communities but have not been well-introduced to the computer graphics community. In this paper, we provide an overview of DGGSs and their use in digitally representing the Earth, describe several current Digital Earth systems and their methods of Earth representation, and list a number of applications of Digital Earths with related works. Moreover, we discuss the key research areas and related papers from computer graphics that are useful for a Digital Earth system, such as advanced techniques for geospatial data creation and representation.},
	keywords     = {Digital Earth,Discrete Global Grid System,Geospatial visualization,Virtual Globe}
}
@inbook{Glynn2015,
	title        = {Bioerosion and Coral Reef Growth: A Dynamic Balance},
	author       = {Peter W. Glynn and Derek P. Manzello},
	year         = 2015,
	booktitle    = {Coral Reefs in the Anthropocene},
	publisher    = {Springer Netherlands},
	pages        = {67--97},
	doi          = {10.1007/978-94-017-7249-5_4},
	isbn         = 9789401772495,
	url          = {http://link.springer.com/10.1007/978-94-017-7249-5_4},
	abstract     = {This volume investigates the effects of human activities on coral reefs, which provide important life-supporting systems to surrounding natural and human communities. It examines the self-reinforcing ecological, economic and technological mechanisms that degrade coral reef ecosystems around the world. Topics include reefs and limestones in Earth history; the interactions between corals and their symbiotic algae; diseases of coral reef organisms; the complex triangle between reef fishes, seaweeds and corals; coral disturbance and recovery in a changing world. In addition, the authors take key recent advances in DNA studies into account which provides new insights into the population biology, patterns of species distributions, recent evolution and vulnerabilities to environmental stresses. These DNA analyses also provide new understandings of the limitations of coral responses and scales of management necessary to sustain coral reefs in their present states. Coral reefs have been essential sources of food, income and resources to humans for millennia. This book details the delicate balance that exists within these ecosystems at all scales, from geologic time to cellular interactions and explores how recent global and local changes influence this relationship. It will serve as an indispensable resource for all those interested in learning how human activities have affected this vital ecosystem around the world.},
	city         = {Dordrecht}
}
@article{Jokiel2015,
	title        = {Comparison of methods used to estimate coral cover in the Hawaiian Islands},
	author       = {Paul L. Jokiel and Ku'ulei S. Rodgers and Eric K. Brown and Jean C. Kenyon and Greta Aeby and William R. Smith and Fred Farrell},
	year         = 2015,
	journal      = {PeerJ},
	volume       = 2015,
	doi          = {10.7717/peerj.954},
	issn         = 21678359,
	abstract     = {Nine coral survey methods were compared at ten sites in various reef habitats with different levels of coral cover in K\={a}ne'ohe Bay, O'ahu, Hawai'i. Mean estimated coverage at the different sites ranged from less than 10\% cover to greater than 90\% cover. The methods evaluated include line transects, various visual and photographic belt transects, video transects and visual estimates. At each site 25 m transect lines were laid out and secured. Observers skilled in each method measured coral cover at each site. The time required to run each transect, time required to process data and time to record the results were documented. Cost of hardware and software for each method was also tabulated. Results of this investigation indicate that all of the methods used provide a good first estimate of coral cover on a reef. However, there were differences between the methods in detecting the number of coral species. For example, the classic "quadrat" method allows close examination of small and cryptic coral species that are not detected by other methods such as the "towboard" surveys. The time, effort and cost involved with each method varied widely, and the suitability of each method for answering particular research questions in various environments was evaluated. Results of this study support the finding of three other comparison method studies conducted at various geographic locations throughout the world. Thus, coral cover measured by different methods can be legitimately combined or compared in many situations. The success of a recent modeling effort based on coral cover data consisting of observations taken in Hawai'i using the different methods supports this conclusion.},
	issue        = 5,
	keywords     = {Coral cover,Coral reefs,Hawaii,Methods comparison}
}
@article{Skorkovska2015,
	title        = {Hydraulic erosion modeling on a triangular mesh},
	author       = {V\v{e}ra Skorkovsk\'{a} and Ivana Kolingerov\'{a} and Bedrich Benes},
	year         = 2015,
	journal      = {Lecture Notes in Geoinformation and Cartography},
	volume       = 211,
	pages        = {237--247},
	doi          = {10.1007/978-3-319-18407-4_20},
	isbn         = 9783319184067,
	issn         = 18632351,
	abstract     = {Although hydraulic erosion modeling on a GIS terrain models has been addressed by a body of previous work, it still remains an open problem. In GIS, raster representation and triangular irregular networks (TIN) are the most commonly used surface models, because they are simple and offer implicit topological information. However, these data structures do not allow the simulation of erosion on concave terrain features, such as caves or overhangs. Other methods, more commonly used in the computational fluid dynamics, use volumetric data representation. They are able to model the 3D features, but they usually have high memory requirements and are computationally demanding. We propose a novel solution to the hydraulic erosion modeling problem that uses a triangular mesh data structure. Our framework allows for adaptive changes of the mesh resolution according to the local complexity of the terrain, which leads to lower memory requirements when compared to the volumetric approaches. Our data structure also supports the visualization of the concave 3D features, allowing the simulation and visualization of erosion on terrain elements such as tunnels or caves.},
	keywords     = {Erosion,Hydraulic erosion,Smoothed particle hydrodynamics,Terrain modeling,Triangular mesh}
}
@article{Vinyals2015,
	title        = {Pointer Networks},
	author       = {Oriol Vinyals and Meire Fortunato and Navdeep Jaitly},
	year         = 2015,
	journal      = {Nips 2015},
	pages        = {1--9},
	url          = {http://arxiv.org/abs/1506.03134},
	abstract     = {We introduce a new neural architecture to learn the conditional probability of an output sequence with elements that are discrete tokens corresponding to positions in an input sequence. Such problems cannot be trivially addressed by existent approaches such as sequence-to-sequence and Neural Turing Machines, because the number of target classes in each step of the output depends on the length of the input, which is variable. Problems such as sorting variable sized sequences, and various combinatorial optimization problems belong to this class. Our model solves the problem of variable size output dictionaries using a recently proposed mechanism of neural attention. It differs from the previous attention attempts in that, instead of using attention to blend hidden units of an encoder to a context vector at each decoder step, it uses attention as a pointer to select a member of the input sequence as the output. We call this architecture a Pointer Net (Ptr-Net). We show Ptr-Nets can be used to learn approximate solutions to three challenging geometric problems -- finding planar convex hulls, computing Delaunay triangulations, and the planar Travelling Salesman Problem -- using training examples alone. Ptr-Nets not only improve over sequence-to-sequence with input attention, but also allow us to generalize to variable size output dictionaries. We show that the learnt models generalize beyond the maximum lengths they were trained on. We hope our results on these tasks will encourage a broader exploration of neural learning for discrete problems.}
}
@article{Chevalier2015a,
	title        = {Hydrodynamics of the Toliara Reef Lagoon (Madagascar): Example of a Lagoon Influenced by Waves and Tides},
	author       = {Cristele Chevalier and Jean Luc Devenon and Gilles Rougier and Jean Blanchot},
	year         = 2015,
	journal      = {Journal of Coastal Research},
	volume       = 31,
	pages        = {1403--1416},
	doi          = {10.2112/JCOASTRES-D-13-00077.1},
	issn         = 15515036,
	abstract     = {Chevalier; C.; Devenon, J.-L.; Rougier, G., and Blanchot, J., 2015. Hydrodynamics of the Toliara reef lagoon (Madagascar): Example of a lagoon influenced by waves and tides. In meso-tidal lagoons, the coral reef barrier can be temporarily submerged at high tide and partially exposed at low tide, which causes highly specific lagoon dynamics. To understand those dynamics, three field-measurement campaigns were conducted in the Toliara Lagoon (Madagascar), where the tide and the waves increase that effect. The method combined measurements taken from fixed moorings and measurements from a small, moving, inflatable boat along the transects through the reef passages. A tidal analysis methodology adapted to this lagoon was used to reconstitute the currents through the passages and to determine the spatial and temporal current variability. Then, the lagoon water dynamics were studied. The tidal dynamics of the lagoon appear to depend significantly on flows through the passages, although they were also affected by water passing across the reef. Water entered the lagoon through the passages during the tidal flow and left it during the ebb. The tidal-prism flushing time (estimated using the tidal prism method) was 1 day during spring tide and 5 days during neap tide. At the same time, the average flow during a tidal cycle appears to be directly linked to the waves breaking over the reef. Indeed, the average cross-reef flow was inflowing and was mainly driven by the ocean swell. That inflow was balanced by an outflow through the passages. Hence, the average bulk flushing time was estimated at 13 days during the wet season and 4 days during the dry season.},
	issue        = 6,
	keywords     = {Meso-tidal reef lagoon,Toliara (Tulear) Lagoon.,flushing time,reef barrier overflow}
}
@article{Chevalier2015b,
	title        = {Impact of cross-reef water fluxes on lagoon dynamics: a simple parameterization for coral lagoon circulation model, with application to the Ouano Lagoon, New Caledonia},
	author       = {Cristele Chevalier and Damien Sous and Jean Luc Devenon and Marc Pagano and Gilles Rougier and Jean Blanchot},
	year         = 2015,
	journal      = {Ocean Dynamics},
	volume       = 65,
	pages        = {1509--1534},
	doi          = {10.1007/s10236-015-0879-x},
	isbn         = 1023601508,
	issn         = 16167228,
	abstract     = {This manuscript presents a combined experimental and numerical study of the impact of cross-reef fluxes on coral reef lagoon dynamics. The selected field site is the Ouano Lagoon (New Caledonia Island, France) in the South Western Pacific Ocean. Measurements of wave transformation above the reef and current profiles through passages and reef openings have been carried out during a 3-month survey. Data analysis reveals the preponderant roles played by both tides and waves on the lagoon dynamics. Based on field data, a simple parameterization of cross-reef fluxes is implemented in a coastal lagoon circulation model and a satisfactory agreement is found between parameterized model and field results. The model is thus used as a numerical experimental tool in order to analyse the cross-reef flows' possible influence on a narrow lagoon dynamics. The results highlight the importance of cross-reef fluxes induced by wave breaking over the reef barrier on the whole lagoon circulation and water properties.},
	issue        = 11,
	keywords     = {Channel lagoon,Circulation model,Coral reef lagoon,Cross-reef fluxes,Lagoon hydrodynamics}
}
@phdthesis{Crause2015,
	title        = {Fast, Realistic Terrain Synthesis},
	author       = {Justin Crause},
	year         = 2015,
	url          = {http://library.wur.nl/WebQuery/wurpubs/fulltext/353506},
	institution  = {University of Cape Town}
}
@techreport{Pytel2015,
	title        = {Procedural Modeling of Cave-like Channels},
	author       = {Alex Pytel and Stephen Mann},
	year         = 2015,
	journal      = {Journal of Computer Graphics Techniques},
	volume       = 4,
	url          = {http://jcgt.org},
	abstract     = {Figure 1. Procedurally modeled channel network: (a) protochannels; (b) channels with breakthrough from lower to higher level. Abstract Hydraulic erosion that takes place underground leads to the formation of complex channel networks whose morphology emerges from the dynamic behavior of each channel, based on the presence of other channels nearby. Our approach to the problem of modeling such channel networks for computer graphics application involves a self-organized model of channel development and a two-stage simulation for constructing the geometry of the channels. By emphasizing self-organization of flow and pressure, our simulation is able to reproduce several types of channel behavior known from hydrogeomorphology, such as tributary capture.},
	issue        = 2
}
@article{Araujo2015,
	title        = {A Survey on Implicit Surface Polygonization},
	author       = {B. R. de Ara\'{u}jo and Daniel S. Lopes and Pauline Jepp and Joaquim A. Jorge and Brian Wyvill},
	year         = 2015,
	month        = 7,
	journal      = {ACM Computing Surveys},
	volume       = 47,
	pages        = {1--39},
	doi          = {10.1145/2732197},
	issn         = {0360-0300},
	url          = {https://dl.acm.org/doi/10.1145/2732197},
	abstract     = {<p>Implicit surfaces (IS) are commonly used in image creation, modeling environments, modeling objects, and scientific data visualization. In this article, we present a survey of different techniques for fast visualization of IS. The main classes of visualization algorithms are identified along with the advantages of each in the context of the different types of IS commonly used in computer graphics. We focus closely on polygonization methods, as they are the most suited to fast visualization. Classification and comparison of existing approaches are presented using criteria extracted from current research. This enables the identification of the best strategies according to the number of specific requirements, such as speed, accuracy, quality, or stylization.</p>},
	issue        = 4,
	keywords     = {Body sensor network,Inertial navigation,Motion capture,Particle filter}
}
@phdthesis{GenevauxThesis,
	title        = {Repr\'{e}sentation, mod\'{e}lisation et g\'{e}n\'{e}ration proc\'{e}durale de terrains},
	author       = {Jean-David G\'{e}nevaux},
	year         = 2015,
	month        = 9,
	city         = {Lyon},
	institution  = {Universit\'{e} Lumi\`{e}re Lyon 2}
}
@phdthesis{GrosbelletThesis,
	title        = {G\'{e}n\'{e}ration de d\'{e}tails dans les mondes proc\'{e}duraux},
	author       = {Fran\c{c}ois Grosbellet},
	year         = 2015,
	month        = 11,
	city         = {Limoges},
	institution  = {Universit\'{e} de Limoges}
}
@article{Vermeulen2015,
	title        = {Urban layout optimization framework to maximize direct solar irradiation},
	author       = {Thibaut Vermeulen and Catherine Knopf-Lenoir and Pierre Villon and Benoit Beckers},
	year         = 2015,
	month        = 5,
	journal      = {Computers, Environment and Urban Systems},
	publisher    = {Elsevier Ltd},
	volume       = 51,
	pages        = {1--12},
	doi          = {10.1016/j.compenvurbsys.2015.01.001},
	issn         = {01989715},
	abstract     = {The need to save energy at the urban level leads to study how numerical simulations and optimization methods can help the architects to design buildings and districts with the best possible energetic performances, regarding daylight, warming or cooling, and photovoltaic capabilities.This work presents a study of solar potential maximization over a district and its relation with urban shape. For this purpose, two geometrical models are proposed. The first one is derived from the literature and describes a grid of buildings in open area; the second one studies moderately dense urban configurations with a pre-existent urban-context. A clear sky model is considered to compute direct solar radiation and an evolutionary algorithm is used to optimize the shape and the distribution of buildings inside a fixed area.Results show some clues on the optimal distribution of buildings considering the total direct solar irradiation to be captured by an urban district for various densities and compare the solar potential at different latitudes between 40\textdegree{} and 60\textdegree{}N.},
	keywords     = {Building shape,Evolutionary algorithm,Solar radiation,Urban layout}
}
@article{Rogers2015,
	title        = {Field observations of wave-driven circulation over spur and groove formations on a coral reef},
	author       = {Justin S. Rogers and Stephen G. Monismith and Robert B. Dunbar and David Koweek},
	year         = 2015,
	journal      = {Journal of Geophysical Research: Oceans},
	publisher    = {Blackwell Publishing Ltd},
	volume       = 120,
	pages        = {145--160},
	doi          = {10.1002/2014JC010464},
	issn         = 21699291,
	abstract     = {Spur and groove (SAG) formations are found on the forereefs of many coral reefs worldwide. Modeling results have shown that SAG formations together with shoaling waves induce a nearshore Lagrangian circulation pattern of counter-rotating circulation cells, but these have never been observed in the field. We present results from two separate field studies of SAG formations on Palmyra Atoll which show their effect on waves to be small, but reveal a persistent order 1 cm/s depth-averaged Lagrangian offshore flow over the spur and onshore flow over the grooves. This circulation was stronger for larger, directly incident waves and low alongshore flow conditions, consistent with predictions from modeling. Favorable forcing conditions must be maintained on the order of 1 h to accelerate and develop the SAG circulation cells. The primary cross and alongshore depth-averaged momentum balances were between the pressure gradient, radiation stress gradient, and nonlinear convective terms, and the bottom drag was similar to values found on other reefs. The vertical structure of these circulation cells was previously unknown and the results show a complex horizontal offshore Lagrangian flow over the spurs near the surface driven by alongshore variability in radiation stress gradients. Vertical flow was downward over the spur and upward over the groove, likely driven by alongshore differences in bottom stress and not by vortex forcing.},
	issue        = 1,
	keywords     = {Palmyra Atoll,coral reef,hydrodynamics,spur and groove,wave-current interaction}
}
@article{Zanni2015,
	title        = {N-ary implicit blends with topology control N-ary Implicit Blends with Topology Control author preprint},
	author       = {C\'{e}dric Zanni and Marie-Paule Cani and Michael Gleicher and C Zanni and M Gleicher and M.-P Cani},
	year         = 2015,
	journal      = {Computers and Graphics},
	volume       = 46,
	pages        = {1--13},
	doi          = {10.1016/j.cag.2014.09.012ï},
	url          = {https://inria.hal.science/hal-01073088v1},
	abstract     = {To cite this version: C\'{e}dric Zanni, Marie-Paule Cani, Michael Gleicher. N-ary implicit blends with topology control. Abstract Constructive implicit surfaces are attractive for modeling and animation because they seamlessly handle shapes with complex and dynamic topology. However, the way they merge shapes is difficult to control. This paper introduces a solution: an improved blend operator that provides control over how topology changes are handled. It is based on a correction applied to the standard blending operator: the sum. Building on summation preserves the n-ary nature of the blend, providing the simplicity of arbitrary (e.g. flat) construction trees and segmentation invariance. The correction is based on projection to a reference case in the variation-space defined by the field and the norm of its gradient. It provides a single parameter, allowing for tuning behavior to achieve effects ranging from avoiding topological combination, through merging only during overlap, to merging at a distance. Dynamic adjustment of the parameter allows for context-dependent effects. Applications range from skeleton-based modeling, where shapes keep the topology of their skeleton, to objects that change topology during animation, with controllable merging. We illustrate the latter with Manga-style hair, where merging depends on the angle between hair wisps. Figure 1: Topology control for implicit models can be used to prevent blending at distance and guarantee the topology of skeleton-based surfaces (left) or to control the dynamic topology of Manga-style hair (right), where blending should not only depend on distance but also on the angle between neighboring hair-wisps.},
	keywords     = {()}
}
@article{Gatys2015,
	title        = {A Neural Algorithm of Artistic Style},
	author       = {Leon A. Gatys and Alexander S. Ecker and Matthias Bethge},
	year         = 2015,
	month        = 8,
	url          = {http://arxiv.org/abs/1508.06576},
	abstract     = {In fine art, especially painting, humans have mastered the skill to create unique visual experiences through composing a complex interplay between the content and style of an image. Thus far the algorithmic basis of this process is unknown and there exists no artificial system with similar capabilities. However, in other key areas of visual perception such as object and face recognition near-human performance was recently demonstrated by a class of biologically inspired vision models called Deep Neural Networks. Here we introduce an artificial system based on a Deep Neural Network that creates artistic images of high perceptual quality. The system uses neural representations to separate and recombine content and style of arbitrary images, providing a neural algorithm for the creation of artistic images. Moreover, in light of the striking similarities between performance-optimised artificial neural networks and biological vision, our work offers a path forward to an algorithmic understanding of how humans create and perceive artistic imagery.}
}
@techreport{Gallop2015,
	title        = {Wave attenuation over the Great Barrier Reef matrix},
	author       = {Shari L Gallop and Ian R Young and Tom Durrant Oceanum},
	year         = 2015,
	url          = {https://www.researchgate.net/publication/280007028},
	abstract     = {The user has requested enhancement of the downloaded file.}
}
@article{Wahidi2015,
	title        = {Entity-based landscape modelling to assess the impacts of different incentives mechanisms on argan forest dynamics},
	author       = {Farid El Wahidi and Julien Radoux and Quentin Ponette and Pierre Defourny},
	year         = 2015,
	month        = 12,
	journal      = {Land},
	publisher    = {MDPI AG},
	volume       = 4,
	pages        = {1003--1029},
	doi          = {10.3390/land4041003},
	issn         = {2073445X},
	abstract     = {Illegal occupation of argan forest parcels by local households is a new phenomenon in South West Morocco. This is primarily due to the weakening of traditional common control systems and to the boom of the argan oil price. The scope of this work is to develop a decision support system based on dynamic spatial modelling, allowing to anticipate the land tenure dynamics and their impact on forest stand degradation under different policy scenarios. The model simulates the change of land possession by locals and the forest stand degradation levels. The methodological approach combines a Markov chain analysis (MCA) with stakeholders' preferences for land tenure. First, parcels' transition probabilities are computed using the MCA. Second, the acquiring suitability map is derived from multi-criteria evaluation procedure (AHP) using biophysical and socio-economic data. Finally, uncertainty is introduced in the simulation based on probabilistic analysis for supporting socio-economic diversity and non-mechanistic human behavior. The modelling approach was successfully used to compare three scenarios: business as usual (continuation of illegal acquiring), total disengagement of the population and private/public partnership with incentives for restoring argan parcel. The model yields geographic information about (i) the magnitude of the on-going process; (ii) the potential occurrence of land use conflicts induced by new policies; and (iii) the location of land conservation or degradation hot-spots. The outcomes of the "business as usual" and of the "total disengagement" models were similar over a 30-year simulation period: in both cases, the proportion of "highly degraded" parcels was doubled and the number of "quite degraded" parcels was increased by 50\%. On the other hand, should the private/public partnership effectively work, about 40\% of the parcels could be restored to a sustainable level.},
	issue        = 4,
	keywords     = {Argan forest dynamics,Entity based,Incentives mechanisms,Markov chain analysis,Multicriteria evaluation,Spatial modelling,Stakeholder's preferences}
}
@inproceedings{Onrust2015,
	title        = {Procedural generation and interactive web visualization of natural environments},
	author       = {Benny Onrust and Rafael Bidarra and Robert Rooseboom and Johan Van De Koppel},
	year         = 2015,
	month        = 6,
	booktitle    = {Proceedings - Web3D 2015: 20th International Conference on 3D Web Technology},
	publisher    = {Association for Computing Machinery, Inc},
	pages        = {133--141},
	doi          = {10.1145/2775292.2775306},
	isbn         = 9781450336475,
	abstract     = {Interactive 3D visualization of natural environments can help ecologists, policy makers and the broad public in general to better understand, promote and protect both existing and developing environments. The creation and exploration of virtual worlds can be very helpful for this purpose. However, current techniques are neither able to generate sound natural environments from ecological data nor do they provide web-based visualizations at interactive rates of such detailed ecological systems. In this paper, we approach the challenge of developing and interactively visualizing in real time ecologically accurate and visually convincing models of complex natural environments over the web. For this, we propose a framework that (i) is able to combine landscape maps and ecological statistical data, translating them to an ecologically sound plant distribution, and (ii) creates a detailed 3D representation of the natural environment and provides for its fully interactive visualization in real-time over the web. The main contribution of our research consists of the real-time web-based visualization of complete and visually convincing natural environments with their high density and variability of individual organisms. The vegetation model combines and improves techniques from procedural ecosystem generation and neutral landscape modeling. It is able to generate diverse ecological sound plant distribution directly from landscape maps with statistics about coverage and patchiness of plant species. The visualization model uses several existing level-of-detail and illumination techniques to achieve interactive frame rates and improve realism. From the validation of the results with ecology experts we conclude that our framework provides very convincing interactive visualizations of large virtual natural environments.},
	keywords     = {Ecological models,Procedural generation,WebGL}
}
@article{Shanin2015,
	title        = {New procedure for the simulation of belowground competition can improve the performance of forest simulation models},
	author       = {Vladimir Shanin and Raisa M\"{a}kip\"{a}\"{a} and Maxim Shashkov and Natalya Ivanova and Konstantin Shestibratov and Svetlana Moskalenko and Liliya Rocheva and Pavel Grabarnik and Kapitolina Bobkova and Alexey Manov and Andrey Osipov and Elvira Burnasheva and Maria Bezrukova},
	year         = 2015,
	month        = 11,
	journal      = {European Journal of Forest Research},
	publisher    = {Springer Verlag},
	volume       = 134,
	pages        = {1055--1074},
	doi          = {10.1007/s10342-015-0909-8},
	issn         = 16124669,
	abstract     = {The major part of existing models of belowground competition in mixed forest stands is limited in explaining the spatial distribution of roots as a response to competitive pressure from neighbours and heterogeneity of soil properties. We are presenting a new spatially explicit and multi-layered discrete model of belowground competition, RootInt (ROOTs INTake). It describes spatial distribution of belowground biomass and allows simulation of competition between trees for soil nutrients. The tree-specific area of root zone is calculated on the basis of stem diameter, with site-specific modifiers to account for the effect of soil fertility and moisture. The shape of root zone is dependent on the amount of available nitrogen in the current cell, distance between this cell and the stem base, and the mass of roots of other plants. RootInt was incorporated into ecosystem model EFIMOD to refine the existing description of belowground competition in forest stands with multiple cohorts and tree species. The results of simulation showed that bringing more complexity into structure of stand (including initial spatial locations of trees, species composition and age structure, vertical structure of canopy) resulted in higher spatial variation in competition intensity, as well as in higher rates of resource uptake. This indicates that stands with complex canopy structure had high plasticity in their root systems and were adapted to intensive competition for soil resources.},
	issue        = 6,
	keywords     = {Adaptation,Forest ecosystems,Meta-analysis,Process-based model,Root systems}
}
@article{Hahne2016,
	title        = {Refocusing distance of a standard plenoptic camera},
	author       = {Christopher Hahne and Amar Aggoun and Vladan Velisavljevic and Susanne Fiebig and Matthias Pesch},
	year         = 2016,
	month        = 9,
	journal      = {Optics Express},
	publisher    = {The Optical Society},
	volume       = 24,
	pages        = 21521,
	doi          = {10.1364/oe.24.021521},
	issn         = {1094-4087},
	url          = {http://www.trioptics.com/knowledge-base/mtf-and-image-quality/.23.C.Hahne,%22Zemaxarchivefilecontainingplenopticcameradesign,%22figsharehttp://dx.doi.org/10.6084/m9.figshare.3381082.http://dx.doi.org/10.6084/m9.figshare.3362152.},
	abstract     = {\textcopyright{} 2016 Optical Society of America. Recent developments in computational photography enabled variation of the optical focus of a plenoptic camera after image exposure, also known as refocusing. Existing ray models in the field simplify the camera's complexity for the purpose of image and depth map enhancement, but fail to satisfyingly predict the distance to which a photograph is refocused. By treating a pair of light rays as a system of linear functions, it will be shown in this paper that its solution yields an intersection indicating the distance to a refocused object plane. Experimental work is conducted with different lenses and focus settings while comparing distance estimates with a stack of refocused photographs for which a blur metric has been devised. Quantitative assessments over a 24 m distance range suggest that predictions deviate by less than 0.35 \% in comparison to an optical design software. The proposed refocusing estimator assists in predicting object distances just as in the prototyping stage of plenoptic cameras and will be an essential feature in applications demanding high precision in synthetic focus or where depth map recovery is done by analyzing a stack of refocused photographs.},
	issue        = 19,
	keywords     = {(1101758) Computational imaging,(1103010) Image reconstruction techniques,(1105200) Photography,OCIS codes: (0803620) Lens system design}
}
@article{Cippitelli2016,
	title        = {A Human Activity Recognition System Using Skeleton Data from RGBD Sensors},
	author       = {Enea Cippitelli and Samuele Gasparrini and Ennio Gambi and Susanna Spinsante},
	year         = 2016,
	journal      = {Computational Intelligence and Neuroscience},
	publisher    = {Hindawi Limited},
	volume       = 2016,
	doi          = {10.1155/2016/4351435},
	issn         = 16875273,
	abstract     = {The aim of Active and Assisted Living is to develop tools to promote the ageing in place of elderly people, and human activity recognition algorithms can help to monitor aged people in home environments. Different types of sensors can be used to address this task and the RGBD sensors, especially the ones used for gaming, are cost-effective and provide much information about the environment. This work aims to propose an activity recognition algorithm exploiting skeleton data extracted by RGBD sensors. The system is based on the extraction of key poses to compose a feature vector, and a multiclass Support Vector Machine to perform classification. Computation and association of key poses are carried out using a clustering algorithm, without the need of a learning algorithm. The proposed approach is evaluated on five publicly available datasets for activity recognition, showing promising results especially when applied for the recognition of AAL related actions. Finally, the current applicability of this solution in AAL scenarios and the future improvements needed are discussed.},
	pmid         = 27069469
}
@article{Guerin2016a,
	title        = {Sparse representation of terrains for procedural modeling},
	author       = {\'{E}ric Gu\'{e}rin and Julie Digne and \'{E}ric Galin and Adrien Peytavie},
	year         = 2016,
	journal      = {Computer Graphics Forum},
	volume       = 35,
	pages        = {177--187},
	doi          = {10.1111/cgf.12821},
	issn         = 14678659,
	abstract     = {In this paper, we present a simple and efficient method to represent terrains as elevation functions built from linear combinations of landform features (atoms). These features can be extracted either from real world data-sets or procedural primitives, or from any combination of multiple terrain models. Our approach consists in representing the elevation function as a sparse combination of primitives, a concept which we call Sparse Construction Tree, which blends the different landform features stored in a dictionary. The sparse representation allows us to represent complex terrains using combinations of atoms from a small dictionary, yielding a powerful and compact terrain representation and synthesis tool. Moreover, we present a method for automatically learning the dictionary and generating the Sparse Construction Tree model. We demonstrate the efficiency of our method in several applications: inverse procedural modeling of terrains, terrain amplification and synthesis from a coarse sketch.},
	issue        = 2
}
@article{Genevaux2016,
	title        = {Mod\'{e}lisation de terrains par primitives},
	author       = {Jean-David G\'{e}nevaux and Fran\c{c}ois Grosbellet and \'{E}ric Galin and Adrien Peytavie and \'{E}ric Gu\'{e}rin and Cyril Briquet},
	year         = 2016,
	keywords     = {implicit surface,natural phenomena,procedural modelling,terrain modelling}
}
@article{Hatanaka2016,
	title        = {Comparative Gait Analysis in Progressive Supranuclear Palsy and Parkinson's Disease},
	author       = {Noriko Hatanaka and Kota Sato and Nozomi Hishikawa and Mami Takemoto and Yasuyuki Ohta and Toru Yamashita and Koji Abe},
	year         = 2016,
	month        = 7,
	journal      = {European Neurology},
	publisher    = {S. Karger AG},
	volume       = 75,
	pages        = {282--289},
	doi          = {10.1159/000445111},
	issn         = 14219913,
	url          = {https://www.karger.com/Article/FullText/445111 https://www.karger.com/Article/Abstract/445111},
	abstract     = {Background: Although changes to gait are an important clinical feature of progressive supranuclear palsy (PSP), systematic analyses have not been well examined, especially in comparison to Parkinson's disease (PD). Methods: The characteristics of gait in 20 PSP patients (14 males and 6 females) were evaluated in comparison to 124 PD patients (64 males and 60 females) and 24 controls, that is, healthy age-matched adults (5 males and 19 females). Gait in patients was recorded in a 10-m walking test at a self-selected speed. During this time, patients felt most comfortable while wearing a new portable triaxial accelerometer rhythmogram device. Gait variables among the 3 groups were compared. Results: Both PSP and PD patients shared the following similar hypokinetic gait characteristics: decreased velocity, step length, cadence and mean acceleration. Step time and variability in step time were mutually related. However, among the 3 groups, PSP patients showed characteristically low vertical displacement and a higher acceleration than PD patients at the same cadence. Conclusion: Although PSP and PD patients showed similar hypokinetic gait, a reduced vertical displacement characterized walking in PSP patients, differing substantially from the characteristics of walking displayed by PD patients.},
	issue        = {5-6},
	keywords     = {Acceleration,Gait,Parkinson's disease,Progressive supranuclear palsy,Vertical displacement},
	pmid         = 27288001
}
@article{Zhang2016,
	title        = {Real-time Action Recognition with Enhanced Motion Vector CNNs},
	author       = {Bowen Zhang and Limin Wang and Zhe Wang and Yu Qiao and Hanli Wang},
	year         = 2016,
	month        = 4,
	journal      = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	publisher    = {IEEE Computer Society},
	volume       = {2016-Decem},
	pages        = {2718--2726},
	url          = {http://arxiv.org/abs/1604.07669},
	abstract     = {The deep two-stream architecture exhibited excellent performance on video based action recognition. The most computationally expensive step in this approach comes from the calculation of optical flow which prevents it to be real-time. This paper accelerates this architecture by replacing optical flow with motion vector which can be obtained directly from compressed videos without extra calculation. However, motion vector lacks fine structures, and contains noisy and inaccurate motion patterns, leading to the evident degradation of recognition performance. Our key insight for relieving this problem is that optical flow and motion vector are inherent correlated. Transferring the knowledge learned with optical flow CNN to motion vector CNN can significantly boost the performance of the latter. Specifically, we introduce three strategies for this, initialization transfer, supervision transfer and their combination. Experimental results show that our method achieves comparable recognition performance to the state-of-the-art, while our method can process 390.7 frames per second, which is 27 times faster than the original two-stream method.}
}
@phdthesis{Bitiusca2016,
	title        = {Eulerian Fluid Simulator},
	author       = {Liviu-George Bitiușc\u{a}},
	year         = 2016,
	issue        = {August}
}
@article{VonRadziewsky2016,
	title        = {Optimized subspaces for deformation-based modeling and shape interpolation},
	author       = {Philipp Von Radziewsky and Elmar Eisemann and Hans Peter Seidel and Klaus Hildebrandt},
	year         = 2016,
	journal      = {Computers and Graphics (Pergamon)},
	volume       = 58,
	pages        = {128--138},
	doi          = {10.1016/j.cag.2016.05.016},
	issn         = {00978493},
	url          = {https://graphics.tudelft.nl/Publications-new/2016/VESH16/optimizedSubspaces.pdf},
	abstract     = {We propose a novel construction of subspaces for real-time deformation-based modeling and shape interpolation. The scheme constructs a subspace that optimally approximates the manifold of deformations relevant for a specific modeling or interpolation problem. The idea is to automatically sample the deformation manifold and construct the subspace that best-approximates these snapshots. This is realized by writing the shape modeling and interpolation problems as parametrized optimization problems with few parameters. The snapshots are generated by sampling the parameter domain and computing the corresponding minimizers. Finally, the optimized subspaces are constructed using a mass-dependent principle component analysis. The optimality provided by this scheme contrasts it from alternative approaches, which aim at constructing spaces containing low-frequency deformations. The benefit of this construction is that compared to alternative approaches a similar approximation quality is achieved with subspaces of significantly smaller dimension. This is crucial because the run-times and memory requirements of the real-time shape modeling and interpolation schemes mainly depend on the dimensions of the subspaces.},
	keywords     = {Shape deformation,Shape interpolation,Shape modeling}
}
@misc{Ensimag2016,
	title        = {TP 2 : Lissage laplacien},
	author       = {Ensimag},
	year         = 2016,
	pages        = {2--5},
	url          = {https://team.inria.fr/imagine/files/2015/09/tp_lissage.pdf}
}
@article{Guerin2016,
	title        = {Efficient modeling of entangled details for natural scenes},
	author       = {Eric Gu\'{e}rin and Eric Galin and Fran\c{c}ois Grosbellet and Adrien Peytavie and Jean-David G\'{e}nevaux},
	year         = 2016,
	month        = 10,
	journal      = {Computer Graphics Forum},
	volume       = 35,
	pages        = {257--267},
	doi          = {10.1111/cgf.13023},
	issn         = {0167-7055},
	url          = {https://onlinelibrary.wiley.com/doi/10.1111/cgf.13023},
	abstract     = {<p>Digital landscape realism often comes from the multitude of details that are hard to model such as fallen leaves, rock piles or entangled fallen branches. In this article, we present a method for augmenting natural scenes with a huge amount of details such as grass tufts, stones, leaves or twigs. Our approach takes advantage of the observation that those details can be approximated by replications of a few similar objects and therefore relies on mass-instancing. We propose an original structure, the Ghost Tile, that stores a huge number of overlapping candidate objects in a tile, along with a pre-computed collision graph. Details are created by traversing the scene with the Ghost Tile and generating instances according to user-defined density fields that allow to sculpt layers and piles of entangled objects while providing control over their density and distribution.</p>},
	issue        = 7
}
@article{Cordonnier2016,
	title        = {Large Scale Terrain Generation from Tectonic Uplift and Fluvial Erosion},
	author       = {Guillaume Cordonnier and Jean Braun and Marie-Paule Cani and Bedrich Benes and \'{E}ric Galin and Adrien Peytavie and \'{E}ric Gu\'{e}rin},
	year         = 2016,
	month        = 5,
	journal      = {Computer Graphics Forum},
	volume       = 35,
	pages        = {165--175},
	doi          = {10.1111/cgf.12820},
	issn         = {0167-7055},
	url          = {https://onlinelibrary.wiley.com/doi/10.1111/cgf.12820},
	abstract     = {<p>At large scale, landscapes result from the combination of two major processes: tectonics which generate the main relief through crust uplift, and weather which accounts for erosion. This paper presents the first method in computer graphics that combines uplift and hydraulic erosion to generate visually plausible terrains. Given a user-painted uplift map, we generate a stream graph over the entire domain embedding elevation information and stream flow. Our approach relies on the stream power equation introduced in geology for hydraulic erosion. By combining crust uplift and stream power erosion we generate large realistic terrains at a low computational cost. Finally, we convert this graph into a digital elevation model by blending landform feature kernels whose parameters are derived from the information in the graph. Our method gives high-level control over the large scale dendritic structures of the resulting river networks, watersheds, and mountains ridges.</p>},
	issue        = 2
}
@phdthesis{Blomqvist2016,
	title        = {Generating Compelling Procedural 3D Environments and Landscapes},
	author       = {Oscar Blomqvist and Pierre Kraft and Hampus Lidin and Rimmer Motzheim and Adam Tonderski and Gabriel Wagner},
	year         = 2016,
	issue        = {June}
}
@article{Snodgrass2016,
	title        = {Controllable procedural content generation via constrained multi-dimensional markov chain sampling},
	author       = {Sam Snodgrass and Santiago Onta\~{n}\'{o}n},
	year         = 2016,
	journal      = {IJCAI International Joint Conference on Artificial Intelligence},
	volume       = {2016-Janua},
	pages        = {780--786},
	issn         = 10450823,
	url          = {https://www.ijcai.org/Proceedings/16/Papers/116.pdf},
	abstract     = {Statistical models, such as Markov chains, have recently started to be studied for the purpose of Procedural Content Generation (PCG). A major problem with this approach is controlling the sampling process in order to obtain output satisfying some desired constraints. In this paper we present three approaches to constraining the content generated using multi-dimensional Markov chains: (1) a generate and test approach that simply resamples the content until the desired constraints are satisfied, (2) an approach that finds and resamples parts of the generated content that violate the constraints, and (3) an incremental method that checks for constraint violations during sampling. We test our approaches by generating maps for two classic video games, Super Mario Bros. and Kid Icarus.},
	issue        = {MdMC}
}
@phdthesis{Moussaoui2016,
	title        = {Geometric Constraint Solver},
	author       = {Adel Moussaoui},
	year         = 2016,
	volume       = 8,
	pages        = {17--34},
	url          = {Evolution des propriétés diélectriques, ferroélectriques et électromécaniques dans le système pseudo-binaire (1-x)BaTi0.8Zr0.2O3- xBa0.7Ca0.3TiO3 / Corrélations structures et propriétés Feres Benabdallah%0A},
	abstract     = {A geometric constraint system consists of a finite set of geometric elements, such as points, lines, and circles, along with relationships of different types such as distance, angle, incidence and parallelism. This problem is central to many applications, such as computer-aided design, molecular modelling and recently localization in wireless sensor networks. Solving a geometric constraint system consists of finding real coordinates of geometric elements in the Euclidean space. In 2-dimensional geometric constraint solving, graph-based techniques are a dominant approach, particularly in the computer-aided design context. To speed up the resolution process, these methods transform the geometric problem into a graph, which is decomposed into small subgraphs. Each one is solved, separately, and the final solution is obtained by recomposing the solved subgraphs. However, most of the previous research on graph-based approaches has only focused on the decomposition without any attention on what will be decomposed: the geometric constraint graph. Major proposed algorithms are discussed or compared theoretically, without presenting any tests on graphs instances with different structural properties, representing several cases of difficulties. Why? because as far as we know, there is no known algorithm for the creation of non-decomposable graphs or graphs with interesting structural properties that best highlight the efficiency of any algorithm. Our contribution is the design of a simple, but efficient random 2D geometric constraint graph generator. It can be used to make benchmarks for consistent tests, or to observe the behaviour of geometric constraints solving algorithms. It produces problem instances with various sizes and structural properties, covering different cases of complexity. Our design is based on the problem classification reported in the literature. We proved that our proposed generator is complete, customizable, simple and efficient. It has been validated experimentally and some of its properties have been theoretically proved.},
	issue        = 1,
	keywords     = {Acari,Agricultur,Animalia,Arachnida,Arthropoda}
}
@phdthesis{Becher2016,
	title        = {Feature Based Volumetric Terrain Generation},
	author       = {Michael Becher},
	year         = 2016,
	issue        = 74
}
@article{Guzdial2016,
	title        = {Learning to blend computer game levels},
	author       = {Matthew Guzdial and Mark Riedl},
	year         = 2016,
	journal      = {Proceedings of the 7th International Conference on Computational Creativity, ICCC 2016},
	pages        = {354--361},
	isbn         = 9782746691551,
	url          = {https://arxiv.org/pdf/1603.02738.pdf},
	abstract     = {We present an approach to generate novel computer game levels that blend different game concepts in an unsupervised fashion. Our primary contribution is an analogical reasoning process to construct blends between level design models learned from gameplay videos. The models represent probabilistic relationships between elements in the game. An analogical reasoning process maps features between two models to produce blended models that can then generate new level chunks. As a proof-of-concept we train our system on the classic platformer game Super Mario Bros. due to its highly-regarded and well understood level design. We evaluate the extent to which the models represent stylistic level design knowledge and demonstrate the ability of our system to explain levels that were blended by human expert designers.}
}
@article{Grosbellet2016,
	title        = {Environmental Objects for Authoring Procedural Scenes},
	author       = {Francois Grosbellet and Adrien Peytavie and \'{E}ric Gu\'{e}rin and \'{E}ric Galin and St\'{e}phane M\'{e}rillou and Bedrich Benes},
	year         = 2016,
	month        = 2,
	journal      = {Computer Graphics Forum},
	volume       = 35,
	pages        = {296--308},
	doi          = {10.1111/cgf.12726},
	issn         = {0167-7055},
	url          = {https://onlinelibrary.wiley.com/doi/10.1111/cgf.12726},
	abstract     = {We propose a novel approach for authoring large scenes with automatic enhancement of objects to create geometric decoration details such as snow cover, icicles, fallen leaves, grass tufts or even trash. We introduce environmental objects that extend an input object geometry with a set of procedural effects that defines how the object reacts to the environment, and by a set of scalar fields that defines the influence of the object over of the environment. The user controls the scene by modifying environmental variables, such as temperature or humidity fields. The scene definition is hierarchical: objects can be grouped and their behaviours can be set at each level of the hierarchy. Our per object definition allows us to optimize and accelerate the effects computation, which also enables us to generate large scenes with many geometric details at a very high level of detail. In our implementation, a complex urban scene of 10~000 m <sup>2</sup> , represented with details of less than 1 cm, can be locally modified and entirely regenerated in a few seconds.},
	issue        = 1
}
@article{Nicolas-Carlock2016,
	title        = {Fractality a la carte: A general particle aggregation model},
	author       = {J. R. Nicolas-Carlock and J. L. Carrillo-Estrada and V. Dossetti},
	year         = 2016,
	journal      = {Scientific Reports},
	publisher    = {Nature Publishing Group},
	volume       = 6,
	pages        = {1--8},
	doi          = {10.1038/srep19505},
	issn         = 20452322,
	abstract     = {In nature, fractal structures emerge in a wide variety of systems as a local optimization of entropic and energetic distributions. The fractality of these systems determines many of their physical, chemical and/or biological properties. Thus, to comprehend the mechanisms that originate and control the fractality is highly relevant in many areas of science and technology. In studying clusters grown by aggregation phenomena, simple models have contributed to unveil some of the basic elements that give origin to fractality, however, the specific contribution from each of these elements to fractality has remained hidden in the complex dynamics. Here, we propose a simple and versatile model of particle aggregation that is, on the one hand, able to reveal the specific entropic and energetic contributions to the clusters' fractality and morphology, and, on the other, capable to generate an ample assortment of rich natural-looking aggregates with any prescribed fractal dimension.},
	issue        = {December 2015}
}
@article{Gonzalez-Rivero2016,
	title        = {Scaling up ecological measurements of coral reefs using semi-automated field image collection and analysis},
	author       = {Manuel Gonz\'{a}lez-Rivero and Oscar Beijbom and Alberto Rodriguez-Ramirez and Tadzio Holtrop and Yeray Gonz\'{a}lez-Marrero and Anjani Ganase and Chris Roelfsema and Stuart Phinn and Ove Hoegh-Guldberg},
	year         = 2016,
	journal      = {Remote Sensing},
	volume       = 8,
	doi          = {10.3390/rs8010030},
	issn         = 20724292,
	abstract     = {Ecological measurements in marine settings are often constrained in space and time, with spatial heterogeneity obscuring broader generalisations. While advances in remote sensing, integrative modelling and meta-analysis enable generalisations from field observations, there is an underlying need for high-resolution, standardised and geo-referenced field data. Here, we evaluate a new approach aimed at optimising data collection and analysis to assess broad-scale patterns of coral reef community composition using automatically annotated underwater imagery, captured along 2 km transects. We validate this approach by investigating its ability to detect spatial (e.g., across regions) and temporal (e.g., over years) change, and by comparing automated annotation errors to those of multiple human annotators. Our results indicate that change of coral reef benthos can be captured at high resolution both spatially and temporally, with an average error below 5\%, among key benthic groups. Cover estimation errors using automated annotation varied between 2\% and 12\%, slightly larger than human errors (which varied between 1\% and 7\%), but small enough to detect significant changes among dominant groups. Overall, this approach allows a rapid collection of in-situ observations at larger spatial scales (km) than previously possible, and provides a pathway to link, calibrate, and validate broader analyses across even larger spatial scales (10-10,000 km2).},
	issue        = 1,
	keywords     = {Coral reefs,Monitoring,Support vector machine,XL Catlin Seaview Survey}
}
@article{Goldberg2016,
	title        = {Atolls of the world: Revisiting the original checklist},
	author       = {Walter M. Goldberg},
	year         = 2016,
	journal      = {Atoll Research Bulletin},
	volume       = 2016,
	pages        = {1--47},
	doi          = {10.5479/si.0077-5630.610},
	issn         = {00775630},
	abstract     = {There is only one published list of atolls of the world (Bryan, 1953) and it is the source of the often-quoted figure that there are 425 or ``more than 400'' of them. However, the original compendium included many banks and other reefs without lagoons. A re-examination of Bryan's data, along with charts, satellite photographs and updated literature suggests that the number of atolls is indeed ``more than 400,'' despite the deletion of more than 100 of his entries. There are 439 atolls identified in the present summary, but the list is broadly constructed, inclusive, and not limited to those known to have formed on subsiding volcanic platforms. In addition, 171 of those listed (39\%) are primarily subtidal atoll reefs with little or no island development. These particular atolls comprise 96\% of those from Fiji, 94\% of those in the South China Sea, and 62\% of those in Indonesia. With few exceptions, all of these reef systems are specifically identified and verified using Google Earth, Landsat or other satellite imagery, making this group an important and under-appreciated element of atoll geomorphology. Eliminating atoll reefs from consideration reduces the list of atolls to 268. Of these, 104 are closed and lack a direct passage connecting the lagoon and the surrounding ocean. Closed lagoons are typical of atolls in French Polynesia (53 of 78 with lagoons), even though most of them are euhaline and are open to exchange of ocean water by indirect mechanisms. By contrast, many atolls in the central Pacific, including most of those in Tuvalu, the Phoenix Islands and the Line Islands, have developed isolated lagoons containing hypersaline, brackish, and even fresh water. The location and type of atoll (atoll reef, and atolls that are open, closed, or closed with altered lagoon salinity/oxygen) are specified on maps and tables appended to this work, and a photographic record of all but two of 439 atolls has been assembled as a supplement. This list is by no means complete. There are numerous atolls or atoll-like structures that do not have a satellite record or an adequate description on charts or in the literature. This is especially true of Indonesia, Fiji and islands east of Papua New Guinea where further exploration is likely to increase the number of entries.},
	issue        = 610
}
@article{Zhao2016,
	title        = {Relationship templates for creating scene variations},
	author       = {Xi Zhao and Ruizhen Hu and Paul Guerrero and Niloy Mitra and Taku Komura},
	year         = 2016,
	journal      = {ACM Transactions on Graphics},
	volume       = 35,
	doi          = {10.1145/2980179.2982410},
	isbn         = 9781450345149,
	issn         = 15577368,
	url          = {https://paulguerrero.net/papers/Reltemplates.pdf},
	abstract     = {We propose a novel example-based approach to synthesize scenes with complex relations, e.g., when one object is 'hooked', 'surrounded', 'contained' or 'tucked into' another object. Existing relationship descriptors used in automatic scene synthesis methods are based on contacts or relative vectors connecting the object centers. Such descriptors do not fully capture the geometry of spatial interactions, and therefore cannot describe complex relationships. Our idea is to enrich the description of spatial relations between object surfaces by encoding the geometry of the open space around objects, and use this as a template for fitting novel objects. To this end, we introduce relationship templates as descriptors of complex relationships; they are computed from an example scene and combine the interaction bisector surface (IBS) with a novel feature called the space coverage feature (SCF), which encodes the open space in the frequency domain. New variations of a scene can be synthesized efficiently by fitting novel objects to the template. Our method greatly enhances existing automatic scene synthesis approaches by allowing them to handle complex relationships, as validated by our user studies. The proposed method generalizes well, as it can form complex relationships with objects that have a topology and geometry very different from the example scene.},
	issue        = 6,
	keywords     = {Relationship Templates,Scene Synthesis,Spatial Relationships}
}
@article{Xing2016,
	title        = {Energy-brushes: Interactive tools for illustrating stylized elemental dynamics},
	author       = {Jun Xing and Rubaiat Habib Kazi and Tovi Grossman and Li Yi Wei and Jos Stam and George Fitzmaurice},
	year         = 2016,
	journal      = {UIST 2016 - Proceedings of the 29th Annual Symposium on User Interface Software and Technology},
	pages        = {755--766},
	doi          = {10.1145/2984511.2984585},
	isbn         = 9781450345316,
	abstract     = {Dynamic effects such as waves, splashes, fire, smoke, and explosions are an integral part of stylized animations. However, such dynamics are challenging to produce, as manually sketching key-frames requires significant effort and artistic expertise while physical simulation tools lack sufficient expressiveness and user control. We present an interactive interface for designing these elemental dynamics for animated illustrations. Users draw with coarse-scale energy brushes which serve as control gestures to drive detailed flow particles which represent local velocity fields. These fields can convey both realistic and artistic effects based on user specification. This painting metaphor for creating elemental dynamics simplifies the process, providing artistic control, and preserves the fluidity of sketching. Our system is fast, stable, and intuitive. An initial user evaluation shows that even novice users with no prior animation experience can create intriguing dynamics using our system.},
	keywords     = {Casual animation,Dynamics,Interactive illustrations,Sketching}
}
@article{Fridenfalk2016,
	title        = {Pattern Generation with Cellular Automata in Hexagonal Modular Spaces},
	author       = {M Fridenfalk},
	year         = 2016,
	journal      = {SIGRAD},
	abstract     = {This paper presents new methods for the generation of hexagonal patterns, based on cellular automata in small-sized regular hexagonal modular spaces. The patterns are intended to be used for procedural content generation in computer games, but could also be applied for diverse ends, such as logotype design and architecture.}
}
@article{Scalise2016,
	title        = {Emulating cellular automata in chemical reaction–diffusion networks},
	author       = {Dominic Scalise and Rebecca Schulman},
	year         = 2016,
	month        = 6,
	journal      = {Natural Computing},
	publisher    = {Springer Netherlands},
	volume       = 15,
	pages        = {197--214},
	doi          = {10.1007/s11047-015-9503-8},
	issn         = 15729796,
	abstract     = {Chemical reactions and diffusion can produce a wide variety of static or transient spatial patterns in the concentrations of chemical species. Little is known, however, about what dynamical patterns of concentrations can be reliably programmed into such reaction–diffusion systems. Here we show that given simple, periodic inputs, chemical reactions and diffusion can reliably emulate the dynamics of a deterministic cellular automaton, and can therefore be programmed to produce a wide range of complex, discrete dynamics. We describe a modular reaction–diffusion program that orchestrates each of the fundamental operations of a cellular automaton: storage of cell state, communication between neighboring cells, and calculation of cells' subsequent states. Starting from a pattern that encodes an automaton's initial state, the concentration of a ``state'' species evolves in space and time according to the automaton's specified rules. To show that the reaction–diffusion program we describe produces the target dynamics, we simulate the reaction–diffusion network for two simple one-dimensional cellular automata using coupled partial differential equations. Reaction–diffusion based cellular automata could potentially be built in vitro using networks of DNA molecules that interact via branch migration processes and could in principle perform universal computation, storing their state as a pattern of molecular concentrations, or deliver spatiotemporal instructions encoded in concentrations to direct the behavior of intelligent materials.},
	issue        = 2,
	keywords     = {Cellular automata,Chemical reaction network,DNA strand displacement,Distributed computation,Intelligent materials,Molecular programming,Programmable matter,Reaction–diffusion}
}
@inbook{VilaConcejo2016,
	title        = {Storms in Coral Reefs},
	author       = {Ana Vila-Concejo and Paul Kench},
	year         = 2016,
	month        = 8,
	booktitle    = {Coastal Storms: Processes and Impacts},
	publisher    = {Wiley Blackwell},
	pages        = {127--149},
	doi          = {10.1002/9781118937099.ch7},
	isbn         = 9781118937099,
	abstract     = {This chapter examines the effects of storm events on coral reefs and reef-associated landforms. It begins with a brief examination of the geomorphic units of reef systems, places the physical dynamics of reefs within an eco-morphodynamic framework and highlights the unique aspects of the interaction of waves and storm waves with reef systems that force ecological and geomorphic change. The focus of the chapter is on the event-scale effects of storm events. Storm effects are considered with respect to both the structure of coral reefs, which is further considered on the different morphological components, and sedimentary landforms. Storm driven effects are placed within the eco-morphodynamic framework that reflects the interaction of biological and physical processes. The chapter also highlights contemporary research questions in understanding the influence of storms on the current dynamics and future trajectories of coral reef structure and associated sedimentary landforms.},
	keywords     = {Coral reefs,Eco-morphodynamic framework,Morphological components,Reef-associated landforms,Sedimentary landforms,Storm events}
}
@article{Williams2016,
	title        = {Reflections on a decade of autonomous underwater vehicles operations for marine survey at the Australian Centre for Field Robotics},
	author       = {Stefan B. Williams and Oscar Pizarro and Daniel M. Steinberg and Ariell Friedman and Mitch Bryson},
	year         = 2016,
	journal      = {Annual Reviews in Control},
	publisher    = {Elsevier Ltd},
	volume       = 42,
	pages        = {158--165},
	doi          = {10.1016/j.arcontrol.2016.09.010},
	issn         = 13675788,
	abstract     = {This paper describes insights gained from a decade of autonomous marine systems development at the University of Sydney's Australian Centre for Marine Robotics. Over the course of this time, we have deployed numerous vehicles and imaging platforms in support of applications in engineering science, marine ecology, archaeology and geoscience. We have operated an Australia-wide benthic observing program designed to deliver precisely navigated, repeat imagery of the seafloor. This initiative makes extensive use of Autonomous Underwater Vehicles (AUVs) to collect high-resolution stereo imagery, multibeam sonar and water column measurements on an annual or semi-annual basis at sites around Australia, spanning the full latitudinal range of the continent from tropical reefs in the north to temperate regions in the south. We have also contributed to expeditions to document coral bleaching, cyclone recovery, submerged neolithic settlement sites, ancient shipwrecks, methane seeps and deepwater hydrothermal vents. We briefly consider how automated tools for working with this imagery have facilitated the resulting science outcomes.},
	keywords     = {Autonomous vehicles,Marine systems}
}
@inproceedings{Ketabchi2016,
	title        = {3D Maquetter: Sketch-Based 3D Content Modeling for Digital Earth},
	author       = {Kaveh Ketabchi and Adam Runions and Faramarz F. Samavati},
	year         = 2016,
	month        = 2,
	booktitle    = {Proceedings - 2015 International Conference on Cyberworlds, CW 2015},
	publisher    = {Institute of Electrical and Electronics Engineers Inc.},
	pages        = {98--106},
	doi          = {10.1109/CW.2015.41},
	isbn         = 9781467394031,
	abstract     = {We present a sketch-based system for the creation and editing 3D content such as Digital Elevation Models, vegetation and bodies of water for Digital Earth representations. The proposed system employs a set of sketch-based tools to integrate commonly available data sources, such as orthophotos and Digital Elevation Models (DEM), to facilitate the rapid creation and integration of detailed geospatial content. Consequently, our system can be used to enhance the quality of Digital Earth data by enabling the straightforward creation of new 3D landscape elements.},
	keywords     = {Computer Graphics,Digital Earth,Interaction Techniques,Sketch-based Modeling}
}
@inproceedings{Vidimce2016,
	title        = {Foundry: Hierarchical material design for multi-material fabrication},
	author       = {Kiril Vidim\v{c}e and Alexandre Kaspar and Ye Wang and Wojciech Matusik},
	year         = 2016,
	month        = 10,
	booktitle    = {UIST 2016 - Proceedings of the 29th Annual Symposium on User Interface Software and Technology},
	publisher    = {Association for Computing Machinery, Inc},
	pages        = {563--574},
	doi          = {10.1145/2984511.2984516},
	isbn         = 9781450345316,
	abstract     = {We demonstrate a new approach for designing functional material definitions for multi-material fabrication using our system called Foundry. Foundry provides an interactive and visual process for hierarchically designing spatially-varying material properties (e.g., appearance, mechanical, optical). The resulting meta-materials exhibit structure at the micro and macro level and can surpass the qualities of traditional composites. The material definitions are created by composing a set of operators into an operator graph. Each operator performs a volume decomposition operation, remaps space, or constructs and assigns a material composition. The operators are implemented using a domain-specific language for multi-material fabrication; users can easily extend the library by writing their own operators. Foundry can be used to build operator graphs that describe complex, parameterized, resolution-independent, and reusable material definitions. We also describe how to stage the evaluation of the final material definition which in conjunction with progressive refinement, allows for interactive material evaluation even for complex designs. We show sophisticated and functional parts designed with our system.},
	keywords     = {3D printing,Fabrication,Materials}
}
@inproceedings{Rose2016,
	title        = {Algorithms and approaches for procedural terrain generation},
	author       = {Thomas J. Rose and Anastasios G. Bakaoukas},
	year         = 2016,
	month        = 10,
	booktitle    = {2016 8th International Conference on Games and Virtual Worlds for Serious Applications, VS-Games 2016},
	publisher    = {Institute of Electrical and Electronics Engineers Inc.},
	doi          = {10.1109/VS-GAMES.2016.7590336},
	isbn         = 9781509027224,
	abstract     = {This paper aims to discuss existing approaches to procedural terrain generation for games. This will include both the many functions that are used to generate 'noise' (something that has proved exceptionally useful in procedural terrain and texture synthesis) as well as some advanced procedural content generation techniques. The paper concludes with a summary of the discussed material while attempting to highlight areas for future research.},
	keywords     = {Fractal,Noise function,Pseudo-random,Terrain}
}
@article{Zeppilli2016,
	title        = {Seafloor heterogeneity influences the biodiversity-ecosystem functioning relationships in the deep sea},
	author       = {Daniela Zeppilli and Antonio Pusceddu and Fabio Trincardi and Roberto Danovaro},
	year         = 2016,
	month        = 5,
	journal      = {Scientific Reports},
	publisher    = {Nature Publishing Group},
	volume       = 6,
	doi          = {10.1038/srep26352},
	issn         = 20452322,
	abstract     = {Theoretical ecology predicts that heterogeneous habitats allow more species to co-exist in a given area. In the deep sea, biodiversity is positively linked with ecosystem functioning, suggesting that deep-seabed heterogeneity could influence ecosystem functions and the relationships between biodiversity and ecosystem functioning (BEF). To shed light on the BEF relationships in a heterogeneous deep seabed, we investigated variations in meiofaunal biodiversity, biomass and ecosystem efficiency within and among different seabed morphologies (e.g., furrows, erosional troughs, sediment waves and other depositional structures, landslide scars and deposits) in a narrow geo-morphologically articulated sector of the Adriatic Sea. We show that distinct seafloor morphologies are characterized by highly diverse nematode assemblages, whereas areas sharing similar seabed morphologies host similar nematode assemblages. BEF relationships are consistently positive across the entire region, but different seabed morphologies are characterised by different slope coefficients of the relationship. Our results suggest that seafloor heterogeneity, allowing diversified assemblages across different habitats, increases diversity and influence ecosystem processes at the regional scale, and BEF relationships at smaller spatial scales. We conclude that high-resolution seabed mapping and a detailed analysis of the species distribution at the habitat scale are crucial for improving management of goods and services delivered by deep-sea ecosystems.},
	pmid         = 27211908
}
@article{Hsu2017,
	title        = {Extracting gait velocity and stride length from surrounding radio signals},
	author       = {Chen Yu Hsu and Yuchen Liu and Zachary Kabelac and Rumen Hristov and Dina Katabi and Christine Liu},
	year         = 2017,
	journal      = {Conference on Human Factors in Computing Systems - Proceedings},
	volume       = {2017-May},
	pages        = {2116--2126},
	doi          = {10.1145/3025453.3025937},
	isbn         = 9781450346559,
	abstract     = {Gait velocity and stride length are critical health indicators for older adults. A decade of medical research shows that they provide a predictor of future falls, hospitalization, and functional decline among seniors. However, currently these metrics are measured only occasionally during medical visits. Such infrequent measurements hamper the opportunity to detect changes and intervene early in the impairment process. In this paper, we develop a sensor that uses radio signals to continuously measure gait velocity and stride length at home. Our sensor hangs on a wall like a picture frame. It does not require the monitored person to wear or carry a device on her body. Our approach builds on recent advances in wireless systems which have shown that one can locate people based on how their bodies impact the surrounding radio signals. We demonstrate the accuracy of our method by comparing it to the gold standard in clinical tests, and the VICON motion tracking system. Our experience from deploying the sensor in 14 homes indicates comfort with the technology and a high acceptance rate.},
	keywords     = {Continuous monitoring,Device-free sensing,Gait velocity,Stride length,Wireless sensing}
}
@article{Ma2017,
	title        = {Active Compressive Sensing via Pyroelectric Infrared Sensor for Human Situation Recognition},
	author       = {Rui Ma and Fei Hu and Qi Hao},
	year         = 2017,
	journal      = {IEEE Transactions on Systems, Man, and Cybernetics: Systems},
	volume       = 47,
	pages        = {3340--3350},
	doi          = {10.1109/TSMC.2016.2578465},
	issn         = 21682232,
	abstract     = {Conventional pyroelectric infrared (PIR) motion sensors use paired elements for the detection of moving targets. This method makes them incapable of measuring thermal signals from static targets. We need an active sensor that can detect static thermal subjects. This paper presents our design of active PIR sensors. The proposed PIR sensing systems can actively detect static thermal targets by using three methods that are suitable to different applications: 1) a sensor that can be rotated by a self-controlled servo motor for the detection of moving or static thermal subjects nearby; 2) a sensor that is equipped with a mask for low-complexity posture recognition; and 3) a sensor that can be worn on the wrist for the recognition of surrounding subjects (this sensor is especially useful for blind users). Compressive sensing (CS) theory indicates that random down-sampling method can capture more accurate information of the original signal than the evenly spaced sampling. Based on CS theory, we have developed the random sampling structures for the active PIR systems, and have built a statistical feature space for human scenario recognition. The experimental results demonstrate that the active sensing system can efficiently measure the static thermal targets, and the random sampling scheme has a better recognition performance than the even sampling scheme.},
	issue        = 12,
	keywords     = {Active sensing,compressive sensing (CS),pyroelectric infrared (PIR) sensor,random sampling,situation recognition}
}
@misc{Short2017,
	title        = {Procedural Generation in Game Design - Google Livres},
	author       = {Tania Short and Tarn Adams},
	year         = 2017,
	url          = {https://books.google.fr/books?hl=fr&lr=&id=Rj4PEAAAQBAJ&oi=fnd&pg=PP1&dq=procedural+generation&ots=HDpV2D6fYE&sig=00uNJnqhoid3QRa0z1fznNW-1ao&redir_esc=y#v=onepage&q=procedural generation&f=false}
}
@article{Freiknecht2017,
	title        = {A survey on the procedural generation of virtual worlds},
	author       = {Jonas Freiknecht and Wolfgang Effelsberg},
	year         = 2017,
	journal      = {Multimodal Technologies and Interaction},
	volume       = 1,
	pages        = {1--34},
	doi          = {10.3390/mti1040027},
	issn         = 24144088,
	abstract     = {This survey presents algorithms for the automatic generation of content for virtual worlds, in particular for games. After a definition of the term procedural content generation, the algorithms to generate realistic objects such as landscapes and vegetation, road networks, buildings, living beings and stories are introduced in detail. In our discussion, we emphasize a good compromise between the realism of the objects and the performance of the algorithms. The survey also assesses each generated object type in terms of its applicability in games and simulations of virtual worlds.},
	issue        = 4,
	keywords     = {Multimedia content creation,Procedural content generation,Serious games,Virtual worlds}
}
@article{Liu2017,
	title        = {Spatiotemporal gait characteristics in patients with COPD during the Gait real-time analysis interactive lab-based 6-minute walk test},
	author       = {Wai Yan Liu and Martijn A. Spruit and Jeannet M. Delbressine and Paul J.B. Willems and Frits M.E. Franssen and Emiel F.M. Wouters and Kenneth Meijer},
	year         = 2017,
	month        = 12,
	journal      = {PLoS ONE},
	publisher    = {Public Library of Science},
	volume       = 12,
	pages        = {e0190099},
	doi          = {10.1371/journal.pone.0190099},
	issn         = 19326203,
	url          = {https://doi.org/10.1371/journal.pone.0190099},
	abstract     = {Background and aim Overground gait assessment is limited by the analysis of multiple strides or both spatiotemporal gait characteristics, while fixed speed treadmill walking restricts natural gait speed variations. The Gait Real-time Analysis Interactive Lab (GRAIL)-based 6-minute walk test (6MWT) enables 3D motion analysis and self-paced treadmill walking, and could provide insight in gait alterations in patients with chronic obstructive pulmonary disease (COPD). The aim of this study is to compare spatiotemporal gait characteristics between patients with COPD and healthy elderly during the GRAIL-based 6MWT. Materials and methods Eighty COPD patients (60\% male; 62\pm{}7 years; FEV1:56\pm{}19\% predicted) and 38 healthy elderly (63\% male; 62\pm{}6 years; FEV1:119\pm{}17\% predicted) performed two GRAIL-based 6MWTs. Mean differences and coefficient of variation of spatiotemporal gait characteristics were calculated using the trial with the largest walk distance. Sub-analyses were conducted to account for walking speed differences between groups, and muscle strength and COPD severity within the patient group. Results COPD patients showed increased temporal gait characteristics, decreased stride and step lengths, and increased gait variability compared to healthy elderly (p<0.01). Stride length variability remained increased in COPD after correction for walking speed (MD:0.98\%, CI:0.36–1.61, p = 0.003). Reduced quadriceps strength did not translate into altered gait characteristics, while COPD severity is associated with stride time (left MD:-0.02s, CI:-0.04–0.01, p = 0.003; right MD:-0.02s, CI:-0.04–0.01, p = 0.003). Discussion COPD patients performed the GRAIL-based 6MWT differently compared to healthy elderly. Further research should use other variability measures to investigate gait characteristics in COPD, to assess subtle alterations in gait and to enable development of rehabilitation strategies to improve gait, and possibly balance and fall risk in COPD. Other lower limb muscle groups should be considered when investigating gait alterations in COPD. Conclusion COPD patients have different gait characteristics compared to healthy elderly. Independent of walking speed, COPD patients demonstrate increased stride length variability during the GRAIL-based 6MWT compared to healthy elderly.},
	issue        = 12,
	keywords     = {Body limbs,Chronic obstructive pulmonary disease,Dyspnea,Fatigue,Gait analysis,Geriatric care,Oxygen,Walking},
	pmid         = 29284059
}
@article{Yentes2017,
	title        = {Patients with chronic obstructive pulmonary disease walk with altered step time and step width variability as compared with healthy control subjects},
	author       = {Jennifer M. Yentes and Stephen I. Rennard and Kendra K. Schmid and Daniel Blanke and Nicholas Stergiou},
	year         = 2017,
	month        = 6,
	journal      = {Annals of the American Thoracic Society},
	publisher    = {American Thoracic Society},
	volume       = 14,
	pages        = {858--866},
	doi          = {10.1513/AnnalsATS.201607-547OC},
	issn         = 23256621,
	url          = {www.atsjournals.org},
	abstract     = {Rationale: Compared with control subjects, patients with chronic obstructive pulmonary disease (COPD) have an increased incidence of falls and demonstrate balance deficits and alterations in mediolateral trunk acceleration while walking. Measures of gait variability have been implicated as indicators of fall risk, fear of falling, and future falls. Objectives: To investigate whether alterations in gait variability are found in patientswithCOPDas comparedwith healthy control subjects. Methods: Twenty patients withCOPD(16 males; mean age, 63.6\pm{} 9.7 yr; FEV1/FVC, 0.52\pm{}0.12) and 20 control subjects (9 males; mean age, 62.568.2 yr) walked for 3minutes on a treadmill while their gait was recorded. The amount (SD and coefficient of variation) and structure of variability (sample entropy, a measure of regularity) were quantified for step length, time, and width at three walking speeds (selfselected and 620\% of self-selected speed). Generalized linear mixed models were used to compare dependent variables. Results: Patients withCOPDdemonstrated increased mean and SD step time across all speed conditions as compared with control subjects. They also walked with a narrower step width that increased with increasing speed, whereas the healthy control subjects walked with a wider step width that decreased as speed increased. Further, patients with COPD demonstrated less variability in step width, with decreased SD, compared with control subjects at all three speed conditions. No differences in regularity of gait patterns were found between groups. Conclusions: Patients with COPD walk with increased duration of time between steps, and this timing is more variable than that of control subjects.They also walk with a narrower stepwidth inwhich the variability of the step widths from step to step is decreased. Changes in these parameters have been related to increased risk of falling in aging research. This provides a mechanism that could explain the increased prevalence of falls in patients with COPD.},
	issue        = 6,
	keywords     = {Biomechanics,Entropy,Gait,Locomotion,Lung disease},
	pmid         = 28267374
}
@article{Beckham2017,
	title        = {A step towards procedural terrain generation with GANs},
	author       = {Christopher Beckham and Christopher Pal},
	year         = 2017,
	month        = 7,
	url          = {http://arxiv.org/abs/1707.03383},
	abstract     = {Procedural terrain generation for video games has been traditionally been done with smartly designed but handcrafted algorithms that generate heightmaps. We propose a first step toward the learning and synthesis of these using recent advances in deep generative modelling with openly available satellite imagery from NASA.}
}
@article{Guerin2017,
	title        = {Interactive example-based terrain authoring with conditional generative adversarial networks},
	author       = {\'{E}ric Gu\'{e}rin and Julie Digne and \'{E}ric Galin and Adrien Peytavie and Christian Wolf and Bed\v{r}ich Bene\v{s} and Beno\^{\i}t Martinez},
	year         = 2017,
	journal      = {ACM Transactions on Graphics},
	volume       = 36,
	doi          = {10.1145/3130800.3130804},
	issn         = 15577368,
	abstract     = {Authoring virtual terrains presents a challenge and there is a strong need for authoring tools able to create realistic terrains with simple user-inputs and with high user control. We propose an example-based authoring pipeline that uses a set of terrain synthesizers dedicated to specific tasks. Each terrain synthesizer is a Conditional Generative Adversarial Network trained by using real-world terrains and their sketched counterparts. The training sets are built automatically with a view that the terrain synthesizers learn the generation from features that are easy to sketch. During the authoring process, the artist first creates a rough sketch of the main terrain features, such as rivers, valleys and ridges, and the algorithm automatically synthesizes a terrain corresponding to the sketch using the learned features of the training samples. Moreover, an erosion synthesizer can also generate terrain evolution by erosion at a very low computational cost. Our framework allows for an easy terrain authoring and provides a high level of realism for a minimum sketch cost. We show various examples of terrain synthesis created by experienced as well as inexperienced users who are able to design a vast variety of complex terrains in a very short time.},
	issue        = 6,
	keywords     = {Deep Learning,Procedural modeling,Terrain generation}
}
@article{Argudo2017a,
	title        = {Coherent multi-layer landscape synthesis},
	author       = {Oscar Argudo and Carlos Andujar and Antonio Chica and \'{E}ric Gu\'{e}rin and Julie Digne and Adrien Peytavie and \'{E}ric Galin},
	year         = 2017,
	journal      = {Visual Computer},
	volume       = 33,
	pages        = {1005--1015},
	doi          = {10.1007/s00371-017-1393-6},
	issn         = {01782789},
	abstract     = {We present an efficient method for generating coherent multi-layer landscapes. We use a dictionary built from exemplars to synthesize high-resolution fully featured terrains from input low-resolution elevation data. Our example-based method consists in analyzing real-world terrain examples and learning the procedural rules directly from these inputs. We take into account not only the elevation of the terrain, but also additional layers such as the slope, orientation, drainage area, the density and distribution of vegetation, and the soil type. By increasing the variety of terrain exemplars, our method allows the user to synthesize and control different types of landscapes and biomes, such as temperate or rain forests, arid deserts and mountains.},
	issue        = {6-8},
	keywords     = {Coherent multi-layer landscapes,Dictionary matching,Example-based modeling}
}
@article{DeGoes2017,
	title        = {Regularized Kelvinlets: Sculpting Brushes based on Fundamental Solutions of Elasticity},
	author       = {Fernando De Goes and Doug L. James},
	year         = 2017,
	journal      = {ACM Transactions on Graphics},
	volume       = 36,
	pages        = {401--411},
	doi          = {10.1145/3072959.3073595},
	issn         = 15577368,
	abstract     = {We introduce a new technique for real-Time physically based volume sculpting of virtual elastic materials. Our formulation is based on the elastic response to localized force distributions associated with common modeling primitives such as grab, scale, twist, and pinch. The resulting brush-like displacements correspond to the regularization of fundamental solutions of linear elasticity in infinite 2D and 3D media. These deformations thus provide the realism and plausibility of volumetric elasticity, and the interactivity of closed-form analytical solutions. To finely control our elastic deformations, we also construct compound brushes with arbitrarily fast spatial decay. Furthermore, pointwise constraints can be imposed on the displacement field and its derivatives via a single linear solve. We demonstrate the versatility and efficiency of our method with multiple examples of volume sculpting and image editing.},
	issue        = 4,
	keywords     = {Linear elasticity,Sculpting brushes}
}
@article{Tompson2017,
	title        = {Accelerating eulerian fluid simulation with convolutional networks},
	author       = {Jonathan Tompson and Kristofer Schlachter and Pablo Sprechmann and Ken Perlin},
	year         = 2017,
	journal      = {34th International Conference on Machine Learning, ICML 2017},
	volume       = 7,
	pages        = {5258--5267},
	isbn         = 9781510855144,
	abstract     = {Efficient simulation of the Navicr-Stokes equations for fluid flow is a long standing problem in applied mathematics, for which state-of-the-art methods require large compute resources. In this work, we propose a data-driven approach that leverages the approximation power of deep-learning with the precision of standard solvers to obtain fast and highly realistic simulations. Our method solves the incompressible Euler equations using the standard operator splitting method, in which a large sparse linear system with many free parameters must be solved. We use a Convolutional Network with a highly tailored architecture, trained using a novel unsupervised learning framework to solve the linear system. We present real-time 2D and 3D simulations that outperform recently proposed data-driven methods; the obtained results are realistic and show good generalization properties.}
}
@article{Collon2017,
	title        = {Statistical metrics for the characterization of karst network geometry and topology},
	author       = {Pauline Collon and David Bernasconi and C\'{e}cile Vuilleumier and Philippe Renard},
	year         = 2017,
	journal      = {Geomorphology},
	publisher    = {Elsevier B.V.},
	volume       = 283,
	pages        = {122--142},
	doi          = {10.1016/j.geomorph.2017.01.034},
	issn         = {0169555X},
	url          = {http://dx.doi.org/10.1016/j.geomorph.2017.01.034},
	abstract     = {Statistical metrics can be used to analyse the morphology of natural or simulated karst systems; they allow describing, comparing, and quantifying their geometry and topology. In this paper, we present and discuss a set of such metrics. We study their properties and their usefulness based on a set of more than 30 karstic networks mapped by speleologists. The data set includes some of the largest explored cave systems in the world and represents a broad range of geological and speleogenetic conditions allowing us to test the proposed metrics, their variability, and their usefulness for the discrimination of different morphologies. All the proposed metrics require that the topographical survey of the caves are first converted to graphs consisting of vertices and edges. This data preprocessing includes several quality check operations and some corrections to ensure that the karst is represented as accurately as possible. The statistical parameters relating to the geometry of the system are then directly computed on the graphs, while the topological parameters are computed on a reduced version of the network focusing only on its structure. Among the tested metrics, we include some that were previously proposed such as tortuosity or the Howard's coefficients. We also investigate the possibility to use new metrics derived from graph theory. In total, 21 metrics are introduced, discussed in detail, and compared on the basis of our data set. This work shows that orientation analysis and, in particular, the entropy of the orientation data can help to detect the existence of inception features. The statistics on branch length are useful to describe the extension of the conduits within the network. Rather surprisingly, the tortuosity does not vary very significantly. It could be heavily influenced by the survey methodology. The degree of interconnectivity of the network, related to the presence of maze patterns, can be measured using different metrics such as the Howard's parameters, global cyclic coefficient, or the average vertex degree. The average vertex degree of the reduced graph proved to be the most useful as it is simple to compute, it discriminates properly the interconnected systems (mazes) from the acyclic ones (tree-like structures), and it permits us to classify the acyclic systems as a function of the total number of branches. This topological information is completed by three parameters, allowing us to refine the description. The correlation of vertex degree is rather simple to obtain. It is systematically positive on all studied data sets indicating a predominance of assortative networks among karst systems. The average shortest path length is related to the transport efficiency. It is shown to be mainly correlated to the size of the network. Finally, central point dominance allows us to identify the presence of a centralized organization.},
	keywords     = {Database,Geometry,Graph theory,Karst characterization,Karst pattern,Topology}
}
@article{Cordonnier2017a,
	title        = {Sculpting Mountains: Interactive Terrain Modeling Based on Subsurface Geology},
	author       = {Guillaume Cordonnier and Marie-Paule Cani and Bed\v{r}ich Bene\v{s} and Jean Braun and \'{E}ric Galin},
	year         = 2017,
	journal      = {IEEE Transactions on Visualization and Computer Graphics},
	volume       = 24,
	doi          = {10.1109/TVCG.2017.2689022},
	url          = {http://www.ieee.org/publications_standards/publications/rights/index.html},
	abstract     = {Most mountain ranges are formed by the compression and folding of colliding tectonic plates. Subduction of one plate causes large-scale asymmetry while their layered composition (or stratigraphy) explains the multi-scale folded strata observed on real terrains. We introduce a novel interactive modeling technique to generate visually plausible, large scale terrains that capture these phenomena. Our method draws on both geological knowledge for consistency and on sculpting systems for user interaction. The user is provided hands-on control on the shape and motion of tectonic plates, represented using a new geologically-inspired model for the Earth crust. The model captures their volume preserving and complex folding behaviors under collision, causing mountains to grow. It generates a volumetric uplift map representing the growth rate of subsurface layers. Erosion and uplift movement are jointly simulated to generate the terrain. The stratigraphy allows us to render folded strata on eroded cliffs. We validated the usability of our sculpting interface through a user study, and compare the visual consistency of the earth crust model with geological simulation results and real terrains.},
	keywords     = {Terrains,geology,interactive design,mountains}
}
@article{Onrust2017,
	title        = {Ecologically Sound Procedural Generation of Natural Environments},
	author       = {Benny Onrust and Rafael Bidarra and Robert Rooseboom and Johan Van De Koppel},
	year         = 2017,
	journal      = {International Journal of Computer Games Technology},
	volume       = 2017,
	doi          = {10.1155/2017/7057141},
	issn         = 16877055,
	url          = {https://downloads.hindawi.com/journals/ijcgt/2017/7057141.pdf},
	abstract     = {Current techniques for the creation and exploration of virtual worlds are largely unable to generate sound natural environments from ecological data and to provide interactive web-based visualizations of such detailed environments. We tackle this challenge and propose a novel framework that (i) explores the advantages of landscape maps and ecological statistical data, translating them to an ecologically sound plant distribution, and (ii) creates a visually convincing 3D representation of the natural environment suitable for its interactive visualization over the web. Our vegetation model improves techniques from procedural ecosystem generation and neutral landscape modeling. It is able to generate diverse ecological sound plant distributions directly from landscape maps with statistical ecological data. Our visualization model integrates existing level of detail and illumination techniques to achieve interactive frame rates and improve realism. We validated with ecology experts the outcome of our framework using two case studies and concluded that it provides convincing interactive visualizations of large natural environments.}
}
@article{Lopes2017,
	title        = {Authoring adaptive game world generation},
	author       = {Ricardo Lopes and Elmar Eisemann and Rafael Bidarra},
	year         = 2017,
	journal      = {IEEE TRANSACTIONS ON COMPUTATIONAL INTELLIGENCE AND AI IN GAMES},
	pages        = {1--14},
	url          = {http://dx.doi.org/10.1109/TCIAIG.2017.2678759},
	abstract     = {Current research on adaptive games has mainly focused on adjusting difficulty in a variety of ways, for example, by providing some control over adaptive game world generation. These methods, however, are mostly ad-hoc and require quite some technical skills. To the best of our knowledge, so far there has been no adaptive method that is truly generic and explicitly designed to actively include game designers in the content creation loop. In this article, we introduce a generic method that enables designers to author adaptivity of game world generation, in a very expressive and specific fashion. Our approach uses adaptation rules which build atop gameplay semantics in order to steer the on-line generation of game content. Designers create these rules by associating skill profiles, describing skill proficiency, with content descriptions, detailing the desired properties of specific game world content. This game content is then generated on-line using a rule matching and retrieval approach. We performed user studies with both designers and players, and concluded that adaptation rules provide game designers with a rich expressive range to effectively convey specific adaptive gameplay experiences to players.},
	issue        = {c},
	keywords     = {Netherlands,Rafael Bidarra,TU Delft}
}
@article{Yan2017,
	title        = {\ensuremath{\kappa}-Curves: Interpolation at Local Maximum Curvature},
	author       = {Zhipei Yan and Stephen Schiller and Gregg Wilensky and Scott Schaefer},
	year         = 2017,
	journal      = {ACM Trans. Graph},
	volume       = 36,
	doi          = {10.1145/3072959.3073692},
	abstract     = {Fig. 1. Top row shows example shapes made from the control points below. In all cases, local maxima of curvature only appear at the control points, and the curves are G 2 almost everywhere. We present a method for constructing almost-everywhere curvature-continuous, piecewise-quadratic curves that interpolate a list of control points and have local maxima of curvature only at the control points. Our premise is that salient features of the curve should occur only at control points to avoid the creation of features unintended by the artist. While many artists prefer to use interpolated control points, the creation of artifacts, such as loops and cusps, away from control points has limited the use of these types of curves. By enforcing the maximum curvature property, loops and cusps cannot be created unless the artist intends for them to be. To create such curves, we focus on piecewise quadratic curves, which can have only one maximum curvature point. We provide a simple, iterative optimization that creates quadratic curves, one per interior control point, that meet with G 2 continuity everywhere except at innection points of the curve where the curves are G 1. Despite the nonlinear nature of curvature, our curves only obtain local maxima of the absolute value of curvature only at interpolated control points.},
	keywords     = {CCS Concepts: \textbullet{}Computing methodologies \rightarrow{} Parametri,curvature continuity,monotonic curva-ture}
}
@article{Rongier2017,
	title        = {Stochastic simulation of channelized sedimentary bodies using a constrained L-system},
	author       = {Guillaume Rongier and Pauline Collon and Philippe Renard},
	year         = 2017,
	journal      = {Computers and Geosciences},
	volume       = 105,
	pages        = {158--168},
	doi          = {10.1016/j.cageo.2017.05.006},
	issn         = {00983004},
	url          = {https://hal.archives-ouvertes.fr/hal-01527896/file/Article_ChannelLSystem_Rongier.pdf},
	abstract     = {Simulating realistic sedimentary bodies while conditioning all the available data is a major topic of research. We present a new method to simulate the channel morphologies resulting from the deposition processes. It relies on a formal grammar system, the Lindenmayer system, or L-system. The L-system puts together channel segments based on user-defined rules and parameters. The succession of segments is then interpreted to generate non-rational uniform B-splines representing straight to meandering channels. Constraints attract or repulse the channel from the data during the channel development. They enable to condition various data types, from well data to probability cubes or a confinement. The application to a synthetic case highlights the method's ability to manage various data while preserving at best the channel morphology.},
	keywords     = {Channel,Constraints,Data conditioning,Lindenmayer system,Sedimentary system,Stochastic simulation}
}
@article{Gain2017,
	title        = {EcoBrush: Interactive Control of Visually Consistent Large-Scale Ecosystems},
	author       = {James Gain and H. Long and Guillaume Cordonnier and Marie-Paule Cani},
	year         = 2017,
	journal      = {Computer Graphics Forum},
	volume       = 36,
	pages        = {63--73},
	doi          = {10.1111/cgf.13107},
	issn         = 14678659,
	url          = {https://hal.archives-ouvertes.fr/hal-01519852/file/ecobrush.pdf},
	abstract     = {One challenge in portraying large-scale natural scenes in virtual environments is specifying the attributes of plants, such as species, size and placement, in a way that respects the features of natural ecosystems, while remaining computationally tractable and allowing user design. To address this, we combine ecosystem simulation with a distribution analysis of the resulting plant attributes to create biome-specific databases, indexed by terrain conditions, such as temperature, rainfall, sunlight and slope. For a specific terrain, interpolated entries are drawn from this database and used to interactively synthesize a full ecosystem, while retaining the fidelity of the original simulations. A painting interface supplies users with semantic brushes for locally adjusting ecosystem age, plant density and variability, as well as optionally picking from a palette of precomputed distributions. Since these brushes are keyed to the underlying terrain properties a balance between user control and real-world consistency is maintained. Our system can be be used to interactively design ecosystems up to 5 \texttimes{} 5 km2 in extent, or to automatically generate even larger ecosystems in a fraction of the time of a full simulation, while demonstrating known properties from plant ecology such as succession, self-thinning, and underbrush, across a variety of biomes.},
	issue        = 2,
	keywords     = {1.3.7 [Computer Graphics]: Three-dimensional graph,Categories and Subject Descriptors (according to A}
}
@article{Shifley2017,
	title        = {The past and future of modeling forest dynamics: from growth and yield curves to forest landscape models},
	author       = {Stephen R. Shifley and Hong S. He and Heike Lischke and Wen J. Wang and Wenchi Jin and Eric J. Gustafson and Jonathan R. Thompson and Frank R. Thompson and William D. Dijak and Jian Yang},
	year         = 2017,
	journal      = {Landscape Ecology},
	publisher    = {Springer Netherlands},
	volume       = 32,
	pages        = {1307--1325},
	doi          = {10.1007/s10980-017-0540-9},
	issn         = 15729761,
	abstract     = {Context: Quantitative models of forest dynamics have followed a progression toward methods with increased detail, complexity, and spatial extent. Objectives: We highlight milestones in the development of forest dynamics models and identify future research and application opportunities. Methods: We reviewed milestones in the evolution of forest dynamics models from the 1930s to the present with emphasis on forest growth and yield models and forest landscape models We combined past trends with emerging issues to identify future needs. Results: Historically, capacity to model forest dynamics at tree, stand, and landscape scales was constrained by available data for model calibration and validation; computing capacity; model applicability to real-world problems; and ability to integrate biological, social, and economic drivers of change. As computing and data resources improved, a new class of spatially explicit forest landscape models emerged. Conclusions: We are at a point of great opportunity in development and application of forest dynamics models. Past limitations in computing capacity and in data suitable for model calibration or evaluation are becoming less restrictive. Forest landscape models, in particular, are ready to transition to a central role supporting forest management, planning, and policy decisions. Recommendations: Transitioning forest landscape models to a central role in applied decision making will require greater attention to evaluating performance; building application support staffs; expanding the included drivers of change, and incorporating metrics for social and economic inputs and outputs.},
	issue        = 7,
	keywords     = {Ecosystem services,Forest Vegetation Simulator,Gap model,Individual-tree model,LANDIS,Model validation,Process model,TreeMig}
}
@article{Cordonnier2017b,
	title        = {Authoring landscapes by combining ecosystem and terrain erosion simulation},
	author       = {Guillaume Cordonnier and \'{E}ric Galin and James Gain and Bed\v{r}ich Bene\v{s} and \'{E}ric Gu\'{e}rin and Adrien Peytavie and Marie-Paule Cani},
	year         = 2017,
	journal      = {ACM Transactions on Graphics},
	volume       = 36,
	doi          = {10.1145/3072959.3073667},
	issn         = 15577368,
	url          = {https://hal.archives-ouvertes.fr/hal-01518967/file/authoring-landscapes-combining.pdf},
	abstract     = {We introduce a novel framework for interactive landscape authoring that supports bi-directional feedback between erosion and vegetation simulation. Vegetation and terrain erosion have strong mutual impact and their interplay influences the overall realism of virtual scenes. Despite their importance, these complex interactions have been neglected in computer graphics. Our framework overcomes this by simulating the effect of a variety of geomor-phological agents and the mutual interaction between different material and vegetation layers, including rock, sand, humus, grass, shrubs, and trees. Users are able to exploit these interactions with an authoring interface that consistently shapes the terrain and populates it with details. Our method, validated through side-by-side comparison with real terrains, can be used not only to generate realistic static landscapes, but also to follow the temporal evolution of a landscape over a few centuries.},
	issue        = 4,
	keywords     = {Erosion,Landscape,Simulation of natural phenomena,Stochastic,Terrain,Vegetation}
}
@article{Becher2017,
	title        = {Feature-based volumetric terrain generation},
	author       = {Michael Becher and Michael Krone and Guido Reina and Thomas Ertl},
	year         = 2017,
	journal      = {Proceedings - I3D 2017: 21st ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games},
	doi          = {10.1145/3023368.3023383},
	isbn         = 9781450348867,
	abstract     = {Two-dimensional heightfields are the most common data structure used for storing and rendering of terrain in offline rendering and especially real-time computer graphics. By its very nature, a heightfield cannot store terrain structures with multiple vertical layers such as overhanging cliffs, caves, or arches. This restriction does not apply to volumetric data structures. However, the workflow of manual modelling and editing of volumetric terrain usually is tedious and very time-consuming. Therefore, we propose to use three-dimensional curve-based primitives to efficiently model prominent, large-scale terrain features. We present a technique for volumetric generation of a complete terrain surface from the sparse input data by means of diffusion-based algorithms. By combining an efficient, feature-based toolset with a volumetric terrain representation, the modelling workflow is accelerated and simplified while retaining the full artistic freedom of volumetric terrains. All stages of our method are GPU-accelerated using compute shaders to ensure interactive editing of terrain.},
	keywords     = {Diffusion algorithms,GPU,Interactive modelling,Splinecurves,Terrain,Volumetric}
}
@article{Villanueva2017,
	title        = {Symmetry-aware Sparse Voxel DAGs ( SSVDAGs ) for compression-domain tracing of high-resolution geometric scenes},
	author       = {Alberto Jaspe Villanueva and Fabio Marton and Enrico Gobbetti},
	year         = 2017,
	journal      = {Journal of Computer Graphics Techniques},
	volume       = 6,
	pages        = {1--30},
	abstract     = {Voxelized representations of complex 3D scenes are widely used to accelerate visibility queries in many GPU rendering techniques. Since GPU memory is limited, it is important that these data structures can be kept within a strict memory budget. Recently, directed acyclic graphs (DAGs) have been successfully introduced to compress sparse voxel octrees (SVOs), but they are limited to sharing identical regions of space. In this paper, we show that a more efficient lossless compression of geometry can be achieved while keeping the same visibility-query performance. This is accomplished by merging subtrees that are identical through a similarity transform and by exploiting the skewed distribution of references to shared nodes to store child pointers using a variabile bit-rate encoding. We also describe how, by selecting plane reflections along the main grid directions as symmetry transforms, we can construct highly compressed GPU-friendly structures using a fully out-of-core method. Our results demonstrate that state-of-the-art compression and real-time tracing performance can be achieved on high- resolution voxelized representations of real-world scenes of very different characteristics, including large CAD models, 3D scans, and typical gaming models, leading, for instance, to real-time GPU in-core visualization with shading and shadows of the full Boeing 777 at sub-millimeter precision. This article is based on an earlier work: SSVDAGs: Symmetry-aware Sparse Voxel DAGs, in Proceedings of the 20th ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games c ?ACM, 2016. http://dx.doi.org/10.1145/2856400.2856420. We include here a more thorough exposition, a description of alternative construction and tracing methods, as well as additional results. In order to facilitate understanding, evaluation and extensions, the full source code of the method is provided in the supplementary material.},
	issue        = 2,
	keywords     = {Journal of Computer Graphics Techniques}
}
@article{Faraj2017,
	title        = {A generic framework for the structured abstraction of images},
	author       = {Noura Faraj and Gui Song Xia and Julie Delon and Yann Gousseau},
	year         = 2017,
	journal      = {Proceedings - Non-Photorealistic Animation and Rendering, NPAR 2017 - Part of Expressive 2017},
	doi          = {10.1145/3092919.3092930},
	isbn         = 9781450350815,
	abstract     = {Structural properties are important clues for non-photorealistic representations of digital images. Therefore, image analysis tools have been intensively used either to produce stroke-based renderings or to yield abstractions of images. In this work, we propose to use a hierarchical and geometrical image representation, called a topographic map, made of shapes organized in a tree structure. There are two main advantages of this analysis tool. Firstly, it is able to deal with all scales, so that every shape of the input image is represented. Secondly, it accounts for the inclusion properties within the image. By iteratively performing simple local operations on the shapes (removal, rotation, scaling, replacement\cdots{}), we are able to generate abstract renderings of digital photographs ranging from geometrical abstraction and painting-like effects to style transfer, using the same framework. In particular, results show that it is possible to create abstract images evoking Malevitchs Suprematist school, while remaining grounded in the structure of digital images, by replacing all the shapes in the tree by simple geometric shapes.},
	keywords     = {Hierarchical,Image abstraction,Image processing,Image representation,Morphological,Picture/image generation}
}
@article{Abuzuraiq2017,
	title        = {On using graph partitioning with isomorphism constraint in procedural content generation},
	author       = {Ahmed M. Abuzuraiq},
	year         = 2017,
	journal      = {ACM International Conference Proceeding Series},
	volume       = {Part F1301},
	pages        = {1--10},
	doi          = {10.1145/3102071.3110575},
	isbn         = 9781450353199,
	abstract     = {This paper describes an algorithm to solve the problem of partitioning a planar graph with a constraint on which partitions should be adjacent or nonadjacent. We explore the applications of the algorithm in Procedural Content Generation in games which includes: The generation of political maps, distribution of terrain and converting or linking Mission Graphs to game spaces. We solve this problem using A-Star search with a heuristic for measuring graphs similarity and we suggest techniques such as graph coarsening to limit the search space. The algorithm sensitivity to the initial state is analyzed next and a restart policy is suggested to overcome that. Additionally, we present multiple constraints that can aid in better controlling the outcomes of the algorithm and we show how these constraints can help in the implementation of the displayed applications.},
	keywords     = {A-Star Search,Games,Graph Coarsening,Graph Isomorphism,Graph Partitioning,Isospectrality,Mission Graph,Political Maps,Procedural Content Generation,Quotient Graph,Restart Policy}
}
@article{Bremaud2017,
	title        = {Random Graphs},
	author       = {Pierre Br\'{e}maud},
	year         = 2017,
	journal      = {Probability Theory and Stochastic Modelling},
	volume       = 78,
	pages        = {255--286},
	doi          = {10.1007/978-3-319-43476-6_10},
	issn         = 21993149,
	abstract     = {This section features what is perhaps the earliest non-trivial result concerning the evolution of a stochastic process, namely the Galton–Watson branching process. It involves a graph, here a ``genealogical'' tree.},
	keywords     = {Bond Percolation,Extinction Probability,Giant Component,Random Graph,Subcritical Case}
}
@article{Arafat2017,
	title        = {Hypergraph drawing by force-directed placement},
	author       = {Naheed Anjum Arafat and St\'{e}phane Bressan},
	year         = 2017,
	journal      = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume       = {10439 LNCS},
	pages        = {387--394},
	doi          = {10.1007/978-3-319-64471-4_31},
	isbn         = 9783319644707,
	issn         = 16113349,
	url          = {http://www.mathe2.uni-bayreuth.de/axel/papers/reingold:graph_drawing_by_force_directed_placement.pdf},
	abstract     = {We propose a family of algorithms that transform a hypergraph drawing problem into a graph drawing problem and leverage force-directed graph drawing algorithms in order to draw hypergraphs. We propose and discuss a number of criteria to evaluate the quality of the drawings from the points of view of aesthetics and of visualization and analytics. We empirically and comparatively evaluate the quality of the drawings based on these criteria on both synthetic and real data sets. Experiments reveal that the algorithms are generally effective and the drawings generated are aesthetically pleasing.},
	issue        = {March},
	keywords     = {Force-directed graph drawing,Hypergraph,Visualization}
}
@article{Flotynski2017,
	title        = {Ontology-Based Representation and Modelling of Synthetic 3D Content: A State-of-the-Art Review},
	author       = {Jakub Floty\'{n}ski and Krzysztof Walczak},
	year         = 2017,
	journal      = {Computer Graphics Forum},
	volume       = 36,
	pages        = {329--353},
	doi          = {10.1111/cgf.13083},
	issn         = 14678659,
	abstract     = {An indispensable element of any practical 3D/VR/AR application is synthetic three-dimensional (3D) content. Such content is characterized by a variety of features--geometry, structure, space, appearance, animation and behaviour--which makes the modelling of 3D content a much more complex, difficult and time-consuming task than in the case of other types of content. One of the promising research directions aiming at simplification of modelling 3D content is the use of the semantic web approach. The formalism provided by semantic web techniques enables declarative knowledge-based modelling of content based on ontologies. Such modelling can be conducted at different levels of abstraction, possibly domain-specific, with inherent separation of concerns. The use of semantic web ontologies enables content representation independent of particular presentation platforms and facilitates indexing, searching and analysing content, thus contributing to increased content re-usability. A range of approaches have been proposed to permit semantic representation and modelling of synthetic 3D content. These approaches differ in the methodologies and technologies used as well as their scope and application domains. This paper provides a review of the current state of the art in representation and modelling of 3D content based on semantic web ontologies, together with a classification, characterization and discussion of the particular approaches.},
	issue        = 8,
	keywords     = {1,2,3,5,7,acm ccs,artificial,augmented and virtual realities,computer graphics,graphical user interfaces,gui,h,i,information interfaces and presentation,multimedia information systems,three-dimensional graphics and realism,user interfaces,virtual reality}
}
@article{Angles2017,
	title        = {Sketch-based implicit blending},
	author       = {Baptiste Angles and Marco Tarini and Brian Wyvill and Lo\"{\i}c Barthe and Andrea Tagliasacchi},
	year         = 2017,
	month        = 12,
	journal      = {ACM Transactions on Graphics},
	volume       = 36,
	pages        = {1--13},
	doi          = {10.1145/3130800.3130825},
	issn         = {0730-0301},
	url          = {https://dl.acm.org/doi/10.1145/3130800.3130825},
	abstract     = {<p>Implicit models can be combined by using composition operators; functions that determine the resulting shape. Recently, gradient-based composition operators have been used to express a variety of behaviours including smooth transitions, sharp edges, contact surfaces, bulging, or any combinations. The problem for designers is that building new operators is a complex task that requires specialized technical knowledge. In this work, we introduce an automatic method for deriving a gradient-based implicit operator from 2D drawings that prototype the intended visual behaviour. To solve this inverse problem, in which a shape defines a function, we introduce a general template for implicit operators. A user's sketch is interpreted as samples in the 3D operator's domain. We fit the template to the samples with a non-rigid registration approach. The process works at interactive rates and can accommodate successive refinements by the user. The final result can be applied to 3D surfaces as well as to 2D shapes. Our method is able to replicate the effect of any blending operator presented in the literature, as well as generating new ones such as non-commutative operators. We demonstrate the usability of our method with examples in font-design, collision-response modeling, implicit skinning, and complex shape design.</p>},
	issue        = 6
}
@article{Mallios2017,
	title        = {Underwater caves sonar data set},
	author       = {Angelos Mallios and Eduard Vidal and Ricard Campos and Marc Carreras},
	year         = 2017,
	journal      = {International Journal of Robotics Research},
	volume       = 36,
	pages        = {1247--1251},
	doi          = {10.1177/0278364917732838},
	issn         = 17413176,
	abstract     = {This paper describes a data set collected with an autonomous underwater vehicle testbed in the unstructured environment of an underwater cave complex. The vehicle is equipped with two mechanically scanned imaging sonar sensors to simultaneously map the caves horizontal and vertical surfaces, a Doppler velocity log, two inertial measurement units, a depth sensor, and a vertically mounted camera imaging the sea floor for ground truth validation at specific points. The testbed collected the data in July 2013, guided by a human diver, to sidestep autonomous navigation in a complex environment. For ease of use, the original robot operating system bag files are provided together with a version combining imagery and human-readable text files for processing on other environments.},
	issue        = 12,
	keywords     = {Underwater robotics,acoustic imaging sonar,field and service robotics,simultaneous localization and mapping,underwater caves}
}
@article{Costello2017,
	title        = {Marine biogeographic realms and species endemicity},
	author       = {Mark J. Costello and Peter Tsai and Pui Shan Wong and Alan Kwok Lun Cheung and Zeenatul Basher and Chhaya Chaudhary},
	year         = 2017,
	journal      = {Nature Communications},
	publisher    = {Springer US},
	volume       = 8,
	pages        = {1--9},
	doi          = {10.1038/s41467-017-01121-2},
	issn         = 20411723,
	url          = {http://dx.doi.org/10.1038/s41467-017-01121-2},
	abstract     = {Marine biogeographic realms have been inferred from small groups of species in particular environments (e.g., coastal, pelagic), without a global map of realms based on statistical analysis of species across all higher taxa. Here we analyze the distribution of 65,000 species of marine animals and plants, and distinguish 30 distinct marine realms, a similar proportion per area as found for land. On average, 42\% of species are unique to the realms. We reveal 18 continental-shelf and 12 offshore deep-sea realms, reflecting the wider ranges of species in the pelagic and deep-sea compared to coastal areas. The most widespread species are pelagic microscopic plankton and megafauna. Analysis of pelagic species recognizes five realms within which other realms are nested. These maps integrate the biogeography of coastal and deep-sea, pelagic and benthic environments, and show how land-barriers, salinity, depth, and environmental heterogeneity relate to the evolution of biota. The realms have applications for marine reserves, biodiversity assessments, and as an evolution relevant context for climate change studies.},
	issue        = 1,
	pmid         = 29051522
}
@article{Weidner2017,
	title        = {Underwater cave mapping using stereo vision},
	author       = {Nick Weidner and Sharmin Rahman and Alberto Quattrini Li and Ioannis Rekleitis},
	year         = 2017,
	journal      = {Proceedings - IEEE International Conference on Robotics and Automation},
	publisher    = {IEEE},
	pages        = {5709--5715},
	doi          = {10.1109/ICRA.2017.7989672},
	isbn         = 9781509046331,
	issn         = 10504729,
	abstract     = {This paper presents a systematic approach for the 3-D mapping of underwater caves. Exploration of underwater caves is very important for furthering our understanding of hydrogeology, managing efficiently water resources, and advancing our knowledge in marine archaeology. Underwater cave exploration by human divers however, is a tedious, labor intensive, extremely dangerous operation, and requires highly skilled people. As such, it is an excellent fit for robotic technology, which has never before been addressed. In addition to the underwater vision constraints, cave mapping presents extra challenges in the form of lack of natural illumination and harsh contrasts, resulting in failure for most of the state-of-the-art visual based state estimation packages. A new approach employing a stereo camera and a video-light is presented. Our approach utilizes the intersection of the cone of the video-light with the cave boundaries: walls, floor, and ceiling, resulting in the construction of a wire frame outline of the cave. Successive frames are combined using a state of the art visual odometry algorithm while simultaneously inferring scale through the stereo reconstruction. Results from experiments at a cave, part of the Sistema Camilo, Quintana Roo, Mexico, validate our approach. The cave wall reconstruction presented provides an immersive experience in 3-D.}
}
@article{Storlazzi2017,
	title        = {Modeling fine-scale coral larval dispersal and interisland connectivity to help designate mutually-supporting coral reef marine protected areas: Insights from Maui Nui, Hawaii},
	author       = {Curt D. Storlazzi and Maarten van Ormondt and Yi Leng Chen and Edwin P.L. Elias},
	year         = 2017,
	journal      = {Frontiers in Marine Science},
	volume       = 4,
	pages        = {1--14},
	doi          = {10.3389/fmars.2017.00381},
	issn         = 22967745,
	abstract     = {Connectivity among individual marine protected areas (MPAs) is one of the most important considerations in the design of integrated MPA networks. To provide such information for managers in Hawaii, USA, a numerical circulation model was developed to determine the role of ocean currents in transporting coral larvae from natal reefs throughout the high volcanic islands of the Maui Nui island complex in the southeastern Hawaiian Archipelago. Spatially- and temporally-varying wind, wave, and circulation model outputs were used to drive a km-scale, 3-dimensional, physics-based circulation model for Maui Nui. The model was calibrated and validated using satellite-tracked ocean surface current drifters deployed during coral-spawning conditions, then used to simulate the movement of the larvae of the dominant reef-building coral, Porites compressa, from 17 reefs during eight spawning events in 2010-2013. These simulations make it possible to investigate not only the general dispersal patterns from individual coral reefs, but also how anomalous conditions during individual spawning events can result in large deviations from those general patterns. These data also help identify those reefs that are dominated by self-seeding and those where self-seeding is limited to determine their relative susceptibility to stressors and potential roadblocks to recovery. Overall, the numerical model results indicate that many of the coral reefs in Maui Nui seed reefs on adjacent islands, demonstrating the interconnected nature of the coral reefs in Maui Nui and providing a key component of the scientific underpinning essential for the design of a mutually supportive network of MPAs to enhance conservation of coral reefs.},
	issue        = {DEC},
	keywords     = {Coral,Design,Larvae,Marine protected area,Model,Porites compressa,Reef}
}
@techreport{Shand2017,
	title        = {Affordable coastal protection in the Pacific Islands - Desktop Review},
	author       = {Tom Shand and James T. Carley},
	year         = 2017,
	doi          = {10.13140/RG.2.2.18657.66403},
	issue        = {February}
}
@article{Davis2017,
	title        = {Two-dimensional discrete Fourier transform analysis of karst and coral reef morphologies},
	author       = {Jerry D. Davis and Joseph D. Chojnacki},
	year         = 2017,
	journal      = {Transactions in GIS},
	volume       = 21,
	pages        = {521--545},
	doi          = {10.1111/tgis.12277},
	issn         = 14679671,
	abstract     = {Fourier transforms have been used in the analysis of landscapes that exhibit the influence of cyclic structures or other morphogenetic controls. Two-dimensional Fourier transforms have been most successful when modeling features with a high frequency over the sample space. This research focuses on applications of 2D discrete Fourier transforms for karst and spur and groove coral reefs, using ArcGIS geoprocessing tools extended with Python NumPy numerical methods. Ten-meter digital elevation data from Puerto Rico and Kentucky holokarst landscapes and five-meter bathymetry from more unidirectional spur and groove coral reefs at Midway Atoll were analyzed. Our method identifies the dominant contributing waves in frequency space, and analyzed power contributions by 5\textdegree{} and 15\textdegree{} azimuth bins. A limiting factor in this analysis is the spatial extent of consistent morphology in the landscape. In contrast to time-domain Fourier analysis, dominant landform frequencies can thus be of low magnitude, creating an imprecise estimate of wave morphometry and direction since this is derived from the combination of inverted x and y frequency values, and the limited frequency grain inherent in the discrete model degrades precision in the solution. Simulated karst and spur \& groove landscapes were used to evaluate the grain of waveform orientation solutions.},
	issue        = 3
}
@phdthesis{Gardiner2017,
	title        = {Variable Patterns in Spur and Groove Reef Morphology Explained by Physical Controls and their Relevance for Platform-Top Sedimentology},
	author       = {Robert C Jr Gardiner},
	year         = 2017,
	url          = {http://nsuworks.nova.edu/occ_stuetd/443},
	issue        = 443,
	institution  = {Nova Southeastern University}
}
@article{Jones2017,
	title        = {Fast computation of accurate sphere-cube intersection volume},
	author       = {Bruce D. Jones and John R. Williams},
	year         = 2017,
	month        = 6,
	journal      = {Engineering Computations},
	volume       = 34,
	pages        = {1204--1216},
	doi          = {10.1108/EC-02-2016-0052},
	issn         = {0264-4401},
	url          = {https://www.emerald.com/insight/content/doi/10.1108/EC-02-2016-0052/full/html},
	issue        = 4
}
@article{Jensen2017,
	title        = {Predicting ice shape evolution in a bulk microphysics model},
	author       = {Anders A. Jensen and Jerry Y. Harrington and Hugh Morrison and Jason A. Milbrandt},
	year         = 2017,
	journal      = {Journal of the Atmospheric Sciences},
	volume       = 74,
	pages        = {2081--2104},
	doi          = {10.1175/JAS-D-16-0350.1},
	issn         = 15200469,
	abstract     = {A novel bulk microphysics scheme that predicts the evolution of ice properties, including aspect ratio (shape), mass, number, size, and density is described, tested, and demonstrated. The scheme is named the Ice-Spheroids Habit Model with Aspect-Ratio Evolution (ISHMAEL). Ice is modeled as spheroids and is nucleated as one of two species depending on nucleation temperature. Microphysical process rates determine how shape and other ice properties evolve. A third aggregate species is also employed, diversifying ice properties in the model. Tests of ice shape evolution during vapor growth and riming are verified against wind tunnel data, revealing that the model captures habit-dependent riming and its effect on fall speed. Lagrangian parcel studies demonstrate that the bulk model captures ice property evolution during riming and melting compared with a bin model. Finally, the capabilities of ISHMAEL are shown in a 2D kinematic framework with a simple updraft. A direct result of predicting ice shape evolution is that various states of ice from unrimed to lightly rimed to densely rimed can be modeled without converting ice mass between predefined ice categories (e.g., snow and graupel). This leads to a different spatial precipitation distribution compared with the traditional method of separating snow and graupel and converting between the two categories, because ice in ISHMAEL sorts in physical space based on the amount of rime, which controls the thickness and therefore fall speed. Predicting these various states of rimed ice leads to a reduction in vapor growth rate and an increase in riming rate in a simple updraft compared with the traditional approach.},
	issue        = 6,
	keywords     = {Cloud microphysics,Cloud parameterizations,Clouds,Ice crystals,Ice loss/growth,Ice particles}
}
@article{Croissant2017,
	title        = {A precipiton-based approach to model hydro-sedimentary hazards induced by large sediment supplies in alluvial fans},
	author       = {Thomas Croissant and Dimitri Lague and Philippe Davy and Tim Davies and Philippe Steer},
	year         = 2017,
	journal      = {Earth Surface Processes and Landforms},
	volume       = 42,
	pages        = {2054--2067},
	doi          = {10.1002/esp.4171},
	issn         = 10969837,
	abstract     = {Mountain ranges are frequently subjected to mass wasting events triggered by storms or earthquakes and supply large volumes of sediment into river networks. Besides altering river dynamics, large sediment deliveries to alluvial fans are known to cause hydro-sedimentary hazards such as flooding and river avulsion. Here we explore how the sediment supply history affects hydro-sedimentary river and fan hazards, and how well can it be predicted given the uncertainties on boundary conditions. We use the 2D morphodynamic model Eros with a new 2D hydrodynamic model driven by a sequence of flood, a sediment entrainment/transport/deposition model and a bank erosion law. We first evaluate the model against a natural case: the 1999 Mount Adams rock avalanche and subsequent avulsion on the Poerua river fan (West Coast, New Zealand). By adjusting for the unknown sediment supply history, Eros predicts the evolution of the alluvial riverbed during the first post-landslide stages within 30 cm. The model is subsequently used to infer how the sediment supply volume and rate control the fan aggradation patterns and associated hazards. Our results show that the total injected volume controls the overall levels of aggradation, but supply rates have a major control on the location of preferential deposition, avulsion and increased flooding risk. Fan re-incision following exhaustion of the landslide-derived sediment supply leads to sediment transfer and deposition downstream and poses similar, but delayed, hydro-sedimentary hazards. Our results demonstrate that 2D morphodynamics models are able to capture the full range of hazards occurring in alluvial fans including river avulsion aggradation and floods. However, only ensemble simulations accounting for uncertainties in boundary conditions (e.g., discharge history, initial topography, grain size) as well as model realization (e.g., non-linearities in hydro-sedimentary processes) can be used to produce probabilistic hazards maps relevant for decision making. Copyright \textcopyright{} 2017 John Wiley \& Sons, Ltd.},
	issue        = 13,
	keywords     = {alluvial fan dynamics,hydro-sedimentary hazards,morphodynamic modeling}
}
@article{Sous2017,
	title        = {Circulation patterns in a channel reef-lagoon system, Ouano lagoon, New Caledonia},
	author       = {Damien Sous and Cristele Chevalier and Jean-Luc Devenon and Jean Blanchot and Marc Pagano},
	year         = 2017,
	month        = 9,
	journal      = {Estuarine, Coastal and Shelf Science},
	volume       = 196,
	pages        = {315--330},
	doi          = {10.1016/j.ecss.2017.07.015},
	issn         = {02727714},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0272771416304474}
}
@article{Chevalier2017,
	title        = {The atypical hydrodynamics of the Mayotte Lagoon (Indian Ocean): Effects on water age and potential impact on plankton productivity},
	author       = {C. Chevalier and J. L. Devenon and M. Pagano and G. Rougier and J. Blanchot and R. Arfi},
	year         = 2017,
	journal      = {Estuarine, Coastal and Shelf Science},
	volume       = 196,
	pages        = {182--197},
	doi          = {10.1016/j.ecss.2017.06.027},
	issn         = {02727714},
	abstract     = {In mesotidal lagoons of the Indian Ocean, the coral reef barrier may be temporarily submerged at high tide and partially exposed at low tide, and this may cause unusual lagoon dynamics. A field measurement campaign was conducted in the north-east Mayotte Lagoon in order to understand these processes. An experimental approach was used, combining measurements taken by 1) a side-mounted Acoustic Doppler Current Profiler (ADCP) on a moving boat along transects through the reef passages (17 transects) and 2) by more conventional high-resolution moored ADCP measurements. A specific tidal analysis methodology was used to determine the spatial variability of the velocity. The tidal hydrodynamics within the lagoon were determined using a numerical model and then analyzed. The tide acted as a quasi-progressive forced wave in the lagoon: at low tide, water entered through the south passage, over the reef and left the lagoon through the north passage. This flow was reversed at high tide. The tide-driven quasi-progressive wave created a specific lagoon dynamics. Contrary to most other channel lagoons, the flow over the reef was mainly outward. This increases the inflow through the passages, which renews the water in the lagoon as shown by the indicators of age and origin of the water inside the lagoon. This study also showed the importance of these indicators for better understanding the variations and levels of plankton biomass (with chlorophyll concentration as proxy) which is quite high in this lagoon.},
	keywords     = {Barrier reef overflow,Mayotte Lagoon,Mesotidal reef lagoon,Side-mounted ADCP,Water renewal indicators}
}
@article{Othmani2017,
	title        = {High-resolution numerical modelling of the barotropic tides in the Gulf of Gabes, eastern Mediterranean Sea (Tunisia)},
	author       = {Achref Othmani and B\'{e}chir B\'{e}jaoui and Crist\`{e}le Chevalier and Dalila Elhmaidi and Jean Luc Devenon and Lotfi Aleya},
	year         = 2017,
	journal      = {Journal of African Earth Sciences},
	volume       = 129,
	pages        = {224--232},
	doi          = {10.1016/j.jafrearsci.2017.01.007},
	issn         = 18791956,
	abstract     = {A high-resolution 2D barotropic tidal model was developed for the Gulf of Gabes and used to characterise hydrodynamic processes and tidal dynamics. The model is based on the Regional Ocean Modelling System. It is forced at the open boundaries by the semidiurnal M2 and S2 astronomical components while meteorological forcing has been neglected. The model results show good agreement with observations confirming that it reproduces the gulf's main tidal characteristics reasonably well. In fact, the simulated semidiurnal tidal components M2 and S2 generate important sea level variations and coastal currents. Tidal propagation is directed to the gulf's western sector while tidal resonance occurs in its inner sector where the M2 and S2 amplitudes are about 50 and 36~cm, respectively. Phase maxima (170\textdegree{}–185\textdegree{}) are located inside Boughrara Lagoon for both the simulated M2 and S2 tides. The strongest currents are found in shallow coastal regions and at the lagoon's western inlet. During spring tides, currents are around 10–20~cm~s-1 in the gulf center and up to 50~cm~s-1 inside the lagoon.},
	keywords     = {Gulf of Gabes,High resolution,Hydrodynamics,Numerical modelling,Tide}
}
@inproceedings{Isola2017,
	title        = {Image-to-Image Translation with Conditional Adversarial Networks},
	author       = {Phillip Isola and Jun-Yan Zhu and Tinghui Zhou and Alexei A Efros},
	year         = 2017,
	month        = 7,
	booktitle    = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	publisher    = {IEEE},
	pages        = {5967--5976},
	doi          = {10.1109/CVPR.2017.632},
	isbn         = {978-1-5386-0457-1},
	url          = {http://arxiv.org/abs/1611.07004 http://ieeexplore.ieee.org/document/8100115/},
	abstract     = {We investigate conditional adversarial networks as a general-purpose solution to image-to-image translation problems. These networks not only learn the mapping from input image to output image, but also learn a loss function to train this mapping. This makes it possible to apply the same generic approach to problems that traditionally would require very different loss formulations. We demonstrate that this approach is effective at synthesizing photos from label maps, reconstructing objects from edge maps, and colorizing images, among other tasks. Indeed, since the release of the pix2pix software associated with this paper, a large number of internet users (many of them artists) have posted their own experiments with our system, further demonstrating its wide applicability and ease of adoption without the need for parameter tweaking. As a community, we no longer hand-engineer our mapping functions, and this work suggests we can achieve reasonable results without hand-engineering our loss functions either.}
}
@phdthesis{vanDijk2017,
	title        = {Solving Puzzles using Cellular Automata},
	author       = {Stef van Dijk},
	year         = 2017,
	url          = {www.liacs.leidenuniv.nl},
	abstract     = {This thesis is about cellular automata and whether or not they are able to solve different kinds of puzzles. In the first part it is explained what a cellular autamaton is and how it works. Furthermore is the connection between puzzles and cellular automata explained and some related work is given.},
	keywords     = {Thesis Bachelor Informatica - 2016-2017}
}
@article{Pratt2017,
	title        = {Shear velocity structure of the crust and upper mantle of Madagascar derived from surface wave tomography},
	author       = {Martin J. Pratt and Michael E. Wysession and Ghassan Aleqabi and Douglas A. Wiens and Andrew A. Nyblade and Patrick Shore and G\'{e}rard Rambolamanana and Fenitra Andriampenomanana and Tsiriandrimanana Rakotondraibe and Robert D. Tucker and Guilhem Barruol and Elisa Rindraharisaona},
	year         = 2017,
	month        = 1,
	journal      = {Earth and Planetary Science Letters},
	publisher    = {Elsevier B.V.},
	volume       = 458,
	pages        = {405--417},
	doi          = {10.1016/j.epsl.2016.10.041},
	issn         = {0012821X},
	abstract     = {The crust and upper mantle of the Madagascar continental fragment remained largely unexplored until a series of recent broadband seismic experiments. An island-wide deployment of broadband seismic instruments has allowed the first study of phase velocity variations, derived from surface waves, across the entire island. Late Cenozoic alkaline intraplate volcanism has occurred in three separate regions of Madagascar (north, central and southwest), with the north and central volcanism active until <1 Ma, but the sources of which remains uncertain. Combined analysis of three complementary surface wave methods (ambient noise, Rayleigh wave cross-correlations, and two-plane-wave) illuminate the upper mantle down to depths of 150 km. The phase-velocity measurements from the three methods for periods of 8–182 s are combined at each node and interpolated to generate the first 3-D shear-velocity model for sub-Madagascar velocity structure. Shallow (upper 10 km) low-shear-velocity regions correlate well with sedimentary basins along the west coast. Upper mantle low-shear-velocity zones that extend to at least 150 km deep underlie the north and central regions of recent alkali magmatism. These anomalies appear distinct at depths <100 km, suggesting that any connection between the zones lies at depths greater than the resolution of surface-wave tomography. An additional low-shear velocity anomaly is also identified at depths 50–150 km beneath the southwest region of intraplate volcanism. We interpret these three low-velocity regions as upwelling asthenosphere beneath the island, producing high-elevation topography and relatively low-volume magmatism.},
	keywords     = {Madagascar,ambient noise,intraplate volcanism,surface wave,tomography}
}
@article{Shi2017,
	title        = {A review of simulation-based urban form generation and optimization for energy-driven urban design},
	author       = {Zhongming Shi and Jimeno A. Fonseca and Arno Schlueter},
	year         = 2017,
	month        = 8,
	journal      = {Building and Environment},
	volume       = 121,
	pages        = {119--129},
	doi          = {10.1016/j.buildenv.2017.05.006},
	issn         = {03601323},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0360132317301865},
	abstract     = {This paper first defines the concept of energy-driven urban design. It aims to reveal synergies and trade-offs that may arise while designing urban areas for better energy performance. To facilitate urban planners and designers tackle these problems at the early stage of their work, this paper proposes the idea of simulation-based urban form generation and optimization modeling. It connects parametric models of urban form generation to an optimization engine coupled with a widely available program of energy systems. To build up the model of simulation-based urban form generation and optimization modeling, this paper reviews the state-of-the-art of simulation-based design generation and optimization modeling and discusses its application on energy-driven urban design at the district scale. The paper compares the main generative methods and presents their limitations and advantages to aid energy-driven urban design. For the urban form generation modeling, the paper also reviews the most relevant approaches to urban morphology. These approaches help to define the urban elements for the urban form generation. Most of the existing design generation and optimization models are observed to consist of a workflow, a generative method, and a series of generation constraints. Based on this, the paper proposes a model of simulation-based urban form generation and optimization modeling for energy-driven urban design. The model consists of a workflow with three steps, a collection step, the generation step, and the optimization step. The constraints yet need to be defined. At the district scale, the model also has to work at an appropriate resolution and precision. Highlights-The concept of Energy-driven urban design is defined.-A series of generative methods are comapred for Energy-driven urban design.-Prevailing urban morphological approaches are reviewed to building up the urban design prototype for optimization.-A brief model of generative design modeling for energy-driven urban design is proposed. Four sets of constraints are defined.},
	keywords     = {Energy-driven urban design,Generative methods,Simulation-based optimization modeling,Urban form generation modeling,Urban morphology}
}
@article{Miller2017,
	title        = {A comparison of genetic connectivity in two deep sea corals to examine whether seamounts are isolated islands or stepping stones for dispersal},
	author       = {Karen J. Miller and Rasanthi M. Gunasekera},
	year         = 2017,
	month        = 4,
	journal      = {Scientific Reports},
	publisher    = {Nature Publishing Group},
	volume       = 7,
	doi          = {10.1038/srep46103},
	issn         = 20452322,
	abstract     = {Ecological processes in the deep sea are poorly understood due to the logistical constraints of sampling thousands of metres below the ocean's surface and remote from most land masses. Under such circumstances, genetic data provides unparalleled insight into biological and ecological relationships. We use microsatellite DNA to compare the population structure, reproductive mode and dispersal capacity in two deep sea corals from seamounts in the Southern Ocean. The solitary coral Desmophyllum dianthus has widespread dispersal consistent with its global distribution and resilience to disturbance. In contrast, for the matrix-forming colonial coral Solenosmilia variabilis asexual reproduction is important and the dispersal of sexually produced larvae is negligible, resulting in isolated populations. Interestingly, despite the recognised impacts of fishing on seamount communities, genetic diversity on fished and unfished seamounts was similar for both species, suggesting that evolutionary resilience remains despite reductions in biomass. Our results provide empirical evidence that a group of seamounts can function either as isolated islands or stepping stones for dispersal for different taxa. Furthermore different strategies will be required to protect the two sympatric corals and consequently the recently declared marine reserves in this region may function as a network for D. dianthus, but not for S. variabilis.},
	pmid         = 28393887
}
@article{Jouves2017,
	title        = {Speleogenesis, geometry, and topology of caves: A quantitative study of 3D karst conduits},
	author       = {Johan Jouves and Sophie Viseur and Bruno Arfib and C\'{e}cile Baudement and Hubert Camus and Pauline Collon and Yves Guglielmi},
	year         = 2017,
	month        = 12,
	journal      = {Geomorphology},
	publisher    = {Elsevier B.V.},
	volume       = 298,
	pages        = {86--106},
	doi          = {10.1016/j.geomorph.2017.09.019},
	issn         = {0169555X},
	abstract     = {Karst systems are hierarchically spatially organized three-dimensional (3D) networks of conduits behaving as drains for groundwater flow. Recently, geostatistical approaches proposed to generate karst networks from data and parameters stemming from analogous observed karst features. Other studies have qualitatively highlighted relationships between speleogenetic processes and cave patterns. However, few studies have been performed to quantitatively define these relationships. This paper reports a quantitative study of cave geometries and topologies that takes the underlying speleogenetic processes into account. In order to study the spatial organization of caves, a 3D numerical database was built from 26 caves, corresponding to 621 km of cumulative cave passages representative of the variety of karst network patterns. The database includes 3D speleological surveys for which the speleogenetic context is known, allowing the polygenic karst networks to be divided into 48 monogenic cave samples and classified into four cave patterns: vadose branchwork (VB), water-table cave (WTC), looping cave (LC), and angular maze (AM). Eight morphometric cave descriptors were calculated, four geometrical parameters (width-height ratio, tortuosity, curvature, and vertical index) and four topological ones (degree of node connectivity, \ensuremath{\alpha} and \ensuremath{\gamma} graph indices, and ramification index) respectively. The results were validated by statistical analyses (Kruskal-Wallis test and PCA). The VB patterns are clearly distinct from AM ones and from a third group including WTC and LC. A quantitative database of cave morphology characteristics is provided, depending on their speleogenetic processes. These characteristics can be used to constrain and/or validate 3D geostatistical simulations. This study shows how important it is to relate the geometry and connectivity of cave networks to recharge and flow processes. Conversely, the approach developed here provides proxies to estimate the evolution of the vadose zone to epiphreatic and phreatic zones in limestones from the quantitative analysis of existing cave patterns.},
	keywords     = {Karst characterization,Morphometric analysis,Speleogenesis,Statistics}
}
@article{Zhu2017,
	title        = {Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks},
	author       = {Jun-Yan Zhu and Taesung Park and Phillip Isola and Alexei A. Efros},
	year         = 2017,
	month        = 3,
	url          = {http://arxiv.org/abs/1703.10593},
	abstract     = {Image-to-image translation is a class of vision and graphics problems where the goal is to learn the mapping between an input image and an output image using a training set of aligned image pairs. However, for many tasks, paired training data will not be available. We present an approach for learning to translate an image from a source domain $X$ to a target domain $Y$ in the absence of paired examples. Our goal is to learn a mapping $G: X \rightarrow Y$ such that the distribution of images from $G(X)$ is indistinguishable from the distribution $Y$ using an adversarial loss. Because this mapping is highly under-constrained, we couple it with an inverse mapping $F: Y \rightarrow X$ and introduce a cycle consistency loss to push $F(G(X)) \approx X$ (and vice versa). Qualitative results are presented on several tasks where paired training data does not exist, including collection style transfer, object transfiguration, season transfer, photo enhancement, etc. Quantitative comparisons against several prior methods demonstrate the superiority of our approach.}
}
@book{Burkhard2017,
	title        = {Mapping Ecosystem Services},
	author       = {Benjamin Burkhard and Joachim Maes},
	year         = 2017,
	publisher    = {Pensoft Publishers, Sofia},
	pages        = 374,
	isbn         = {978-954-642-829-5}
}
@inproceedings{Pirk2017,
	title        = {Interactive wood combustion for botanical tree models},
	author       = {S\"{o}ren Pirk and Michal Jarzabek and Torsten H\"{a}drich and Dominik L. Michels and Wojciech Palubicki},
	year         = 2017,
	month        = 11,
	booktitle    = {ACM Transactions on Graphics},
	publisher    = {Association for Computing Machinery},
	volume       = 36,
	doi          = {10.1145/3130800.3130814},
	issn         = 15577368,
	abstract     = {We present a novel method for the combustion of botanical tree models. Tree models are represented as connected particles for the branching structure and a polygonal surface mesh for the combustion. Each particle stores biological and physical attributes that drive the kinetic behavior of a plant and the exothermic reaction of the combustion. Coupled with realistic physics for rods, the particles enable dynamic branch motions. We model material properties, such as moisture and charring behavior, and associate them with individual particles. The combustion is efficiently processed in the surface domain of the tree model on a polygonal mesh. A user can dynamically interact with the model by initiating fires and by inducing stress on branches. The flames realistically propagate through the tree model by consuming the available resources. Our method runs at interactive rates and supports multiple tree instances in parallel. We demonstrate the effectiveness of our approach through numerous examples and evaluate its plausibility against the combustion of real wood samples.},
	issue        = 6,
	keywords     = {Botanical Tree Models,Interactive Modeling,Natural Phenomena,Visual Models of Trees,Wood Combustion}
}
@article{Pizarro2017,
	title        = {Unraveling the structure and composition of Varadero Reef, an improbable and imperiled coral reef in the Colombian Caribbean},
	author       = {Valeria Pizarro and Sara C. Rodr\'{\i}guez and Mateo L\'{o}pez-Victoria and Fernando A. Zapata and Sven Zea and Claudia T. Galindo-Mart\'{\i}nez and Roberto Iglesias-Prieto and Joseph Pollock and M\'{o}nica Medina},
	year         = 2017,
	journal      = {PeerJ},
	publisher    = {PeerJ Inc.},
	volume       = 2017,
	doi          = {10.7717/peerj.4119},
	issn         = 21678359,
	abstract     = {Coral reefs are commonly associated with oligotrophic, well-illuminated waters. In 2013, a healthy coral reef was discovered in one of the least expected places within the Colombian Caribbean: at the entrance of Cartagena Bay, a highly-polluted system that receives industrial and sewage waste, as well as high sediment and freshwater loads from an outlet of the Magdalena River (the longest and most populated river basin in Colombia). Here we provide the first characterization of Varadero Reef's geomorphology and biological diversity. We also compare these characteristics with those of a nearby reference reef, Bar\'{u} Reef, located in an area much less influenced by the described polluted system. Below the murky waters, we found high coral cover of 45.1\% (\pm{}3.9; up to 80\% in some sectors), high species diversity, including 42 species of scleractinian coral, 38 of sponge, three of lobster, and eight of sea urchin; a fish community composed of 61 species belonging to 24 families, and the typical zonation of a Caribbean fringing reef. All attributes found correspond to a reef that, according to current standards should be considered in ''good condition''. Current plans to dredge part of Varadero threaten the survival of this reef. There is, therefore, an urgent need to describe the location and characteristics of Varadero as a first step towards gaining acknowledgement of its existence and garnering inherent legal and environmental protections.},
	issue        = 12,
	keywords     = {Caribbean coral reefs,Coral reef biodiversity,Paradoxical reef,Reef dredging,Resistance}
}
@inproceedings{Li2017,
	title        = {Networked human motion capture system based on quaternion navigation},
	author       = {Jie Li and Zhe Long Wang and Hongyu Zhao and Raffaele Gravina and Giancarlo Fortino and Yongmei Jiang and Kai Tang},
	year         = 2017,
	booktitle    = {BodyNets International Conference on Body Area Networks},
	doi          = {10.1145/0000000.0000000},
	issn         = 23103582,
	abstract     = {In this paper, from the perspective of human ergonomics, we analyze the movement of the joints in the process of human body movements, and we establish a dynamic model according to the human skeleton structure. On this basis, from the rigid body dynamics point of view, combined with the principle of inertial navigation, a body sensor network based on MEMS inertial sensors is built to capture human body motion in real time. On the basis of space trajectory of human body movement and traditional human motion solution strategy, a human motion solution strategy based on particle filter fusion solution is proposed to realize the prediction of human motion analysis. Therefore, we evaluate the performance of the designed system by comparing with the real motion. Finally, in order to verify the human motion data, the motion capture data verification platforms are established. Experimental results show that the proposed joint attitude solution algorithm can achieve a relatively smooth tracking effect and provides a certain reference value.},
	keywords     = {Body sensor network,Inertial navigation,Motion capture,Particle filter}
}
@article{Wang2017,
	title        = {Ultrasonic time-frequency method to evaluate the deterioration properties of rock suffered from freeze-thaw weathering},
	author       = {Peng Wang and Jinyu Xu and Xinyu Fang and Peixi Wang and Guanghui Zheng and Ming Wen},
	year         = 2017,
	month        = 11,
	journal      = {Cold Regions Science and Technology},
	publisher    = {Elsevier B.V.},
	volume       = 143,
	pages        = {13--22},
	doi          = {10.1016/j.coldregions.2017.07.002},
	issn         = {0165232X},
	abstract     = {Cyclic freeze-thaw (F-T) is a serious natural weathering mechanism for rock engineering and stone constrictions in cold regions. Considering the universality and destructiveness of rock F-T weathering, evaluation of rock deterioration is of vital importance. In this work, ultrasonic detections and mechanical experiments including uniaxial compression, splitting tension and angle-changed shear tests were carried out on red-sandstone specimens without and after different F-T cycles. Attenuation occurred to almost all of the indexes of red-sandstone after F-T weathering, including mechanical properties such as uniaxial compressive strength (UCS), deformation modulus (Ed), splitting tensile strength (STS), cohesion (C) and friction angle (\ensuremath{\phi}), and ultrasonic properties such as the P-wave velocity (Vp), head-wave amplitude (Ah), centroid frequency (fc) and kurtosis of frequency spectrum (KFS). After 25 F-T cycles, the UCS, Ed, STS, C, \ensuremath{\phi}, Vp, Ah, fc and KFS decreased by 42.5, 63.0, 87.3, 33.7, 22.6, 50.6, 24.6, 38.3 and 0.56\%, respectively. With increasing number of F-T cycles, similar convergent decrease tendencies between the UCS, Ed, STS, C and the Vp, Ah, fc, KFS were found, confirming the effectiveness of the ultrasonic time-frequency method to estimate the deterioration of rock suffered from F-T weathering. Similar degradation behavior in ultrasonic time-frequency properties and in mechanical properties resulted from the microscopic damages of red-sandstone suffered from F-T weathering. An ultrasonic evaluation auxiliary graph is suggested as a convenient practical evaluation method in rock engineering.},
	keywords     = {Aging rock,Cold regions,Freeze-thaw weathering,Frequency spectrum,Ultrasonic time-frequency evaluation,Waveform}
}
@article{Meinecke2017,
	title        = {Multiscale Modeling of Diffusion in a Crowded Environment},
	author       = {Lina Meinecke},
	year         = 2017,
	month        = 11,
	journal      = {Bulletin of Mathematical Biology},
	publisher    = {Springer New York LLC},
	volume       = 79,
	pages        = {2672--2695},
	doi          = {10.1007/s11538-017-0346-6},
	issn         = 15229602,
	abstract     = {We present a multiscale approach to model diffusion in a crowded environment and its effect on the reaction rates. Diffusion in biological systems is often modeled by a discrete space jump process in order to capture the inherent noise of biological systems, which becomes important in the low copy number regime. To model diffusion in the crowded cell environment efficiently, we compute the jump rates in this mesoscopic model from local first exit times, which account for the microscopic positions of the crowding molecules, while the diffusing molecules jump on a coarser Cartesian grid. We then extract a macroscopic description from the resulting jump rates, where the excluded volume effect is modeled by a diffusion equation with space-dependent diffusion coefficient. The crowding molecules can be of arbitrary shape and size, and numerical experiments demonstrate that those factors together with the size of the diffusing molecule play a crucial role on the magnitude of the decrease in diffusive motion. When correcting the reaction rates for the altered diffusion we can show that molecular crowding either enhances or inhibits chemical reactions depending on local fluctuations of the obstacle density.},
	issue        = 11,
	keywords     = {Macromolecular crowding,Stochastic reaction–diffusion simulations},
	pmid         = 28924915
}
@inbook{Crooks2017,
	title        = {Agent-Based Modeling},
	author       = {Andrew Crooks and Alison Heppenstall and Nick Malleson},
	year         = 2017,
	month        = 7,
	booktitle    = {Comprehensive Geographic Information Systems},
	publisher    = {Elsevier Inc.},
	volume       = 3,
	pages        = {218--243},
	doi          = {10.1016/B978-0-12-409548-9.09704-9},
	isbn         = 9780128046609,
	abstract     = {Agent-based modeling (ABM) is a technique that allows us to explore how the interactions of heterogeneous individuals impact on the wider behavior of social/spatial systems. In this article, we introduce ABM and its utility for studying geographical systems. We discuss how agent-based models have evolved over the last 20 years and situate the discipline within the broader arena of geographical modeling. The main properties of ABM are introduced and we discuss how models are capable of capturing and incorporating human behavior. We then discuss the steps taken in building an agent-based model and the issues of verification and validation of such models. As the focus of the article is on ABM of geographical systems, we then discuss the need for integrating geographical information into models and techniques and toolkits that allow for such integration. Once the core concepts and techniques of creating agent-based models have been introduced, we then discuss a wide range of applications of agent-based models for exploring various aspects of geographical systems. We conclude the article by outlining challenges and opportunities of ABM in understanding geographical systems and human behavior.},
	keywords     = {Agent-based modeling,Calibration,Complexity,Geographical information science,Modeling and simulation,Validation,Verification}
}
@inproceedings{Lock2018,
	title        = {Visual analytics of single cell microscopy data using a collaborative immersive environment},
	author       = {John G. Lock and Daniel Filonik and Robert Lawther and Nalini Pather and Katharina Gaus and Sarah Kenderdine and Tomasz Bednarz},
	year         = 2018,
	month        = 12,
	booktitle    = {Proceedings of the 16th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and its Applications in Industry - VRCAI '18},
	publisher    = {ACM Press},
	pages        = {1--4},
	doi          = {10.1145/3284398.3284412},
	isbn         = 9781450360876,
	url          = {http://dl.acm.org/citation.cfm?doid=3284398.3284412},
	abstract     = {Understanding complex physiological processes demands the integration of diverse insights derived from visual and quantitative analysis of bio-image data, such as microscopy images. This process is currently constrained by disconnects between methods for interpreting data, as well as by language barriers that hamper the necessary cross-disciplinary collaborations. Using immersive analytics, we leveraged bespoke immersive visualizations to integrate bio-images and derived quantitative data, enabling deeper comprehension and seamless interaction with multi-dimensional cellular information. We designed and developed a visualization platform that combines time-lapse confocal microscopy recordings of cancer cell motility with image-derived quantitative data spanning 52 parameters. The integrated data representations enable rapid, intuitive interpretation, bridging the divide between bio-images and quantitative information. Moreover, the immersive visualization environment promotes collaborative data interrogation, supporting vital cross-disciplinary collaborations capable of deriving transformative insights from rapidly emerging bio-image big data.},
	city         = {New York, New York, USA},
	keywords     = {Confocal Microscopy,High-Performance Visualization,Systems Microscopy,Visual and Immersive Analytics}
}
@inproceedings{Faiez2018,
	title        = {Best Road Based Immersive Visualization Framework for patient in emergency},
	author       = {Hanen Faiez and Jalel Akaichi},
	year         = 2018,
	month        = 12,
	booktitle    = {Proceedings of the 7th International Conference on Software Engineering and New Technologies - ICSENT 2018},
	publisher    = {ACM Press},
	pages        = {1--5},
	doi          = {10.1145/3330089.3330114},
	isbn         = 9781450361019,
	url          = {http://dl.acm.org/citation.cfm?doid=3330089.3330114},
	abstract     = {To immerse a person is to give him the feeling of being present in a virtual space. To concatenate immersive with analytic we obtain "The immersive analytics". Immersive Analysis is an area that explores new interaction and display technologies for analytics to support multi-discipline data reasoning. Monitoring systems and routing algorithms are two disciplines that have greatly beneficiated from this area since that the image is the basis on which we build our decision in this kind of systems. Since these techniques increase the human capacity for analysis and to understand heterogeneous, massive and often multiform data sets, and because a good detection of routing or performance degradation anomalies depends on a good data analysis, using a visual analysis system we show in this article how immersive analysis immerse the user in his task to better support data analysis allowing him to provide clear and timely information to make the right decision specially in emergencies.},
	city         = {New York, New York, USA},
	keywords     = {Immersive Analytics,Monitoring systems,Routing Protocol}
}
@article{Yang2018,
	title        = {Multi-frame Quality Enhancement for Compressed Video},
	author       = {Ren Yang and Mai Xu and Zulin Wang and Tianyi Li},
	year         = 2018,
	journal      = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	pages        = {6664--6673},
	doi          = {10.1109/CVPR.2018.00697},
	isbn         = 9781538664209,
	issn         = 10636919,
	abstract     = {The past few years have witnessed great success in applying deep learning to enhance the quality of compressed image/video. The existing approaches mainly focus on enhancing the quality of a single frame, ignoring the similarity between consecutive frames. In this paper, we investigate that heavy quality fluctuation exists across compressed video frames, and thus low quality frames can be enhanced using the neighboring high quality frames, seen as Multi-Frame Quality Enhancement (MFQE). Accordingly, this paper proposes an MFQE approach for compressed video, as a first attempt in this direction. In our approach, we firstly develop a Support Vector Machine (SVM) based detector to locate Peak Quality Frames (PQFs) in compressed video. Then, a novel Multi-Frame Convolutional Neural Network (MF-CNN) is designed to enhance the quality of compressed video, in which the non-PQF and its nearest two PQFs are as the input. The MF-CNN compensates motion between the non-PQF and PQFs through the Motion Compensation subnet (MC-subnet). Subsequently, the Quality Enhancement subnet (QE-subnet) reduces compression artifacts of the non-PQF with the help of its nearest PQFs. Finally, the experiments validate the effectiveness and generality of our MFQE approach in advancing the state-of-the-art quality enhancement of compressed video. The code of our MFQE approach is available at https://github.com/ryangBUAA/MFQE.git.}
}
@inproceedings{Zhao,
	title        = {RF-based 3D skeletons},
	author       = {Mingmin Zhao and Yonglong Tian and Hang Zhao and Mohammad Abu Alsheikh and Tianhong Li and Rumen Hristov and Zachary Kabelac and Dina Katabi and Antonio Torralba},
	year         = 2018,
	month        = 8,
	booktitle    = {Proceedings of the 2018 Conference of the ACM Special Interest Group on Data Communication},
	publisher    = {ACM},
	pages        = {267--281},
	doi          = {10.1145/3230543.3230579},
	isbn         = 9781450355674,
	url          = {https://dl.acm.org/doi/10.1145/3230543.3230579},
	abstract     = {This paper introduces RF-Pose3D, the first system that infers 3D human skeletons from RF signals. It requires no sensors on the body, and works with multiple people and across walls and occlusions. Further, it generates dynamic skeletons that follow the people as they move, walk or sit. As such, RF-Pose3D provides a significant leap in RF-based sensing and enables new applications in gaming, healthcare, and smart homes. RF-Pose3D is based on a novel convolutional neural network (CNN) architecture that performs high-dimensional convolutions by decomposing them into low-dimensional operations. This property allows the network to efficiently condense the spatio-temporal information in RF signals. The network first zooms in on the individuals in the scene, and crops the RF signals reflected off each person. For each individual , it localizes and tracks their body parts-head, shoulders , arms, wrists, hip, knees, and feet. Our evaluation results show that RF-Pose3D tracks each keypoint on the human body with an average error of 4.2 cm, 4.0 cm, and 4.9 cm along the X, Y, and Z axes respectively. It maintains this accuracy even in the presence of multiple people, and in new environments that it has not seen in the training set. Demo videos are available at our website: http://rfpose3d.csail.mit.edu.},
	city         = {New York, NY, USA},
	keywords     = {CCS CONCEPTS \textbullet{} Networks \rightarrow{} Cyber-physical networks,KEYWORDS RF Sensing, 3D Human Pose Estimation, Mac,Sensor networks,\textbullet{} Computing methodologies \rightarrow{} Machine learning}
}
@inproceedings{Farhad,
	title        = {Non-Intrusive Human Motion Recognition Using Distributed Sparse Sensors and the Genetic Algorithm Based Neural Network},
	author       = {Farhad Pourpanah and Bin Zhang and Rui Ma and Qi Hao},
	year         = 2018,
	month        = 10,
	booktitle    = {2018 IEEE SENSORS},
	publisher    = {IEEE},
	pages        = {1--4},
	doi          = {10.1109/ICSENS.2018.8589618},
	isbn         = {978-1-5386-4707-3},
	url          = {https://ieeexplore.ieee.org/document/8589618/}
}
@article{Zhu,
	title        = {Visual Object Networks: Image Generation with Disentangled 3D Representation},
	author       = {Jun-Yan Zhu and Zhoutong Zhang and Chengkai Zhang and Jiajun Wu and Antonio Torralba and Joshua B. Tenenbaum and William T. Freeman},
	year         = 2018,
	month        = 12,
	url          = {http://arxiv.org/abs/1812.02725},
	abstract     = {Recent progress in deep generative models has led to tremendous breakthroughs in image generation. However, while existing models can synthesize photorealistic images, they lack an understanding of our underlying 3D world. We present a new generative model, Visual Object Networks (VON), synthesizing natural images of objects with a disentangled 3D representation. Inspired by classic graphics rendering pipelines, we unravel our image formation process into three conditionally independent factors---shape, viewpoint, and texture---and present an end-to-end adversarial learning framework that jointly models 3D shapes and 2D images. Our model first learns to synthesize 3D shapes that are indistinguishable from real shapes. It then renders the object's 2.5D sketches (i.e., silhouette and depth map) from its shape under a sampled viewpoint. Finally, it learns to add realistic texture to these 2.5D sketches to generate natural images. The VON not only generates images that are more realistic than state-of-the-art 2D image synthesis methods, but also enables many 3D operations such as changing the viewpoint of a generated image, editing of shape and texture, linear interpolation in texture and shape space, and transferring appearance across different objects and viewpoints.}
}
@article{Florinsky2018,
	title        = {Towards geomorphometric modelling of the topography of the Arctic Ocean floor},
	author       = {I V Florinsky and S V Filippov and A S Abramova and Yu A Zarayskaya and E V Selezneva and I V Florinsky and S V Filippov},
	year         = 2018,
	journal      = {Proceedings of the 7th International Conference on Cartography \& GIS},
	volume       = 1,
	pages        = {166--173},
	issue        = {June}
}
@article{Cruz2018,
	title        = {Patch-based Terrain Synthesis},
	author       = {Leandro Cruz and Luiz Velho and \'{E}ric Galin and Adrien Peytavie and \'{E}ric Gu\'{e}rin},
	year         = 2018,
	doi          = {https://dx.doi.org/10.5220/0005360201890194},
	isbn         = {0005360201890}
}
@article{Paris2018,
	title        = {Amplification de Terrains avec des caract\'{e}ristiques implicites 3D},
	author       = {Axel Paris and \'{E}ric Galin and Adrien Peytavie and \'{E}ric Gu\'{e}rin and James Gain},
	year         = 2018,
	journal      = {Journ\'{e}es de l'Association Fran\c{c}aise d'Informatique Graphique}
}
@article{Smith2018,
	title        = {Multi-view silhouette and depth decomposition for high resolution 3D object representation},
	author       = {Edward Smith and Scott Fujimoto and David Meger},
	year         = 2018,
	journal      = {Advances in Neural Information Processing Systems},
	volume       = {2018-Decem},
	pages        = {6478--6488},
	issn         = 10495258,
	abstract     = {We consider the problem of scaling deep generative shape models to high-resolution. Drawing motivation from the canonical view representation of objects, we introduce a novel method for the fast up-sampling of 3D objects in voxel space through networks that perform super-resolution on the six orthographic depth projections. This allows us to generate high-resolution objects with more efficient scaling than methods which work directly in 3D. We decompose the problem of 2D depth super-resolution into silhouette and depth prediction to capture both structure and fine detail. This allows our method to generate sharp edges more easily than an individual network. We evaluate our work on multiple experiments concerning high-resolution 3D objects, and show our system is capable of accurately predicting novel objects at resolutions as large as 512\texttimes{}512\texttimes{}512 - the highest resolution reported for this task. We achieve state-of-the-art performance on 3D object reconstruction from RGB images on the ShapeNet dataset, and further demonstrate the first effective 3D super-resolution method.},
	issue        = {Nips}
}
@article{Dong2018,
	title        = {An Efficient Volumetric Mesh Representation for Real-Time Scene Reconstruction Using Spatial Hashing},
	author       = {Wei Dong and Jieqi Shi and Weijie Tang and Xin Wang and Hongbin Zha},
	year         = 2018,
	journal      = {Proceedings - IEEE International Conference on Robotics and Automation},
	pages        = {6323--6330},
	doi          = {10.1109/ICRA.2018.8463157},
	isbn         = 9781538630815,
	issn         = 10504729,
	abstract     = {Mesh plays an indispensable role in dense realtime reconstruction essential in robotics. Efforts have been made to maintain flexible data structures for 3D data fusion, yet an efficient incremental framework specifically designed for online mesh storage and manipulation is missing. We propose a novel framework to compactly generate, update, and refine mesh for scene reconstruction upon a volumetric representation. Maintaining a spatial-hashed field of cubes, we distribute vertices with continuous value on discrete edges that support O(1) vertex accessing and forbid memory redundancy. By introducing Hamming distance in mesh refinement, we further improve the mesh quality regarding the triangle type consistency with a low cost. Lock-based and lock-free operations were applied to avoid thread conflicts in GPU parallel computation. Experiments demonstrate that the mesh memory consumption is significantly reduced while the running speed is kept in the online reconstruction process.},
	issue        = {May}
}
@techreport{Bastani2018,
	title        = {RoadTracer: Automatic Extraction of Road Networks from Aerial Images},
	author       = {Favyen Bastani and Songtao He and Sofiane Abbar and Mohammad Alizadeh and Hari Balakrishnan and Sanjay Chawla and Sam Madden and David Dewitt},
	year         = 2018,
	month        = 2,
	journal      = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	pages        = {4720--4728},
	doi          = {10.1109/CVPR.2018.00496},
	isbn         = 9781538664209,
	issn         = 10636919,
	url          = {https://roadmaps.},
	abstract     = {Mapping road networks is currently both expensive and labor-intensive. High-resolution aerial imagery provides a promising avenue to automatically infer a road network. Prior work uses convolutional neural networks (CNNs) to detect which pixels belong to a road (segmentation), and then uses complex post-processing heuristics to infer graph connectivity. We show that these segmentation methods have high error rates because noisy CNN outputs are difficult to correct. We propose RoadTracer, a new method to automatically construct accurate road network maps from aerial images. RoadTracer uses an iterative search process guided by a CNN-based decision function to derive the road network graph directly from the output of the CNN. We compare our approach with a segmentation method on fifteen cities, and find that at a 5\% error rate, RoadTracer correctly captures 45\% more junctions across these cities.}
}
@unpublished{Singh2018,
	title        = {Automatic Secondary Motion with Dynamic Kelvinlets},
	author       = {Jasmeet Singh and Dave Pagurek},
	year         = 2018,
	volume       = {c},
	pages        = {1--7}
}
@article{Dey2018,
	title        = {Procedural feature generation for volumetric terrains using voxel grammars},
	author       = {Rahul Dey and Jason G. Doig and Christos Gatzidis},
	year         = 2018,
	month        = 8,
	journal      = {Entertainment Computing},
	publisher    = {Elsevier B.V.},
	volume       = 27,
	pages        = {128--136},
	doi          = {10.1016/j.entcom.2018.04.003},
	issn         = 18759521,
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S1875952117301349},
	abstract     = {Terrain generation is a fundamental requirement of many computer graphics simulations, including computer games, flight simulators and environments in feature films. There has been a considerable amount of research in this domain, which ranges between fully automated and semi-automated methods. Voxel representations of 3D terrains can create rich features that are not found in other forms of terrain generation techniques, such as caves and overhangs. In this article, we introduce a semi-automated method of generating features for volumetric terrains using a rule-based procedural generation system. Features are generated by selecting subsets of a voxel grid as input symbols to a grammar, composed of user-created operators. This results in overhangs and caves generated from a set of simple rules. The feature generation runs on the CPU and the GPU is utilised to extract a robust mesh from the volumetric dataset.},
	keywords     = {Grammar,Procedural generation,Terrain,Voxels}
}
@article{Norato2034,
	title        = {Topology optimization with supershapes},
	author       = {Juli\'{a}n A. Norato},
	year         = 2018,
	month        = 8,
	journal      = {Structural and Multidisciplinary Optimization},
	volume       = 58,
	pages        = {415--434},
	doi          = {10.1007/s00158-018-2034-z},
	issn         = {1615-147X},
	url          = {http://link.springer.com/10.1007/s00158-018-2034-z},
	abstract     = {This work presents a method for the continuum-based topology optimization of structures whereby the structure is represented by the union of supershapes. Supershapes are an extension of superellipses that can exhibit variable symmetry as well as asymmetry and that can describe through a single equation, the so-called superformula, a wide variety of shapes, including geometric primitives. As demonstrated by the author and his collaborators and by others in previous work, the availability of a feature-based description of the geometry opens the possibility to impose geometric constraints that are otherwise difficult to impose in density-based or level set-based approaches. Moreover, such description lends itself to direct translation to computer aided design systems. This work is an extension of the author's group previous work, where it was desired for the discrete geometric elements that describe the structure to have a fixed shape (but variable dimensions) in order to design structures made of stock material, such as bars and plates. The use of supershapes provides a more general geometry description that, using a single formulation, can render a structure made exclusively of the union of geometric primitives. It is also desirable to retain hallmark advantages of existing methods, namely the ability to employ a fixed grid for the analysis to circumvent re-meshing and the availability of sensitivities to use robust and efficient gradient-based optimization methods. The conduit between the geometric representation of the supershapes and the fixed analysis discretization is, as in previous work, a differentiable geometry projection that maps the supershapes parameters onto a density field. The proposed approach is demonstrated on classical problems of 2-dimensional compliance-based topology optimization.},
	issue        = 2,
	keywords     = {Geometry projection,Superformula,Supershapes,Topology optimization}
}
@article{Argudo2018,
	title        = {Terrain super-resolution through aerial imagery and fully convolutional networks},
	author       = {Oscar Argudo and Antonio Chica and Carlos Andujar},
	year         = 2018,
	journal      = {Computer Graphics Forum},
	volume       = 37,
	pages        = {101--110},
	doi          = {10.1111/cgf.13345},
	issn         = 14678659,
	abstract     = {Despite recent advances in surveying techniques, publicly available Digital Elevation Models (DEMs) of terrains are lowresolution except for selected places on Earth. In this paper we present a new method to turn low-resolution DEMs into plausible and faithful high-resolution terrains. Unlike other approaches for terrain synthesis/amplification (fractal noise, hydraulic and thermal erosion, multi-resolution dictionaries), we benefit from high-resolution aerial images to produce highly-detailed DEMs mimicking the features of the real terrain. We explore different architectures for Fully Convolutional Neural Networks to learn upsampling patterns for DEMs from detailed training sets (high-resolution DEMs and orthophotos), yielding up to one order of magnitude more resolution. Our comparative results show that our method outperforms competing data amplification approaches in terms of elevation accuracy and terrain plausibility.},
	issue        = 2,
	keywords     = {Image processing,Shape modeling}
}
@article{Talgorn2018,
	title        = {Real-time sketch-based terrain generation},
	author       = {Fran\c{c}ois Xavier Talgorn and Far\`{e}s Belhadj},
	year         = 2018,
	journal      = {ACM International Conference Proceeding Series},
	pages        = {13--18},
	doi          = {10.1145/3208159.3208184},
	isbn         = 1595930361,
	url          = {https://www.researchgate.net/profile/Fares-Belhadj/publication/325327322_Real-Time_Sketch-Based_Terrain_Generation/links/6054c4b4a6fdccbfeaf0a8b2/Real-Time-Sketch-Based-Terrain-Generation.pdf},
	abstract     = {We tackle the problem of real-time constrained terrain generation by proposing a new fractal-based GPU model. Our approach allows to control the terrain's topology and aspect both on a global and local scope in a homogeneous manner. Relying on a sequential model of constrained midpoint displacement, we implement its GPU parallelization, improve the quality of results by erasing its artifacts and propose to extend parameterization with the objective of a finer-grained local control over the generated topologies. In order to test this approach, we propose a minimalistic sketch-based terrain editor that highlights the benefits of such a model in terms of instantaneous responsiveness, realism and expressiveness offering new perspectives both in terrain authoring tools and in real-time procedural generation of pseudo-infinite universe.},
	issue        = {March 2021},
	keywords     = {GPU-based algorithm,Real-time terrain generation,Sketch-based interface}
}
@article{Seidel2018,
	title        = {Autonomous tools in system design: Reflective practice in ubisofts ghost recon wildlands project},
	author       = {Stefan Seidel and Nicholas Berente and Beno\^{\i}t Martinez and Aron Lindberg and Kalle Lyytinen and Jeffrey V. Nickerson},
	year         = 2018,
	journal      = {Computer},
	volume       = 51,
	pages        = {16--23},
	doi          = {10.1109/MC.2018.3971341},
	issn         = 15580814,
	abstract     = {Ubisoft's game designers successfully used autonomous tools to develop an innovative virtual world. The authors discuss the reflective practices underlying this success and how autonomous tools enable more complex system design.},
	issue        = 10,
	keywords     = {AI,Ghost Recon Wildlands,Ubisoft,Winning and Losing in IT,artificial intelligence,autonomous tools,design,design processes,game design,machine learning,procedural generation,reflective practice}
}
@article{Cordonnier2018,
	title        = {Interactive generation of time-evolving, snow-covered landscapes with avalanches},
	author       = {Guillaume Cordonnier and Pierre Ecormier-Nocca and \'{E}ric Galin and James Gain and Bed\v{r}ich Bene\v{s} and Marie-Paule Cani},
	year         = 2018,
	journal      = {Computer Graphics Forum},
	volume       = 37,
	pages        = {497--509},
	doi          = {10.1111/cgf.13379},
	issn         = 14678659,
	url          = {https://hal.inria.fr/hal-01736971/file/interactive-generation-time.pdf},
	abstract     = {We introduce a novel method for interactive generation of visually consistent, snow-covered landscapes and provide control of their dynamic evolution over time. Our main contribution is the real-time phenomenological simulation of avalanches and other user-guided events, such as tracks left by Nordic skiing, which can be applied to interactively sculpt the landscape. The terrain is modeled as a height field with additional layers for stable, compacted, unstable, and powdery snow, which behave in combination as a semi-viscous fluid. We incorporate the impact of several phenomena, including sunlight, temperature, prevailing wind direction, and skiing activities. The snow evolution includes snow-melt and snow-drift, which affect stability of the snow mass and the probability of avalanches. A user can shape landscapes and their evolution either with a variety of interactive brushes, or by prescribing events along a winter season time-line. Our optimized GPU-implementation allows interactive updates of snow type and depth across a large (10 \texttimes{} 10km) terrain, including real-time avalanches, making this suitable for visual assets in computer games. We evaluate our method through perceptual comparison against exiting methods and real snow-depth data.},
	issue        = 2,
	keywords     = {Computing methodologies \rightarrow{} Shape modeling,Human-centered computing \rightarrow{} Interaction techniques}
}
@article{Garrote2018,
	title        = {HMAPs - Hybrid Height- Voxel Maps for Environment Representation},
	author       = {Luis Garrote and Cristiano Premebida and David Silva and Urbano J. Nunes},
	year         = 2018,
	journal      = {IEEE International Conference on Intelligent Robots and Systems},
	pages        = {1197--1203},
	doi          = {10.1109/IROS.2018.8594113},
	isbn         = 9781538680940,
	issn         = 21530866,
	url          = {http://home.isr.uc.pt/~cpremebida/files_cp/HMAPs_Hybrid Height Voxel Maps for Environment Representation.pdf},
	abstract     = {This paper presents a hybrid 3D-like grid-based mapping approach, that we called HMAP, used as a reliable and efficient 3D representation of the environment surrounding a mobile robot. Considering 3D point-clouds as input data, the proposed mapping approach addresses the representation of height-voxel (HVoxel) elements inside the HMAP, where free and occupied space is modeled through HVoxels, resulting in a reliable method for 3D representation. The proposed method corrects some of the problems inherent to the representation of complex environments based on 2D and 2.5D representations, while keeping an updated grid representation. Additionally, we also propose a complete pipeline for SLAM based on HMAPs. Indoor and outdoor experiments were carried out to validate the proposed representation using data from a Microsoft Kinect One (indoor) and a Velodyne VLP-16 LiDAR (outdoor). The obtained results show that HMAPs can provide a more detailed view of complex elements in a scene when compared to a classic 2.5D representation. Moreover, validation of the proposed SLAM approach was carried out in an outdoor dataset with promising results, which lay a foundation for further research in the topic.}
}
@article{Pedoja2019,
	title        = {On the long-lasting sequences of coral reef terraces from SE Sulawesi (Indonesia): Distribution, formation, and global significance},
	author       = {Kevin Pedoja and Laurent Husson and Antoine Bezos and Anne-Morwenn Pastier and Andy Muhammad Imran and Camilo Arias-Ruiz and Anta-Clarisse Sarr and Mary Elliot and Edwige Pons-Branchu and Ma\"{e}lle Nexer and Vincent Regard and Abdul Hafidz and Xavier Robert and Laurent Benoit and Bernard Delcaillau and Christine Authemayou and Caroline Dumoulin and Ga\"{e}l Choblet},
	year         = 2018,
	month        = 5,
	journal      = {Quaternary Science Reviews},
	volume       = 188,
	pages        = {37--57},
	doi          = {10.1016/j.quascirev.2018.03.033},
	issn         = {02773791},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0277379117309824}
}
@article{Johnson2018,
	title        = {On the rise and fall of oceanic islands : Towards a global theory following the pioneering studies of Charles Darwin and James Dwight Dana},
	author       = {Markes E Johnson and B Gudveig Baarli and M\'{a}rio Cach\~{a}o and Eduardo Mayoral and Ricardo S Ramalho and Ana Santos and Carlos M da Silva},
	year         = 2018,
	journal      = {Earth-Science Reviews},
	publisher    = {Elsevier},
	volume       = 180,
	pages        = {17--36},
	doi          = {10.1016/j.earscirev.2018.03.008},
	issn         = {0012-8252},
	url          = {https://doi.org/10.1016/j.earscirev.2018.03.008},
	issue        = {November 2017},
	keywords     = {Carbonate deposits (rhodoliths and corals),Coastal geomorphology,Oceanic islands,Subsidence,Unconformities,Uplift}
}
@article{Purkis2018,
	title        = {Remote sensing tropical coral reefs: The view from above},
	author       = {Sam J. Purkis},
	year         = 2018,
	journal      = {Annual Review of Marine Science},
	volume       = 10,
	pages        = {149--168},
	doi          = {10.1146/annurev-marine-121916-063249},
	issn         = 19410611,
	abstract     = {Carbonate precipitation has been a common life strategy for marine organisms for 3.7 billion years, as, therefore, has their construction of reefs. As favored by modern corals, reef-forming organisms have typically adopted a niche in warm, shallow, well-lit, tropical marine waters, where they are capable of building vast carbonate edifices. Because fossil reefs form water aquifers and hydrocarbon reservoirs, considerable effort has been dedicated to understanding their anatomy and morphology. Remote sensing has a particular role to play here. Interpretation of satellite images has done much to reveal the grand spatial and temporal tapestry of tropical reefs. Comparative sedimentology, whereby modern environments are contrasted with the rock record to improve interpretation, has been particularly transformed by observations made from orbit. Satellite mapping has also become a keystone technology to quantify the coral reef crisis - it can be deployed not only directly to quantify the distribution of coral communities, but also indirectly to establish a climatology for their physical environment. This article reviews the application of remote sensing to tropical coralgal reefs in order to communicate how this fast-growing technology might be central to addressing the coral reef crisis and to look ahead at future developments in the science.},
	issue        = {August},
	keywords     = {carbonate reefs,climate change,remote sensing},
	pmid         = 28793810
}
@article{Gao2018,
	title        = {Animating fluid sediment mixture in particle-laden flows},
	author       = {Ming Gao and Andre Pradhana and Xuchen Han and Qi Guo and Grant Kot and Eftychios Sifakis and Chenfanfu Jiang},
	year         = 2018,
	journal      = {ACM Transactions on Graphics},
	volume       = 37,
	doi          = {10.1145/3197517.3201309},
	issn         = 15577368,
	abstract     = {In this paper, we present a mixed explicit and semi-implicit Material Point Method for simulating particle-laden flows. We develop a Multigrid Preconditioned fluid solver for the Locally Averaged Navier Stokes equation. This is discretized purely on a semi-staggered standard MPM grid. Sedimentation is modeled with the Drucker-Prager elastoplasticity flow rule, enhanced by a novel particle density estimation method for converting particles between representations of either continuum or discrete points. Fluid and sediment are two-way coupled through a momentum exchange force that can be easily resolved with two MPM background grids. We present various results to demonstrate the efficacy of our method.},
	issue        = 4,
	keywords     = {Material point method (MPM),Multiphase,Particlefluid interaction,Sediment transport,Sedimentation}
}
@article{Bansal2018,
	title        = {Emergent complexity via multi-agent competition},
	author       = {Trapit Bansal and Jakub Pachocki and Szymon Sidor and Ilya Sutskever and Igor Mordatch},
	year         = 2018,
	journal      = {6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings},
	volume       = 2,
	pages        = {1--12},
	abstract     = {Reinforcement learning algorithms can train agents that solve problems in complex, interesting environments. Normally, the complexity of the trained agent is closely related to the complexity of the environment. This suggests that a highly capable agent requires a complex environment for training. In this paper, we point out that a competitive multi-agent environment trained with self-play can produce behaviors that are far more complex than the environment itself. We also point out that such environments come with a natural curriculum, because for any skill level, an environment full of agents of this level will have the right level of difficulty. This work introduces several competitive multi-agent environments where agents compete in a 3D world with simulated physics. The trained agents learn a wide variety of complex and interesting skills, even though the environment themselves are relatively simple. The skills include behaviors such as running, blocking, ducking, tackling, fooling opponents, kicking, and defending using both arms and legs. A highlight of the learned behaviors can be found here: https://goo.gl/eR7fbX.}
}
@article{Shaw2018,
	title        = {Island Formation Resulting From Radially Symmetric Flow Expansion},
	author       = {John B. Shaw and Kimberly Miller and Brandon McElroy},
	year         = 2018,
	journal      = {Journal of Geophysical Research: Earth Surface},
	volume       = 123,
	pages        = {363--383},
	doi          = {10.1002/2017JF004464},
	issn         = 21699011,
	abstract     = {Island formation and distributary channel branching are important processes in prograding river deltas. We develop and test a new theory predicting the distance to islands and channel bifurcations based on fluid mass conservation and radially symmetric transport conditions. We analyze channelization and island formation using nine new and five existing delta experiments as well as four field deltas. The new experiments were designed to produce islands from initial deposition of a mouth bar. Before island formation, each bar evolved into a radially symmetric deposit with unchannelized flow over its top previously described as a topographic flow expansion. This morphology was stable to topographic perturbations, and its distal limit prograded basinward while maintaining a characteristic flow depth. Island formation and channel branching occurred on top of this deposit. We hypothesize that this distance (\ensuremath{\Psi}) is set by the location where boundary shear stress applied by expanding, radially averaged flow falls below the threshold of sediment motion. The model predicts that the distance to the first island scales with water discharge, scales inversely with flow depth, and scales with the inverse square root of median grain diameter. From experiment to field scales, distances to island locations are predicted within a factor of two.},
	issue        = 2,
	keywords     = {coast,delta,flow expansion,island,jet,mouth bar}
}
@article{JohnsonGupta2018,
	title        = {Image Generation from Scene Graphs},
	author       = {Justin Johnson and Agrim Gupta and Li Fei-Fei},
	year         = 2018,
	journal      = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	pages        = {1219--1228},
	doi          = {10.1109/CVPR.2018.00133},
	isbn         = 9781538664209,
	issn         = 10636919,
	url          = {https://arxiv.org/pdf/1804.01622.pdf},
	abstract     = {To truly understand the visual world our models should be able not only to recognize images but also generate them. To this end, there has been exciting recent progress on generating images from natural language descriptions. These methods give stunning results on limited domains such as descriptions of birds or flowers, but struggle to faithfully reproduce complex sentences with many objects and relationships. To overcome this limitation we propose a method for generating images from scene graphs, enabling explicitly reasoning about objects and their relationships. Our model uses graph convolution to process input graphs, computes a scene layout by predicting bounding boxes and segmentation masks for objects, and converts the layout to an image with a cascaded refinement network. The network is trained adversarially against a pair of discriminators to ensure realistic outputs. We validate our approach on Visual Genome and COCO-Stuff, where qualitative results, ablations, and user studies demonstrate our method's ability to generate complex images with multiple objects.}
}
@article{Li2018,
	title        = {Physically-Based Algorithm for Natural Rime Growth Simulation},
	author       = {Ye Li and Meng Yang and Gang Yang},
	year         = 2018,
	journal      = {Proceedings - 8th International Conference on Virtual Reality and Visualization, ICVRV 2018},
	pages        = {70--73},
	doi          = {10.1109/ICVRV.2018.00021},
	isbn         = 9781538684979,
	abstract     = {In order to show a common natural landscape in winter, the charm of rime, an algorithm for rime growth simulation based on a physical approach is proposed in this paper. This algorithm mainly simulates two main kinds of rimes' growth, especially their morphology and direction, under the condition of surrounding factors, including the air pressure, temperature and wind. Firstly, this algorithm calculates the length of rime by using the icing conductor model which is established according to fluid mechanics and thermodynamic principles, a fractal method is introduced into our algorithm to simulate the morphology of the crystalline rime, and a segmentation method is for the simulation of the needle-like rime's morphology; After that, wind field is simulated by adopting the function of Perlin Noise. Finally, it analyzes the offset details of the rime growth in the wind according to its material mechanics knowledge. The wind force is used to calculate the deviation of rime. Experimental results show us that our algorithm in this paper can simulate two kinds of rime realistically, effectively and efficiently.},
	keywords     = {crystalline rime,growth simulation,needlelike rime,physical approach}
}
@inproceedings{DiasFernandes2018,
	title        = {Space Colonisation for Procedural Road Generation},
	author       = {Gabriel Dias Fernandes and Antonio Ramires Fernandes},
	year         = 2018,
	month        = 11,
	booktitle    = {2018 International Conference on Graphics and Interaction (ICGI)},
	publisher    = {IEEE},
	pages        = {1--8},
	doi          = {10.1109/ITCGI.2018.8602928},
	isbn         = {978-1-5386-8228-9},
	url          = {https://ieeexplore.ieee.org/document/8602928/},
	issue        = 1
}
@article{Nikeghabali2018,
	title        = {Application of the SPH Method to Breaking and Undular Tidal Bores on a Movable Bed},
	author       = {Pooyan Nikeghbali and Pourya Omidvar},
	year         = 2018,
	journal      = {Journal of Waterway, Port, Coastal, and Ocean Engineering},
	volume       = 144,
	doi          = {10.1061/(asce)ww.1943-5460.0000424},
	isbn         = 7184645634,
	issn         = {0733-950X},
	abstract     = {Investigation of breaking and undular tidal bores is a challenging problem in river mouths as fluid flows upstream, where significant bed erosion and scour take place under the bore. In this study, smoothed particle hydrodynamics (SPH) was used to simulate the breaking and undular tidal bores on a movable bed. To model the bores, a moving gate was used to block a steady uniform flow in a channel, and bores were consequently generated as a positive surge and propagated upstream. First, results were presented for the breaking and undular bores on a flat bed, looking carefully at velocity and surface profiles, which were compared with available experimental data. Then, the breaking and undular bores were tested in a channel with a movable bed using a previous experimental study of particle motion. The authors show the morphology changes of the bed under the breaking and undular bore. The results show that the SPH method can be successfully used to investigate the dynamics of the tidal bore and its effects on a movable bed.},
	issue        = 2
}
@inproceedings{Sahbaei2018,
	title        = {Implicit representation of inscribed volumes},
	author       = {Parto Sahbaei and David Mould and Brian Wyvill},
	year         = 2018,
	month        = 8,
	booktitle    = {Proceedings of the Joint Symposium on Computational Aesthetics and Sketch-Based Interfaces and Modeling and Non-Photorealistic Animation and Rendering},
	publisher    = {ACM},
	pages        = {1--7},
	doi          = {10.1145/3229147.3229164},
	isbn         = 9781450358927,
	url          = {https://dl.acm.org/doi/10.1145/3229147.3229164},
	abstract     = {Title from content provider. The Expressive conference series was born out of three workshops; CAe - Computational Aesthetics, SBIM - Sketch Based Interfaces Modelling and animation and NPAR - Non-Photo Realistic Animation and Rendering. The amalgamation has brought together artists, scientists, researchers and practitioners to showcase cutting-edge research and artistic innovation in these disciplines. We are jointly sponsored by Eurographics and ACM SIGGRAPH and are grateful for a generous donation from Disney Research. The conference is now in the fourteenth year of running under the Expressive banner.},
	city         = {New York, NY, USA}
}
@article{Uchida2018,
	title        = {Numerical investigation of terrain-induced turbulence in complex terrain by Large-Eddy Simulation (LES) technique},
	author       = {Takanori Uchida},
	year         = 2018,
	month        = 10,
	journal      = {Energies},
	publisher    = {MDPI AG},
	volume       = 11,
	doi          = {10.3390/en11102638},
	issn         = 19961073,
	abstract     = {In the present study, field observation wind data from the time of the wind turbine blade damage accident on Shiratakiyama Wind Farm were analyzed in detail. In parallel, high-resolution large-eddy simulation (LES) turbulence simulations were performed in order to examine the model's ability to numerically reproduce terrain-induced turbulence (turbulence intensity) under strong wind conditions (8.0–9.0 m/s at wind turbine hub height). Since the wind velocity and time acquired from the numerical simulation are dimensionless, they are converted to full scale. As a consequence, both the standard deviation of the horizontal wind speed (m/s) and turbulence intensity evaluated from the field observation and simulated wind data are successfully in close agreement. To investigate the cause of the wind turbine blade damage accident on Shiratakiyama Wind Farm, a power spectral analysis was performed on the fluctuating components of the observed time series data of wind speed (1 s average values) for a 10 min period (total of 600 data) by using a fast Fourier transform (FFT). It was suggested that the terrain-induced turbulence which caused the wind turbine blade damage accident on Shiratakiyama Wind Farm was attributable to rapid wind speed and direction fluctuations which were caused by vortex shedding from Tenjogadake (elevation: 691.1 m) located upstream of the wind farm.},
	issue        = 10,
	keywords     = {Complex terrain,LES,Terrain-induced turbulence,Turbulence intensity,Vortex shedding}
}
@inproceedings{DoNascimento2018,
	title        = {GPU-Based Real-Time Procedural Distribution of Vegetation on Large-Scale Virtual Terrains},
	author       = {Bruno Torres Do Nascimento and Flavio Paulus Franzin and Cesar Tadeu Pozzer},
	year         = 2018,
	month        = 7,
	booktitle    = {Brazilian Symposium on Games and Digital Entertainment, SBGAMES},
	publisher    = {IEEE Computer Society},
	volume       = {2018-November},
	pages        = {157--166},
	doi          = {10.1109/SBGAMES.2018.00027},
	isbn         = 9781538677698,
	issn         = 21596662,
	abstract     = {We present a novel framework for real-time procedural distribution of vegetation, capable of handling large-scale terrains. Our approach considers several natural aspects that influence the adaptability of each plant type to topographic and environmental factors displayed across the terrain, as well as interactions between different plant types. The adaptability of each plant type is modeled through a set of consistent parameters that afford full control to the user over the final results of the distribution process. The proposed architecture relies on GPU parallelization and GPU instancing to improve performance. Our framework can be used to generate the vegetation cover of a terrain at runtime or to create an initial distribution that could latter be manually edited, expediting the process of decorating large environments. The results show that our framework can achieve natural looking vegetation distributions, while maintaining the computational costs compatible with realtime applications.},
	keywords     = {GPU-based,Large scale,Procedural,Real-time,Vegetation distribution,Virtual terrains}
}
@article{Tomlinson2019,
	title        = {Immersive Three-Dimensional Modeling and Virtual Reality for Enhanced Visualization of Operative Neurosurgical Anatomy},
	author       = {Samuel B. Tomlinson and Benjamin K. Hendricks and Aaron Cohen-Gadol},
	year         = 2019,
	month        = 11,
	journal      = {World Neurosurgery},
	publisher    = {Elsevier Inc.},
	volume       = 131,
	pages        = {313--320},
	doi          = {10.1016/j.wneu.2019.06.081},
	issn         = 18788769,
	abstract     = {Learning the endless intricacies of operative neurosurgical anatomy requires that surgeons complement their intraoperative experiences with a variety of educational resources. In the past 2 decades, rapid improvements in digital graphics and computing power have enabled a new generation of 3-dimensional (3D) virtual resources that overcome limitations of more traditional 2-dimensional materials. Today, dozens of immersive 3D visualization platforms exist for applications such as learning neuroanatomy, simulating operative techniques, and planning surgical interventions with patient-specific models. The purpose of this article is to identify current applications of 3D digital modeling and virtual reality in neurosurgery. In addition, we showcase a new series of freely available 3D virtual-reality models created to assist in learning complex cranial anatomy. We anticipate these models to have a wide range of educational, clinical, and research applications. Three-dimensional visualization is poised to modernize the ways we learn and teach neurosurgical anatomy outside of the operating room. Future generations of neurosurgeons are expected to benefit from these technologies from the earliest stages of training.},
	keywords     = {3D,Operative anatomy,Resident education,The Neurosurgical Atlas,Virtual reality},
	pmid         = 31658575
}
@article{Wang_a_2019,
	title        = {A Vision of Bringing Immersive Visualization to Scientific Workflows},
	author       = {Xiyao Wang and Lonni Besan\c{c}on and Florimond Gu\'{e}niat and Mickael Sereno and Mehdi Ammi and Tobias Isenberg},
	year         = 2019,
	journal      = {The ACM CHI Conference on Human Factors in Computing Systems - Workshop on Interaction Design \& Prototyping for Immersive Analytics},
	url          = {https://hal.archives-ouvertes.fr/hal-02053969}
}
@article{Yang2019,
	title        = {Enhancing Quality for HEVC Compressed Videos},
	author       = {Ren Yang and Mai Xu and Tie Liu and Zulin Wang and Zhenyu Guan},
	year         = 2019,
	journal      = {IEEE Transactions on Circuits and Systems for Video Technology},
	publisher    = {IEEE},
	volume       = 29,
	pages        = {2039--2054},
	doi          = {10.1109/TCSVT.2018.2867568},
	issn         = 10518215,
	abstract     = {The latest High Efficiency Video Coding (HEVC) standard has been increasingly applied to generate video streams over the Internet. However, HEVC compressed videos may incur severe quality degradation, particularly at low bit rates. Thus, it is necessary to enhance the visual quality of HEVC videos at the decoder side. To this end, this paper proposes a quality enhancement convolutional neural network (QE-CNN) method that does not require any modification of the encoder to achieve quality enhancement for HEVC. In particular, our QE-CNN method learns QE-CNN-I and QE-CNN-P models to reduce the distortion of HEVC I and P/B frames, respectively. The proposed method differs from the existing CNN-based quality enhancement approaches, which only handle intra-coding distortion and are thus not suitable for P/B frames. Our experimental results validate that our QE-CNN method is effective in enhancing quality for both I and P/B frames of HEVC videos. To apply our QE-CNN method in time-constrained scenarios, we further propose a time-constrained quality enhancement optimization (TQEO) scheme. Our TQEO scheme controls the computational time of QE-CNN to meet a target, meanwhile maximizing the quality enhancement. Next, the experimental results demonstrate the effectiveness of our TQEO scheme from the aspects of time control accuracy and quality enhancement under different time constraints. Finally, we design a prototype to implement our TQEO scheme in a real-time scenario.},
	issue        = 7,
	keywords     = {HEVC,convolutional neural network,quality enhancement}
}
@article{Ghadiyaram2019,
	title        = {Large-scale weakly-supervised pre-training for video action recognition},
	author       = {Deepti Ghadiyaram and Matt Feiszli and Du Tran and Xueting Yan and Heng Wang and Dhruv Mahajan},
	year         = 2019,
	month        = 5,
	url          = {http://arxiv.org/abs/1905.00561},
	abstract     = {Current fully-supervised video datasets consist of only a few hundred thousand videos and fewer than a thousand domain-specific labels. This hinders the progress towards advanced video architectures. This paper presents an in-depth study of using large volumes of web videos for pre-training video models for the task of action recognition. Our primary empirical finding is that pre-training at a very large scale (over 65 million videos), despite on noisy social-media videos and hashtags, substantially improves the state-of-the-art on three challenging public action recognition datasets. Further, we examine three questions in the construction of weakly-supervised video action datasets. First, given that actions involve interactions with objects, how should one construct a verb-object pre-training label space to benefit transfer learning the most? Second, frame-based models perform quite well on action recognition; is pre-training for good image features sufficient or is pre-training for spatio-temporal features valuable for optimal transfer learning? Finally, actions are generally less well-localized in long videos vs. short videos; since action labels are provided at a video level, how should one choose video clips for best performance, given some fixed budget of number or minutes of videos?}
}
@article{Martinez,
	title        = {Action recognition with spatial-temporal discriminative filter banks},
	author       = {Brais Martinez and Davide Modolo and Yuanjun Xiong and Joseph Tighe},
	year         = 2019,
	month        = 8,
	url          = {http://arxiv.org/abs/1908.07625},
	abstract     = {Action recognition has seen a dramatic performance improvement in the last few years. Most of the current state-of-the-art literature either aims at improving performance through changes to the backbone CNN network, or they explore different trade-offs between computational efficiency and performance, again through altering the backbone network. However, almost all of these works maintain the same last layers of the network, which simply consist of a global average pooling followed by a fully connected layer. In this work we focus on how to improve the representation capacity of the network, but rather than altering the backbone, we focus on improving the last layers of the network, where changes have low impact in terms of computational cost. In particular, we show that current architectures have poor sensitivity to finer details and we exploit recent advances in the fine-grained recognition literature to improve our model in this aspect. With the proposed approach, we obtain state-of-the-art performance on Kinetics-400 and Something-Something-V1, the two major large-scale action recognition benchmarks.}
}
@article{Jayadevan2019,
	title        = {Skeleton Extraction from 3D Point Clouds by Decomposing the Object into Parts},
	author       = {Vijai Jayadevan and Edward Delp and Zygmunt Pizlo},
	year         = 2019,
	month        = 12,
	journal      = {arXiv},
	publisher    = {arXiv},
	url          = {http://arxiv.org/abs/1912.11932},
	abstract     = {Decomposing a point cloud into its components and extracting curve skeletons from point clouds are two related problems. Decomposition of a shape into its components is often obtained as a byproduct of skeleton extraction. In this work, we propose to extract curve skeletons, from unorganized point clouds, by decomposing the object into its parts, identifying part skeletons and then linking these part skeletons together to obtain the complete skeleton. We believe it is the most natural way to extract skeletons in the sense that this would be the way a human would approach the problem. Our parts are generalized cylinders (GCs). Since, the axis of a GC is an integral part of its definition, the parts have natural skeletal representations. We use translational symmetry, the fundamental property of GCs, to extract parts from point clouds. We demonstrate how this method can handle a large variety of shapes. We compare our method with state of the art methods and show how a part based approach can deal with some of the limitations of other methods. We present an improved version of an existing point set registration algorithm and demonstrate its utility in extracting parts from point clouds. We also show how this method can be used to extract skeletons from and identify parts of noisy point clouds. A part based approach also provides a natural and intuitive interface for user interaction. We demonstrate the ease with which mistakes, if any, can be fixed with minimal user interaction with the help of a graphical user interface.},
	keywords     = {3D object segmentation,3D point clouds,3D shape decomposition,Curve skeleton extraction,Translational symmetry,registration}
}
@techreport{Yang2019a,
	title        = {Rapport de Stage Simulateur temps r\'{e}el 3D de fonds marins pour la robotique},
	author       = {Chen Yang},
	year         = 2019,
	institution  = {LIRMM}
}
@article{Dam2019,
	title        = {Terrain Generation Based on Real World Locations for Military Training and Simulation},
	author       = {Peter Dam and Fernanda Duarte and Alberto Raposo},
	year         = 2019,
	journal      = {Brazilian Symposium on Games and Digital Entertainment, SBGAMES},
	publisher    = {IEEE},
	volume       = {2019-Octob},
	pages        = {173--181},
	doi          = {10.1109/SBGames.2019.00031},
	isbn         = 9781728146379,
	issn         = 21596662,
	abstract     = {The task of recreating a real world location in a virtual environment is never easy, and a high degree of similarity is crucial for specialized training and simulation sessions, which are becoming ever more employed in the military to improve training methods. Allowing the users to recognize the location in the virtual environment through the use of real maps, for example, increases user engagement, helping to increase the overall quality of the training session. One factor that must be accounted for is the availability of data to perform the creation of these virtual environments, especially in locations such as areas with low population density or small cities in South America. In this paper we present a method to enable the creation, with limited data availability, of a very large, high quality, and optimized environment for ground-level simulations using Unity 3D, one of the current state of the art game engines.},
	keywords     = {real world,serious games,simulation,terrain generation,training,virtual environment}
}
@article{Argudo2019,
	title        = {Orometry-based terrain analysis and synthesis},
	author       = {Oscar Argudo and Eric Galin and Adrien Peytavie and Axel Paris and James Gain and Eric Gu\'{e}rin},
	year         = 2019,
	month        = 12,
	journal      = {ACM Transactions on Graphics},
	volume       = 38,
	pages        = {1--12},
	doi          = {10.1145/3355089.3356535},
	issn         = {0730-0301},
	url          = {https://dl.acm.org/doi/10.1145/3355089.3356535},
	abstract     = {<p>Mountainous digital terrains are an important element of many virtual environments and find application in games, film, simulation and training. Unfortunately, while existing synthesis methods produce locally plausible results they often fail to respect global structure. This is exacerbated by a dearth of automated metrics for assessing terrain properties at a macro level.</p>},
	issue        = 6
}
@article{Galin2019,
	title        = {A Review of Digital Terrain Modeling},
	author       = {Eric Galin and Eric Gu\'{e}rin and Adrien Peytavie and Guillaume Cordonnier and Marie-Paule Cani and Bedrich Benes and James Gain},
	year         = 2019,
	month        = 5,
	journal      = {Computer Graphics Forum},
	volume       = 38,
	pages        = {553--577},
	doi          = {10.1111/cgf.13657},
	issn         = {0167-7055},
	url          = {https://onlinelibrary.wiley.com/doi/10.1111/cgf.13657},
	abstract     = {<p>Terrains are a crucial component of three-dimensional scenes and are present in many Computer Graphics applications. Terrain modeling methods focus on capturing landforms in all their intricate detail, including eroded valleys arising from the interplay of varied phenomena, dendritic mountain ranges, and complex river networks. Set against this visual complexity is the need for user control over terrain features, without which designers are unable to adequately express their artistic intent. This article provides an overview of current terrain modeling and authoring techniques, organized according to three categories: procedural modeling, physically-based simulation of erosion and land formation processes, and example-based methods driven by scanned terrain data. We compare and contrast these techniques according to several criteria, specifically: the variety of achievable landforms; realism from both a perceptual and geomorphological perspective; issues of scale in terms of terrain extent and sampling precision; the different interaction metaphors and attendant forms of user-control, and computation and memory performance. We conclude with an in-depth discussion of possible research directions and outstanding technical and scientific challenges.</p>},
	issue        = 2
}
@article{Peytavie2019,
	title        = {Procedural Riverscapes},
	author       = {Adrien Peytavie and Thibault Dupont and \'{E}ric Gu\'{e}rin and Yann Cortial and Bedrich Benes and James Gain and \'{E}ric Galin},
	year         = 2019,
	month        = 10,
	journal      = {Computer Graphics Forum},
	volume       = 38,
	pages        = {35--46},
	doi          = {10.1111/cgf.13814},
	issn         = {0167-7055},
	url          = {https://onlinelibrary.wiley.com/doi/10.1111/cgf.13814},
	abstract     = {<p>This paper addresses the problem of creating animated riverscapes through a novel procedural framework that generates the inscribing geometry of a river network and then synthesizes matching real-time water movement animation. Our approach takes bare-earth heightfields as input, derives hydrologically-inspired river network trajectories, carves riverbeds into the terrain, and then automatically generates a corresponding blend-flow tree for the water surface. Characteristics, such as the riverbed width, depth and shape, as well as elevation and flow of the fluid surface, are procedurally derived from the terrain and river type. The riverbed is inscribed by combining compactly supported elevation modifiers over the river course. Subsequently, the water surface is defined as a time-varying continuous function encoded as a blend-flow tree with leaves that are parameterized procedural flow primitives and internal nodes that are blend operators. While river generation is fully automated, we also incorporate intuitive interactive editing of both river trajectories and individual riverbed and flow primitives. The resulting framework enables the generation of a wide range of river forms, ranging from slow meandering rivers to rapids with churning water, including surface effects, such as foam and leaves carried downstream.</p>},
	issue        = 7
}
@article{Paris2019a,
	title        = {Terrain Amplification with Implicit 3D Features},
	author       = {Axel Paris and Eric Galin and Adrien Peytavie and Eric Gu\'{e}rin and James Gain},
	year         = 2019,
	month        = 10,
	journal      = {ACM Transactions on Graphics},
	volume       = 38,
	pages        = {1--15},
	doi          = {10.1145/3342765},
	issn         = {0730-0301},
	url          = {https://dl.acm.org/doi/10.1145/3342765},
	abstract     = {<p>While three-dimensional landforms, such as arches and overhangs, occupy a relatively small proportion of most computer-generated landscapes, they are distinctive and dramatic and have an outsize visual impact. Unfortunately, the dominant heightfield representation of terrain precludes such features, and existing in-memory volumetric structures are too memory intensive to handle larger scenes.</p>},
	issue        = 5
}
@article{Paris2019b,
	title        = {Desertscape Simulation},
	author       = {Axel Paris and Adrien Peytavie and \'{E}ric Gu\'{e}rin and Oscar Argudo and \'{E}ric Galin},
	year         = 2019,
	month        = 10,
	journal      = {Computer Graphics Forum},
	volume       = 38,
	pages        = {47--55},
	doi          = {10.1111/cgf.13815},
	issn         = {0167-7055},
	url          = {https://onlinelibrary.wiley.com/doi/10.1111/cgf.13815},
	abstract     = {<p>We present an interactive aeolian simulation to author hot desert scenery. Wind is an important erosion agent in deserts which, despite its importance, has been neglected in computer graphics. Our framework overcomes this and allows generating a variety of sand dunes, including barchans, longitudinal and anchored dunes, and simulates abrasion which erodes bedrock and sculpts complex landforms. Given an input time varying high altitude wind field, we compute the wind field at the surface of the terrain according to the relief, and simulate the transport of sand blown by the wind. The user can interactively model complex desert landscapes, and control their evolution throughout time either by using a variety of interactive brushes or by prescribing events along a user-defined time-line.</p>},
	issue        = 7,
	keywords     = {aeolian erosion,desert,procedural modeling,sand dune simulation}
}
@article{Marchand2019,
	title        = {Optimisation du traitement de nuage de points pour la production de plan de fa\c{c}ade au sein d'un cabinet de g\'{e}om\`{e}tre-expert},
	author       = {Maxime Marchand},
	year         = 2019
}
@article{Lachat2019a,
	title        = {Relev\'{e} et consolidation de nuages de points issus de multiples capteurs pour la num\'{e}risation 3D du patrimoine},
	author       = {Elise Lachat},
	year         = 2019,
	journal      = {Traitement du signal et de l'image},
	pages        = 330
}
@article{Seidel2019,
	title        = {Designing with Autonomous Tools: Video Games, Procedural Generation, and Creativity},
	author       = {Stefan Seidel and Nicholas Berente and John Gibbs and Stefan Seidel and John Gibbs},
	year         = 2019,
	journal      = {ICIS Proceedings}
}
@phdthesis{Bayer2019,
	title        = {Triplanar Displacement Mapping for Terrain Rendering},
	author       = {Florian Bayer},
	year         = 2019,
	pages        = {1985--1989},
	abstract     = {For the past few decades, relational databases have been the default choice for data storage, especially for enterprise applications. Currently, many other database technologies are grabbing more attention due to their high performance, scalability, and availability options, such as Not Only SQL (NoSQL) technologies. Choosing the right database technology for applications among a plethora of database options is a challenging task. This research aims to provide a systematic and experimental evaluation of four NoSQL databases across the spectrum of different NoSQL categories. The investigated databases are Redis, MongoDB, Neo4j, and Cassandra. We study multiple aspects such as the database transaction support, query options, data layout, scalability, availability, security, and durability. Besides, we analyze the data modelling of each database using a data model from the Transaction Processing Council Ad-hoc (TPCH) benchmark. Furthermore, we evaluate the query capabilities of each database using three complex queries from the same benchmark. Based on the examination, we capture the strengths and weaknesses each database has. Finally, we present a set of factors that influence the adoption of a NoSQL solution. These factors assist software architects and developers to choose the proper database technology for their specific application needs.},
	institution  = {Technische Universitat Munchen}
}
@article{DeGoes2019,
	title        = {Sharp kelvinlets: Elastic deformations with cusps and localized falloffs},
	author       = {Fernando De Goes and Doug L. James},
	year         = 2019,
	journal      = {Proceedings - DigiPro 2019: ACM Digital Production Symposium},
	doi          = {10.1145/3329715.3338884},
	isbn         = 9781450367998,
	abstract     = {In this work, we present an extension of the regularized Kelvinlet technique suited to non-smooth, cusp-like edits. Our approach is based on a novel multi-scale convolution scheme that layers Kelvinlet deformations into a finite but spiky solution, thus offering physically based volume sculpting with sharp falloff profiles. We also show that the Laplacian operator provides a simple and effective way to achieve elastic displacements with fast far-field decay, thereby avoiding the need for multi-scale extrapolation. Finally, we combine the multi-scale convolution and Laplacian machinery to produce Sharp Kelvinlets, a new family of analytic fundamental solutions of linear elasticity with control over both the locality and the spikiness of the brush profile. Closed-form expressions and reference implementation are also provided.},
	keywords     = {Linear elasticity,Profile control,Regularized kelvinlets,Sculpting brushes}
}
@inbook{OswaldoValencia-Rosado2019,
	title        = {Methods for Procedural Terrain Generation: A Review},
	author       = {Luis Oswaldo Valencia-Rosado and Oleg Starostenko},
	year         = 2019,
	pages        = {58--67},
	doi          = {10.1007/978-3-030-21077-9_6},
	url          = {https://link.springer.com/10.1007/978-3-030-21077-9_6},
	abstract     = {Advances in computer graphics allow to simulate ever growing virtual worlds with a higher level of realism which can even be created in real time. An integral part of these worlds are the terrains which are the physical features of the land. Despite the capabilities of modern computer systems, the creation process still demands high amounts of man-hours. To automatically generate coherent, realistic-looking and useful content is still and open problem, and research focuses on how to automatize these processes while allowing users to exert a certain degree on control over the generated content. This survey goes over the different techniques used for the automatic generation of terrains, which include different land formations such as mountains, valleys, rivers, shores, etc. These terrains have different uses such as simulation or entertainment which translates on different needs over the desired realism of the terrain and the degree of control that users have. Through time, different approaches have been proposed: repeating patterns that resemble those seen in nature; using software agents that imitate geological processes; using artificial intelligence techniques for pattern recognition and imitation of landscapes; or allowing users to interact with the system to draw desired terrain features. This review presents an overview of the area and discusses how different techniques adapt to the different needs and different stages of terrain creation.},
	keywords     = {Automatic,Landscape,Simulation,Videogames,Virtual}
}
@article{Zhao2019,
	title        = {Multi-theme generative adversarial terrain amplification},
	author       = {Yiwei Zhao and Han Liu and Igor Borovikov and Ahmad Beirami and Maziar Sanjabi and Kazi Zaman},
	year         = 2019,
	journal      = {ACM Transactions on Graphics},
	volume       = 38,
	doi          = {10.1145/3355089.3356553},
	issn         = 15577368,
	url          = {https://dl.acm.org/doi/pdf/10.1145/3355089.3356553},
	note         = {Se compare directement aux r\'{e}sultats produits par <br/><br/>Eric Gu\'{e}rin, Julie Digne, Eric Galin, Adrien Peytavie, ChristianWolf, Bedrich Benes, and Beno\^{\i}t Martinez. 2017. Interactive example-based terrain authoring with conditional generative adversarial networks. ACMTransactions on Graphics (TOG) 36, 6 (2017)<br/><br/>Produit de bien meilleurs r\'{e}sultats.},
	abstract     = {Achieving highly detailed terrain models spanning vast areas is crucial to modern computer graphics. The pipeline for obtaining such terrains is via amplification of a low-resolution terrain to refine the details given a desired theme, which is a time-consuming and labor-intensive process. Recently, data-driven methods, such as the sparse construction tree, have provided a promising direction to equip the artist with better control over the theme. These methods learn to amplify terrain details by using an exemplar of highresolution detailed terrains to transfer the theme. In this paper, we propose Generative Adversarial Terrain Amplification (GATA) that achieves better local/global coherence compared to the existing data-driven methods while providing even more ways to control the theme. GATA is comprised of two key ingredients. The first one is a novel embedding of themes into vectors of real numbers to achieve a single tool for multi-theme amplification. The theme component can leverage existing LIDAR data to generate similar terrain features. It can also generate new fictional themes by tuning the embedding vector or even encoding a new example terrain into an embedding. The second one is an adversarially trained model that, conditioned on an embedding and a low-resolution terrain, generates a high-resolution terrain adhering to the desired theme. The proposed integral approach reduces the need for unnecessary manual adjustments, can speed up the development, and brings the model quality to a new level. Our implementation of the proposed method has proved successful in large-scale terrain authoring for an open-world game.},
	issue        = 6
}
@article{Brandt2019,
	title        = {The reduced immersed method for real-time fluid-elastic solid interaction and contact simulation},
	author       = {Christopher Brandt and Leonardo Scandolo and Elmar Eisemann and Klaus Hildebrandt},
	year         = 2019,
	journal      = {ACM Transactions on Graphics},
	volume       = 38,
	doi          = {10.1145/3355089.3356496},
	issn         = 15577368,
	url          = {https://graphics.tudelft.nl/Publications-new/2019/BSEH19/immersed.pdf},
	abstract     = {We introduce the Reduced Immersed Method (RIM) for the real-time simulation of two-way coupled incompressible fluids and elastic solids and the interaction of multiple deformables with (self-)collisions. Our framework is based on a novel discretization of the immersed boundary equations of motion, which model fluid and deformables as a single incompressible medium and their interaction as a unified system on a fixed domain combining Eulerian and Lagrangian terms. One advantage for real-time simulations resulting from this modeling is that two-way coupling phenomena can be faithfully simulated while avoiding costly calculations such as tracking the deforming fluid-solid interfaces and the associated fluid boundary conditions. Our discretization enables the combination of a PIC/FLIP fluid solver with a reduced-order Lagrangian elasticity solver. Crucial for the performance of RIM is the efficient transfer of information between the elasticity and the fluid solver and the synchronization of the Lagrangian and Eulerian settings. We introduce the concept of twin subspaces that enables an efficient reduced-order modeling of the transfer. Our experiments demonstrate that RIM handles complex meshes and highly resolved fluids for large time steps at high framerates on of-the-shelf hardware, even in the presence of high velocities and rapid user interaction. Furthermore, it extends reduced-order elasticity solvers such as Hyper-Reduced Projective Dynamics with natural collision handling.},
	issue        = 6,
	keywords     = {Elastic solids,Fluid simulation,Immersed boundary method,Model reduction,Projective dynamics,Real-time simulation,Solid-fluid coupling,Subspace dynamics}
}
@phdthesis{Longay2019,
	title        = {Interactive Procedural Modelling of Trees and Landscapes},
	author       = {Steven Longay},
	year         = 2019,
	journal      = {The Grants Register 2019},
	pages        = {768--770},
	doi          = {10.1007/978-1-349-95810-8_1179},
	url          = {http://algorithmicbotany.org/papers/longay.th2014.small.pdf},
	abstract     = {Three-dimensional kinematics of the lower extremities are typically assessed with external markers attached to the segments of interest. However, these markers may move considerably with respect to the underlying bone, and thus, large errors may be introduced. The purpose of this study was to determine the three-dimensional skeletal tibiocalcaneal (ankle joint complex, AJC) and tibiofemoral (knee) motion during the stance phase of walking and running, and to compare this to the respective motion determined from external markers.\r\n\r\nMarker triads were attached to intracortical bone pins inserted into the calcaneus, tibia, and femur of five subjects. Additionally, external markers were attached to the shoe, shank, and thigh. For each subject, three walking and five running trials were filmed with three high speed cameras (50 Hz for walking, 200 Hz for running). Cardan angles were calculated to express the intersegmental knee and AJC motion. Knee flexion/extension, ab/adduction, and internal/external knee rotation as well as AJC plantar/dorsiflexion, ab/adduction and in/eversion were calculated both from skeletal and external markers.\r\n\r\nFor walking and running, it was found that the skeletal tibiocalcaneal (AJC) motions were well reflected when using external markers. However, the rotations were generally overestimated when using external markers. For instance, during running, the maximal initial eversion occurring from touchdown to midstance averaged 16.0 when using external markers. However, the same variable determined from skeletal markers was only 8.6.\r\n\r\nDuring walking and running, the skeletal knee flexion/extension was well represented with skin markers. For ab/adduction and internal/external knee rotation, the agreement between external and skeletal kinematics ranged from good to virtually no agreement. In some subjects, the errors exceeded the actual skeletal motion. Methodological problems were also identified with the determination of tibiofemoral kinematics. Internal/external knee rotation and particularly ab/adduction can be expected to be small, and thus, they are highly affected by cross-talk caused by uncertainties in defining the anatomical coordinate systems.\r\n\r\nThe results of this project suggest that (a) tibiocalcaneal motions are generally well represented with external markers, but absolute values have to be interpreted with caution, and that (b) knee rotations other than flexion/extension may be affected with substantial errors when using skin markers.}
}
@article{Petrovas2019,
	title        = {Automated Digital Terrain Elevation Modification by Procedural Generation Approach},
	author       = {Aurimas Petrovas and Romualdas Bausys},
	year         = 2019,
	journal      = {2019 Open Conference of Electrical, Electronic and Information Sciences, eStream 2019 - Proceedings},
	publisher    = {IEEE},
	doi          = {10.1109/eStream.2019.8732171},
	isbn         = 9781728124995,
	abstract     = {Creative content requires a lot of human resources. Computational creativity gets more attention as computational resources are getting fast enough to quickly create automated content with enough precision and similarity to human-created digital assets. Paper explores terrain generation methods and proposes a different solution to generate mountains. A landscape is created using voxel-based cubes and the base map is modified using generation agents. Vertical points are extended and filled using arithmetic operations between arrays for each vertical point. Height normalization is applied to remove rare mountain elevation layers.},
	keywords     = {Computational creativity,game design,procedural generation,terrain}
}
@article{Lipp2019,
	title        = {Local Editing of Procedural Models},
	author       = {M. Lipp and M. Specht and C. Lau and P. Wonka and P. M\"{u}ller},
	year         = 2019,
	journal      = {Computer Graphics Forum},
	volume       = 38,
	pages        = {13--25},
	doi          = {10.1111/cgf.13615},
	issn         = 14678659,
	abstract     = {Procedural modeling is used across many industries for rapid 3D content creation. However, professional procedural tools often lack artistic control, requiring manual edits on baked results, diminishing the advantages of a procedural modeling pipeline. Previous approaches to enable local artistic control require special annotations of the procedural system and manual exploration of potential edit locations. Therefore, we propose a novel approach to discover meaningful and non-redundant good edit locations (GELs). We introduce a bottom-up algorithm for finding GELs directly from the attributes in procedural models, without special annotations. To make attribute edits at GELs persistent, we analyze their local spatial context and construct a meta-locator to uniquely specify their structure. Meta-locators are calculated independently per attribute, making them robust against changes in the procedural system. Functions on meta-locators enable intuitive and robust multi-selections. Finally, we introduce an algorithm to transfer meta-locators to a different procedural model. We show that our approach greatly simplifies the exploration of the local edit space, and we demonstrate its usefulness in a user study and multiple real-world examples.},
	issue        = 2,
	keywords     = {CCS Concepts,\textbullet{} Computing methodologies \rightarrow{} Mesh geometry models}
}
@article{Shen2019,
	title        = {Progressive embedding},
	author       = {Hanxiao Shen and Zhongshi Jiang and Denis Zorin and Daniele Panozzo},
	year         = 2019,
	journal      = {ACM Transactions on Graphics},
	volume       = 38,
	doi          = {10.1145/3306346.3323012},
	issn         = 15577368,
	url          = {https://cims.nyu.edu/gcl/papers/2019-Progressive.pdf},
	abstract     = {Tutte embedding is one of the most common building blocks in geometry processing algorithms due to its simplicity and provable guarantees. Although provably correct in infinite precision arithmetic, it fails in challenging cases when implemented using floating point arithmetic, largely due to the induced exponential area changes. We propose Progressive Embedding, with similar theoretical guarantees to Tutte embedding, but more resilient to the rounding error of floating point arithmetic. Inspired by progressive meshes, we collapse edges on an invalid embedding to a valid, simplified mesh, then insert points back while maintaining validity. We demonstrate the robustness of our method by computing embeddings for a large collection of disk topology meshes. By combining our robust embedding with a variant of the matchmaker algorithm, we propose a general algorithm for the problem of mapping multiply connected domains with arbitrary hard constraints to the plane, with applications in texture mapping and remeshing.},
	issue        = 4
}
@article{Hu2019,
	title        = {Triwild: Robust triangulation with curve constraints},
	author       = {Yixin Hu and Teseo Schneider and Xifeng Gao and Qingnan Zhou and Alec Jacobson and Denis Zorin and Daniele Panozzo},
	year         = 2019,
	journal      = {ACM Transactions on Graphics},
	volume       = 38,
	doi          = {10.1145/3306346.3323011},
	issn         = 15577368,
	url          = {https://cims.nyu.edu/gcl/papers/2019-TriWild.pdf},
	abstract     = {We propose a robust 2D meshing algorithm, TriWild, to generate curved triangles reproducing smooth feature curves, leading to coarse meshes designed to match the simulation requirements necessary by applications and avoiding the geometrical errors introduced by linear meshes. The robustness and effectiveness of our technique are demonstrated by batch processing an SVG collection of 20k images, and by comparing our results against state of the art linear and curvilinear meshing algorithms. We demonstrate for our algorithm the practical utility of computing diffusion curves, fluid simulations, elastic deformations, and shape inflation on complex 2D geometries.},
	issue        = 4,
	keywords     = {Curved Triangulation,Mesh Generation,Robust Geometry Processing}
}
@article{Kim2019,
	title        = {Automatic generation of game content using a graph-based wave function collapse algorithm},
	author       = {Hwanhee Kim and Seongtaek Lee and Hyundong Lee and Teasung Hahn and Shinjin Kang},
	year         = 2019,
	journal      = {IEEE Conference on Computatonal Intelligence and Games, CIG},
	volume       = {2019-Augus},
	pages        = {1--5},
	doi          = {10.1109/CIG.2019.8848019},
	isbn         = 9781728118840,
	issn         = 23254289,
	abstract     = {This paper describes graph-based Wave Function Collapse algorithm for procedural content generation. The goal of this system is to enable a game designer to procedurally create key content elements in the game level through simple association rule input. To do this, we propose a graph-based data structure that can be easily integrated with a navigation mesh data structure in a three-dimensional world. With our system, if the user inputs the minimum association rule, it is possible to effectively perform procedural content generation in the three-dimensional world. The experimental results show that the Wave Function Collapse algorithm, which is a texture synthesis algorithm, can be extended to a non-grid shape with high controllability and scalability.},
	issue        = {October},
	keywords     = {Procedural Content Generation (PCG),Wave Function Collapse (WFC)}
}
@article{Zhang2019,
	title        = {Computer-assisted Relief Modelling: A Comprehensive Survey},
	author       = {Yu Wei Zhang and Jing Wu and Zhongping Ji and Mingqiang Wei and Caiming Zhang},
	year         = 2019,
	journal      = {Computer Graphics Forum},
	volume       = 38,
	pages        = {521--534},
	doi          = {10.1111/cgf.13655},
	issn         = 14678659,
	abstract     = {As an art form between drawing and sculpture, relief has been widely used in a variety of media for signs, narratives, decorations and other purposes. Traditional relief creation relies on both professional skills and artistic expertise, which is extremely time-consuming. Recently, automatic or semi-automatic relief modelling from a 3D object or a 2D image has been a subject of interest in computer graphics. Various methods have been proposed to generate reliefs with few user interactions or minor human efforts, while preserving or enhancing the appearance of the input. This survey provides a comprehensive review of the advances in computer-assisted relief modelling during the past decade. First, we provide an overview of relief types and their art characteristics. Then, we introduce the key techniques of object-space methods and image-space methods respectively. Advantages and limitations of each category are discussed in details. We conclude the report by discussing directions for possible future research.},
	issue        = 2,
	keywords     = {bas-relief,high relief,image-space modelling,object-space modelling,relief modelling}
}
@book{Williamson2019,
	title        = {Lecture 09 Normalized Adjacency and Laplacian Matrices},
	author       = {Lecturer David P Williamson},
	year         = 2019,
	pages        = {1--7}
}
@article{Cortial2019,
	title        = {Procedural Tectonic Planets},
	author       = {Yann Cortial and Adrien Peytavie and \'{E}ric Galin and \'{E}ric Gu\'{e}rin},
	year         = 2019,
	journal      = {Eurographics Computer Graphics Forum},
	volume       = 38,
	pages        = {1--11},
	doi          = {10.1111/cgf.13614},
	issn         = 14678659,
	abstract     = {We present a procedural method for authoring synthetic tectonic planets. Instead of relying on computationally demanding physically-based simulations, we capture the fundamental phenomena into a procedural method that faithfully reproduces large-scale planetary features generated by the movement and collision of the tectonic plates. We approximate complex phenomena such as plate subduction or collisions to deform the lithosphere, including the continental and oceanic crusts. The user can control the movement of the plates, which dynamically evolve and generate a variety of landforms such as continents, oceanic ridges, large scale mountain ranges or island arcs. Finally, we amplify the large-scale planet model with either procedurally-defined or real-world elevation data to synthesize coherent detailed reliefs. Our method allows the user to control the evolution of an entire planet interactively, and to trigger specific events such as catastrophic plate rifting.},
	issue        = 2,
	keywords     = {CCS Concepts,Shape modeling,\textbullet{} Computing methodologies \rightarrow{} Computer graphics}
}
@article{Tricard2019,
	title        = {Procedural Phasor Noise},
	author       = {Thibault Tricard and Semyon Efremov and C\'{e}dric Zanni and Fabrice Neyret and Jon\`{a}s Mart\'{\i}nez and Sylvain Lefebvre},
	year         = 2019,
	journal      = {ACM Transactions on Graphics},
	volume       = 38,
	url          = {https://hal.archives-ouvertes.fr/hal-02118508/file/ProceduralPhasorNoise.pdf},
	issue        = 4
}
@article{Jaiswal2019,
	title        = {Deformable Terrain Model for the Real-Time Multibody Simulation of a Tractor with a Hydraulically Driven Front-Loader},
	author       = {Suraj Jaiswal and Pasi Korkealaakso and Rafael Aman and Jussi Sopanen and Aki Mikkola},
	year         = 2019,
	journal      = {IEEE Access},
	volume       = 7,
	pages        = {172694--172708},
	doi          = {10.1109/ACCESS.2019.2956164},
	issn         = 21693536,
	abstract     = {A real-time multibody model of an off-road vehicle can be used to analyze the dynamics of tasks, such as loading and/or transferring material from deformable ground. This analysis requires an accurate description of the mechanics, hydraulic actuators, and the terrain. The objective of this paper is to introduce a novel, real-time capable, deformable terrain/soil model that can interact with the mechanics of a multibody system model and the dynamics of a hydraulics model. To this end, a tractor is modeled by using a semi-recursive multibody formulation based on velocity transformation. The hydraulic actuation of the tractor's front-loader is modeled by using the lumped fluid theory. The tractor loads and transfers sand material from a deformable sand field (the ground), which is modeled by combining mesh-based and particle-based soil representation approaches for the real-time simulation of soil deformation. The work cycle of the tractor model follows a 3D maneuver that is used to load and transfer sand material. During the digging and dumping operations, the static sand field is converted into sand particles and vice versa respectively. For the presented work cycle, the real-time capability of the system is analyzed and determined. Furthermore, the dynamic actuator forces in the hydraulic cylinders are compared with the static actuator forces. The introduced real-time capable tractor simulation model can be utilized in product development and other product processes.},
	keywords     = {Deformable soil/terrain model,hydraulic actuators,multibody system dynamics,real-time simulation,semi-recursive formulation,vehicle dynamics}
}
@article{Gumusay2019,
	title        = {A review of seagrass detection, mapping and monitoring applications using acoustic systems},
	author       = {Mustafa Umit Gumusay and Tolga Bakirman and Inci Tuney Kizilkaya and Nedim Onur Aykut},
	year         = 2019,
	journal      = {European Journal of Remote Sensing},
	publisher    = {Taylor \& Francis},
	volume       = 52,
	pages        = {1--29},
	doi          = {10.1080/22797254.2018.1544838},
	issn         = 22797254,
	url          = {https://doi.org/10.1080/22797254.2018.1544838},
	abstract     = {Seagrass meadows are key elements of marine ecosystems as they affect the physical, chemical and biological environment and provide habitats for fish and invertebrates. Human activities have caused a deterioration in seagrass which has led to unstable benthic habitats; therefore, to prevent major decline, seagrass distribution must be mapped and monitored. Acoustic systems allow researchers, scientists and decision makers to collect high-resolution datasets such as bathymetry, backscatter and sub-bottom profiles. These systems are able to characterise the properties of the seafloor including plants, sediments and habitats. In this review, we examine seagrass mapping, monitoring and detection applications using acoustic systems in the literature. Although there are various methodologies for data collection, processing, classification and validation, these are limited to certain seagrass species or study areas. Further worldwide research is required to achieve consistent seagrass detection systems with data acquisition, pre-processing, classification and post-processing.},
	issue        = 1,
	keywords     = {Seagrass,acoustics,backscatter,bathymetry,detection,mapping,monitoring}
}
@article{Pelletier2019,
	title        = {Probl\`{e}mes et m\'{e}thodes de l'\'{e}tude g\'{e}omorphologique des r\'{e}cifs coralliens},
	author       = {De M A Gibert M Pelletier},
	year         = 2019,
	journal      = {Geocarrefour},
	volume       = 28,
	pages        = {174--180}
}
@article{Louis2019,
	title        = {HIL Simulator for AUV with ContrACT},
	author       = {Silvain Louis and David Andreu and Karen Godary-dejean and Lionel Lapierre and Silvain Louis and David Andreu and Karen Godary-dejean and Lionel Lapierre and H I L Simulator and Silvain L Ouis and David A Ndreu and Karen G Odary Ejean and Lionel L Apierre},
	year         = 2019,
	journal      = {CAR: Control Architectures of Robots}
}
@article{Duvall2019,
	title        = {Collapsing Complexity: Quantifying Multiscale Properties of Reef Topography},
	author       = {Melissa S. Duvall and James L. Hench and Johanna H. Rosman},
	year         = 2019,
	journal      = {Journal of Geophysical Research: Oceans},
	volume       = 124,
	pages        = {5021--5038},
	doi          = {10.1029/2018JC014859},
	issn         = 21699291,
	abstract     = {Seafloor topography affects a wide range of physical and biological processes; therefore, collapsing the three-dimensional structure of the bottom to roughness metrics is a common challenge in studies of marine systems. Here we assessed the properties captured by metrics previously proposed for the seafloor, as well as metrics developed to characterize other types of rough surfaces. We considered three classes of metrics: properties of the bottom elevation distribution (e.g., standard deviation), length scale ratios (e.g., rugosity), and metrics that describe how topography varies with spatial scale (e.g., H\"{o}lder exponents). The metrics were assessed using idealized topography and natural seafloor topography data from airborne lidar measurements of a coral reef. We illustrate that common roughness metrics (e.g., rugosity) can have the same value for topographies that are geometrically very different, limiting their utility. Application of the wavelet leaders technique to the reef data set demonstrates that the topography has a power law scaling behavior, but it is multifractal so a distribution of H\"{o}lder exponents is needed to describe its scaling behavior. Using principal component analysis, we identify three dominant modes of topographic variability, or ways metrics covary, among and within reef zones. Collectively, the results presented here show that coral reef topography is both multiscale and multifractal. While individual metrics that capture specific topography properties relevant to a given process may be suitable for some studies, many applications will require a set of metrics that includes statistics that capture how topography varies with spatial scale.},
	issue        = 7,
	keywords     = {Moorea,coral reef,fractal Brownian motion,multifractal,rugosity,topographic complexity}
}
@article{Lu2019,
	title        = {A Rigging-Skinning Scheme to Control Fluid Simulation},
	author       = {Jia Ming Lu and Xiao Song Chen and Xiao Yan and Chen Feng Li and Ming Lin and Shi Min Hu},
	year         = 2019,
	journal      = {Computer Graphics Forum},
	volume       = 38,
	pages        = {501--512},
	doi          = {10.1111/cgf.13856},
	issn         = 14678659,
	url          = {https://cg.cs.tsinghua.edu.cn/papers/CGF-2019-fluid.pdf},
	abstract     = {Inspired by skeletal animation, a novel rigging-skinning flow control scheme is proposed to animate fluids intuitively and efficiently. The new animation pipeline creates fluid animation via two steps: fluid rigging and fluid skinning. The fluid rig is defined by a point cloud with rigid-body movement and incompressible deformation, whose time series can be intuitively specified by a rigid body motion and a constrained free-form deformation, respectively. The fluid skin generates plausible fluid flows by virtually fluidizing the point-cloud fluid rig with adjustable zero- and first-order flow features and at fixed computational cost. Fluid rigging allows the animator to conveniently specify the desired low-frequency flow motion through intuitive manipulations of a point cloud, while fluid skinning truthfully and efficiently converts the motion specified on the fluid rig into plausible flows of the animation fluid, with adjustable fine-scale effects. Besides being intuitive, the rigging-skinning scheme for fluid animation is robust and highly efficient, avoiding completely iterative trials or time-consuming nonlinear optimization. It is also versatile, supporting both particle- and grid- based fluid solvers. A series of examples including liquid, gas and mixed scenes are presented to demonstrate the performance of the new animation pipeline.},
	issue        = 7,
	keywords     = {CCS Concepts,\textbullet{} Computing methodologies \rightarrow{} Physical simulation}
}
@article{Gosselin2019,
	title        = {Mechanics of a plant in fluid flow},
	author       = {Fr\'{e}d\'{e}rick P. Gosselin},
	year         = 2019,
	journal      = {Journal of Experimental Botany},
	volume       = 70,
	pages        = {3533--3548},
	doi          = {10.1093/jxb/erz288},
	issn         = 14602431,
	url          = {https://arxiv.org/ftp/arxiv/papers/1905/1905.08055.pdf},
	abstract     = {Plants live in constantly moving fluid, whether air or water. In response to the loads associated with fluid motion, plants bend and twist, often with great amplitude. These large deformations are not found in traditional engineering application and thus necessitate new specialized scientific developments. Studying fluid-structure interaction (FSI) in botany, forestry, and agricultural science is crucial to the optimization of biomass production for food, energy, and construction materials. FSIs are also central in the study of the ecological adaptation of plants to their environment. This review paper surveys the mechanics of FSI on individual plants. I present a short refresher on fluid mechanics then dive into the statics and dynamics of plant-fluid interactions. For every phenomenon considered, I examine the appropriate dimensionless numbers to characterize the problem, discuss the implications of these phenomena on biological processes, and propose future research avenues. I cover the concept of reconfiguration while considering poroelasticity, torsion, chirality, buoyancy, and skin friction. I also assess the dynamical phenomena of wave action, flutter, and vortex-induced vibrations.},
	issue        = 14,
	keywords     = {Aerodynamics,Current,Drag,Elasticity,Flow-induced vibrations,Fluid-structure interactions,Hydrodynamics,Loads,Pollen release and capture,Reconfiguration,Waves,Wind},
	pmid         = 31198946
}
@article{Baker2019,
	title        = {Emergent Tool Use From Multi-Agent Autocurricula},
	author       = {Bowen Baker and Ingmar Kanitscheider and Todor Markov and Yi Wu and Glenn Powell and Bob McGrew and Igor Mordatch},
	year         = 2019,
	month        = 9,
	doi          = {https://doi.org/10.48550/arXiv.1909.07528},
	url          = {http://arxiv.org/abs/1909.07528},
	abstract     = {Through multi-agent competition, the simple objective of hide-and-seek, and standard reinforcement learning algorithms at scale, we find that agents create a self-supervised autocurriculum inducing multiple distinct rounds of emergent strategy, many of which require sophisticated tool use and coordination. We find clear evidence of six emergent phases in agent strategy in our environment, each of which creates a new pressure for the opposing team to adapt; for instance, agents learn to build multi-object shelters using moveable boxes which in turn leads to agents discovering that they can overcome obstacles using ramps. We further provide evidence that multi-agent competition may scale better with increasing environment complexity and leads to behavior that centers around far more human-relevant skills than other self-supervised reinforcement learning methods such as intrinsic motivation. Finally, we propose transfer and fine-tuning as a way to quantitatively evaluate targeted capabilities, and we compare hide-and-seek agents to both intrinsic motivation and random initialization baselines in a suite of domain-specific intelligence tests.}
}
@article{Mo2019,
	title        = {StructureNet: Hierarchical graph networks for 3D shape generation},
	author       = {Kaichun Mo and Paul Guerrero and Li Yi and Hao Su and Peter Wonka and Kaust Niloy J. Mitra and Leonidas J. Guibas},
	year         = 2019,
	journal      = {ACM Transactions on Graphics},
	volume       = 38,
	doi          = {10.1145/3355089.3356527},
	issn         = 15577368,
	url          = {https://paulguerrero.net/papers/StructureNet.pdf},
	abstract     = {The ability to generate novel, diverse, and realistic 3D shapes along with associated part semantics and structure is central to many applications requiring high-quality 3D assets or large volumes of realistic training data. A key challenge towards this goal is how to accommodate diverse shape variations, including both continuous deformations of parts as well as structural or discrete alterations which add to, remove from, or modify the shape constituents and compositional structure. Such object structure can typically be organized into a hierarchy of constituent object parts and relationships, represented as a hierarchy of n-ary graphs. We introduce StructureNet, a hierarchical graph network which (i) can directly encode shapes represented as such n-ary graphs, (ii) can be robustly trained on large and complex shape families, and (iii) be used to generate a great diversity of realistic structured shape geometries. Technically, we accomplish this by drawing inspiration from recent advances in graph neural networks to propose an order-invariant encoding of n-ary graphs, considering jointly both part geometry and inter-part relations during network training. We extensively evaluate the quality of the learned latent spaces for various shape families and show significant advantages over baseline and competing methods. The learned latent spaces enable several structure-aware geometry processing applications, including shape generation and interpolation, shape editing, or shape structure discovery directly from un-annotated images, point clouds, or partial scans.},
	issue        = 6,
	keywords     = {Autoencoder,Generative models,Graph neural networks,Object structure,Shape analysis and synthesis}
}
@article{Sharma2019,
	title        = {Understanding snow bedform formation by adding sintering to a cellular automata model},
	author       = {Varun Sharma and Louise Braud and Michael Lehning},
	year         = 2019,
	journal      = {Cryosphere},
	volume       = 13,
	pages        = {3239--3260},
	doi          = {10.5194/tc-13-3239-2019},
	issn         = 19940424,
	url          = {https://tc.copernicus.org/articles/13/3239/2019/tc-13-3239-2019.pdf},
	abstract     = {Cellular-automata-based modelling for simulating snow bedforms and snow deposition is introduced in this study. The well-known ReSCAL model, previously used for sand bedforms, is adapted for this purpose by implementing a simple sintering mechanism. The effect of sintering is first explored for solitary barchan dunes of different sizes and flow conditions. Three types of behaviour are observed: small barchans continue their motion without any perceptible difference while large barchans sinter immediately. Barchans of intermediate size split, leaving behind a sintered core and a smaller barchan is formed. It is found that sintering introduces an upper limit to the size of bedforms that can remain mobile. The concept of "maximum streamwise length" (MSL) is introduced and MSL is identified for different wind speeds using the solitary dune scenario. Simulations of the full evolution from an initially flat snow layer to a complex dune field are performed next. It is found that the largest bedforms lie below the MSL threshold. Additionally, it is found that shallow snow layers are most susceptible to mechanical destabilization by the wind.},
	issue        = 12
}
@article{Anagha2019,
	title        = {Terrain generation from user text using cellular automata},
	author       = {C. Anagha Zachariah and G. Pankaj Kumar and D. R. Umesh and M. N. Arun Kumar},
	year         = 2019,
	journal      = {International Journal of Recent Technology and Engineering},
	volume       = 8,
	pages        = {8041--8045},
	doi          = {10.35940/ijrte.C6425.098319},
	issn         = 22773878,
	url          = {https://www.ijrte.org/wp-content/uploads/papers/v8i3/C6425098319.pdf},
	abstract     = {Last decade has been witnessed for the dramatic advancement in computer games. Latest studies shows that procedurally generated content makes the players remain engaged for a long time. Incorporating the user's preferences and creativity in the games is still a challenging task. In this paper, we focus on the diversity of terrain generation in terms of its components. Personalization of user experience via effective modeling, combined with real-time adjustment of the content helps for meaningful content generation. Our engine accepts input from the user in Terrain development language (TDL).The user has to specify the type and features of the terrain. The engine extracts features through Terrain Development Algorithm (TDA) and generates individual components according to the information. The end result is to provide a user skill-matched terrain, which can be rendered for various games.},
	issue        = 3,
	keywords     = {Cellular automata,Terrain development algorithm,Terrain language}
}
@article{Wang2019,
	title        = {Planit: Planning and instantiating indoor scenes with relation graph and spatial prior networks},
	author       = {Kai Wang and Yu An Lin and Ben Weissmann and Manolis Savva and Angel X. Chang and Daniel Ritchie},
	year         = 2019,
	journal      = {ACM Transactions on Graphics},
	volume       = 38,
	doi          = {10.1145/3306346.3322941},
	issn         = 15577368,
	url          = {https://dl.acm.org/doi/pdf/10.1145/3306346.3322941},
	abstract     = {We present a new framework for interior scene synthesis that combines a high-level relation graph representation with spatial prior neural networks. We observe that prior work on scene synthesis is divided into two camps: object-oriented approaches (which reason about the set of objects in a scene and their configurations) and space-oriented approaches (which reason about what objects occupy what regions of space). Our insight is that the object-oriented paradigm excels at high-level planning of how a room should be laid out, while the space-oriented paradigm performs well at instantiating a layout by placing objects in precise spatial configurations. With this in mind, we present PlanIT, a layout-generation framework that divides the problem into two distinct planning and instantiation phases. PlanIT represents the ``plan'' for a scene via a relation graph, encoding objects as nodes and spatial/semantic relationships between objects as edges. In the planning phase, it uses a deep graph convolutional generative model to synthesize relation graphs. In the instantiation phase, it uses image-based convolutional network modules to guide a search procedure that places objects into the scene in a manner consistent with the graph. By decomposing the problem in this way, PlanIT generates scenes of comparable quality to those generated by prior approaches (as judged by both people and learned classifiers), while also providing the modeling flexibility of the intermediate relationship graph representation. These graphs allow the system to support applications such as scene synthesis from a partial graph provided by a user.},
	issue        = 4,
	keywords     = {Convolutional networks,Deep learning,Graph generation,Indoor scene synthesis,Neural networks,Object layout,Relationship graphs}
}
@article{Ashual2019,
	title        = {Specifying object attributes and relations in interactive scene generation},
	author       = {Oron Ashual and Lior Wolf},
	year         = 2019,
	journal      = {Proceedings of the IEEE International Conference on Computer Vision},
	volume       = {2019-Octob},
	pages        = {4560--4568},
	doi          = {10.1109/ICCV.2019.00466},
	isbn         = 9781728148038,
	issn         = 15505499,
	url          = {https://arxiv.org/pdf/1909.05379.pdf},
	abstract     = {We introduce a method for the generation of images from an input scene graph. The method separates between a layout embedding and an appearance embedding. The dual embedding leads to generated images that better match the scene graph, have higher visual quality, and support more complex scene graphs. In addition, the embedding scheme supports multiple and diverse output images per scene graph, which can be further controlled by the user. We demonstrate two modes of per-object control: (i) importing elements from other images, and (ii) navigation in the object space by selecting an appearance archetype. Our code is publicly available at https://www.github.com/ashual/scene-generation.}
}
@article{Sous2019,
	title        = {Wave transformation over a barrier reef},
	author       = {Damien Sous and Marion Tissier and Vincent Rey and Julien Touboul and Fr\'{e}d\'{e}ric Bouchette and Jean-Luc Devenon and Cristele Chevalier and Jer\^{o}me Aucan},
	year         = 2019,
	month        = 8,
	journal      = {Continental Shelf Research},
	volume       = 184,
	pages        = {66--80},
	doi          = {10.1016/j.csr.2019.07.010},
	issn         = {02784343},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0278434318304904}
}
@article{Warszawski2019,
	title        = {Procedural method for fast table mountains modelling in virtual environments},
	author       = {Korneliusz K. Warszawski and S\l{}awomir S. Nikiel and Marcin Mrugalski},
	year         = 2019,
	journal      = {Applied Sciences (Switzerland)},
	volume       = 9,
	doi          = {10.3390/app9112352},
	issn         = 20763417,
	abstract     = {Natural terrains created by long-term erosion processes can sometimes have spectacular forms and shapes. The visible form depends often upon internal geological structure and materials. One of the unique terrain artefacts occur in the form of table mountains and can be observed in the Monument Valley (Colorado Plateau, USA). In the following article a procedural method is considered for terrain modelling of structures, geometrically similar to the mesas and buttes hills. This method is not intended to simulate physically inspired erosion processes, but targets directly the generation of eroded forms. The results can be used as assets by artists and designers. The proposed terrain model is based on a height-field representation extended by materials and its hardness information. The starting point of the technique is the Poisson Faulting algorithm that was originally used to obtain fractional Brownian surfaces. In the modification, the step function as the fault line generator was replaced with a circular one. The obtained geometry was used for materials' classification and the hardness part of the modelled terrain. The final model was achieved by the erosive modification of geometry according to the materials and its hardness data. The results are similar to the structures observed in nature and are achieved within an acceptable time for real-time interactions.},
	issue        = 11,
	keywords     = {Computer graphics,Erosion simulation,Poisson faulting,Terrain modelling,Virtual environment}
}
@article{Park2019,
	title        = {Water resource and ecotone transformation in coastal ecosystems},
	author       = {Joseph Park and Jed Redwine and Troy D. Hill and Kevin Kotun},
	year         = 2019,
	month        = 8,
	journal      = {Ecological Modelling},
	publisher    = {Elsevier B.V.},
	volume       = 405,
	pages        = {69--85},
	doi          = {10.1016/j.ecolmodel.2019.04.015},
	issn         = {03043800},
	abstract     = {Mangrove marshes are a significant global ecosystem, finely-tuned to contemporary sea level. As sea level rises the mangrove-to-freshwater ecotone reflects underlying groundwater salinity indicating the transformation of freshwater resources into saltwater unsuitable for consumption or agriculture. Hydrological numerical models can predict this dynamic given sufficient environmental detail, however, detailed data is often lacking. Alternatively, agent-based models can predict landscape vegetation changes and the associated fresh-to-saline water transformation based only on landscape surface features. We apply such a model to the southern tip of the Florida peninsula at the nexus of a metropolis and World Heritage wildlife preserve: the Florida Everglades, to predict ecotone dynamics and aquifer water resources in response to warming climate and rising sea level. The model is based on species-specific behaviors for freshwater grasses and salt-tolerant red mangroves with relevance to global mangrove ecosystems.},
	keywords     = {Freshwater resource,Mangrove ecotone,Sea level rise}
}
@article{Chan2019,
	title        = {Lenia: Biology of artificial life},
	author       = {Bert Wang Chak Chan},
	year         = 2019,
	journal      = {Complex Systems},
	publisher    = {Complex Systems Publications, Inc},
	volume       = 28,
	pages        = {251--256},
	doi          = {10.25088/ComplexSystems.28.3.251},
	issn         = {08912513},
	abstract     = {A new system of artificial life called Lenia (from Latin lenis ``smooth''), a two-dimensional cellular automaton with continuous spacetime state and generalized local rule, is reported. Computer simulations show that Lenia supports a great diversity of complex autonomous patterns or ``life forms'' bearing resemblance to real-world microscopic organisms. More than 400 species in 18 families have been identified, many discovered via interactive evolutionary computation. They differ from other cellular automata patterns in being geometric, metameric, fuzzy, resilient, adaptive and rule generic. Basic observations of the system are presented regarding the properties of spacetime and basic settings. A broad survey of the life forms is provided and categorized into a hierarchical taxonomy, and their distribution is mapped in the parameter hyperspace. Their morphological structures and behavioral dynamics are described, and possible mechanisms of their self-organization, self-direction and plasticity are proposed. Finally, the study of Lenia and how it would be related to biology, artificial life and artificial intelligence is discussed.},
	issue        = 3,
	keywords     = {Artificial life,Complex system,Geometric cellular automata,Interactive evolutionary computation}
}
@book{Baukal2019,
	title        = {Computational Fluid Dynamics in Industrial Combustion},
	author       = {Charles E. Baukal and Vladimir Y. Gershtein and Xianming Li},
	year         = 2019,
	publisher    = {CRC Press},
	pages        = {1--648},
	isbn         = 9780367397982,
	edition      = {Routledge},
	editor       = {Charles E. Baukal}
}
@phdthesis{DupontThesis,
	title        = {Repr\'{e}sentation, mod\'{e}lisation et g\'{e}n\'{e}ration proc\'{e}durale de paysages de rivi\`{e}res naturelles},
	author       = {Thibault Dupont},
	year         = 2019,
	month        = 12,
	url          = {https://theses.hal.science/tel-03281195},
	city         = {Lyon},
	institution  = {Universit\'{e} Claude Bernard lyon 1}
}
@article{Tavernier2019,
	title        = {Making Gabor Noise Fast and Normalized},
	author       = {Vincent Tavernier and Fabrice Neyret and Romain Vergne and Jo\"{e}lle Thollot and V Tavernier and F Neyret and R Vergne and J Thollot},
	year         = 2019,
	pages        = {37--40},
	doi          = {10.2312/egs.20191009ï},
	url          = {https://inria.hal.science/hal-02104389},
	abstract     = {Gabor Noise is a powerful procedural texture synthesis technique, but it has two major drawbacks: It is costly due to the high required splat density and not always predictable because properties of instances can differ from those of the process. We bench performance and quality using alternatives for each Gabor Noise ingredient: point distribution, kernel weighting and kernel shape. For this, we introduce 3 objective criteria to measure process convergence, process stationarity, and instance stationarity. We show that minor implementation changes allow for 17 - 24\texttimes{} speed-up with same or better quality.},
	keywords     = {CCS,Computing methodologies \rightarrow{},Concepts \textbullet{},Texturing;}
}
@misc{Nelson2019,
	title        = {Oxygen: the universal currency on coral reefs},
	author       = {Hannah R. Nelson and Andrew H. Altieri},
	year         = 2019,
	month        = 4,
	journal      = {Coral Reefs},
	publisher    = {Springer Verlag},
	volume       = 38,
	pages        = {177--198},
	doi          = {10.1007/s00338-019-01765-0},
	issn         = {07224028},
	abstract     = {Coral reefs are suffering unprecedented declines worldwide. Most studies focus on stressors such as rising temperatures, nutrient pollution, overfishing, and ocean acidification as drivers of this degradation. However, recent mass mortality events associated with low oxygen on coral reefs indicate that oxygen is a critical factor that can be limiting in reef environments. Here, we present evidence that integrates across disciplines and perspectives to reveal how natural and anthropogenic factors drive variation in oxygen at multiple scales on coral reefs. This variation, in turn, limits essential processes such as productivity, respiration, and calcification on reefs and often plays a role in the outcome of interactions between corals and their competitors, pathogens, and mutualists. Moreover, the apparent effects of temperature, eutrophication, acidification, and other stressors on corals are commonly mediated by oxygen. As a consequence, the imprint of oxygen variation is evident in many patterns including reef biodiversity, coral bleaching, colony morphology, and fish behavior. We suggest that the structure and dynamics of coral reefs can be fully understood only by considering the ubiquitous role of oxygen, and we identify critical areas of future oxygen research to guide the study and management of coral reefs in a changing world.},
	issue        = 2,
	keywords     = {Bleaching,Calcification,Climate change,Dead zones,Hyperoxia,Hypoxia}
}
@article{Makowski2019,
	title        = {Synthetic silviculture: Multi-scale modeling of plant ecosystems},
	author       = {Mi\l{}osz Makowski and Torsten H\"{a}drich and Jan Scheffczyk and Dominik L. Michels and S\"{o}ren Pirk and Wojtek Pa\l{}ubicki},
	year         = 2019,
	month        = 7,
	journal      = {ACM Transactions on Graphics},
	publisher    = {Association for Computing Machinery},
	volume       = 38,
	doi          = {10.1145/3306346.3323039},
	issn         = 15577368,
	abstract     = {Due to the enormous amount of detail and the interplay of various biological phenomena, modeling realistic ecosystems of trees and other plants is a challenging and open problem. Previous research on modeling plant ecologies has focused on representations to handle this complexity, mostly through geometric simplifications, such as points or billboards. In this paper we describe a multi-scale method to design large-scale ecosystems with individual plants that are realistically modeled and faithfully capture biological features, such as growth, plant interactions, different types of tropism, and the competition for resources. Our approach is based on leveraging inter- and intra-plant self-similarities for efficiently modeling plant geometry. We focus on the interactive design of plant ecosystems of up to 500K plants, while adhering to biological priors known in forestry and botany research. The introduced parameter space supports modeling properties of nine distinct plant ecologies while each plant is represented as a 3D surface mesh. The capabilities of our framework are illustrated through numerous models of forests, individual plants, and validations.},
	issue        = 4,
	keywords     = {Botanical Tree Models,Ecosystem Design,Interactive Modeling,Multi-Scale,Natural Phenomena,Plant Ecosystems,Self-Organization,Self-Similarity,Visual Models of Trees}
}
@inproceedings{Spick2019,
	title        = {Realistic and textured terrain generation using GANs},
	author       = {Ryan Spick and James Alfred Walker},
	year         = 2019,
	month        = 12,
	booktitle    = {Proceedings - CVMP 2019: 16th ACM SIGGRAPH European Conference on Visual Media Production},
	publisher    = {Association for Computing Machinery, Inc},
	doi          = {10.1145/3359998.3369407},
	isbn         = 9781450370035,
	abstract     = {In computer graphics and virtual environment development, a large portion of time is spent creating assets - one of these being the terrain environment, which usually forms the basis of many large graphical worlds. The texturing of height maps is usually performed as a post-processing step - with software requiring access to the height and gradient of the terrain in order to generate a set of conditions for colouring slopes, flats, mountains etc. With further additions such as biomes specifying which predominant texturing the region should exhibit such as grass, snow, dirt etc. much like the real-world. These methods combined with a height map generation algorithm can create impressive terrain renders which look visually stunning - however can appear somewhat repetitive. Previous work has explored the use of variants of Generative Adversarial Networks for the learning of elevation data through real-world data sets of world height data. In this paper, a method is proposed for learning not only the height map values but also the corresponding satellite image of a specific region. This data is trained through a non-spatially dependant generative adversarial network, which can produce an endless amount of variants of a specific region. The textured outputs are measured using existing similarity metrics and compared to the original region, which yields strong results. Additionally, a visual and statistical comparison of other deep learning image synthesis techniques is performed. The network outputs are also rendered in a 3D graphics engine and visualised in the paper. This method produces powerful outputs when compared directly with the training region, creating a tool that can produce many different variants of the target terrain. This is ideally suited for the use of a developer wanting a large number of specific structures of terrain.},
	keywords     = {Deep Learning,Generative Adversarial Networks,Procedural Content Generation}
}
@inproceedings{Gaillard2019,
	title        = {Dendry: A procedural model for dendritic patterns},
	author       = {Mathieu Gaillard and Bedrich Benes and Eric Gu rin and Eric Galin and Damien Rohmer and Marie Paule Cani},
	year         = 2019,
	month        = 5,
	booktitle    = {Proceedings - I3D 2019: ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games},
	publisher    = {Association for Computing Machinery, Inc},
	doi          = {10.1145/3306131.3317020},
	isbn         = 9781450363105,
	abstract     = {We introduce Dendry, a procedural function that generates dendritic patterns and is locally computable. The function is controlled by parameters such as the level of branching, the degree of local smoothing, random seeding and local disturbance parameters, and the range of the branching angles. It is also controlled by a global control function that defines the overall shape and can be used, for example, to initialize local minima. The algorithm returns the distance to a tree structure which is implicitly constructed on the fly, while requiring a small memory footprint. The evaluation can be performed in parallel for multiple points and scales linearly with the number of cores. We demonstrate an application of our model to the generation of terrain heighfields with consistent river networks. A quad core implementation of our algorithm takes about ten seconds for a 512 512 resolution grid on the CPU.},
	keywords     = {Dendritic Patterns,Geometric Modeling,Procedural Modeling,Terrain Modeling}
}
@article{Green2019,
	title        = {Two-step Constructive Approaches for Dungeon Generation},
	author       = {Michael Cerny Green and Ahmed Khalifa and Athoug Alsoughayer and Divyesh Surana and Antonios Liapis and Julian Togelius},
	year         = 2019,
	month        = 6,
	journal      = {ACM Computing Surveys},
	publisher    = {National Institute of Standards and Technology (NIST)},
	url          = {http://arxiv.org/abs/1906.04660},
	abstract     = {This paper presents a two-step generative approach for creating dungeons in the rogue-like puzzle game MiniDungeons 2. Generation is split into two steps, initially producing the architectural layout of the level as its walls and floor tiles, and then furnishing it with game objects representing the player's start and goal position, challenges and rewards. Three layout creators and three furnishers are introduced in this paper, which can be combined in different ways in the two-step generative process for producing diverse dungeons levels. Layout creators generate the floors and walls of a level, while furnishers populate it with monsters, traps, and treasures. We test the generated levels on several expressivity measures, and in simulations with procedural persona agents.},
	keywords     = {conversational search,information retrieval,neural network,reference resolution}
}
@techreport{Krs2019,
	title        = {Optimization and Control in Procedural Modeling},
	author       = {Vojtech Krs},
	year         = 2019
}
@inproceedings{Bender2019,
	title        = {Volume Maps: An Implicit Boundary Representation for SPH},
	author       = {Jan Bender and Tassilo Kugelstadt and Marcel Weiler and Dan Koschier},
	year         = 2019,
	month        = 10,
	booktitle    = {Motion, Interaction and Games},
	publisher    = {ACM},
	pages        = {1--10},
	doi          = {10.1145/3359566.3360077},
	isbn         = 9781450369947,
	url          = {https://dl.acm.org/doi/10.1145/3359566.3360077},
	abstract     = {In this paper, we present a novel method for the robust handling of static and dynamic rigid boundaries in Smoothed Particle Hydrodynamics (SPH) simulations. We build upon the ideas of the density maps approach which has been introduced recently by Koschier and Bender. They precompute the density contributions of solid boundaries and store them on a spatial grid which can be efficiently queried during runtime. This alleviates the problems of commonly used boundary particles, like bumpy surfaces and inaccurate pressure forces near boundaries. Our method is based on a similar concept but we precompute the volume contribution of the boundary geometry and store it on a grid. This maintains all benefits of density maps but offers a variety of advantages which are demonstrated in several experiments. Firstly, in contrast to the density maps method we can compute derivatives in the standard SPH manner by differentiating the kernel function. This results in smooth pressure forces, even for lower map resolutions, such that precomputation times and memory requirements are reduced by more than two orders of magnitude compared to density maps Furthermore, this directly fits into the SPH concept so that vol ume maps can be seamlessly combined with existing SPH methods Finally, the kernel function is not baked into the map such that the same volume map can be used with different kernels. This is especially useful when we want to incorporate common surface tension or viscosity methods that use different kernels than the fluid simulation.},
	city         = {New York, NY, USA},
	keywords     = {Boundary handling,Fluid simulation,Smoothed Particle Hydrodynamics}
}
@article{Azman2020,
	title        = {Characterisation and computational analysis of a novel lipase nanobio-based reagent for visualising latent fingerprints on water-immersed glass slides},
	author       = {Aida Rasyidah Azman and Naji Arafat Mahat and Roswanira Abdul Wahab and Wan Azlina Ahmad and Mohamad Afiq Mohamed Huri and Azzmer Azzar Abdul Hamid and Aliyu Adamu and Geshina Ayu Mat Saat},
	year         = 2020,
	month        = 9,
	journal      = {Process Biochemistry},
	publisher    = {Elsevier Ltd},
	volume       = 96,
	pages        = {102--112},
	doi          = {10.1016/j.procbio.2020.05.033},
	issn         = 13595113,
	abstract     = {Considering the significant evidential values of fingerprints in underwater criminal investigations and the need to visualise them using a user- and environmentally-friendly reagent, development of a novel, rapid and relatively greener nanobio-based reagent (NBR) is deemed beneficial. Lipase from the commercial Candida rugosa immobilised onto acid-functionalised multi-walled carbon nanotubes (NBR) was used as the safer and cheap lipid-sensing reagent to visualise groomed whole/split fingerprints on non-porous objects immersed in stagnant tap water for up to 30 days under a laboratory-controlled setting. Attenuated Total Reflectance – Fourier Transform Spectrometry, Field Emission Scanning Electron Microscopy and bioinformatics (molecular docking and molecular dynamics simulations) were employed to characterise and confirm the attachment of NBR onto the lipid constituents of wet fingerprints. Chromatographic results further confirmed the presence of n-hexadecanoic and octadecanoic acids on fingerprints up to 30 days of immersion. Thus, NBR may potentially be useful as the future state-of-the-art fingerprint visualisation technology.},
	keywords     = {Bioinformatics,Candida rugosa lipase,Forensic science,Latent fingerprint,Nanobio-based reagent}
}
@book{Engebretsen2020,
	title        = {Data Visualization in Society},
	author       = {Martin Engebretsen and Helen Kennedy and Jill Walker and Giorgia Aiello and Torgeir Uberg and Eef Masson and Karin van and Salla-Maaria Laaksonen and Juho Pa\"a\"kko\"nen and Mikael Snaprud and Andrea Velazquez and Arran L. and Christopher Birchall and Daniela Geenen and Maranke Wieringa and Jill Simpson and Wibke Weber and Elise Seip T\o{}nnessen and Catherine D'Ignazio and Rahul Bhargava and Lulu Pinney and Arlene Archer and Travis Noakes and Sara Brinch and Tuomo Hiippala and Jonathan Gray and Verena Elisabeth Lechner and Aria Alamalhodaei and Alexandra Alberda and Anna Feigenbaum and John P. Wihbey and Sarah J. Jackson and Pedro M. Cruz and Brooke Foucault Welles and Rosemary Lucy Hill and Britta Ricker and Menno-Jan Kraak and Yuri Engelhardt and Anna Berti Suman and Miren Gutie\'rrez and Alberto Cairo},
	year         = 2020,
	publisher    = {Amsterdam University Press},
	doi          = {10.5117/9789463722902},
	isbn         = 9789463722902,
	url          = {https://www.aup.nl/en/book/9789463722902}
}
@article{Duan,
	title        = {Omni-sourced Webly-supervised Learning for Video Recognition},
	author       = {Haodong Duan and Yue Zhao and Yuanjun Xiong and Wentao Liu and Dahua Lin},
	year         = 2020,
	month        = 3,
	url          = {http://arxiv.org/abs/2003.13042},
	abstract     = {We introduce OmniSource, a novel framework for leveraging web data to train video recognition models. OmniSource overcomes the barriers between data formats, such as images, short videos, and long untrimmed videos for webly-supervised learning. First, data samples with multiple formats, curated by task-specific data collection and automatically filtered by a teacher model, are transformed into a unified form. Then a joint-training strategy is proposed to deal with the domain gaps between multiple data sources and formats in webly-supervised learning. Several good practices, including data balancing, resampling, and cross-dataset mixup are adopted in joint training. Experiments show that by utilizing data from multiple sources and formats, OmniSource is more data-efficient in training. With only 3.5M images and 800K minutes videos crawled from the internet without human labeling (less than 2\% of prior works), our models learned with OmniSource improve Top-1 accuracy of 2D- and 3D-ConvNet baseline models by 3.0\% and 3.9\%, respectively, on the Kinetics-400 benchmark. With OmniSource, we establish new records with different pretraining strategies for video recognition. Our best models achieve 80.4\%, 80.5\%, and 83.6 Top-1 accuracies on the Kinetics-400 benchmark respectively for training-from-scratch, ImageNet pre-training and IG-65M pre-training.}
}
@article{Feichtenhofer,
	title        = {X3D: Expanding Architectures for Efficient Video Recognition},
	author       = {Christoph Feichtenhofer},
	year         = 2020,
	month        = 4,
	url          = {http://arxiv.org/abs/2004.04730},
	abstract     = {This paper presents X3D, a family of efficient video networks that progressively expand a tiny 2D image classification architecture along multiple network axes, in space, time, width and depth. Inspired by feature selection methods in machine learning, a simple stepwise network expansion approach is employed that expands a single axis in each step, such that good accuracy to complexity trade-off is achieved. To expand X3D to a specific target complexity, we perform progressive forward expansion followed by backward contraction. X3D achieves state-of-the-art performance while requiring 4.8x and 5.5x fewer multiply-adds and parameters for similar accuracy as previous work. Our most surprising finding is that networks with high spatiotemporal resolution can perform well, while being extremely light in terms of network width and parameters. We report competitive accuracy at unprecedented efficiency on video classification and detection benchmarks. Code will be available at: https://github.com/facebookresearch/SlowFast}
}
@article{Zhou2020,
	title        = {Learning to Estimate 3D Human Pose from Point Cloud},
	author       = {Yufan Zhou and Haiwei Dong and Abdulmotaleb El Saddik},
	year         = 2020,
	month        = 10,
	journal      = {IEEE Sensors Journal},
	publisher    = {Institute of Electrical and Electronics Engineers Inc.},
	volume       = 20,
	pages        = {12334--12342},
	doi          = {10.1109/JSEN.2020.2999849},
	issn         = 15581748,
	abstract     = {3D pose estimation is a challenging problem in computer vision. Most of the existing neural-network-based approaches address color or depth images through convolution networks (CNNs). In this paper, we study the task of 3D human pose estimation from depth images. Different from the existing CNN-based human pose estimation method, we propose a deep human pose network for 3D pose estimation by taking the point cloud data as input data to model the surface of complex human structures. We first cast the 3D human pose estimation from 2D depth images to 3D point clouds and directly predict the 3D joint position. Our experiments on two public datasets show that our approach achieves higher accuracy than previous state-of-art methods. The reported results on both ITOP and EVAL datasets demonstrate the effectiveness of our method on the targeted tasks.},
	issue        = 20,
	keywords     = {Edge feature,depth image,pose regression network}
}
@article{Kalfaoglu,
	title        = {Late Temporal Modeling in 3D CNN Architectures with BERT for Action Recognition},
	author       = {M. Esat Kalfaoglu and Sinan Kalkan and A. Aydin Alatan},
	year         = 2020,
	month        = 8,
	url          = {http://arxiv.org/abs/2008.01232},
	abstract     = {In this work, we combine 3D convolution with late temporal modeling for action recognition. For this aim, we replace the conventional Temporal Global Average Pooling (TGAP) layer at the end of 3D convolutional architecture with the Bidirectional Encoder Representations from Transformers (BERT) layer in order to better utilize the temporal information with BERT's attention mechanism. We show that this replacement improves the performances of many popular 3D convolution architectures for action recognition, including ResNeXt, I3D, SlowFast and R(2+1)D. Moreover, we provide the-state-of-the-art results on both HMDB51 and UCF101 datasets with 85.10\% and 98.69\% top-1 accuracy, respectively. The code is publicly available.},
	keywords     = {3D Convolution,Action Recognition,BERT,Late Tem-poral Modeling,Temporal Attention}
}
@techreport{Sanchez-Caballero2020,
	title        = {3DFCNN: Real-Time Action Recognition using 3D Deep Neural Networks with Raw Depth Information},
	author       = {Adrian Sanchez-Caballero and Sergio De L\'{o}pez-Diz and David Fuentes-Jimenez and Cristina Losada-Guti\'{e}rrez and Marta Marr\'{o}n-Romera and David Casillas-Perez and Mohammad Ibrahim Sarker},
	year         = 2020,
	abstract     = {Human actions recognition is a fundamental task in artificial vision, that has earned a great importance in recent years due to its multiple applications in different areas. In this context, this paper describes an approach for real-time human action recognition from raw depth image-sequences, provided by an RGB-D camera. The proposal is based on a 3D fully convolutional neural network, named 3DFCNN, which automatically encodes spatio-temporal patterns from depth sequences without pre-processing. Furthermore, the described 3D-CNN allows actions classification from the spatial and temporal encoded information of depth sequences. The use of depth data ensures that action recognition is carried out protecting people's privacy, since their identities can not be recognized from these data. 3DFCNN has been evaluated and its results compared to those from other state-of-the-art methods within three widely used datasets, with different characteristics (resolution, sensor type, number of views, camera location, etc.). The obtained results allows validating the proposal, concluding that it outperforms several state-of-the-art approaches based on classical computer vision techniques. Furthermore , it achieves action recognition accuracy comparable to deep learning based state-of-the-art methods with a lower computational cost, which allows its use in real-time applications.}
}
@article{Chapron2020,
	title        = {Real-time gait speed evaluation at home in a multi residents context},
	author       = {K\'{e}vin Chapron and K\'{e}vin Bouchard and S\'{e}bastien Gaboury},
	year         = 2020,
	journal      = {Multimedia Tools and Applications},
	doi          = {10.1007/s11042-020-08962-y},
	issn         = 15737721,
	abstract     = {In recent years, the aging of the population has attracted considerable attention in the scientific community. An important fact is an increasing number of senior people will suffer from cognitive decline and there is almost no existing way to detect it early without the intervention of a clinician. Indeed, the sooner the cognitive decline is detected, the professional can elaborate a more adequate strategy to slow it down. In fact, Mild Cognitive Impairments (MCI) have been strongly correlated to a decreasing gait speed over the time. However, it would take a lot of human resources to carry out a standardized walking speed test every year to follow the evolution of this one. In fact, it is unthinkable in the current context of healthcare economics scarcity, thus finding a way of measuring it automatically at home could be a promising solution. This ambient sensor should be able to measure the gait speed of an inhabitant and automatically associate it to the right resident in a multi-resident context. In this paper, we present a new prototype to monitor gait speed continuously at home non intrusively. When coupled with a wristband capable of communicating through BLE, the gait speed can then be associated with the right person in a multi-resident context. The proposed prototype was tested in a realistic smart home context and results obtained are very encouraging.},
	keywords     = {Gait speed evaluation,Multi resident identification,Smart home,Speed sensor,Wearable sensors}
}
@article{Sansano-Sansano2020,
	title        = {BLE-GSpeed: A New BLE-Based Dataset to Estimate User Gait Speed},
	author       = {Emilio Sansano-Sansano and Fernando J. Aranda and Ra\'{u}l Montoliu and Fernando J. \'{A}lvarez},
	year         = 2020,
	month        = 12,
	journal      = {Data},
	volume       = 5,
	pages        = 115,
	doi          = {10.3390/data5040115},
	issn         = {2306-5729},
	url          = {https://www.mdpi.com/2306-5729/5/4/115},
	abstract     = {<p>To estimate the user gait speed can be crucial in many topics, such as health care systems, since the presence of difficulties in walking is a core indicator of health and function in aging and disease. Methods for non-invasive and continuous assessment of the gait speed may be key to enable early detection of cognitive diseases such as dementia or Alzheimer's disease. Wearable technologies can provide innovative solutions for healthcare problems. Bluetooth Low Energy (BLE) technology is excellent for wearables because it is very energy efficient, secure, and inexpensive. In this paper, the BLE-GSpeed database is presented. The dataset is composed of several BLE RSSI measurements obtained while users were walking at a constant speed along a corridor. Moreover, a set of experiments using a baseline algorithm to estimate the gait speed are also presented to provide baseline results to the research community.</p>},
	issue        = 4,
	keywords     = {BLE-based technology,Gait speed,Public database}
}
@article{Yang2020,
	title        = {Efficient learning-based blur removal method based on sparse optimization for image restoration},
	author       = {Haoyuan Yang and Xiuqin Su and Songmao Chen and Wenhua Zhu and Chunwu Ju},
	year         = 2020,
	journal      = {PLoS ONE},
	publisher    = {Public Library of Science},
	volume       = 15,
	doi          = {10.1371/journal.pone.0230619},
	issn         = 19326203,
	abstract     = {In imaging systems, image blurs are a major source of degradation. This paper proposes a parameter estimation technique for linear motion blur, defocus blur, and atmospheric turbulence blur, and a nonlinear deconvolution algorithm based on sparse representation. Most blur removal techniques use image priors to estimate the point spread function (PSF); however, many common forms of image priors are unable to exploit local image information fully. In this paper, the proposed method does not require models of image priors. Further, it is capable of estimating the PSF accurately from a single input image. First, a blur feature in the image gradient domain is introduced, which has a positive correlation with the degree of blur. Next, the parameters for each blur type are estimated by a learning-based method using a general regression neural network. Finally, image restoration is performed using a half-quadratic optimization algorithm. Evaluation tests confirmed that the proposed method outperforms other similar methods and is suitable for dealing with motion blur in real-life applications.},
	issue        = 3,
	pmid         = 32218591
}
@article{Wang2020,
	title        = {VR content creation and exploration with deep learning: A survey},
	author       = {Miao Wang and Xu Quan Lyu and Yi Jun Li and Fang Lue Zhang},
	year         = 2020,
	journal      = {Computational Visual Media},
	volume       = 6,
	pages        = {3--28},
	doi          = {10.1007/s41095-020-0162-z},
	issn         = 20960662,
	abstract     = {Virtual reality (VR) offers an artificial, computer generated simulation of a real life environment. It originated in the 1960s and has evolved to provide increasing immersion, interactivity, imagination, and intelligence. Because deep learning systems are able to represent and compose information at various levels in a deep hierarchical fashion, they can build very powerful models which leverage large quantities of visual media data. Intelligence of VR methods and applications has been significantly boosted by the recent developments in deep learning techniques. VR content creation and exploration relates to image and video analysis, synthesis and editing, so deep learning methods such as fully convolutional networks and general adversarial networks are widely employed, designed specifically to handle panoramic images and video and virtual 3D scenes. This article surveys recent research that uses such deep learning methods for VR content creation and exploration. It considers the problems involved, and discusses possible future directions in this active and emerging research area.},
	issue        = 1,
	keywords     = {360\textdegree{} image and video virtual content,deep learning,neural networks,virtual reality}
}
@article{Paper2020,
	title        = {EvolGL: Life in a Pond},
	author       = {Santi Garcia Carbajal and Martin Bosque Moran and Fermin Gonzalez Martinez},
	year         = 2020,
	journal      = {Artificial Life IX},
	doi          = {10.7551/mitpress/1429.003.0014},
	abstract     = {In this work we present the first version of Evolgl, an artificial environment for the development and study of 3D artificial lifeforms. In this first phase on the development of the project we have focused in setting up a virtual world governed by its own laws, whose state had direct influence upon the artificial beings that inhabit it. Starting from the definition of this virtual world, we have designed a basic type of creature (Evolworm), and the genetic coding of its main characteristics. Evolutionary techniques are then used to evolve the morphological features and behavioural aspects of Evolworms. They must learn to be unfolded inside the world, escape from their enemies, find couple, and obtain food. All of this in absence of an explicitly defined fitness function. In the future we are using this environment to study some classical techniques in the evolutionary computation field, like niche programming, and promotion of junk code (introns). GA-P techniques are used to code the external appearance of the individuals (the texture), to let evolution end up with individuals adapted to be invisible in some zones of the world. The artificial system of vision, and the implementation of the worms' behavioral mechanisms so that their actions are provoked exclusively by the sensory information are still under development. At this moment, we have obtained distinct forms of evolworms, as well as different bosses of behaviour that we describe in this article.},
	issue        = {December}
}
@article{Argudo2020,
	title        = {Simulation, modeling and authoring of glaciers},
	author       = {Oscar Argudo and Eric Galin and Adrien Peytavie and Axel Paris and Eric Gu\'{e}rin},
	year         = 2020,
	month        = 12,
	journal      = {ACM Transactions on Graphics},
	volume       = 39,
	pages        = {1--14},
	doi          = {10.1145/3414685.3417855},
	issn         = {0730-0301},
	url          = {https://dl.acm.org/doi/10.1145/3414685.3417855},
	abstract     = {Glaciers are some of the most visually arresting and scenic elements of cold regions and high mountain landscapes. Although snow-covered terrains have previously received attention in computer graphics, simulating the temporal evolution of glaciers as well as modeling their wide range of features has never been addressed. In this paper, we combine a Shallow Ice Approximation simulation with a procedural amplification process to author high-resolution realistic glaciers. Our multiresolution method allows the interactive simulation of the formation and the evolution of glaciers over hundreds of years. The user can easily modify the environment variables, such as the average temperature or precipitation rate, to control the glacier growth, or directly use brushes to sculpt the ice or bedrock with interactive feedback. Mesoscale and smallscale landforms that are not captured by the glacier simulation, such as crevasses, moraines, seracs, ogives, or icefalls are synthesized using procedural rules inspired by observations in glaciology and according to the physical parameters derived from the simulation. Our method lends itself to seamless integration into production pipelines to decorate reliefs with glaciers and realistic ice features.},
	issue        = 6,
	keywords     = {"Procedural terrain modeling,glacier simulation"}
}
@article{Paquier2020,
	title        = {3D numerical simulation of seagrass movement under waves and currents with GPUSPH},
	author       = {Anne El\'{e}onore Paquier and Thibault Oudart and Caroline Le Bouteiller and Samuel Meul\'{e} and Philippe Larroud\'{e} and Robert A. Dalrymple},
	year         = 2020,
	month        = 8,
	journal      = {International Journal of Sediment Research},
	publisher    = {Elsevier B.V.},
	doi          = {10.1016/j.ijsrc.2020.08.003},
	issn         = 10016279,
	abstract     = {The current study tries a new approach to simulating interactions between waves and seagrass through Smoothed Particle Hydrodynamics (SPH). In this model, the plants are defined as a solid that respects Hooke's law, and are assumed to have direct interaction with the fluid. Given the characteristics of the SPH method, especially in terms of computational time, the dimensions of the simulations were limited. The first goal of the current study was to optimize the approach to avoid reaching certain limits such as the rupture of the simulated plant. Plant movements under waves and/or currents have been studied by several authors in various in-situ, physical, and numerical experiments concerning various vegetation species, thus proving that plant movements can be successfully reproduced by SPH 2D/3D. Manning's roughness coefficient, n, was calculated to confirm that the results were in accordance with what had been measured in flume studies. Even though there is still room for improvement, it is shown that this method can be used to estimate Manning's coefficient for coastal vegetation (seagrass and saltmarsh vegetation) and to greatly improve the modeling and forecasting of coastal erosion and storm surge risks by including the effects of vegetation in integrated models.},
	keywords     = {Current,Fluid structure interaction,GPUSPH,Numerical seagrass movement,Waves}
}
@article{Haetinger2020,
	title        = {Regularized Kelvinlet Inversion for Real-Time Image Deformation and Video Time Warping},
	author       = {Guilherme G. Haetinger and Eduardo S.L. Gastal},
	year         = 2020,
	journal      = {Proceedings - 2020 33rd SIBGRAPI Conference on Graphics, Patterns and Images, SIBGRAPI 2020},
	pages        = {124--131},
	doi          = {10.1109/SIBGRAPI51738.2020.00025},
	isbn         = 9781728192741,
	abstract     = {We present a novel approach for image deformation and video time warping. Our technique involves the inversion of the nonlinear regularized Kelvinlet equations, leading to higher quality results and time/space efficiency compared to naive solutions. Inversion is performed by a per-pixel optimization process, being inherently parallel and achieving real-time performance in Full HD videos (over 300 fps). We demonstrate our method on a variety of images and videos, in addition to discussing some important technical and theoretical details.},
	keywords     = {image and video processing,image warping,interpolation,time warp,video retiming}
}
@article{Rabbani2020,
	title        = {Fast Eulerian Fluid Simulation In Games Using Poisson Filters},
	author       = {A H Rabbani and S. Khiat},
	year         = 2020,
	journal      = {ACM SIGGRAPH / Eurographics Symposium on Computer Animation},
	volume       = 2,
	pages        = {1--3},
	url          = {https://www.youtube.com/watch?v=_3eyPUyqluc&t=0s},
	keywords     = {Computer Graphics Forum,EUROGRAPHICS}
}
@article{Weiss2020,
	title        = {Triplanar Displacement Mapping for Terrain Rendering},
	author       = {Sebastian Weiss and Rudiger Westermann and Florian Bayer},
	year         = 2020,
	journal      = {Eurographics 2020 - Short Papers},
	pages        = {4 pages},
	doi          = {10.2312/egs.20201016},
	issn         = {1017-4656},
	url          = {https://diglib.eg.org/handle/10.2312/egs20201016},
	abstract     = {Heightmap-based terrain representations are common in computer games and simulations. However, adding geometric details to such a representation during rendering on the GPU is difficult to achieve. In this paper, we propose a combination of triplanar mapping, displacement mapping, and tessellation on the GPU, to create extruded geometry along steep faces of heightmap-based terrain fields on-the-fky during rendering. The method allows rendering geometric details such as overhangs and boulders, without explicit triangulation. We further demonstrate how to handle collisions and shadows for the enriched geometry.},
	keywords     = {Computer Graphics Forum,EUROGRAPHICS}
}
@techreport{Ortiz2020,
	title        = {Introduction to sequential Gaussian simulation},
	author       = {Julian M. Ortiz},
	year         = 2020,
	pages        = {7--19},
	url          = {https://qspace.library.queensu.ca/handle/1974/28538},
	abstract     = {Geostatistics deals with two different problems: estimation and uncertainty quantifica-tion. MultiGaussian and indicator kriging allow determining the local uncertainty at every location. However, these methods do not permit quantifying uncertainty over a larger volume, or characterizing the expected variability in a sequence of points that will be transferred to another process. In this paper, the concept of geostatistical simulation is introduced along with an explanation about why it is necessary and how it is different from estimation. Sequential Gaussian simulation is introduced as one of the most used algorithms for multiGaussian simulation, and as a natural extension from multiGaussian kriging.},
	institution  = {Queen's University},
	keywords     = {preprint}
}
@article{Sharp2020,
	title        = {You can find geodesic paths in triangle meshes by just flipping edges},
	author       = {Nicholas Sharp and Keenan Crane},
	year         = 2020,
	journal      = {ACM Transactions on Graphics},
	volume       = 39,
	doi          = {10.1145/3414685.3417839},
	issn         = 15577368,
	url          = {https://www.cs.cmu.edu/~kmcrane/Projects/FlipOut/FlipOut.pdf},
	abstract     = {This paper introduces a new approach to computing geodesics on polyhedral surfaces - -the basic idea is to iteratively perform edge flips, in the same spirit as the classic Delaunay flip algorithm. This process also produces a triangulation conforming to the output geodesics, which is immediately useful for tasks in geometry processing and numerical simulation. More precisely, our FlipOut algorithm transforms a given sequence of edges into a locally shortest geodesic while avoiding self-crossings (formally: it finds a geodesic in the same isotopy class). The algorithm is guaranteed to terminate in a finite number of operations; practical runtimes are on the order of a few milliseconds, even for meshes with millions of triangles. The same approach is easily applied to curves beyond simple paths, including closed loops, curve networks, and multiply-covered curves. We explore how the method facilitates tasks such as straightening cuts and segmentation boundaries, computing geodesic B\'{e}zier curves, extending the notion of constrained Delaunay triangulations (CDT) to curved surfaces, and providing accurate boundary conditions for partial differential equations (PDEs). Evaluation on challenging datasets such as Thingi10k indicates that the method is both robust and efficient, even for low-quality triangulations.},
	issue        = 6,
	keywords     = {edge flip,geodesic,triangulation}
}
@article{Qili2020,
	title        = {Numerical simulation of the flow and erosion behavior of exhaust gas and particles in polysilicon reduction furnace},
	author       = {Wang Qili and Jia Binbin and Yu Mingquan and He Min and Li Xiaochuan and Sridhar Komarneni},
	year         = 2020,
	journal      = {Scientific Reports},
	publisher    = {Springer US},
	volume       = 10,
	pages        = {1--12},
	doi          = {10.1038/s41598-020-58529-y},
	issn         = 20452322,
	url          = {http://dx.doi.org/10.1038/s41598-020-58529-y https://www.nature.com/articles/s41598-020-58529-y.pdf},
	abstract     = {In order to study the flow and erosion behavior of gas-solid exhaust in the polysilicon reduction furnace, the flow characteristics of exhaust gas and silicon particles were analyzed. The flow model and erosion model of exhaust gas and silicon particles were established based on the gas-solid flow theory and the erosion theory. The erosion and wear behavior of the gas-solid mixture in the flow passage pipeline were studied by numerical simulation. The results show that the wear and erosion from Nos. 1 to 8 regions at the bottom of the ring were caused by silicon particles colliding with high angle. The wear and erosion of 2 regions from Nos. 9 to 10 at the outside of the up azimuth on both sides of loop pipe outlets, 4 regions from Nos. 11 to 14 on the upper and lower wall of single furnace main channel were severely affected wear regions, which is caused by silicon particles with low angle and high velocity. Through comparative analysis, the erosion of upper wall of single furnace main channel is most serious. Increased gas velocity, particle concentration and particle size will exacerbate the erosion and wear rate of the pipeline in polysilicon reduction furnace, but the distribution and development of severe wear zone would not be affected significantly.},
	issue        = 1,
	pmid         = 32024886
}
@phdthesis{Ecormier-nocca2020,
	title        = {Cr\'{e}ation d'\'{e}cosyst\`{e}mes coh\'{e}rents et anim\'{e}s : Apprentissage efficace \`{a} partir de donn\'{e}es partielles},
	author       = {Pierre Ecormier-Nocca},
	year         = 2020,
	url          = {https://tel.archives-ouvertes.fr/tel-03086483/document}
}
@article{Seidel2020,
	title        = {Artificial Intelligence and Video Game Creation: a Framework for the New Logic of Autonomous Design},
	author       = {Stefan Seidel and Nicholas Berente and Aron Lindberg and Kalle Lyytinen and Beno\^{\i}t Martinez and Jeffrey V. Nickerson},
	year         = 2020,
	journal      = {Journal of Digital Social Research},
	volume       = 2,
	pages        = {126--157},
	url          = {https://jdsr.se/ojs/index.php/jdsr/article/download/46/30},
	abstract     = {Autonomous, intelligent tools are reshaping all sorts of work practices, including innovative design work. These tools generate outcomes with little or no user intervention and produce designs of unprecedented complexity and originality, ushering profound changes to how organizations will design and innovate in future. In this paper, we formulate conceptual foundations to analyze the impact of autonomous design tools on design work. We proceed in two steps. First, we conceptualize autonomous design tools as `rational' agents which will participate in the design process. We show that such agency can be realized through two separate approaches of information processing: symbolic and connectionist. Second, we adopt control theory to unpack the relationships between the autonomous design tools, human actors involved in the design, and the environment in which the tools operate. The proposed conceptual framework lays a foundation for studying the new kind of material agency of autonomous design tools in organizational contexts. We illustrate the analytical value of the proposed framework by drawing on two examples from the development of Ubisoft's Ghost Recon Wildlands video game, which relied on such tools. We conclude this essay by constructing a tentative research agenda for the research into autonomous design tools and design work. Keywords:},
	issue        = 3,
	keywords     = {artificial intelligence,autonomous design tools,control,design,digital innovation,indiana,innovation,liechtenstein,organizing,university of liechtenstein,university of notre dame,usa,work}
}
@article{Fischer2020,
	title        = {AutoBiomes: procedural generation of multi-biome landscapes},
	author       = {Roland Fischer and Philipp Dittmann and Ren\'{e} Weller and Gabriel Zachmann},
	year         = 2020,
	journal      = {Visual Computer},
	volume       = 36,
	pages        = {2263--2272},
	doi          = {10.1007/s00371-020-01920-7},
	isbn         = {0037102001},
	issn         = {01782789},
	url          = {https://www.researchgate.net/profile/Gabriel-Zachmann/publication/343196448_AutoBiomes_procedural_generation_of_multi-biome_landscapes/links/5f258e7da6fdcccc43a058a8/AutoBiomes-procedural-generation-of-multi-biome-landscapes.pdf},
	abstract     = {Advances in computer technology and increasing usage of computer graphics in a broad field of applications lead to rapidly rising demands regarding size and detail of virtual landscapes. Manually creating huge, realistic looking terrains and populating them densely with assets is an expensive and laborious task. In consequence, (semi-)automatic procedural terrain generation is a popular method to reduce the amount of manual work. However, such methods are usually highly specialized for certain terrain types and especially the procedural generation of landscapes composed of different biomes is a scarcely explored topic. We present a novel system, called AutoBiomes, which is capable of efficiently creating vast terrains with plausible biome distributions and therefore different spatial characteristics. The main idea is to combine several synthetic procedural terrain generation techniques with digital elevation models (DEMs) and a simplified climate simulation. Moreover, we include an easy-to-use asset placement component which creates complex multi-object distributions. Our system relies on a pipeline approach with a major focus on usability. Our results show that our system allows the fast creation of realistic looking terrains.},
	issue        = {10-12},
	keywords     = {Biomes,Climate simulation,Digital elevation models,Procedural content generation,Terrain generation,Virtual worlds}
}
@article{Gasch2020,
	title        = {Procedural modelling of terrains with constraints},
	author       = {Cristina Gasch and Miguel Chover and Inmaculada Remolar and Cristina Rebollo},
	year         = 2020,
	journal      = {Multimedia Tools and Applications},
	publisher    = {Multimedia Tools and Applications},
	volume       = 79,
	pages        = {31125--31146},
	doi          = {10.1007/s11042-020-09476-3},
	issn         = 15737721,
	abstract     = {Terrain is an essential part of any outdoor environment and, consequently, many techniques have appeared that deal with the problem of its automatic generation, such as procedural modeling. One form to create terrains is using noise functions because its low computational cost and its random result. However, the randomness of these functions also makes it difficult to have any control over the result obtained. In order to solve the problem of lack of control, this paper presents a new method noise-based that allows procedural terrains creation with elevation constraints (GPS routes, points of interest and areas of interest). For this, the method establishes the restrictions as fixed values in the heightmap function and creates a system of equations to obtain all points that they depend this restrictions. In this way, the terrain obtained maintains the random noise, but including the desired restrictions. The paper also includes how we apply this method on large terrain models without losing resolution or increasing the computational cost excessively. The results show that our method makes it possible to integrate this kind of constraints with high accuracy and realism while preserving the natural appearance of the procedural generation.},
	issue        = {41-42},
	keywords     = {GPS routes,Perlin noise,Procedural generation,Terrain modelling}
}
@article{Pintore2020,
	title        = {State-of-the-art in Automatic 3D Reconstruction of Structured Indoor Environments},
	author       = {Giovanni Pintore and Claudio Mura and Fabio Ganovelli and Lizeth Fuentes-Perez and Renato Pajarola and Enrico Gobbetti},
	year         = 2020,
	journal      = {Computer Graphics Forum},
	volume       = 39,
	pages        = {667--699},
	doi          = {10.1111/cgf.14021},
	issn         = 14678659,
	url          = {https://diglib.eg.org/bitstream/handle/10.1111/cgf14021/v39i2pp667-699.pdf?sequence=1&isAllowed=y},
	abstract     = {Creating high-level structured 3D models of real-world indoor scenes from captured data is a fundamental task which has important applications in many fields. Given the complexity and variability of interior environments and the need to cope with noisy and partial captured data, many open research problems remain, despite the substantial progress made in the past decade. In this survey, we provide an up-to-date integrative view of the field, bridging complementary views coming from computer graphics and computer vision. After providing a characterization of input sources, we define the structure of output models and the priors exploited to bridge the gap between imperfect sources and desired output. We then identify and discuss the main components of a structured reconstruction pipeline, and review how they are combined in scalable solutions working at the building level. We finally point out relevant research issues and analyze research trends.},
	issue        = 2,
	keywords     = {CCS Concepts,Computer vision,Computer vision problems,Reconstruction,Shape inference,Shape modeling,\textbullet{} Applied computing \rightarrow{} Computer-aided design,\textbullet{} Computing methodologies \rightarrow{} Computer graphics}
}
@article{Sane2020,
	title        = {A Survey of Seed Placement and Streamline Selection Techniques},
	author       = {Sudhanshu Sane and Roxana Bujack and Christoph Garth and Hank Childs},
	year         = 2020,
	journal      = {Computer Graphics Forum},
	volume       = 39,
	pages        = {785--809},
	doi          = {10.1111/cgf.14036},
	issn         = 14678659,
	url          = {https://diglib.eg.org/bitstream/handle/10.1111/cgf14036/v39i3pp785-809.pdf?sequence=1&isAllowed=y},
	abstract     = {Streamlines are an extensively utilized flow visualization technique for understanding, verifying, and exploring computational fluid dynamics simulations. One of the major challenges associated with the technique is selecting which streamlines to display. Using a large number of streamlines results in dense, cluttered visualizations, often containing redundant information and occluding important regions, whereas using a small number of streamlines could result in missing key features of the flow. Many solutions to select a representative set of streamlines have been proposed by researchers over the past two decades. In this state-of-the-art report, we analyze and classify seed placement and streamline selection (SPSS) techniques used by the scientific flow visualization community. At a high-level, we classify techniques into automatic and manual techniques, and further divide automatic techniques into three strategies: density-based, feature-based, and similarity-based. Our analysis evaluates the identified strategy groups with respect to focus on regions of interest, minimization of redundancy, and overall computational performance. Finally, we consider the application contexts and tasks for which SPSS techniques are currently applied and have potential applications in the future.},
	issue        = 3,
	keywords     = {CCS Concepts,\textbullet{} Human-centered computing \rightarrow{} Scientific visualizat}
}
@article{Chaudhuri2020,
	title        = {Learning Generative Models of 3D Structures},
	author       = {Siddhartha Chaudhuri and Daniel Ritchie and Jiajun Wu and Kai Xu and Hao Zhang},
	year         = 2020,
	journal      = {Computer Graphics Forum},
	volume       = 39,
	pages        = {643--666},
	doi          = {10.1111/cgf.14020},
	issn         = 14678659,
	abstract     = {3D models of objects and scenes are critical to many academic disciplines and industrial applications. Of particular interest is the emerging opportunity for 3D graphics to serve artificial intelligence: computer vision systems can benefit from synthetically-generated training data rendered from virtual 3D scenes, and robots can be trained to navigate in and interact with real-world environments by first acquiring skills in simulated ones. One of the most promising ways to achieve this is by learning and applying generative models of 3D content: computer programs that can synthesize new 3D shapes and scenes. To allow users to edit and manipulate the synthesized 3D content to achieve their goals, the generative model should also be structure-aware: it should express 3D shapes and scenes using abstractions that allow manipulation of their high-level structure. This state-of-the-art report surveys historical work and recent progress on learning structure-aware generative models of 3D shapes and scenes. We present fundamental representations of 3D shape and scene geometry and structures, describe prominent methodologies including probabilistic models, deep generative models, program synthesis, and neural networks for structured data, and cover many recent methods for structure-aware synthesis of 3D shapes and indoor scenes.},
	issue        = 2,
	keywords     = {CCS Concepts,Deep learning,Hierarchical models,Neural networks,Representation of structured data,Shape and scene synthesis,\textbullet{} Computing methodologies \rightarrow{} Structure-aware genera}
}
@article{Layton2020,
	title        = {Kelp Forest Restoration in Australia},
	author       = {Cayne Layton and Melinda A. Coleman and Ezequiel M. Marzinelli and Peter D. Steinberg and Stephen E. Swearer and Adriana Verg\'{e}s and Thomas Wernberg and Craig R. Johnson},
	year         = 2020,
	journal      = {Frontiers in Marine Science},
	volume       = 7,
	pages        = {1--12},
	doi          = {10.3389/fmars.2020.00074},
	issn         = 22967745,
	abstract     = {Kelp forests dominate the rocky coasts of temperate Australia and are the foundation of the Great Southern Reef. Much like terrestrial forests, these marine forests create complex habitat for diverse communities of flora and fauna. Kelp forests also support coastal food-webs and valuable fisheries and provide a suite of additional ecosystem services. In many regions of Australia and around the world, kelp forests are in decline due to ocean warming, overgrazing, and pollution. One potential tool in the conservation and management of these important ecosystems is habitat restoration, the science and practice of which is currently undergoing substantial expansion. We summarize the present state of Australian kelp forests and emphasize that consideration of the initial drivers of kelp decline is a critical first step in restoration. With a focus on Australian examples, we review methods, implementation and outcomes of kelp forest restoration, and discuss suitable measures of success and the estimated costs of restoration activities. We propose a workflow and decision system for kelp forest restoration that identifies alternative pathways for implementation and acknowledges that under some circumstances restoration at scale is not possible or feasible. As a case study, we then apply the Society for Ecological Restoration's 5-star evaluation to Operation Crayweed, Australia's primary example of kelp forest restoration. Overall, no single method of kelp forest restoration is suitable for all situations, but outcomes can be optimized by ameliorating the driver(s) of kelp decline and achieving ongoing natural recruitment of kelp. Whilst scalability of kelp forest restoration to the seascape-scale remains a considerable challenge, the present review should provide a platform for future restoration efforts. However, it is also crucial to emphasize that the challenges of restoration place a high value on preventative conservation and protection of existing kelp forest ecosystems – prevention is invariably better than cure.},
	issue        = {February},
	keywords     = {Great Southern Reef,canopy,ecosystem,habitat-forming,macroalga,rehabilitation}
}
@article{Risandi2020,
	title        = {Shoreline Variability at a Reef-Fringed Pocket Beach},
	author       = {Johan Risandi and Jeff E. Hansen and Ryan J. Lowe and Dirk P. Rijnsdorp},
	year         = 2020,
	journal      = {Frontiers in Marine Science},
	volume       = 7,
	pages        = {1--16},
	doi          = {10.3389/fmars.2020.00445},
	issn         = 22967745,
	abstract     = {Pocket beaches bound by headlands or other geologic features are common worldwide and experience constrained alongshore transport that influences their morphological changes. Pocket beaches fringed by shallow reefs have not been well-studied, yet can be commonly found throughout temperate and tropical regions. The presence of a reef is expected to drive distinct hydrodynamic processes and shoreline responses to offshore waves and water levels, which is investigated in this study. To examine the drivers of shoreline variability, a 20-month field study was conducted on a reef-fringed pocket beach in southwestern Australia (Gnarabup Beach), using a series of in situ wave and water level observations, topographic surveys, as well as video shoreline monitoring. The results indicate that the beach as a whole (alongshore averaged) was in a mostly stable state. However, we observed substantial spatial variability of the local shorelines in response to offshore wave and water levels across a range of time-scales (from individual storms to the seasonal cycle). We observed local regions of beach rotation within cells that were partitioned by the headlands and offshore reefs. The shoreline response was also dictated by the combination of offshore waves and water level which varied seasonally, with the shoreline generally eroding with lower water levels for the same wave height. Despite the contrasting responses in different alongshore locations of the beach, the overall beach volume of the pocket beach was largely conserved.},
	issue        = {June},
	keywords     = {Western Australia,beach rotation,coastal erosion,pocket beach,rocky reef}
}
@article{Scott2020,
	title        = {Hydro-Morphological Characterization of Coral Reefs for Wave Runup Prediction},
	author       = {Fred Scott and Jose A. A. Antolinez and Robert McCall and Curt Storlazzi and Ad Reniers and Stuart Pearson},
	year         = 2020,
	month        = 5,
	journal      = {Frontiers in Marine Science},
	volume       = 7,
	pages        = {1--20},
	doi          = {10.3389/fmars.2020.00361},
	issn         = {2296-7745},
	url          = {https://www.frontiersin.org/article/10.3389/fmars.2020.00361/full},
	issue        = {May},
	keywords     = {cluster analysis,coral reefs,data mining,data mining, cluster analysis, K-means, coral reef,k-means,wave runup,xbeach}
}
@article{daSilva2020,
	title        = {Modelling three-dimensional flow over spur-and-groove morphology},
	author       = {Renan F. da Silva and Curt D. Storlazzi and Justin S. Rogers and Johan Reyns and Robert McCall},
	year         = 2020,
	journal      = {Coral Reefs},
	publisher    = {Springer Berlin Heidelberg},
	volume       = 39,
	pages        = {1841--1858},
	doi          = {10.1007/s00338-020-02011-8},
	issn         = 14320975,
	url          = {https://doi.org/10.1007/s00338-020-02011-8},
	abstract     = {Spur-and-groove (SAG) morphology characterizes the fore reef of many coral reefs worldwide. Although the existence and geometrical properties of SAG have been well documented, an understanding of the hydrodynamics over them is limited. Here, the three-dimensional flow patterns over SAG formations, and a sensitivity of those patterns to waves, currents, and SAG geometry were characterized using the physics-based Delft3D-FLOW and SWAN models. Shore-normal shoaling waves over SAG formations were shown to drive two circulation cells: a cell on the lower fore reef with offshore flow over the spurs and onshore flow over the grooves, except near the seabed where velocities were always onshore, and a cell on the upper fore reef with offshore surface velocities and onshore bottom currents, which result in depth-averaged onshore and offshore flow over the spurs and grooves, respectively. The mechanism driving this flow results from the net of the radiation stress gradients and pressure gradient, which is balanced by the Reynolds stress gradients and bottom friction that differ over the spur and over the groove. Waves were the primary driver of variations in modelled flow over SAG, with the flow strength increasing for increasing wave heights and periods. Spur height, SAG wavelength, and the water depth at peak spur height were the dominant influences on the hydrodynamics, with spur heights directly proportional to the strength of SAG circulation cells. SAG formations with shorter SAG wavelengths only presented one circulation cell on the shallower portion of the reef, as opposed to the two circulation cells for longer SAG wavelengths. SAG formations with peak spur heights occurring in shallower water had stronger circulation than those with peak spur heights occurring in deeper water. These hydrodynamic patterns also likely affect coral and reef development through sediment and nutrient fluxes.},
	issue        = 6,
	keywords     = {(3D) modelling,Coral reef,Currents,Delft3D,Spur-and-groove,Waves}
}
@article{Sous2020,
	title        = {On the small-scale fractal geometrical structure of a living coral reef barrier},
	author       = {Damien Sous and Fr\'{e}d\'{e}ric Bouchette and Erik Doerflinger and Samuel Meul\'{e} and Raphael Certain and Gwladys Toulemonde and Benjamin Dubarbier and Bernard Salvat},
	year         = 2020,
	journal      = {Earth Surface Processes and Landforms},
	volume       = 45,
	pages        = {3042--3054},
	doi          = {10.1002/esp.4950},
	issn         = 10969837,
	abstract     = {The topographical complexity of coral reefs is of primary importance for a number of hydrodynamical and ecological processes. The present study is based on a series of high-resolution seabottom elevation measurements along the Maupiti Barrier Reef, French Polynesia. Several statistical metrics and spectral analysis are used to characterize the spatial evolution of the coral geometrical structure from the reef crest to the backreef. A consistent fractal-like power law exists in the spectral density of bottom elevation for length scales between 0.1 and 7 m, while at larger scale, the reef structure shows a different pattern. Such a fine characterization of the reef geometrical structure provides key elements to reconstruct the reef history, to improve the representation of reef roughness in hydrodynamical models and to monitor the evolution of coral reef systems in the context of global change. \textcopyright{} 2020 John Wiley \& Sons, Ltd.},
	issue        = 12,
	keywords     = {coral reef,fractal law,high-resolution bathymetry,roughness,volcanic island}
}
@article{Masselink2020,
	title        = {Coral reef islands can accrete vertically in response to sea level rise},
	author       = {Gerd Masselink and Eddie Beetham and Paul Kench},
	year         = 2020,
	journal      = {Science Advances},
	volume       = 6,
	doi          = {10.1126/sciadv.aay3656},
	issn         = 23752548,
	abstract     = {Increased flooding due to sea level rise (SLR) is expected to render reef islands, defined as sandy or gravel islands on top of coral reef platforms, uninhabitable within decades. Such projections generally assume that reef islands are geologically inert landforms unable to adjust morphologically. We present numerical modeling results that show reef islands composed of gravel material are morphodynamically resilient landforms that evolve under SLR by accreting to maintain positive freeboard while retreating lagoonward. Such island adjustment is driven by wave overtopping processes transferring sediment from the beachface to the island surface. Our results indicate that such natural adaptation of reef islands may provide an alternative future trajectory that can potentially support near-term habitability on some islands, albeit with additional management challenges. Full characterization of SLR vulnerability at a given reef island should combine morphodynamic models with assessments of climate-related impacts on freshwater supplies, carbonate sediment supply, and future wave regimes.},
	issue        = 24,
	pmid         = 32577502
}
@article{Lange2020,
	title        = {A quick, easy and non-invasive method to quantify coral growth rates using photogrammetry and 3D model comparisons},
	author       = {Ines D. Lange and Chris T. Perry},
	year         = 2020,
	journal      = {Methods in Ecology and Evolution},
	volume       = 11,
	pages        = {714--726},
	doi          = {10.1111/2041-210X.13388},
	issn         = {2041210X},
	abstract     = {Coral growth rates vary significantly with environmental conditions and are thus important indicators of coral health and reef carbonate production. Despite the importance of this metric, data are sparse for most coral genera and species globally, including for many key reef-building species. Traditional methods to obtain growth rates, such as coral coring or staining with Alizarin are destructive and only work for a limited number of species and morphological growth forms. Emerging approaches, using underwater photogrammetry to create digital models of coral colonies, are providing novel and non-invasive ways to explore colony-scale growth patterns and to address existing knowledge gaps. We developed an easy-to-follow workflow to construct three-dimensional (3D) models from overlapping photographs and to measure linear, radial and vertical extension rates of branching, massive and encrusting corals after aligning colony models from subsequent years. The method presented here was applied to measure extension rates for 46 colonies of nine coral species in the remote Chagos Archipelago, Indian Ocean. Proposed image acquisition and software settings produced 3D models of consistently high resolution and detail (precision~\leq{}~0.2~mm) and variability in growth measurements was small despite manual alignment, clipping and ruler placement (SD~\leq{}~0.9~mm). Measured extension rates for the Chagos Archipelago are similar to published rates in the Indo-Pacific where comparable data are available, and provide the first published rates for several species. For encrusting corals, the results emphasize the importance of differentiating between radial and vertical growth. Photogrammetry and 3D model comparisons provide a fast, easy, inexpensive and non-invasive method to quantify coral growth rates for a range of species and morphological growth forms. The simplicity of the presented workflow encourages its repeatability and permits non-specialists to learn photogrammetry with the goal of obtaining linear coral growth rates. Coral growth rates are essential metrics to quantify functional consequences of ongoing community changes on coral reefs and expanded datasets for key coral taxa will aid predictions of geographic variations in coral reef response to increasing global stressors.},
	issue        = 6,
	keywords     = {3D model,Agisoft Metashape,Chagos Archipelago,CloudCompare,coral extension rates,coral growth rates,photogrammetry,structure-from-motion}
}
@article{Lehman2020,
	title        = {The surprising creativity of digital evolution: A collection of anecdotes from the evolutionary computation and artificial life research communities},
	author       = {Joel Lehman and Jeff Clune and Dusan Misevic},
	year         = 2020,
	journal      = {Artificial Life},
	volume       = 26,
	pages        = {274--306},
	doi          = {10.1162/artl_a_00319},
	issn         = 15309185,
	abstract     = {Evolution provides a creative fount of complex and subtle adaptations that often surprise the scientists who discover them. However, the creativity of evolution is not limited to the natural world: Artificial organisms evolving in computational environments have also elicited surprise and wonder from the researchers studying them. The process of evolution is an algorithmic process that transcends the substrate in which it occurs. Indeed, many researchers in the field of digital evolution can provide examples of how their evolving algorithms and organisms have creatively subverted their expectations or intentions, exposed unrecognized bugs in their code, produced unexpectedly adaptations, or engaged in behaviors and outcomes, uncannily convergent with ones found in nature. Such stories routinely reveal surprise and creativity by evolution in these digital worlds, but they rarely fit into the standard scientific narrative. Instead they are often treated as mere obstacles to be overcome, rather than results that warrant study in their own right. Bugs are fixed, experiments are refocused, and one-off surprises are collapsed into a single data point. The stories themselves are traded among researchers through oral tradition, but that mode of information transmission is inefficient and prone to error and outright loss. Moreover, the fact that these stories tend to be shared only among practitioners means that many natural scientists do not realize how interesting and lifelike digital organisms are and how natural their evolution can be. To our knowledge, no collection of such anecdotes has been published before. This article is the crowd-sourced product of researchers in the fields of artificial life and evolutionary computation who have provided first-hand accounts of such cases. It thus serves as a written, fact-checked collection of scientifically important and even entertaining stories. In doing so we also present here substantial evidence that the existence and importance of evolutionary surprises extends beyond the natural world, and may indeed be a universal property of all complex evolving systems.},
	issue        = 2,
	keywords     = {Creativity,Digital evolution,Evolutionary computation,Experimental evolution,Genetic algorithms,Surprise},
	pmid         = 32271631
}
@article{Nash2020,
	title        = {PolyGen: An autoregressive generative model of 3D meshes},
	author       = {Charlie Nash and Yaroslav Ganin and S. M.Ali Eslami and Peter W. Battaglia},
	year         = 2020,
	journal      = {37th International Conference on Machine Learning, ICML 2020},
	volume       = {PartF16814},
	pages        = {7177--7186},
	isbn         = 9781713821120,
	url          = {https://arxiv.org/pdf/2002.10880.pdf},
	abstract     = {Polygon meshes are an efficient representation of 3D geometry, and are of central importance in computer graphics, robotics and games development. Existing learning-based approaches for object synthesis have avoided the challenges of working with 3D meshes, instead using alternative object representations that are more compatible with neural architectures and training approaches. We present PolyGen, a generative model of 3D objects which models the mesh directly, predicting vertices and faces sequentially using a Transformer-based architecture. Our model can condition on a range of inputs, including object classes, voxels, and images, and because the model is probabilistic it can produce samples that capture uncertainty in ambiguous scenarios. We show that the model is capable of producing high-quality, usable meshes, and establish log-likelihood benchmarks for the mesh-modelling task. We also evaluate the conditional models on surface reconstruction metrics against alternative methods, and demonstrate competitive performance despite not training directly on this task.}
}
@article{Zia2020,
	title        = {PyFrac: A planar 3D hydraulic fracture simulator},
	author       = {Haseeb Zia and Brice Lecampion},
	year         = 2020,
	journal      = {Computer Physics Communications},
	volume       = 255,
	doi          = {10.1016/j.cpc.2020.107368},
	issn         = {00104655},
	url          = {https://arxiv.org/pdf/1908.10788.pdf},
	abstract     = {Fluid driven fractures propagate in the upper earth crust either naturally or in response to engineered fluid injections. The quantitative prediction of their evolution is critical in order to better understand their dynamics as well as to optimize their creation. We present an open-source Python implementation of a hydraulic fracture growth simulator based on the implicit level set algorithm originally developed by Peirce \& Detournay (2008). This algorithm couples a finite discretization of the fracture with the use of the near tip asymptotic solutions of a steadily propagating semi-infinite hydraulic fracture. This allows to resolve the multi-scale processes governing hydraulic fracture propagation accurately, even on relatively coarse meshes. We present an overview of the mathematical formulation, the numerical scheme and the details of our implementation. A series of problems including a radial hydraulic fracture verification test, the propagation of a height contained hydraulic fracture, the lateral spreading of a magmatic dyke and an example of fracture closure are presented to demonstrate the capabilities, accuracy and robustness of the implemented algorithm. Program summary: Program title: PyFrac CPC Library link to program files: http://dx.doi.org/10.17632/gv7yy9mmwj.1 Licensing provisions: GPLv3 Programming language: Python Nature of problem: Simulation of the propagation and closure of a planar three-dimensional hydraulic fracture driven by the injection of a Newtonian fluid in a material having heterogeneous fracture toughness under a non-uniform in-situ stress field. Solution method: The fully coupled hydro-mechanical moving boundary problem is solved combining a finite volume scheme for lubrication flow with a boundary element method for elasticity. The algorithm couples a finite scale discretization of the fracture with the near-tip asymptotic solution of a steadily moving hydraulic fracture. The fracture front is tracked via a level set approach using a fast marching method.},
	keywords     = {Fracture propagation,Hydraulic fracture,Level set,Non-linear moving boundary problem}
}
@article{Koenig2020,
	title        = {Identifying lateral boundary conditions for the M2 tide in a coastal model using a stochastic gradient descent algorithm},
	author       = {Guillaume Koenig and Clement Aldebert and Cristele Chevalier and Jean Luc Devenon},
	year         = 2020,
	journal      = {Ocean Modelling},
	volume       = 156,
	pages        = {0--45},
	doi          = {10.1016/j.ocemod.2020.101709},
	issn         = 14635003,
	abstract     = {While lateral boundary conditions are crucial for the physical modeling of ocean dynamics, their estimation may lack accuracy in coastal regions. Data-assimilation has long been used to improve accuracy, but most of the widely-used methods are difficult to implement. We tried a new and an easy-to-implement method to estimate boundary conditions. This method uses data assimilation with a stochastic gradient descent and successive approximations of the boundary conditions. We tested it with twin experiments and a more realistic setting on a tidal model in the lagoon of Ouano, in New-Caledonia. The method proved successful and provided good estimation of the boundary conditions with various settings of subsampling and noise for the pseudo-data in the twin experiments, but there were important oscillations in the experiments with more realistic settings. Here we present those results and discuss the use of our new and easy-to-implement method.},
	keywords     = {Data assimilation,Parameters identification,Stochastic algorithms,Tidal modeling}
}
@article{Kapp2020,
	title        = {Data-driven authoring of large-scale ecosystems},
	author       = {Konrad Kapp and James Gain and Eric Gu\'{e}rin and Eric Galin and Adrien Peytavie},
	year         = 2020,
	month        = 11,
	journal      = {ACM Transactions on Graphics},
	publisher    = {Association for Computing Machinery},
	volume       = 39,
	doi          = {10.1145/3414685.3417848},
	issn         = 15577368,
	abstract     = {In computer graphics populating a large-scale natural scene with plants in a fashion that both reflects the complex interrelationships and diversity present in real ecosystems and is computationally efficient enough to support iterative authoring remains an open problem. Ecosystem simulations embody many of the botanical influences, such as sunlight, temperature, and moisture, but require hours to complete, while synthesis from statistical distributions tends not to capture fine-scale variety and complexity. Instead, we leverage real-world data and machine learning to derive a canopy height model (CHM) for unseen terrain provided by the user. Trees in the canopy layer are then fitted to the resulting CHM through a constrained iterative process that optimizes for a given distribution of species, and, finally, an understorey layer is synthesised using distributions derived from biome-specific undergrowth simulations. Such a hybrid data-driven approach has the advantage that it incorporates subtle biotic, abiotic, and disturbance factors implicitly encoded in the source data and evidences accepted biological behaviour, such as self-thinning, climatic adaptation, and gap dynamics.},
	issue        = 6,
	keywords     = {ecosystem simulation,natural phenomena}
}
@article{Kim2020,
	title        = {Graph Based Wave Function Collapse Algorithm for Procedural Content Generation in Games},
	author       = {Hwanhee Kim and Teasung Hahn and Sookyun Kim and Shinjin Kang},
	year         = 2020,
	month        = 8,
	journal      = {IEICE Transactions on Information and Systems},
	volume       = {E103.D},
	pages        = {1901--1910},
	doi          = {10.1587/transinf.2019EDP7295},
	issn         = {0916-8532},
	url          = {https://www.jstage.jst.go.jp/article/transinf/E103.D/8/E103.D_2019EDP7295/_article},
	abstract     = {This paper describes graph-based Wave Function Collapse algorithm for procedural content generation. The goal of this system is to enable a game designer to procedurally create key content elements in the game level through simple association rule input. To do this, we propose a graph-based data structure that can be easily integrated with a navigation mesh data structure in a three-dimensional world. With our system, if the user inputs the minimum association rule, it is possible to effectively perform procedural content generation in the three-dimensional world. The experimental results show that the Wave Function Collapse algorithm, which is a texture synthesis algorithm, can be extended to non-grid shape content with high controllability and scalability.},
	issue        = 8,
	keywords     = {Game Content,Navigation Mesh,Procedural Content Generation (PCG),Voronoi Diagram,Wave Function Collapse (WFC)}
}
@article{Yan2020,
	title        = {Numerical simulation of rockfall trajectory with consideration of arbitrary shapes of falling rocks and terrain},
	author       = {Peng Yan and Jinhua Zhang and Xiangzhen Kong and Qin Fang},
	year         = 2020,
	month        = 6,
	journal      = {Computers and Geotechnics},
	publisher    = {Elsevier Ltd},
	volume       = 122,
	doi          = {10.1016/j.compgeo.2020.103511},
	issn         = 18737633,
	abstract     = {This paper proposes a 3D model for analyzing the rockfall trajectory within the framework of contact mechanics and rigid body dynamics, focusing on arbitrary shapes of the falling rock and terrain. Firstly, the sphericity and the concavity and convexity are defined to quantitatively describe the overall shape and local appearance of often-observed falling rocks, respectively. A generation algorithm is then proposed to generate falling rock and terrain with arbitrary shapes. The surfaces of the generated falling rock and terrain model are both meshed by triangular elements. A contact searching algorithm as well as a bilinear model for contact collision are presented to solve the interaction between the falling rock and terrain. Validated by available field test data, it is demonstrated that the proposed approach could simulate the four motion modes of rockfall such as falling, bouncing, rolling and sliding, as well as the transition between them.},
	keywords     = {3D modeling,Arbitrary shape,Contact collision,Rigid body dynamics,Rockfall trajectory}
}
@article{Menshutina2020,
	title        = {Cellular Automata in Chemistry and Chemical Engineering},
	author       = {Natalia V Menshutina and Andrey V Kolnoochenko and Evgeniy A Lebedev},
	year         = 2020,
	doi          = {10.1146/annurev-chembioeng},
	url          = {https://doi.org/10.1146/annurev-chembioeng-},
	abstract     = {We review the modern state of cellular automata (CA) applications for solving practical problems in chemistry and chemical technology. We consider the problems of material structure modeling and prediction of materials' morphology-dependent properties. We review the use of the CA approach for modeling diffusion, crystallization, dissolution, erosion, corrosion, ad-sorption, and hydration processes. We also consider examples of hybrid CA-based models, which are combinations of various CA with other computational approaches and modeling methods. Finally, we discuss the use of high-performance parallel computing to increase the efficiency of CA.},
	keywords     = {cellular automata,chemical engineering,chemistry}
}
@article{Temucin2020,
	title        = {Using Cellular Automata as a Basis for Procedural Generation of Organic Cities},
	author       = {Melek B. Temu\c{c}in and \.{I}lker Kocaba\c{s} and Kaya O\u{g}uz},
	year         = 2020,
	month        = 12,
	journal      = {European Journal of Engineering Research and Science},
	publisher    = {European Open Access Publishing (Europa Publishing)},
	volume       = 5,
	pages        = {116--120},
	doi          = {10.24018/ejers.2020.5.12.2293},
	abstract     = {Procedural content generation (PCG) methods are commonly employed in computer games, simulations, and other related industries. While these methods are used for levels, terrains, stories and missions, their usage for procedural city generation is relatively rare because cities are heterogeneous structures with different components such as roads, layouts and buildings that depend on and affect each other. Additionally, ancient cities grew organically to areas that are safe and to those that provide food and water. This resulted in cities that do not have apparent regular patterns, such as rectangular building blocks. We propose an approach that uses cellular automata (CA) that generates clusters of areas. The CA is repeated for each cluster to hierarchically create different levels of the city. This procedure creates an organic city layout with fractal properties. The layout specifies the building blocks, main roads, and foliage. We also present a set of methods that can transform this layout into a three-dimensional model of the city. The results are promising; cities can be created in under a minute with minimal required input, and the resulting virtual city looks organic, rather than an algorithmic layout that has repeating patterns. ~},
	issue        = 12
}
@misc{Zhang2020,
	title        = {An overview of agent-based models in plant biology and ecology},
	author       = {Bo Zhang and Donald L. Deangelis},
	year         = 2020,
	month        = 9,
	journal      = {Annals of Botany},
	publisher    = {Oxford University Press},
	volume       = 126,
	pages        = {539--557},
	doi          = {10.1093/aob/mcaa043},
	issn         = 10958290,
	abstract     = {Agent-based modelling (ABM) has become an established methodology in many areas of biology, ranging from the cellular to the ecological population and community levels. In plant science, two different scales have predominated in their use of ABM. One is the scale of populations and communities, through the modelling of collections of agents representing individual plants, interacting with each other and with the environment. The other is the scale of the individual plant, through the modelling, by functional-structural plant models (FSPMs), of agents representing plant building blocks, or metamers, to describe the development of plant architecture and functions within individual plants. The purpose of this review is to show key results and parallels in ABM for growth, mortality, carbon allocation, competition and reproduction across the scales from the plant organ to populations and communities on a range of spatial scales to the whole landscape. Several areas of application of ABMs are reviewed, showing that some issues are addressed by both population-level ABMs and FSPMs. Continued increase in the relevance of ABM to environmental science and management will be helped by greater integration of ABMs across these two scales.},
	issue        = 4,
	keywords     = {Population-level models,environmental gradients,forest succession,functional-structural plant models,gap phase models,global change,invasive plants,plant carbon allocation,spatial patterns,spatial scaling},
	pmid         = 32173742
}
@inproceedings{Dunbabin2020,
	title        = {Uncrewed Maritime Systems for Coral Reef Conservation},
	author       = {Matthew Dunbabin and Justin Manley and Peter L. Harrison},
	year         = 2020,
	month        = 10,
	booktitle    = {2020 Global Oceans 2020: Singapore - U.S. Gulf Coast},
	publisher    = {Institute of Electrical and Electronics Engineers Inc.},
	doi          = {10.1109/IEEECONF38699.2020.9389173},
	isbn         = 9781728154466,
	abstract     = {This paper provides an overview of demonstrated and emerging work applying Uncrewed Maritime Systems (UMS) to coral reef conservation. It blends theoretical analysis and current field results with a focus on recent developments in Australia. Here a combination of Autonomous Underwater Vehicles (AUVs) and Uncrewed Surface Vehicles (USVs) are being used to support restoration of coral communities on the Great Barrier Reef. In 2018 and 2019, UMS were evaluated to assist in the 'planting' of coral larvae during the reef's annual sexual reproduction periods. Scientific results on actual coral larval settlement and recruitment, and hence coral community restoration using these techniques is showing promise but are beyond the scope of this paper. This paper focuses on the technical challenges and opportunities around employing AUVs and USVs for reef restoration at scale. These include: reduction in platform cost, management of larvae supply, precision of larvae placement and user interface/autonomy. This paper examines the field use of the existing prototype robots from recent on-reef trials and hypothesizes solutions to increase efficiency of larval distribution.}
}
@article{Careil2020,
	title        = {Interactively Modifying Compressed Sparse Voxel Representations},
	author       = {V. Careil and M. Billeter and E. Eisemann},
	year         = 2020,
	month        = 5,
	journal      = {Computer Graphics Forum},
	volume       = 39,
	pages        = {111--119},
	doi          = {10.1111/cgf.13916},
	issn         = {0167-7055},
	url          = {https://onlinelibrary.wiley.com/doi/10.1111/cgf.13916},
	abstract     = {<p>Voxels are a popular choice to encode complex geometry. Their regularity makes updates easy and enables random retrieval of values. The main limitation lies in the poor scaling with respect to resolution. Sparse voxel DAGs (Directed Acyclic Graphs) overcome this hurdle and offer high-resolution representations for real-time rendering but only handle static data. We introduce a novel data structure to enable interactive modifications of such compressed voxel geometry without requiring de- and recompression. Besides binary data to encode geometry, it also supports compressed attributes (e.g., color). We illustrate the usefulness of our representation via an interactive large-scale voxel editor (supporting carving, filling, copying, and painting).</p>},
	issue        = 2,
	keywords     = {CCS,Computing methodologies \rightarrow{},Concepts \textbullet{},Volumetric models;}
}
@inproceedings{Kelvin2020,
	title        = {Procedural Generation of Roads with Conditional Generative Adversarial Networks},
	author       = {Lin Ziwen Kelvin and Anand Bhojan},
	year         = 2020,
	month        = 8,
	booktitle    = {ACM SIGGRAPH 2020 Posters, SIGGRAPH 2020},
	publisher    = {Association for Computing Machinery},
	doi          = {10.1145/3388770.3407422},
	isbn         = 9781450379731,
	abstract     = {Procedural terrain generation refers to the generation of terrain features, such as landscaping, rivers or road networks, through the use of algorithms, with minimal input required from the user. In the process of game development, generating terrain is often an important part of the game development process. Traditional generation methods are often too time consuming especially with larger terrain maps. On the other hand, procedural methods that generate terrain automatically often do not have much user control over the output. We explore the usage of conditional generative adversarial networks in the creation of road maps, as well as the application of such road maps in the creation of game levels in game development engines such as Unreal Engine 4.}
}
@article{Vimont2020,
	title        = {Interactive Meso-scale Simulation of Skyscapes},
	author       = {Ulysse Vimont and James Gain and Maud Lastic and Guillaume Cordonnier and Babatunde Abiodun and Marie Paule Cani},
	year         = 2020,
	month        = 5,
	journal      = {Computer Graphics Forum},
	publisher    = {Blackwell Publishing Ltd},
	volume       = 39,
	pages        = {585--596},
	doi          = {10.1111/cgf.13954},
	issn         = 14678659,
	abstract     = {Although an important component of natural scenes, the representation of skyscapes is often relatively simplistic. This can be largely attributed to the complexity of the thermodynamics underpinning cloud evolution and wind dynamics, which make interactive simulation challenging. We address this problem by introducing a novel layered model that encompasses both terrain and atmosphere, and supports efficient meteorological simulations. The vertical and horizontal layer resolutions can be tuned independently, while maintaining crucial inter-layer thermodynamics, such as convective circulation and land-air transfers of heat and moisture. In addition, we introduce a cloud-form taxonomy for clustering, classifying and upsampling simulation cells to enable visually plausible, finely-sampled volumetric rendering. As our results demonstrate, this pipeline allows interactive simulation followed by up-sampled rendering of extensive skyscapes with dynamic clouds driven by consistent wind patterns. We validate our method by reproducing characteristic phenomena such as diurnal shore breezes, convective cells that contribute to cumulus cloud formation, and orographic effects from moist air driven upslope.},
	issue        = 2,
	keywords     = {Eulerian simulation,procedural modeling}
}
@inproceedings{Kopel2020,
	title        = {Comparison of Procedural Noise-Based Environment Generation Methods},
	author       = {Marek Kopel and Grzegorz Maciejewski},
	year         = 2020,
	booktitle    = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	publisher    = {Springer Science and Business Media Deutschland GmbH},
	volume       = {12496 LNAI},
	pages        = {878--887},
	doi          = {10.1007/978-3-030-63007-2_69},
	isbn         = 9783030630065,
	issn         = 16113349,
	abstract     = {In this paper a comparison of selected algorithms used to procedurally generate terrain for video games is presented. The algorithms' performance is tested with two implementation environments: Unity and Godot. Results are aggregated and discussed. Conclusions drawn are of two types: intuitive and counter-intuitive.},
	keywords     = {Environment,Game world,Procedural generation,Terrain,Video game}
}
@inproceedings{Krs2020,
	title        = {Wind Erosion: Shape Modifications by Interactive Particle-based Erosion and Deposition},
	author       = {V. Krs and T. H\"{a}drich and D. L. Michels and Oliver Deussen and Soren Pirk and Benes Benes},
	year         = 2020,
	booktitle    = {19th ACM SIGGRAPH / Eurographics Symposium on Computer Animation 2020, SCA 2020 - Posters},
	publisher    = {The Eurographics Association},
	pages        = {9--11},
	doi          = {10.2312/sca.20201216},
	abstract     = {We present a novel user-assisted method for physics-inspired modeling of geomorphological features on polygonal meshes using material erosion and deposition as the driving mechanisms. Polygonal meshes defining an input scene are converted into a volumetric data structure that efficiently tracks the mass and boundary of the resulting morphological changes. We use Smoothed Particle Hydrodynamics to simulate fluids and to track eroded material. Eroded material is converted to material particles and naturally deposits in locations such as sinks and corners. Once deposited, we convert material particles back into the volumetric representation.}
}
@techreport{Huppert2020,
	title        = {Hotspot swells and the lifespan of volcanic ocean islands},
	author       = {Kimberly L Huppert and J Taylor Perron and Leigh H Royden},
	year         = 2020,
	url          = {https://www.science.org},
	abstract     = {Volcanic ocean islands generally form on swells-seafloor that is shallower than expected for its age over areas hundreds to more than a thousand kilometers wide-and ultimately subside to form atolls and guyots (flat-topped seamounts). The mechanisms of island drowning remain enigmatic, however, and the subaerial lifespan of volcanic islands varies widely. We examine swell bathymetry and island drowning at 14 hotspots and find a correspondence between island lifespan and residence time atop swell bathymetry, implying that islands drown as tectonic plate motion transports them past mantle sources of swell uplift. This correspondence argues strongly for dynamic uplift of the lithosphere at ocean hotspots. Our results also explain global variations in island lifespan, which influence island topography, biodiversity, and climate.}
}
@techreport{Kovacs2020,
	title        = {Reef Cover Classification Coral reef internal class descriptors for global habitat mapping},
	author       = {E Kovacs and M Lyons and Borrego-Acevedo R Roe and Yuwono D and Wolff J and Tudman P and Murray N and Phinn S},
	year         = 2020
}
@article{Zhu2020,
	title        = {Spatial interpolation using conditional generative adversarial neural networks},
	author       = {Di Zhu and Ximeng Cheng and Fan Zhang and Xin Yao and Yong Gao and Yu Liu},
	year         = 2020,
	month        = 4,
	journal      = {International Journal of Geographical Information Science},
	publisher    = {Taylor and Francis Ltd.},
	volume       = 34,
	pages        = {735--758},
	doi          = {10.1080/13658816.2019.1599122},
	issn         = 13623087,
	abstract     = {Spatial interpolation is a traditional geostatistical operation that aims at predicting the attribute values of unobserved locations given a sample of data defined on point supports. However, the continuity and heterogeneity underlying spatial data are too complex to be approximated by classic statistical models. Deep learning models, especially the idea of conditional generative adversarial networks (CGANs), provide us with a perspective for formalizing spatial interpolation as a conditional generative task. In this article, we design a novel deep learning architecture named conditional encoder-decoder generative adversarial neural networks (CEDGANs) for spatial interpolation, therein combining the encoder-decoder structure with adversarial learning to capture deep representations of sampled spatial data and their interactions with local structural patterns. A case study on elevations in China demonstrates the ability of our model to achieve outstanding interpolation results compared to benchmark methods. Further experiments uncover the learned spatial knowledge in the model's hidden layers and test the potential to generalize our adversarial interpolation idea across domains. This work is an endeavor to investigate deep spatial knowledge using artificial intelligence. The proposed model can benefit practical scenarios and enlighten future research in various geographical applications related to spatial prediction.},
	issue        = 4,
	keywords     = {Spatial interpolation,deep learning,encoder-decoder,generative adversarial networks,spatial prediction}
}
@article{Paris2020,
	title        = {Modeling Rocky Scenery using Implicit Blocks},
	author       = {Axel Paris and Adrien Peytavie and Eric Gu\'{e}rin and Jean-Michel Dischler and Eric Galin},
	year         = 2020,
	journal      = {The Visual Computer},
	volume       = 36,
	pages        = {2251--2261},
	doi          = {10.1007/s00371-020-01905},
	url          = {https://hal.science/hal-02926218v2},
	abstract     = {We present a novel geologically-based method to generate vertical walls of rocky cliffs, crags or promontories. Our method procedurally generates a distribution of fractures in the bedrock to create a set of tiling blocks defined as implicit volumetric primitives. Blocks are in turn implicitly replicated over the vertical parts of the terrain and combined together to obtain a consistent volumetric representation of the fractured bedrock patterns using generalized union and blending operators. Our framework provides multiple levels of control: in addition to automatically generated blocks, the geometry of specific ones can be prescribed by the user using implicit primitives or construction trees, the shape of the blocks can be controlled by several parameters , and the placement rules may adapt according to the underlying geological strata and geometry of the terrain.},
	issue        = 10,
	keywords     = {Implicit surfaces \cdot{},Modeling,Procedural,Synthesis \cdot{},Terrain}
}
@article{Bender2020,
	title        = {Implicit Frictional Boundary Handling for SPH},
	author       = {Jan Bender and Tassilo Kugelstadt and Marcel Weiler and Dan Koschier},
	year         = 2020,
	month        = 10,
	journal      = {IEEE Transactions on Visualization and Computer Graphics},
	publisher    = {IEEE Computer Society},
	volume       = 26,
	pages        = {2982--2993},
	doi          = {10.1109/TVCG.2020.3004245},
	issn         = {1077-2626},
	url          = {https://ieeexplore.ieee.org/document/9123549/},
	abstract     = {In this article, we present a novel method for the robust handling of static and dynamic rigid boundaries in Smoothed Particle Hydrodynamics (SPH) simulations. We build upon the ideas of the density maps approach which has been introduced recently by Koschier and Bender. They precompute the density contributions of solid boundaries and store them on a spatial grid which can be efficiently queried during runtime. This alleviates the problems of commonly used boundary particles, like bumpy surfaces and inaccurate pressure forces near boundaries. Our method is based on a similar concept but we precompute the volume contribution of the boundary geometry. This maintains all benefits of density maps but offers a variety of advantages which are demonstrated in several experiments. First, in contrast to the density maps method we can compute derivatives in the standard SPH manner by differentiating the kernel function. This results in smooth pressure forces, even for lower map resolutions, such that precomputation times and memory requirements are reduced by more than two orders of magnitude compared to density maps. Furthermore, this directly fits into the SPH concept so that volume maps can be seamlessly combined with existing SPH methods. Finally, the kernel function is not baked into the map such that the same volume map can be used with different kernels. This is especially useful when we want to incorporate common surface tension or viscosity methods that use different kernels than the fluid simulation.},
	issue        = 10,
	keywords     = {Smoothed particle hydrodynamics,boundary handling,fluid simulation},
	pmid         = 32746269
}
@article{Bertasius,
	title        = {Is Space-Time Attention All You Need for Video Understanding?},
	author       = {Gedas Bertasius and Heng Wang and Lorenzo Torresani},
	year         = 2021,
	month        = 2,
	url          = {http://arxiv.org/abs/2102.05095},
	abstract     = {We present a convolution-free approach to video classification built exclusively on self-attention over space and time. Our method, named "TimeSformer," adapts the standard Transformer architecture to video by enabling spatiotemporal feature learning directly from a sequence of frame-level patches. Our experimental study compares different self-attention schemes and suggests that "divided attention," where temporal attention and spatial attention are separately applied within each block, leads to the best video classification accuracy among the design choices considered. Despite the radically new design, TimeSformer achieves state-of-the-art results on several action recognition benchmarks, including the best reported accuracy on Kinetics-400 and Kinetics-600. Finally, compared to 3D convolutional networks, our model is faster to train, it can achieve dramatically higher test efficiency (at a small drop in accuracy), and it can also be applied to much longer video clips (over one minute long). Code and models are available at: https://github.com/facebookresearch/TimeSformer.}
}
@phdthesis{GashGarcia2021,
	title        = {Procedural Generation of Natural Environnements},
	author       = {Cristina Gash Garcia},
	year         = 2021,
	isbn         = 2019106426,
	note         = {Use of height maps (only ?)},
	abstract     = {that allow generating complex environments, although they do not usually allow control of the final result. However, these environments need real-time visualization techniques that can handle all the generated geometry interactively. In this sense, the main objective of the thesis is to present a series of methods developed with the intention of controlling the final result in procedural generation and improving the visualization of natural environments. On one side, a new method of procedural terrain generation based on noise functions is presented, which results in a pseudo-random terrain that precisely complies with the height restrictions given in advance. In addition to this, a user-assisted process tree and plant distribution method is introduced, which uses biological constraints on plant species. Finally, to improve the visualization of natural environments. On one side, a new method of procedural terrain generation based on noise functions is presented, which results in a pseudo-random terrain that precisely complies with the height restrictions given in advance. In addition to this, a user-assisted process tree and plant distribution method is introduced, which uses biological constraints on plant species. Finally, to improve the visualization of natural environments, a technique is presented to simplify the foliage of natural elements. This technique is based on mutual information from the point of view and a continuous multiresolution model that uses this technique to display different resolutions of the element according to its importance in the scene, allowing interactive visualization of the natural environment.}
}
@inproceedings{Sauer2021,
	title        = {Testing AGV Mobility Control Method for MANET Coverage Optimization using Procedural Generation},
	author       = {Christian Sauer and Eike Lyczkowski and Marco Schmidt and Andreas N\"{u}chter and Tobias Ho\ss{}feld},
	year         = 2021,
	month        = 11,
	booktitle    = {Proceedings of the 24th International ACM Conference on Modeling, Analysis and Simulation of Wireless and Mobile Systems},
	publisher    = {ACM},
	volume       = 1,
	pages        = {13--22},
	doi          = {10.1145/3479239.3485724},
	isbn         = 9781450390774,
	url          = {https://dl.acm.org/doi/10.1145/3479239.3485724},
	city         = {New York, NY, USA},
	issue        = 1,
	keywords     = {Coverage Optimization,Industrial Application,Mobile Ad-hoc Network,Mobile Robotics,Procedural Generation,all or part of,coverage optimization,industrial application,mobile ad-hoc network,mobile robotics,or,or hard copies of,permission to make digital,procedural generation,this work for personal}
}
@article{Pyarelal2021,
	title        = {Modular Procedural Generation for Voxel Maps},
	author       = {Adarsh Pyarelal and Aditya Banerjee and Kobus Barnard},
	year         = 2021,
	month        = 4,
	doi          = {10.1007/978-3-031-21671-8_6},
	url          = {http://arxiv.org/abs/2104.08890 http://dx.doi.org/10.1007/978-3-031-21671-8_6},
	abstract     = {Task environments developed in Minecraft are becoming increasingly popular for artificial intelligence (AI) research. However, most of these are currently constructed manually, thus failing to take advantage of procedural content generation (PCG), a capability unique to virtual task environments. In this paper, we present mcg, an open-source library to facilitate implementing PCG algorithms for voxel-based environments such as Minecraft. The library is designed with human-machine teaming research in mind, and thus takes a 'top-down' approach to generation, simultaneously generating low and high level machine-readable representations that are suitable for empirical research. These can be consumed by downstream AI applications that consider human spatial cognition. The benefits of this approach include rapid, scalable, and efficient development of virtual environments, the ability to control the statistics of the environment at a semantic level, and the ability to generate novel environments in response to player actions in real time.}
}
@misc{Fleming2021,
	title        = {Procedural Generation Algorithms and Why Use Them Over Machine Learning},
	author       = {Nicholaus Fleming},
	year         = 2021,
	abstract     = {Procedural generation is a particularly interesting feature that appears in some video games. This concept is a type of algorithm that was designed to allow a computer to generate specific content in a seemingly random manner, such as 3-dimensional and 2-dimensional assets in video games. Although, most players do not have a great understanding of how they work, only that when used in games, the algorithm is directly tied to a line of text and numbers called a seed. The question is, how does it work, and more importantly, why would one use either procedural generation or newer content generating algorithms that have come up in recent years like machine learning when creating digital assets?}
}
@phdthesis{Dey2021,
	title        = {Procedural Generation of Features for Volumetric Terrains using a Rule-Based Approach},
	author       = {Rahul Dey},
	year         = 2021
}
@article{Paris2021,
	title        = {Synthesizing Geologically Coherent Cave Networks},
	author       = {Axel Paris and \'{E}ric Gu\'{e}rin and Adrien Peytavie and Pauline Collon and \'{E}ric Galin},
	year         = 2021,
	month        = 10,
	journal      = {Computer Graphics Forum},
	volume       = 40,
	pages        = {277--287},
	doi          = {10.1111/cgf.14420},
	issn         = {0167-7055},
	url          = {https://onlinelibrary.wiley.com/doi/10.1111/cgf.14420},
	note         = {Des points plus ou moins faibles sont r\'{e}partis selon une distribution de Poisson Sampling dans le sol.<br/>Une ou plusieurs sources (Sink) sont d\'{e}finies, une ou plusieurs sorties sont definies (Spring).<br/>Un graphe est cr\'{e}\'{e} en utilisant tous les points de Poisson comme nodes, et le chemin principal est choisi en utilisant un pathfinder (A\textasteriskcentered ou Djikstra).<br/><br/>Les poids de chaque est d\'{e}fini en fonction des nodes d'apr\`{e}s sa position par rapport \`{a} sa distance avec un niveau d'eau (sur l'axe Z), sa distance par rapport \`{a} une \&quot;sph\`{e}re de porosit\'{e}\&quot;},
	abstract     = {<p>We present a geologically-based method to generate complex karstic networks. Karsts are a type of landscape formed by the dissolution of highly soluble rocks (generally limestones). In particular, they are characterized by complex underground networks made of varieties of tunnels and breakout chambers with stalagmites and stalactites. Our method computes skeletons of karstic networks by using a gridless anisotropic shortest path algorithm according to field data of the underground system (such as inlets and outlets), geomorphological features and parameters such as faults, inception horizons, fractures, and permeability contrasts. From this skeleton, we define the geometry of the conduits as a signed distance function construction tree combining primitives with blending and warping operators. Our framework provides multiple levels of control, allowing us to author both the structure of the karstic network and the geometric cross-section shapes and details of the generated conduits.</p>},
	issue        = 7,
	keywords     = {Computer Graphics Forum,EUROGRAPHICS,caves,implicit surfaces,karstic networks,procedural modeling}
}
@article{Metzer2021,
	title        = {Self-Sampling for Neural Point Cloud Consolidation},
	author       = {Gal Metzer and Rana Hanocka and Raja Giryes and Daniel Cohen-Or},
	year         = 2021,
	journal      = {ACM Transactions on Graphics},
	volume       = 40,
	pages        = {1--14},
	doi          = {10.1145/3470645},
	issn         = {0730-0301},
	abstract     = {We introduce a novel technique for neural point cloud consolidation which learns from only the input point cloud. Unlike other point up-sampling methods which analyze shapes via local patches, in this work, we learn from global subsets. We repeatedly self-sample the input point cloud with global subsets that are used to train a deep neural network. Specifically, we define source and target subsets according to the desired consolidation criteria (e.g., generating sharp points or points in sparse regions). The network learns a mapping from source to target subsets, and implicitly learns to consolidate the point cloud. During inference, the network is fed with random subsets of points from the input, which it displaces to synthesize a consolidated point set. We leverage the inductive bias of neural networks to eliminate noise and outliers, a notoriously difficult problem in point cloud consolidation. The shared weights of the network are optimized over the entire shape, learning non-local statistics and exploiting the recurrence of local-scale geometries. Specifically, the network encodes the distribution of the underlying shape surface within a fixed set of local kernels, which results in the best explanation of the underlying shape surface. We demonstrate the ability to consolidate point sets from a variety of shapes, while eliminating outliers and noise.},
	issue        = 5
}
@phdthesis{Lejeune2021a,
	title        = {G\'{e}n\'{e}ration et Analyse de tests pour les syst\`{e}mes autonomes},
	author       = {Cl\'{e}ment Lejeune},
	year         = 2021,
	pages        = 170,
	url          = {http://oatao.univ-toulouse.fr/9278/},
	abstract     = {Les robots autonomes sont principalement test\'{e}s par des exp\'{e}rimentations sur le terrain. Cette approche est co\^{u}teuse et peut pr\'{e}senter des risques. Une m\'{e}thode alternative consiste \`{a} r\'{e}aliser une partie des tests sur une plate-forme de simulation. Ceci soul\`{e}ve plusieurs d\'{e}fis : la g\'{e}n\'{e}ration d'environnements virtuels complexes, la v\'{e}rification automatis\'{e}e du comportement observ\'{e} (oracle de test), et la fid\'{e}lit\'{e} imparfaite de la simulation par rapport \`{a} des tests sur le terrain. Cette th\`{e}se est divis\'{e}e en deux parties ax\'{e}es autour de ces probl\'{e}matiques. Dans une premi\`{e}re partie, nos travaux abordent ces diff\'{e}rents points au travers du cas d'\'{e}tude d'un robot agricole, le robot Oz de la soci\'{e}t\'{e} Na\"{\i}o Technologies. Nous faisons en particulier une analyse comparative des fautes trouv\'{e}es en simula- tion et sur le terrain. La contribution principale de cette partie est de d\'{e}montrer la faisabilit\'{e} et l'efficacit\'{e} du test en simulation sur un cas industriel. Malgr\'{e} leur fid\'{e}lit\'{e} imparfaite, les tests en simulation r\'{e}v\`{e}lent la plupart des fautes trouv\'{e}es par les exp\'{e}rimentationsexp\'{e}rimentations avec le robot r\'{e}el, y compris celles ayant caus\'{e} la majorit\'{e} des d\'{e}faillances sur le terrain. Ils r\'{e}v\`{e}lent \'{e}galement une nouvelle faute pass\'{e}e inaper\c{c}ue sur le terrain mais confirm\'{e}e par l'industriel. Cependant, l'effort d'impl\'{e}mentation des tests virtuels se r\'{e}v\`{e}le important, avec notamment le d\'{e}veloppement d'un g\'{e}n\'{e}- rateur de donn\'{e}es sp\'{e}cifiques aux environnements 3D du robot. Ce constat a men\'{e} la suite de nos travaux vers l'\'{e}tude de la g\'{e}n\'{e}ration de tests. La deuxi\`{e}me partie de nos travaux introduit une nouvelle m\'{e}thode de g\'{e}- n\'{e}ration de test et un outil qui l'impl\'{e}mente. Elle se base sur un mod\`{e}le de donn\'{e}es purement d\'{e}claratif, en combinant la r\'{e}solution de contraintes SMT et l'\'{e}chantillonnage al\'{e}atoire. Bien que le point de d\'{e}part de ces travaux soit la g\'{e}n\'{e}ration d'environnements virtuels pour les syst\`{e}mes autonomes, notre m\'{e}thode de g\'{e}n\'{e}ration s'applique \`{a} un domaine bien plus large. Elle permet de produire des donn\'{e}es structur\'{e}es de tailles variables, tout en respectant des propri\'{e}t\'{e}s s\'{e}mantiques et en offrant de la diversit\'{e}. Nous avons \'{e}valu\'{e} notre m\'{e}thode sur quatre cas d'\'{e}tude venant de domaines d'application vari\'{e}s (le robot Oz, un syst\`{e}me de gestion de taxe, des images de d\'{e}grad\'{e} de gris et des structures arborescentes). Nos r\'{e}sultats montrent des donn\'{e}es g\'{e}n\'{e}r\'{e}es efficacement et couvrant bien l'espace des solutions. Notre m\'{e}thode est comp\'{e}titive au regard des approches existantes auxquelles nous l'avons compar\'{e}e.},
	institution  = {Universit\'{e} Toulouse 3 Paul Sabatier}
}
@article{Weiss2021a,
	title        = {Volumetric Isosurface Rendering with Deep Learning-Based Super-Resolution},
	author       = {Sebastian Weiss and Mengyu Chu and Nils Thuerey and Rudiger Westermann},
	year         = 2021,
	journal      = {IEEE Transactions on Visualization and Computer Graphics},
	volume       = 27,
	pages        = {3064--3078},
	doi          = {10.1109/TVCG.2019.2956697},
	issn         = 19410506,
	abstract     = {Rendering an accurate image of an isosurface in a volumetric field typically requires large numbers of data samples. Reducing this number lies at the core of research in volume rendering. With the advent of deep learning networks, a number of architectures have been proposed recently to infer missing samples in multidimensional fields, for applications such as image super-resolution. In this article, we investigate the use of such architectures for learning the upscaling of a low resolution sampling of an isosurface to a higher resolution, with reconstruction of spatial detail and shading. We introduce a fully convolutional neural network, to learn a latent representation generating smooth, edge-aware depth and normal fields as well as ambient occlusions from a low resolution depth and normal field. By adding a frame-to-frame motion loss into the learning stage, upscaling can consider temporal variations and achieves improved frame-to-frame coherence. We assess the quality of inferred results and compare it to bi-linear and cubic upscaling. We do this for isosurfaces which were never seen during training, and investigate the improvements when the network can train on the same or similar isosurfaces. We discuss remote visualization and foveated rendering as potential applications.},
	issue        = 6,
	keywords     = {Machine learning,extraction of surfaces (isosurfaces, material boun,volume rendering},
	pmid         = 31796410
}
@article{Wang2021a,
	title        = {Predicting the bulk drag coefficient of flexible vegetation in wave flows based on a genetic programming algorithm},
	author       = {Yanxu Wang and Zegao Yin and Yong Liu},
	year         = 2021,
	month        = 3,
	journal      = {Ocean Engineering},
	publisher    = {Elsevier Ltd},
	volume       = 223,
	pages        = 108694,
	doi          = {10.1016/j.oceaneng.2021.108694},
	issn         = {00298018},
	abstract     = {The prediction of the bulk drag coefficient (CD) for aquatic vegetation is of great significance for evaluating the influence of vegetation on the hydrodynamic processes in wave environments. Different CD empirical formulas have been mostly proposed as functions of either Reynolds (Re) number or Keulegan–Carpenter (KC) number in the literature, and the influences of other wave and vegetation parameters on CD were often ignored. The difference in formulas is largely attributable to inconsistent uses of characteristic velocity and length scales in the definitions of Re and KC. By considering the vegetation and hydrodynamic characteristics in this study, new Re and KC numbers were redefined using the mean pore velocity and vegetation-related hydraulic radius. Besides, a genetic programming algorithm was adopted to develop a robust relationship between CD and possible dimensionless variables based on extensive experimental data. Ultimately, a new CD predictor that has a similar form to that of the classical expression was obtained without any prespecified forms before searching. It turns out that the new predictor depends on not only the new KC number but also the submergence ratio and Ursell number. Compared with the existing predictors, the proposed CD predictor exhibits a considerable improvement in predictive ability for a wider parameter space.},
	keywords     = {Aquatic vegetation,Bulk drag coefficient,Genetic programming,Predictor,Wave flows}
}
@article{Collon2021,
	title        = {Corrigendum to ``Statistical metrics for the characterization of karst network geometry and topology'' [Geomorphology (2017) 283: 122–142]},
	author       = {Pauline Collon and David Bernasconi and C\'{e}cile Vuilleumier and Philippe Renard},
	year         = 2021,
	month        = 9,
	journal      = {Geomorphology},
	publisher    = {Elsevier B.V.},
	volume       = 389,
	pages        = 107848,
	doi          = {10.1016/j.geomorph.2021.107848},
	issn         = {0169555X},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0169555X21002567},
	abstract     = {The authors regret that six of the statistical metrics published in Tables 2, 5, and 6 in Collon et al. (2017) are incorrect. The errors were discovered while coding and testing the open-source python package Karstnet freely available at https://github.com/karstnet/karstnet. The errors are smaller than 2\%, except for the correlation of vertex degree, and they do not affect the general conclusions of the paper. The corrected tables are provided in this corrigendum, and we summarize below the changes. Correlation of vertex degree rk (Table 5) The corrected values of the correlation of vertex degree rk are all negative, indicating that the karstic networks in our data set are disassortative as it was reported for other natural networks by Newman (2002). This correction implies the following changes in the text: \textbullet{} In the abstract: ``The correlation of vertex degree is rather simple to obtain. It is systematically negative on all studied data sets indicating a predominance of disassortative networks among karst systems.''\textbullet{} The last paragraph of the section ``4.2.2. Correlation of vertex degrees: assortativity'' must be updated as: ``The values obtained on the 34 reduced networks are all negative, ranging from -0.56 to -0.15. The reduced representations of karstic system are thus disassortative (Table 5). Note that maximal node degrees rarely exceed 4, which limits the interpretation of this parameter, moreover as nodes of degree 2 are removed from the analysis (we work on reduced graphs).''\textbullet{} The second paragraph of the discussion (Section 5.2) must be updated as: ``The correlations of vertex degrees show that the reduced graphs of karstic systems were all slightly disassortative (-0.56 \leq{} rk \leq{} -0.15). Previously, Newman (2002) has shown that many social networks were assortative while technological and biological networks seem to be disassortative. Note that high degree vertices are quite rare in karstic networks: we did not record k values >5.''Branch lengths entropy Hlen (Table 2) In the previous Matlab code, we computed the branch length entropy on 11 bins instead of the 10 bins described in the paper. Correcting this (computing on 10 bins) slightly decreases the values, ranging now from 0.07 to 0.67 instead of 0.18 to 0.74 (page 9). Coefficient of variations of lengths CVlen (Table 2) Contrary to what was written, the coefficient of variations of the lengths was not provided in percentages but in absolute value. A CVlen = 1.09, should thus be read CVlen = 109\%. The update of Table 2 below is also the occasion to put the values in accordance with their definition. Mean length [Formula presented](Table 5) In the previous code, when computing the mean length of the branches, the looping branches (branches that close on the starting point) were ignored. If this is meaningful for tortuosity computation, these branches should not be ignored for the mean length computation. This has been corrected and explains the minor differences observable for the mean length values of Agen Allwed, Daren Cilau, Foussoubie Goule, Krubera, Lechuguilla, MammuthH\"{o}hle, Ratasse, SaintMarcel, Sakany, Shuanghe, SiebenHengsteFull and SiebenHengsteSP2. Average shortest path length [Formula presented](Table 5) In addition, the previous code also ignored independent connected components of two nodes. This is not justified. This correction slightly impacts the values of the [Formula presented]coefficient of Agen Allwed, Arphidia Robinet, Daren Cilau, Grotte du Roy, Krubera, Lechuguilla, Llangattwg, MammuthH\"{o}hle Ratasse, SaintMarcel, Sakany, SiebenHengsteUpPart. Linear correlation coefficients r (Table 6) The corrections described above impact slightly the Pearson correlation coefficient values (differences <0.01), but not the conclusions. The authors would like to apologise for any inconvenience caused.}
}
@article{He,
	title        = {Finding the Skeleton of 2D Shape and Contours: Implementation of Hamilton-Jacobi Skeleton},
	author       = {Yuchen He and Sung Ha Kang and Luis \'{A}lvarez},
	year         = 2021,
	month        = 2,
	journal      = {Image Processing On Line},
	volume       = 11,
	pages        = {18--36},
	doi          = {10.5201/ipol.2021.296},
	issn         = {2105-1232},
	url          = {https://www.ipol.im/pub/art/2021/296/?utm_source=doi},
	abstract     = {This paper presents the details of the flux-ordered thinning algorithm, which we refer to as the Hamilton-Jacobi Skeleton (HJS). It computes the skeleton of any binary 2D shape. It is based on the observation that the skeleton points have low average outward flux of the gradient of the distance transform. The algorithm starts by computing the distance function and approximating the flux values for all pixels inside the shape. Then a procedure called homotopy preserving thinning iteratively removes points with high flux while preserving the homotopy of the shape. In this paper, we implement the distance transform using a fast sweeping algorithm. We present numerical experiments to show the performance of HJS applied to various shapes. We point out that HJS serves as a multi-scale shape representation, a homotopy classifier, and a deficiency detector for binary 2D shapes. We also quantitatively evaluate the shape reconstructed from the medial axis obtained by HJS. Source Code The reviewed source code and documentation for this algorithm are available at the web page of this article 1. See the README.txt file for usage instructions in the archive.},
	keywords     = {2D shape,distance transform,skeleton,thinning algorithm}
}
@article{Yu2021,
	title        = {Repulsive surfaces},
	author       = {Chris Yu and Caleb Brakensiek and Henrik Schumacher and Keenan Crane},
	year         = 2021,
	journal      = {ACM Transactions on Graphics},
	volume       = 40,
	pages        = {1--19},
	doi          = {10.1145/3478513.3480521},
	issn         = {0730-0301},
	url          = {https://www.cs.cmu.edu/~kmcrane/Projects/RepulsiveSurfaces/RepulsiveSurfaces.pdf},
	abstract     = {Functionals that penalize bending or stretching of a surface play a key role in geometric and scientific computing, but to date have ignored a very basic requirement: in many situations, surfaces must not pass through themselves or each other. This paper develops a numerical framework for optimization of surface geometry while avoiding (self-)collision. The starting point is the tangent-point energy , which effectively pushes apart pairs of points that are close in space but distant along the surface. We develop a discretization of this energy for triangle meshes, and introduce a novel acceleration scheme based on a fractional Sobolev inner product. In contrast to similar schemes developed for curves, we avoid the complexity of building a multiresolution mesh hierarchy by decomposing our preconditioner into two ordinary Poisson equations, plus forward application of a fractional differential operator. We further accelerate this scheme via hierarchical approximation, and describe how to incorporate a variety of constraints (on area, volume, etc. ). Finally, we explore how this machinery might be applied to problems in mathematical visualization, geometric modeling, and geometry processing.},
	issue        = 6,
	keywords     = {Computational design, shape optimization, surfaces}
}
@article{Yu2021a,
	title        = {Repulsive Curves},
	author       = {Chris Yu and Henrik Schumacher and Keenan Crane},
	year         = 2021,
	journal      = {ACM Transactions on Graphics},
	volume       = 40,
	doi          = {10.1145/3439429},
	issn         = 15577368,
	url          = {https://www.cs.cmu.edu/~kmcrane/Projects/RepulsiveCurves/RepulsiveCurves.pdf},
	abstract     = {Curves play a fundamental role across computer graphics, physical simulation, and mathematical visualization, yet most tools for curve design do nothing to prevent crossings or self-intersections. This article develops efficient algorithms for (self-)repulsion of plane and space curves that are well-suited to problems in computational design. Our starting point is the so-called tangent-point energy, which provides an infinite barrier to self-intersection. In contrast to local collision detection strategies used in, e.g., physical simulation, this energy considers interactions between all pairs of points, and is hence useful for global shape optimization: local minima tend to be aesthetically pleasing, physically valid, and nicely distributed in space. A reformulation of gradient descent based on a Sobolev-Slobodeckij inner product enables us to make rapid progress toward local minima-independent of curve resolution. We also develop a hierarchical multigrid scheme that significantly reduces the per-step cost of optimization. The energy is easily integrated with a variety of constraints and penalties (e.g., inextensibility, or obstacle avoidance), which we use for applications including curve packing, knot untangling, graph embedding, non-crossing spline interpolation, flow visualization, and robotic path planning.},
	issue        = 2,
	keywords     = {Computational design,curves,knots,shape optimization}
}
@article{Chen2021,
	title        = {A Real-Time Sculpting and Terrain Generation System for Interactive Content Creation},
	author       = {Chien Wen Chen and Min Chun Hu and Wei Ta Chu and Jun Cheng Chen},
	year         = 2021,
	journal      = {IEEE Access},
	publisher    = {IEEE},
	volume       = 9,
	pages        = {114914--114928},
	doi          = {10.1109/ACCESS.2021.3105417},
	issn         = 21693536,
	abstract     = {Volumetric representation is widely used in digital sculpting and terrain generation due to its highly modifiable characteristic. However, storing the entire raw voxel map requires a lot of memory, which limits its application on general machines. In this work, we propose to use a novel data structure based on the concept of layered depth-normal images to replace the commonly used scalar field for storing the volumetric information. The proposed data structure can be quickly edited, and the isosurface can be extracted by using general methods such as Marching Cubes and Dual Contouring. The proposed sculpting system can edit models with multiple resolution levels, and the surface between models of different resolutions can be connected seamlessly. Our method can achieve similar results as the existing volumetric methods while significantly reduces the memory usage and computation time. The model created by our system can be used in common game engines to make highly interactive games. Furthermore, all of our processes are parallel-friendly. We implemented a virtual reality digital content creation tool based on the proposed method to demonstrate the effectiveness and feasibility of our method.},
	keywords     = {Real-time sculpting,terrain generation,virtual reality,volumetric sculpting}
}
@article{Patel2021,
	title        = {Modeling Terrains and~Subsurface Geology},
	author       = {Daniel Patel and Mattia Natali and Endre M. Lidal and Julius Parulek and Emilio Vital Brazil and Ivan Viola},
	year         = 2021,
	journal      = {Interactive Data Processing and 3D Visualization of the Solid Earth},
	pages        = {1--43},
	doi          = {10.1007/978-3-030-90716-7_1},
	url          = {http://data.exppad.com/public/papers/Modeling_Terrains_and_Subsurface_Geology.pdf},
	abstract     = {The process of creating terrain and landscape models is important in a variety of computer graphics and visual- ization applications, from films and computer games, via flight simulators and landscape planning, to scientific visualization and subsurface modelling. Interestingly, the modelling techniques used in this large range of appli- cation areas have started to meet in the last years. In this state-of-the-art report, we present two taxonomies of different modelling methods. Firstly we present a data oriented taxonomy, where we divide modelling into three different scenarios: the data-free, the sparse-data and the dense-data scenario. Then we present a workflow ori- ented taxonomy, where we divide modelling into the separate stages necessary for creating a geological model.We start the report by showing that the new trends in geological modelling are approaching the modelling methods that have been developed in computer graphics. We then give an introduction to the process of geological mod- elling followed by our two taxonomies with descriptions and comparisons of selected methods. Finally we discuss the challenges and trends in geological modelling.},
	issue        = {c}
}
@article{Sellan2021,
	title        = {Swept volumes via spacetime numerical continuation},
	author       = {Silvia Sell\'{a}n and Noam Aigerman and Alec Jacobson},
	year         = 2021,
	journal      = {ACM Transactions on Graphics},
	volume       = 40,
	doi          = {10.1145/3450626.3459780},
	issn         = 15577368,
	url          = {https://www.silviasellan.com/pdf/papers/swept-volumes.pdf},
	abstract     = {Given a solid 3D shape and a trajectory of it over time, we compute its swept volume - the union of all points contained within the shape at some moment in time. We consider the representation of the input and output as implicit functions, and lift the problem to 4D spacetime, where we show the problem gains a continuous structure which avoids expensive global searches. We exploit this structure via a continuation method which marches and reconstructs the zero level set of the swept volume, using the temporal dimension to avoid erroneous solutions. We show that, compared to other methods, our approach is not restricted to a limited class of shapes or trajectories, is extremely robust, and its asymptotic complexity is an order lower than standards used in the industry, enabling its use in applications such as modeling, constructive solid geometry, and path planning.},
	issue        = 4,
	keywords     = {continuation algorithm,swept volume}
}
@article{Ecormier-Nocca2021,
	title        = {Authoring consistent landscapes with flora and fauna},
	author       = {Pierre Ecormier-Nocca and Guillaume Cordonnier and Philippe Carrez and Anne Marie Moigne and Pooran Memari and Bedrich Benes and Marie Paule Cani},
	year         = 2021,
	journal      = {ACM Transactions on Graphics},
	volume       = 40,
	doi          = {10.1145/3450626.3459952},
	issn         = 15577368,
	url          = {https://www-sop.inria.fr/reves/Basilic/2021/ECCMMBC21/Authoring_Consistent_Landscapes_with_Flora_and_Fauna.pdf},
	abstract     = {We present a novel method for authoring landscapes with flora and fauna while considering their mutual interactions. Our algorithm outputs a steady-state ecosystem in the form of density maps for each species, their daily circuits, and a modified terrain with eroded trails from a terrain, climatic conditions, and species with related biological information. We introduce the Resource Access Graph, a new data structure that encodes both interactions between food chain levels and animals traveling between resources over the terrain. A novel competition algorithm operating on this data progressively computes a steady-state solution up the food chain, from plants to carnivores. The user can explore the resulting landscape, where plants and animals are instantiated on the fly, and interactively edit it by over-painting the maps. Our results show that our system enables the authoring of consistent landscapes where the impact of wildlife is visible through animated animals, clearings in the vegetation, and eroded trails. We provide quantitative validation with existing ecosystems and a user-study with expert paleontologist end-users, showing that our system enables them to author and compare different ecosystems illustrating climate changes over the same terrain while enabling relevant visual immersion into consistent landscapes.},
	issue        = 4,
	keywords     = {ecosystems,natural phenomena}
}
@article{Sarkar2021,
	title        = {Procedural Content Generation using Behavior Trees (PCGBT)},
	author       = {Anurag Sarkar and Seth Cooper},
	year         = 2021,
	month        = 6,
	url          = {http://arxiv.org/abs/2107.06638},
	abstract     = {Behavior trees (BTs) are a popular method for modeling NPC and enemy AI behavior and have been widely used in commercial games. In this work, rather than use BTs to model game playing agents, we use them for modeling game design agents, defining behaviors as content generation tasks rather than in-game actions. Similar to how traditional BTs enable modeling behaviors in a modular and dynamic manner, BTs for PCG enable simple subtrees for generating parts of levels to be combined modularly to form complex trees for generating whole levels as well as generators that can dynamically vary the generated content. We refer to this approach as Procedural Content Generation using Behavior Trees, or PCGBT, and demonstrate it by using BTs to model generators for Super Mario Bros., Mega Man and Metroid levels as well as dungeon layouts and discuss several ways in which this paradigm could be applied and extended in the future.}
}
@article{Niyazov2021,
	title        = {Dynamic Decals: Pervasive Freeform Interfaces Using Constrained Deformable Graphical Elements},
	author       = {Aziz Niyazov and Nicolas Mellado and Lo\"{\i}c Barthe and Marcos Serrano},
	year         = 2021,
	journal      = {Proceedings of the ACM on Human-Computer Interaction},
	volume       = 5,
	doi          = {10.1145/3488538},
	issn         = 25730142,
	abstract     = {Pervasive interfaces can present relevant information anywhere in our environment, and they are thus challenged by the non rectilinearity of the display surface (e.g. circular table) and by the presence of objects that can partially occlude the interface (e.g. a book or cup on the table). To tackle this problem, we propose a novel solution based on two core contributions: the decomposition of the interface into deformable graphical units, called Dynamic Decals, and the control of their position and behaviour by a constraint-based approach. Our approach dynamically deforms the interface when needed while minimizing the impact on its visibility and layout properties. To do so, we extend previous work on implicit deformations to propose and experimentally validate functions defining different decal shapes and new deformers modeling decal deformations when they collide. Then, we interactively optimize the decal placements according to the interface geometry and their interrelations. Relations are modeled as constraints and the interface evolution results from an easy and efficient to solve minimization problem. Our approach is validated by a user study showing that, compared to two baselines, Dynamic decals is an aesthetically pleasant interface that preserves visibility, layout and aesthetic properties.},
	issue        = {ISS},
	keywords     = {constraints,contact deformation,optimization,projected interfaces}
}
@article{Jueterbock2021,
	title        = {Adaptation of Temperate Seagrass to Arctic Light Relies on Seasonal Acclimatization of Carbon Capture and Metabolism},
	author       = {Alexander Jueterbock and Bernardo Duarte and James Coyer and Jeanine L. Olsen and Martina Elisabeth Luise Kopp and Irina Smolina and Sophie Arnaud-Haond and Zi Min Hu and Galice Hoarau},
	year         = 2021,
	journal      = {Frontiers in Plant Science},
	volume       = 12,
	doi          = {10.3389/fpls.2021.745855},
	issn         = {1664462X},
	abstract     = {Due to rising global surface temperatures, Arctic habitats are becoming thermally suitable for temperate species. Whether a temperate species can immigrate into an ice-free Arctic depends on its ability to tolerate extreme seasonal fluctuations in daylength. Thus, understanding adaptations to polar light conditions can improve the realism of models predicting poleward range expansions in response to climate change. Plant adaptations to polar light have rarely been studied and remain unknown in seagrasses. If these ecosystem engineers can migrate polewards, seagrasses will enrich biodiversity, and carbon capture potential in shallow coastal regions of the Arctic. Eelgrass (Zostera marina) is the most widely distributed seagrass in the northern hemisphere. As the only seagrass species growing as far north as 70\textdegree{}N, it is the most likely candidate to first immigrate into an ice-free Arctic. Here, we describe seasonal (and diurnal) changes in photosynthetic characteristics, and in genome-wide gene expression patterns under strong annual fluctuations of daylength. We compared PAM measurements and RNA-seq data between two populations at the longest and shortest day of the year: (1) a Mediterranean population exposed to moderate annual fluctuations of 10–14 h daylength and (2) an Arctic population exposed to high annual fluctuations of 0–24 h daylength. Most of the gene expression specificities of the Arctic population were found in functions of the organelles (chloroplast and mitochondrion). In winter, Arctic eelgrass conserves energy by repressing respiration and reducing photosynthetic energy fluxes. Although light-reactions, and genes involved in carbon capture and carbon storage were upregulated in summer, enzymes involved in CO2 fixation and chlorophyll-synthesis were upregulated in winter, suggesting that winter metabolism relies not only on stored energy resources but also on active use of dim light conditions. Eelgrass is unable to use excessive amounts of light during summer and demonstrates a significant reduction in photosynthetic performance under long daylengths, possibly to prevent photoinhibition constrains. Our study identified key mechanisms that allow eelgrass to survive under Arctic light conditions and paves the way for experimental research to predict whether and up to which latitude eelgrass can potentially migrate polewards in response to climate change.},
	issue        = {December},
	keywords     = {Arctic light,carbon capture,climate change,daylength,eelgrass (Zostera marina),energy storage,photosynthesis,respiration}
}
@article{Hochberg2021,
	title        = {Missing the Reef for the Corals: Unexpected Trends Between Coral Reef Condition and the Environment at the Ecosystem Scale},
	author       = {Eric J. Hochberg and Michelle M. Gierach},
	year         = 2021,
	journal      = {Frontiers in Marine Science},
	volume       = 8,
	pages        = {1--10},
	doi          = {10.3389/fmars.2021.727038},
	issn         = 22967745,
	abstract     = {It is incontrovertible that many coral reefs are in various stages of decline and may be unable to withstand the effects of global climate change, jeopardizing vital ecosystem goods and services to hundreds of millions of people around the world. An estimated 50\% of the world's corals have already been lost, and those remaining may be lost by 2030 under the ``business as usual'' CO2 emissions scenario. However, the foundation of these predictions is a surprisingly sparse dataset, wherein ~0.01–0.1\% of the world's reef area has been quantitatively surveyed. Further, the available data comprise observations at the 1–10 m scale, which are not evenly spaced across reefs, but often clustered in areas representing focused survey effort. This impedes modeling and predicting the impact of a changing environment at the ecosystem scale. Here we highlight deficiencies in our current understanding of the relationship between coral reefs and their environments. Specifically, we conduct a meta-analysis using estimates of coral cover from a variety of local surveys, quantitatively relating reef condition to a suite of biogeophysical forcing parameters. We find that readily available public data for coral cover exhibit unexpected trends (e.g., a positive correlation between coral cover and multi-year cumulative thermal stress), contrary to prevailing scientific expectations. We illustrate a significant gap in our current understanding, and thereby prediction, of coral reefs at the ecosystem scale that can only be remedied with uniform, high-density data across vast coral reef regions, such as that from remote sensing.},
	issue        = {August},
	keywords     = {biogeophysical forcing,climate change,coral cover,coral reefs,ecosystem scale,remote sensing}
}
@article{Mcmanus2021,
	title        = {Evolution and connectivity influence the persistence and recovery of coral reefs under climate change in the Caribbean, Southwest Pacific, and Coral Triangle},
	author       = {Lisa C. McManus and Daniel L. Forrest and Edward W. Tekwa and Daniel E. Schindler and Madhavi A. Colton and Michael M. Webster and Timothy E. Essington and Stephen R. Palumbi and Peter J. Mumby and Malin L. Pinsky},
	year         = 2021,
	month        = 9,
	journal      = {Global Change Biology},
	volume       = 27,
	pages        = {4307--4321},
	doi          = {10.1111/gcb.15725},
	issn         = {1354-1013},
	url          = {https://onlinelibrary.wiley.com/doi/10.1111/gcb.15725},
	abstract     = {<p>Corals are experiencing unprecedented decline from climate change-induced mass bleaching events. Dispersal not only contributes to coral reef persistence through demographic rescue but can also hinder or facilitate evolutionary adaptation. Locations of reefs that are likely to survive future warming therefore remain largely unknown, particularly within the context of both ecological and evolutionary processes across complex seascapes that differ in temperature range, strength of connectivity, network size, and other characteristics. Here, we used eco-evolutionary simulations to examine coral adaptation to warming across reef networks in the Caribbean, the Southwest Pacific, and the Coral Triangle. We assessed the factors associated with coral persistence in multiple reef systems to understand which results are general and which are sensitive to particular geographic contexts. We found that evolution can be critical in preventing extinction and facilitating the long-term recovery of coral communities in all regions. Furthermore, the strength of immigration to a reef (destination strength) and current sea surface temperature robustly predicted reef persistence across all reef networks and across temperature projections. However, we found higher initial coral cover, slower recovery, and more evolutionary lag in the Coral Triangle, which has a greater number of reefs and more larval settlement than the other regions. We also found the lowest projected future coral cover in the Caribbean. These findings suggest that coral reef persistence depends on ecology, evolution, and habitat network characteristics, and that, under an emissions stabilization scenario (RCP 4.5), recovery may be possible over multiple centuries.</p>},
	issue        = 18,
	keywords     = {biology,hawaiʻi institute of marine,kaneʻohe,manoa,university of hawaiʻi at}
}
@article{Couch2021,
	title        = {Comparing Coral Colony Surveys From In-Water Observations and Structure-From-Motion Imagery Shows Low Methodological Bias},
	author       = {Courtney S. Couch and Thomas A. Oliver and Rhonda Suka and Mia Lamirand and Mollie Asbury and Corinne Amir and Bernardo Vargas-\'{A}ngel and Morgan Winston and Brittany Huntington and Frances Lichowski and Ariel Halperin and Andrew Gray and Joao Garriques and Jennifer Samson},
	year         = 2021,
	journal      = {Frontiers in Marine Science},
	volume       = 8,
	pages        = {1--14},
	doi          = {10.3389/fmars.2021.647943},
	issn         = 22967745,
	abstract     = {As the threats to coral reefs mount, scientists and managers are looking for innovative ways to increase the scope, scale, and efficiency of coral reef monitoring. Monitoring changes in coral communities and demographic features provides key information about ecosystem function and resilience of reefs. While most monitoring programs continue to rely on in-water visual survey methods, scientists are exploring 3D imaging technologies such as photogrammetry, also known as Structure-from-Motion (SfM), to enhance precision of monitoring, increase logistical efficiency in the field, and generate a permanent record of the reef. Here, we quantitatively compare data generated from in-water surveys to SfM-derived metrics for assessing coral demography, bleaching, and diversity in the main Hawaiian Islands as part of NOAA's National Coral Reef Monitoring Program. Our objectives were to compare between-method error to within-method error, test for bias between methods, and identify strengths and weaknesses of both methods. Colony density, average colony diameter, average partial mortality, prevalence of bleaching, species richness, and species diversity were recorded using both methods within the same survey areas. For all metrics, the magnitude of between-method error was comparable to the within-method error for the in-water method and between method error was significantly higher than within-method error for SfM for one of the seven metrics. Our results also reveal that a majority of the metrics do not vary significantly between methods, nor did we observe a significant interaction between method and habitat type or method and depth. Exceptions include estimates of partial mortality, bleaching prevalence, and Porites juvenile density–though differences between methods are generally small. Our study also highlights that SfM offers a unique opportunity to more rigorously quantify and mitigate inter-observer error by providing observers unlimited ``bottom time'' and the opportunity to work together to resolve difficult annotations. However, the necessary investment in equipment and expertise does present substantial up-front costs, and the time associated with curating imagery, photogrammetric modeling, and manual image annotation can reduce the timeliness of data reporting. SfM provides a powerful tool to reimagine how we study and manage coral reefs, and this study provides the first quantified methodological comparison to validate the transition from standard in-water methods to SfM survey methods for estimates of coral colony-level surveys.},
	issue        = {May},
	keywords     = {Hawaii,benthic monitoring,coral demography,coral diversity,coral reef,photogrammetry,structure-from-motion}
}
@article{Escudero2021,
	title        = {Coral Reef Geometry and Hydrodynamics in Beach Erosion Control in North Quintana Roo, Mexico},
	author       = {Mireille Escudero and Borja G. Reguero and Edgar Mendoza and Fernando Secaira and Rodolfo Silva},
	year         = 2021,
	journal      = {Frontiers in Marine Science},
	volume       = 8,
	pages        = {1--17},
	doi          = {10.3389/fmars.2021.684732},
	issn         = 22967745,
	abstract     = {Coral reefs are increasingly recognized for their shoreline protection services. The hydrodynamic performance of this ecosystem is comparable to artificial low-crested structures often used in coastal protection, whose objective is to emulate the former. Coral reefs also provide other important environmental services (e.g., food production, habitat provision, maintenance of biodiversity and social and cultural services) and leave almost no ecological footprint when conservation and restoration actions are conducted to maintain their coastal protection service. However, studies have focused on their flood protection service, but few have evaluated the morphological effects of coral reefs through their ability to avoid or mitigate coastal erosion. In this paper, we investigate the relation between shoreline change, reefs' geometry and hydrodynamic parameters to elucidate the physics related to how the Mesoamerican Reef in Mexico protects sandy coastlines from erosion. Using numerical wave propagation and historical shoreline change calculated from satellite imagery, a direct correlation was found between shoreline movement, the depths and widths of reef flats, changes in the wave energy flux, and the radiation stresses of breaking waves. The findings indicate that the most remarkable efficacy in preventing beach erosion is due to reefs with shallow crests, wide reef flats, a dissipative lagoon seabed, located at \sim{}300 m from the coastline. The results provide essential insights for reef restoration projects focused on erosion mitigation and designing artificial reefs in microtidal sandy beaches. Results are limited to wave-dominated coasts.},
	issue        = {September},
	keywords     = {beach erosion mitigation,coastal protection,coral reefs,nature-based solutions,radiation stress,wave energy}
}
@article{Lee2021,
	title        = {Investigations Exploring the Use of an Unstructured-Grid, Finite-Volume Modelling Approach to Simulate Coastal Circulation in Remote Island Settings--Case Study Region, Vanuatu/New Caledonia},
	author       = {Serena Blyth Lee and Fan Zhang and Charles James Lemckert and Rodger Tomlinson},
	year         = 2021,
	journal      = {Frontiers in Marine Science},
	volume       = 8,
	doi          = {10.3389/fmars.2021.697741},
	issn         = 22967745,
	abstract     = {Understanding coastal circulation and how it may alter in the future is important in island settings, especially in the South West Pacific, where communities rely heavily upon marine resources, and where sea level rise (SLR) is higher than the global average. In this study we explore the use of an unstructured-mesh finite-volume modelling approach to assist in filling the knowledge gaps with respect to coastal circulation in remote island locations--selecting the Vanuatu and New Caledonia archipelagos as our example study site. Past limited observations and modelling studies are leveraged to construct and verify a regional/coastal ocean model based on the Finite-Volume Community Ocean Model (FVCOM). Following verification with respect to tidal behaviour, we investigate how changes in wind speed and direction, and SLR, alter coastal water levels and coastal currents. Results showed tidal residual circulation was typically associated with flow separation at headlands and islands. Trade winds had negligible effect on water levels at the coast, however, wind-residual circulation was sensitive to both wind speed and direction. Wind-residual currents were typically strongest close to coastlines. Wind residual circulation patterns were strongly influenced by Ekman flow, while island blocking, topographic steering and geostrophic currents also appear to influence current patterns. Tidal amplitudes and phases were unchanged due to SLR of up to 2 m, while maximum current speeds altered by as much as 20 cm/s within some coastal embayments. Non-linear relationships between SLR and maximum current speeds were seen at some coastal reef platform sites. Under higher sea levels, tidal residual currents altered by less than \pm{}2 cm/s which is relatively significant given maximum tidal residual current speeds are typically below 10 cm/s. Our findings indicate that under higher sea levels, coastal processes governing sediment transport, pollutant dispersal and larval transport are likely to alter, which may have implications for coastal environments and ecosystems. Given winds influence coastal circulation and subsequent coastal processes, changes in trade winds due to climate change may act to further alter coastal processes. It is felt that the current modelling approach can be applied to other regions to help fill critical knowledge gaps.},
	issue        = {September},
	keywords     = {circulation,constituents,residual,sea level rise,tidal}
}
@article{Droxler2021,
	title        = {The Origin of Modern Atolls : Challenging Darwin's Deeply Ingrained Theory},
	author       = {Andr\'{e} W Droxler and St\'{e}phan J Jorry},
	year         = 2021,
	journal      = {Annual Review of Marine Science},
	doi          = {https://doi.org/10.1146/annurev-marine-122414- 034137},
	keywords     = {at-topped bank,atoll origin,indian ocean,karsti cation,maldives,paci c ocean,plio-pleistocene,sea level}
}
@article{Li2021,
	title        = {Procedural Modeling of the Great Barrier Reef},
	author       = {Wanwan Li},
	year         = 2021,
	journal      = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume       = {13017 LNCS},
	pages        = {381--391},
	doi          = {10.1007/978-3-030-90439-5_30},
	isbn         = 9783030904388,
	issn         = 16113349,
	abstract     = {Since terrain procedural modeling is widely adopted for the virtual natural scene generations in the game design, movie industry, and digital arts, lots of advanced techniques have been explored by researchers to procedurally synthesize a large variety of different types of terrain and landscapes. In this paper, we present a novel approach to generate a special type of landscape – the Great Barrier Reef – an amazing natural landscape that is currently being ignored. We propose a hypothesis that the Great Barrier Reef is grown with the diffusion-limited aggregation (DLA) model and simulate the DLA process to generate the Great Barrier Reef procedurally. As presented in the results, the procedural Great Barrier Reef generated with our approach looks natural when compared to the photos of the real ones.},
	keywords     = {Diffusion-limited aggregation (DLA),Great Barrier Reef,Landscape,Procedural modeling,Terrain}
}
@article{Para2021b,
	title        = {Generative Layout Modeling using Constraint Graphs},
	author       = {Wamiq Para and Paul Guerrero and Tom Kelly and Leonidas Guibas and Peter Wonka},
	year         = 2021,
	journal      = {Proceedings of the IEEE International Conference on Computer Vision},
	pages        = {6670--6680},
	doi          = {10.1109/ICCV48922.2021.00662},
	isbn         = 9781665428125,
	issn         = 15505499,
	url          = {https://arxiv.org/pdf/2011.13417.pdf},
	abstract     = {We propose a new generative model for layout generation. We generate layouts in three steps. First, we generate the layout elements as nodes in a layout graph. Second, we compute constraints between layout elements as edges in the layout graph. Third, we solve for the final layout using constrained optimization. For the first two steps, we build on recent transformer architectures. The layout optimization implements the constraints efficiently. We show three practical contributions compared to the state of the art: our work requires no user input, produces higher quality layouts, and enables many novel capabilities for conditional layout generation.}
}
@article{Para2021a,
	title        = {SketchGen: Generating Constrained CAD Sketches},
	author       = {Wamiq Reyaz Para and Shariq Farooq Bhat and Paul Guerrero and Tom Kelly and Niloy Mitra and Leonidas Guibas and Peter Wonka},
	year         = 2021,
	journal      = {Advances in Neural Information Processing Systems},
	volume       = 7,
	pages        = {5077--5088},
	isbn         = 9781713845393,
	issn         = 10495258,
	url          = {https://arxiv.org/pdf/2106.02711.pdf},
	abstract     = {Computer-aided design (CAD) is the most widely used modeling approach for technical design. The typical starting point in these designs is 2D sketches which can later be extruded and combined to obtain complex three-dimensional assemblies. Such sketches are typically composed of parametric primitives, such as points, lines, and circular arcs, augmented with geometric constraints linking the primitives, such as coincidence, parallelism, or orthogonality. Sketches can be represented as graphs, with the primitives as nodes and the constraints as edges. Training a model to automatically generate CAD sketches can enable several novel workflows, but is challenging due to the complexity of the graphs and the heterogeneity of the primitives and constraints. In particular, each type of primitive and constraint may require a record of different size and parameter types. We propose SketchGen as a generative model based on a transformer architecture to address the heterogeneity problem by carefully designing a sequential language for the primitives and constraints that allows distinguishing between different primitive or constraint types and their parameters, while encouraging our model to re-use information across related parameters, encoding shared structure. A particular highlight of our work is the ability to produce primitives linked via constraints that enables the final output to be further regularized via a constraint solver. We evaluate our model by demonstrating constraint prediction for given sets of primitives and full sketch generation from scratch, showing that our approach significantly out performs the state-of-the-art in CAD sketch generation.}
}
@article{Mordivintsev2021a,
	title        = {Texture Generation with Neural Cellular Automata},
	author       = {Alexander Mordvintsev and Eyvind Niklasson and Ettore Randazzo},
	year         = 2021,
	month        = 5,
	url          = {http://arxiv.org/abs/2105.07299},
	abstract     = {Neural Cellular Automata (NCA) have shown a remarkable ability to learn the required rules to "grow" images, classify morphologies, segment images, as well as to do general computation such as path-finding. We believe the inductive prior they introduce lends itself to the generation of textures. Textures in the natural world are often generated by variants of locally interacting reaction-diffusion systems. Human-made textures are likewise often generated in a local manner (textile weaving, for instance) or using rules with local dependencies (regular grids or geometric patterns). We demonstrate learning a texture generator from a single template image, with the generation method being embarrassingly parallel, exhibiting quick convergence and high fidelity of output, and requiring only some minimal assumptions around the underlying state manifold. Furthermore, we investigate properties of the learned models that are both useful and interesting, such as non-stationary dynamics and an inherent robustness to damage. Finally, we make qualitative claims that the behaviour exhibited by the NCA model is a learned, distributed, local algorithm to generate a texture, setting our method apart from existing work on texture generation. We discuss the advantages of such a paradigm.}
}
@article{Mordvintsev2021b,
	title        = {$\mu$NCA: Texture Generation with Ultra-Compact Neural Cellular Automata},
	author       = {Alexander Mordvintsev and Eyvind Niklasson},
	year         = 2021,
	month        = 11,
	url          = {http://arxiv.org/abs/2111.13545},
	abstract     = {We study the problem of example-based procedural texture synthesis using highly compact models. Given a sample image, we use differentiable programming to train a generative process, parameterised by a recurrent Neural Cellular Automata (NCA) rule. Contrary to the common belief that neural networks should be significantly over-parameterised, we demonstrate that our model architecture and training procedure allows for representing complex texture patterns using just a few hundred learned parameters, making their expressivity comparable to hand-engineered procedural texture generating programs. The smallest models from the proposed $\mu$NCA family scale down to 68 parameters. When using quantisation to one byte per parameter, proposed models can be shrunk to a size range between 588 and 68 bytes. Implementation of a texture generator that uses these parameters to produce images is possible with just a few lines of GLSL or C code.}
}
@article{Maslin2021,
	title        = {Underwater robots provide similar fish biodiversity assessments as divers on coral reefs},
	author       = {Mathilde Maslin and Silvain Louis and Karen Godary Dejean and Lionel Lapierre and S\'{e}bastien Vill\'{e}ger and Thomas Claverie},
	year         = 2021,
	month        = 12,
	journal      = {Remote Sensing in Ecology and Conservation},
	publisher    = {John Wiley and Sons Inc},
	volume       = 7,
	pages        = {567--578},
	doi          = {10.1002/rse2.209},
	issn         = 20563485,
	abstract     = {Coral reefs are under increasing threat, and the loss of reef-associated fishes providing valuable ecosystem services is accelerating. The monitoring of such rapid changes has become a challenge for ecologists and ecosystems managers using traditional approaches like scuba divers performing underwater visual censuses (UVC) or diver operated video recording (DOV). However, the use of small, low-cost robots could help tackle the challenge of such monitoring, provided that they perform at least as well as diver-based methods. To address this question, tropical fish assemblages from 13 fringing reefs around Mayotte Island (Indian Ocean) were monitored along 50~m-long transects using stereo videos recorded by a semi-autonomous underwater vehicle (SAUV) and by a scuba diver (Diver Operated stereo Video system, DOV). Differences between the methods were tested for complementary fish assemblage metrics (species richness, total biomass, total density, Shannon diversity and Pielou evenness) and for the number and size of nine targeted species. SAUV recorded on average 35\% higher biomass than DOV which in turn recorded on average 12\% higher species richness. Biomass differences were found to be due to SAUV monitoring larger fishes than DOV, a potential marker of human-related fish avoidance behaviour. This study demonstrates that SAUV provides accurate metrics of coral reef fish biodiversity compared to diver-based procedures. Given their ability to conduct video transects at high frequency, 100~m depth range and at a moderate cost, SAUV is a promising tool for monitoring fish assemblages in coral reef ecosystems.},
	issue        = 4,
	keywords     = {Coral reef ecosystems,fish biometrics,marine robotics,stereovision,transect surveys}
}
@article{Palmer2021,
	title        = {Marine robots for coastal ocean research in the Western Indian Ocean},
	author       = {Matthew R. Palmer and Yohana W. Shagude and Michael J. Roberts and Ekaterina Popova and Juliane U. Wihsgott and Shankar Aswani and Jack Coupland and John A. Howe and Brian J. Bett and Kennedy E. Osuka and Colin Abernethy and Sofia Alexiou and Stuart C. Painter and Joseph N. Kamau and Ntahondi Nyandwi and Baraka Sekadende},
	year         = 2021,
	month        = 10,
	journal      = {Ocean and Coastal Management},
	publisher    = {Elsevier Ltd},
	volume       = 212,
	doi          = {10.1016/j.ocecoaman.2021.105805},
	issn         = {09645691},
	abstract     = {Marine robots have the potential to enhance WIO marine research to improve regional adaptation to the challenges presented by climate change by providing enhanced research capacity that bypasses the requirement for expensive infrastructure, such as large research vessels. This paper tests this potential and assesses the readiness of WIO communities to adopt autonomous technologies to meet its marine research priorities. We apply a range of analyses to a marine robots case study undertaken in waters around the island of Pemba, part of the Zanzibar archipelago, in Tanzania in 2019. The campaign formed part of a multinational project focused on increasing WIO capacity to meet food security and ocean sustainability challenges. A community engagement programme with six Tanzanian coastal communities resulted in positive changes in attitudes towards marine robots with reported increases in understanding and acceptance of such technologies. Suspicion of the robots was reduced and a lower risk of removing operational equipment was recorded following the provision of educational material. Cost, risk and benefit analysis shows that marine robots are perceived to provide high level benefits, but come at a high cost that is difficult to achieve using national or regional funding. An assessment of the capacity of WIO marine institutes to adopt such technologies shows that prior to this work, few skills or infrastructure related to marine robots were available to researchers and further confirmed that funding opportunities were perceived to be largely unavailable at institutional, national, regional or international levels. Responses from regional partners following completion of the case study however, revealed an uplift in perceived capacity, particularly related to access to infrastructure and expertise as well as support and opportunities for funding at each level. The presented case study is shown to have been a valuable demonstrator of the benefits of using marine robots to meet WIO coastal ocean research requirements and regional capacity was shown to be substantially increased within the broad range of marine institutes surveyed throughout the case study period. This study demonstrates that taking early steps towards adopting marine autonomous robots has increased WIO regional marine research capacity and increased the confidence and willingness of local researchers to seek alternative solutions to ongoing marine research challenges. Recommendations for future action that will continue to increase the capacity and readiness for regional adoption of marine robots include investment at local, national and regional levels to provide accessible training opportunities and to facilitate regional and international collaborations; investment in a regional hub, or centre of excellence for marine robotic technology; early adoption of newly emerging smaller, cheaper autonomous technologies; investment in local skills and support facilities to aid local buy-in and acceptance while supporting regional capacity.},
	keywords     = {Coastal ocean management,Marine autonomy,Marine robotics,Marine robots,Ocean gliders,Sustainable development}
}
@article{Scott2021,
	title        = {Example-based terrain synthesis with pit removal},
	author       = {Joshua J. Scott and Neil A. Dodgson},
	year         = 2021,
	month        = 10,
	journal      = {Computers and Graphics (Pergamon)},
	publisher    = {Elsevier Ltd},
	volume       = 99,
	pages        = {43--53},
	doi          = {10.1016/j.cag.2021.06.012},
	issn         = {00978493},
	abstract     = {Artificial terrain synthesis is challenging because natural terrain contains many types of features generated by a diverse range of natural processes over vastly different time-scales. Example-based terrain synthesis has been used to overcome the challenge by using real-world terrain as the basis for synthesis. This produces good local behaviour but can have poor global behaviour. We introduce fluid-flow solutions that can be overlaid on multi-resolution example-based terrain synthesis to improve global realism. We apply these to an existing pixel-based terrain synthesis method and to a novel terrain synthesis method, terrain optimisation, based on texture optimisation. Our fluid-flow solutions improve results for artificial terrains.},
	keywords     = {Example-based,Optimization,Terrain}
}
@article{Hadrich2021,
	title        = {Fire in paradise},
	author       = {Torsten H\"{a}drich and Daniel T. Banuti and Wojtek Pa\l{}ubicki and S\"{o}ren Pirk and Dominik L. Michels},
	year         = 2021,
	month        = 7,
	journal      = {ACM Transactions on Graphics},
	publisher    = {Association for Computing Machinery},
	volume       = 40,
	doi          = {10.1145/3450626.3459954},
	issn         = 15577368,
	abstract     = {Resulting from changing climatic conditions, wildfires have become an existential threat across various countries around the world. The complex dynamics paired with their often rapid progression renders wildfires an often disastrous natural phenomenon that is difficult to predict and to counteract. In this paper we present a novel method for simulating wildfires with the goal to realistically capture the combustion process of individual trees and the resulting propagation of fires at the scale of forests. We rely on a state-of-the-art modeling approach for large-scale ecosystems that enables us to represent each plant as a detailed 3D geometric model. We introduce a novel mathematical formulation for the combustion process of plants - also considering effects such as heat transfer, char insulation, and mass loss - as well as for the propagation of fire through the entire ecosystem. Compared to other wildfire simulations which employ geometric representations of plants such as cones or cylinders, our detailed 3D tree models enable us to simulate the interplay of geometric variations of branching structures and the dynamics of fire and wood combustion. Our simulation runs at interactive rates and thereby provides a convenient way to explore different conditions that affect wildfires, ranging from terrain elevation profiles and ecosystem compositions to various measures against wildfires, such as cutting down trees as firebreaks, the application of fire retardant, or the simulation of rain.},
	issue        = 4,
	keywords     = {combustion,fire,fluid dynamics,level of detail,numerical simulation,physics-based modeling,wildfires}
}
@inproceedings{Xiaochen2021,
	title        = {Urban Brush: Intuitive and Controllable Urban Layout Editing},
	author       = {Xiaochen Zhou and Bedrich Benes and Pascal Chang and Marie Paule R. Cani},
	year         = 2021,
	month        = 10,
	booktitle    = {UIST 2021 - Proceedings of the 34th Annual ACM Symposium on User Interface Software and Technology},
	publisher    = {Association for Computing Machinery, Inc},
	pages        = {796--814},
	doi          = {10.1145/3472749.3474787},
	isbn         = 9781450386357,
	abstract     = {Efficient urban layout generation is an interesting and important problem in many applications dealing with computer graphics and entertainment. We introduce a novel framework for intuitive and controllable small and large-scale urban layout editing. The key inspiration comes from the observation that cities develop in small incremental changes e.g., a building is replaced, or a new road is created. We introduce a set of atomic operations that consistently modify the city. For example, two buildings are merged, a block is split in two, etc. Our second inspiration comes from volumetric editings, such as clay manipulation, where the manipulated material is preserved. The atomic operations are used in interactive brushes that consistently modify the urban layout. The city is populated with agents. Like volume transfer, the brushes attract or repulse the agents, and blocks can be merged and populated with smaller buildings. We also introduce a large-scale brush that repairs a part of the city by learning style as distributions of orientations and intersections.},
	keywords     = {Urban modeling,geometry,interactive modeling,procedural models}
}
@article{Bari2021,
	title        = {Association of vegetation indices with atmospheric \& biological factors using MODIS time series products},
	author       = {Ehsanul Bari and Nusrat Jahan Nipa and Bishal Roy},
	year         = 2021,
	month        = 12,
	journal      = {Environmental Challenges},
	publisher    = {Elsevier B.V.},
	volume       = 5,
	doi          = {10.1016/j.envc.2021.100376},
	issn         = 26670100,
	abstract     = {Natural vegetation is a critical component of ecosystem change models and conservation efforts. Over nineteen years, this study explores the spatiotemporal dynamics of normalized difference vegetation index (NDVI) and enhanced vegetation index (EVI) with atmospheric, biological, and soil indicators, and to determine whether a significant correlation exists between these indices in Bangladesh. We used the Google earth engine (GEE) for geospatial analysis using moderate resolution imaging spectroradiometer (MODIS) datasets to perform the study. Vegetation indices are positively correlated with land surface temperature (LST), Humidity, and Evapotranspiration. From 2000 to 2019, the average increase in vegetation cover (NDVI) was 0.1 to 0.3. LST changes from -6\textdegree{}C to +5\textdegree{}C in numerous places over the previous 19 years (increased in urban areas and mostly decreased in the north-eastern part). Due to increased human activity, LST in the northern part of the country has dropped and increased during the last nineteen years in the center and eastern parts. In the future, new studies on vegetation cover and its relationship to other factors, protection of nature, and resource allocation may benefit from the findings of this study.}
}
@article{Mattarei2021,
	title        = {Cubic rational expressions over a finite field},
	author       = {Sandro Mattarei and Marco Pizzato},
	year         = 2021,
	month        = 3,
	url          = {http://arxiv.org/abs/2104.00111},
	abstract     = {We study and partially classify cubic rational expressions $g(x)/h(x)$ over a finite field $F_q$, up to pre- and post-composition with independent M\"obius transformations. In particular, we obtain a full classification when $q$ is even, and prove an upper bound of $4q$ for the number of equivalence classes when $q$ is odd.}
}
@article{Frantz2021,
	title        = {Analysis and stochastic simulation of geometrical properties of conduits in karstic networks},
	author       = {Yves Frantz and Pauline Collon and Philippe Renard and Sophie Viseur},
	year         = 2021,
	month        = 3,
	journal      = {Geomorphology},
	publisher    = {Elsevier B.V.},
	volume       = 377,
	doi          = {10.1016/j.geomorph.2020.107480},
	issn         = {0169555X},
	abstract     = {Despite intensive explorations by speleologists, karstic systems remain only partially described as many conduits are not accessible to humans. The classical exploration techniques produce sparse data, leading to various uncertainties about the conduit dimensions, essential parameters for flow simulations. Stochastic simulations offer a possibility to better assess these uncertainties. In this paper, we propose different methods to stochastically simulate the properties (size and shape anisotropy) of karstic conduits on already existing skeletons. These approaches, based on Sequential Gaussian Simulations (SGS), allow taking different conditioning data into account, while respecting the intricacy of the networks. To infer the input parameters, we perform a statistical study of the conduit dimensions of 49 explored karstic networks, focusing on their equivalent radius and width-height ratio. Thanks to the definition of 1D-curvilinear variograms, we demonstrate the existence of a spatial correlation along the networks, which is even higher when considering independently each conduit. Finally, using ad hoc algorithms implemented for computing both a conduit hierarchy inside karstic networks and a relative position regarding outputs, we find no evidence of an obvious link between these two entities and the studied metrics. The simulation methods are then demonstrated on the karstic network of Arrestelia (Pyr\'{e}n\'{e}es-Atlantiques, France), and show the consistency of the proposed approach with the observations made on the explored natural systems.},
	keywords     = {Conduit geometry,Conduit network,Karst,Statistics,Stochastic simulation}
}
@article{Wang2021,
	title        = {Promoting landscape connectivity of highly urbanized area: An ecological network approach},
	author       = {Shuang Wang and Maoquan Wu and Mengmeng Hu and Chen Fan and Tao Wang and Beicheng Xia},
	year         = 2021,
	month        = 6,
	journal      = {Ecological Indicators},
	publisher    = {Elsevier B.V.},
	volume       = 125,
	doi          = {10.1016/j.ecolind.2021.107487},
	issn         = {1470160X},
	abstract     = {Ecological infrastructure is a popular framework for conservation planning. In this paper, one of the most urbanized regions of China-Shenzhen was chosen as the study area. Ecological infrastructure with different configurations and functions were identified and combined to form the urban ecological network. The ecological sources were identified using morphological spatial pattern analysis (MSPA) and landscape connectivity analysis. The ecological resistance surface developed from ecosystem service value was modified basing on ecological sensitivity and landscape connectivity. The ecological network was constructed by minimum cumulative resistance (MCR) model and then optimized and accessed. The results show that: (1) the ecological network consists of 25 ecological sources distributed mainly in the southeast and west. Twenty-nine ecological corridors were extracted and 36 ecological nodes identified. (2) In the optimized ecological network, 10 new ecological sources were added, and 46 ecological corridors and 59 ecological nodes were identified. It would promote the connectivity of the ecological sources and the stability of ecological functioning process. (3) The ecological network took ecosystem service value and ecological sensitivity into consideration and lays emphasis on improving landscape connectivity, providing an approach to optimizing urban ecological network and contributing to urban planning.},
	keywords     = {Ecological corridors,Ecological resistance,Ecological sources,Ecosystem service,Morphological spatial pattern analysis}
}
@article{Radford2021,
	title        = {Learning Transferable Visual Models From Natural Language Supervision},
	author       = {Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
	year         = 2021,
	month        = 2,
	url          = {http://arxiv.org/abs/2103.00020},
	abstract     = {State-of-the-art computer vision systems are trained to predict a fixed set of predetermined object categories. This restricted form of supervision limits their generality and usability since additional labeled data is needed to specify any other visual concept. Learning directly from raw text about images is a promising alternative which leverages a much broader source of supervision. We demonstrate that the simple pre-training task of predicting which caption goes with which image is an efficient and scalable way to learn SOTA image representations from scratch on a dataset of 400 million (image, text) pairs collected from the internet. After pre-training, natural language is used to reference learned visual concepts (or describe new ones) enabling zero-shot transfer of the model to downstream tasks. We study the performance of this approach by benchmarking on over 30 different existing computer vision datasets, spanning tasks such as OCR, action recognition in videos, geo-localization, and many types of fine-grained object classification. The model transfers non-trivially to most tasks and is often competitive with a fully supervised baseline without the need for any dataset specific training. For instance, we match the accuracy of the original ResNet-50 on ImageNet zero-shot without needing to use any of the 1.28 million training examples it was trained on. We release our code and pre-trained model weights at https://github.com/OpenAI/CLIP.}
}
@article{Rombach2021,
	title        = {High-Resolution Image Synthesis with Latent Diffusion Models},
	author       = {Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Bj\"{o}rn Ommer},
	year         = 2021,
	month        = 12,
	url          = {http://arxiv.org/abs/2112.10752},
	abstract     = {By decomposing the image formation process into a sequential application of denoising autoencoders, diffusion models (DMs) achieve state-of-the-art synthesis results on image data and beyond. Additionally, their formulation allows for a guiding mechanism to control the image generation process without retraining. However, since these models typically operate directly in pixel space, optimization of powerful DMs often consumes hundreds of GPU days and inference is expensive due to sequential evaluations. To enable DM training on limited computational resources while retaining their quality and flexibility, we apply them in the latent space of powerful pretrained autoencoders. In contrast to previous work, training diffusion models on such a representation allows for the first time to reach a near-optimal point between complexity reduction and detail preservation, greatly boosting visual fidelity. By introducing cross-attention layers into the model architecture, we turn diffusion models into powerful and flexible generators for general conditioning inputs such as text or bounding boxes and high-resolution synthesis becomes possible in a convolutional manner. Our latent diffusion models (LDMs) achieve a new state of the art for image inpainting and highly competitive performance on various tasks, including unconditional image generation, semantic scene synthesis, and super-resolution, while significantly reducing computational requirements compared to pixel-based DMs. Code is available at https://github.com/CompVis/latent-diffusion .}
}
@book{Ashtari2021,
	title        = {AutomationML : The Industrial Cookbook},
	author       = {Behrang. Ashtari and Matthias. Bartelt and Anna-Kristin. Behnert and Stefan. Biffl and Jan-Wilhelm. Blume and Dominik. Braun and Kirill. Dorofeev and Rainer. Drath and Lukas. Gehlen and Andreas. Graf and J\"{o}rg. Hinze and Mario. Hoernicke and Lorenz. Hundt and Idar Pe. Ingebrigtsen and Michael. John and Prerna. Juhlin and Bernd. Kuhlenk\"{o}tter and Martin. Langosch and Arndt. L\"{u}der and Roman. Mader and Torben. Meyer and Matthias. M\"{u}ller and Felix. Ocker and Dimitri. Penner and Josef. Prinz and Matthias. Rassl and Markus. Rentschler and Matthias. Riedl and Felix. Rinker and Ronald. Rosendahl and Miriam. Schleipen and Nicole. Schmidt and Andreas. Sch\"{u}ller and Jannis. Sinnemann and Michael. Sollfrank and Katharina. Stark and Ljiljana. Stojanovic and Anton. Strahilov and Thomas. Tauchnitz and Leon. Urbas and Milan. Vathoopan and Birgit. Vogel-Heuser and Bernhard. Wally and Michael. Weyrich and Mathias. Wiegand and Andreas. W\"{u}rger and Ender. Yemenicioglu and Holger. Zipper and Alois. Zoitl and Minjie. Zou},
	year         = 2021,
	publisher    = {De Gruyter Oldenbourg},
	isbn         = 9783110745924,
	abstract     = {This book provides a comprehensive in-depth look into the practical application of AutomationML Edition 2 from an industrial perspective. It is a cookbook for advanced users and describes re-usable pattern solutions for a variety of industrial applications and how to implement it in software. Just to name some: AutomationML modelling of AAS, MTP, SCD, OPC UA, Automation Components, Automation Projects, drive configurations, requirement models, communication systems, electrical interfaces and cables, or semantic integration aspects as eClass integration or handling of semantic heterogeneity. This book guides through the universe of Auto\-mationML from industrial perspective. It is written by AutomationML experts that have industrially implemented AutomationML in pattern solutions for a large variety of applications. This book is structured into three major parts. \textbullet{} Part I: software implementation for developers \textbullet{} Part II: re-usable industrial pattern solutions and domain models \textbullet{} Part III: outlook into future AutomationML applications Additional material to the book and more information about AutomationML on the website: https://www.automationml.org/about-automationml/publications/amlbook. Frontmatter -- Foreword by Prof. Dr. Alexander Fay -- Foreword by Andreas Graf Gatterburg -- Acknowledgement by Prof. Dr. Rainer Drath -- Table of Contents -- About the Editor -- 1 About this book -- Part I: AutomationML Development Support -- 2 Overview of Part I -- 3 Software development with AutomationML -- 4 AutomationML Export and Import Data Interfaces -- 5 The AMLTestCenter Rule-based verification of AML documents for generic and AAS conformity -- References for Part I -- Part II: The Industrial Cookbook -- 6 Overview of Part II -- 7 AML domain model for VDI 3697-1: Data exchange between CAE and PCS -- 8 AML domain model for VDI 3697-2: Data Exchange between CAE systems -- 9 MTP - Automation Engineering of Modular Process Plants -- 10 AML domain model for System Control Diagrams -- 11 Data exchange between ECAD and PLC tools - AR APC -- 12 Modelling of Drive Configurations - AR DRIVES MCAD -- 13 AML domain model for material handling -- 14 The AutomationML Component -- 15 AML domain model for Electric Interfaces -- 16 AutomationML Component Checker -- 17 AML domain model for communication systems -- 18 Modelling OPC UA with AutomationML -- 19 Serialization of the Asset Administration Shell by AutomationML -- 20 AutomationML Industrialization and Toolchain -- 21 AutomationML governance at Daimler AG -- 22 AutomationML and eCl\@ss Integration -- 23 Semantic and Pragmatic Interoperability Mappings -- 24 Extended RoleClass libraries -- 25 AML-based Enterprise Control System Integration by IEC 62264 -- References for Part II -- Part III: The Future - AutomationML Research -- 26 Overview of Part III -- 27 AutomationML based development of mechatronic systems -- 28 Concept to refine and computationally evaluate PPR information in AML -- 29 Integration of data and software into the Digital Twin via AML -- 30 Optimizing the engineering of technical energy management systems -- 31 Skill-Based Engineering of Automation Systems: Use Case and Evaluation -- 32 Engineering Data Logistics based on AML -- 33 Energy optimization during virtual commissioning -- Abbreviations -- Trademarks -- Index}
}
@article{Ghiasi2021,
	title        = {Simple Copy-Paste is a Strong Data Augmentation Method for Instance Segmentation},
	author       = {Golnaz Ghiasi and Yin Cui and Aravind Srinivas and Rui Qian and Tsung-Yi Lin and Ekin D Cubuk and Quoc V Le and Barret Zoph},
	year         = 2021,
	journal      = {CVPR},
	pages        = {2918--2928},
	url          = {https://cocodataset.org/},
	abstract     = {Building instance segmentation models that are data-efficient and can handle rare object categories is an important challenge in computer vision. Leveraging data augmentations is a promising direction towards addressing this challenge. Here, we perform a systematic study of the Copy-Paste augmentation (e.g., [13, 12]) for instance segmentation where we randomly paste objects onto an image. Prior studies on Copy-Paste relied on modeling the surrounding visual context for pasting the objects. However , we find that the simple mechanism of pasting objects randomly is good enough and can provide solid gains on top of strong baselines. Furthermore, we show Copy-Paste is additive with semi-supervised methods that leverage extra data through pseudo labeling (e.g. self-training). On COCO instance segmentation, we achieve 49.1 mask AP and 57.3 box AP, an improvement of +0.6 mask AP and +1.5 box AP over the previous state-of-the-art. We further demonstrate that Copy-Paste can lead to significant improvements on the LVIS benchmark. Our baseline model outperforms the LVIS 2020 Challenge winning entry by +3.6 mask AP on rare categories. 1}
}
@inproceedings{Voulgaris2021,
	title        = {Procedural Terrain Generation Using Generative Adversarial Networks},
	author       = {Georgios Voulgaris and Ioannis Mademlis and Ioannis Pitas},
	year         = 2021,
	booktitle    = {European Signal Processing Conference},
	publisher    = {European Signal Processing Conference, EUSIPCO},
	volume       = {2021-August},
	pages        = {686--690},
	doi          = {10.23919/EUSIPCO54536.2021.9616151},
	isbn         = 9789082797060,
	issn         = 22195491,
	abstract     = {Synthetic terrain realism is critical in VR applications based on computer graphics (e.g., games, simulations). Although fast procedural algorithms for automated terrain generation do exist, they still require human effort. This paper proposes a novel approach to procedural terrain generation, relying on Generative Adversarial Networks (GANs). The neural model is trained using terrestrial Points-of-Interest (PoIs, described by their geodesic coordinates/altitude) and publicly available corresponding satellite images. After training is complete, the GAN can be employed for deriving realistic terrain images on-the-fly, by merely forwarding through it a rough 2D scatter plot of desired PoIs in image form (so-called ``altitude image''). We demonstrate that such a GAN is able to translate this rough, quickly produced sketch into an actual photorealistic terrain image. Additionally, we describe a strategy for enhancing the visual diversity of trained model synthetic output images, by tweaking input altitude image orientation during GAN training. Finally, we perform an objective and a subjective evaluation of the proposed method. Results validate the latter's ability to rapidly create life-like terrain images from minimal input data.},
	keywords     = {Artificial terrain,Deep learning,Generative adversarial networks,Procedural content generation}
}
@article{McGinn2021,
	title        = {Generalised gravitational wave burst generation with generative adversarial networks},
	author       = {J. McGinn and C. Messenger and M. J. Williams and I. S. Heng},
	year         = 2021,
	month        = 8,
	journal      = {Classical and Quantum Gravity},
	publisher    = {IOP Publishing Ltd},
	volume       = 38,
	doi          = {10.1088/1361-6382/ac09cc},
	issn         = 13616382,
	abstract     = {We introduce the use of conditional generative adversarial networks (CGANs) for generalised gravitational wave (GW) burst generation in the time domain. Generative adversarial networks are generative machine learning models that produce new data based on the features of the training data set. We condition the network on five classes of time-series signals that are often used to characterise GWburst searches: sine-Gaussian, ringdown, white noise burst, Gaussian pulse and binary black hole merger. We show that the model can replicate the features of these standard signal classes and, in addition, produce generalised burst signals through interpolation and class mixing.We also present an example application where a convolutional neural network (CNN) classifier is trained on burst signals generated by our CGAN.We show that a CNN classifier trained only on the standard five signal classes has a poorer detection efficiency than a CNN classifier trained on a population of generalised burst signals drawn from the combined signal class space.},
	issue        = 15,
	keywords     = {Generative adversarial networks,Gravitational wave bursts,Gravitational waves,Machine learning}
}
@article{Messa2021,
	title        = {Computational fluid dynamics modelling of liquid–solid slurry flows in pipelines: State-of-the-art and future perspectives},
	author       = {Gianandrea Vittorio Messa and Qi Yang and Oluwaseun Ezekiel Adedeji and Zden\v{e}k Ch\'{a}ra and Carlos Antonio Ribeiro Duarte and V\'{a}clav Matou\v{s}ek and Maria Gra\c{c}a Rasteiro and R. Sean Sanders and Rui C. Silva and Francisco Jos\'{e} De Souza},
	year         = 2021,
	month        = 9,
	journal      = {Processes},
	publisher    = {MDPI},
	volume       = 9,
	doi          = {10.3390/pr9091566},
	issn         = 22279717,
	abstract     = {Slurry pipe transport has directed the efforts of researchers for decades, not only for the practical impact of this problem, but also for the challenges in understanding and modelling the complex phenomena involved. The increase in computer power and the diffusion of multipurpose codes based on Computational Fluid Dynamics (CFD) have opened up the opportunity to gather information on slurry pipe flows at the local level, in contrast with the traditional approaches of simplified theoretical modelling which are mainly based on a macroscopic description of the flow. This review paper discusses the potential of CFD for simulating slurry pipe flows. A comprehensive description of the modelling methods will be presented, followed by an overview of significant publications on the topic. However, the main focus will be the assessment of the potential and the challenges of the CFD approach, underlying the essential interplay between CFD simulations and experiments, discussing the main sources of uncertainty of CFD models, and evaluating existing models based on their interpretative or predictive capacity. This work aims at providing a solid ground for students, academics, and professional engineers dealing with slurry pipe transport, but it will also provide a methodological approach that goes beyond the specific application.},
	issue        = 9,
	keywords     = {Computational fluid dynamics,Eulerian–Eulerian model,Eulerian–Lagrangian model,Mixture model,Slurry erosion,Slurry pipe flows,State-of-the-art,Two-fluid model}
}
@article{Lee,
	title        = {Tropical optimal transport and Wasserstein distances},
	author       = {Wonjun Lee and Wuchen Li and Bo Lin and Anthea Monod},
	year         = 2022,
	month        = 7,
	journal      = {Information Geometry},
	volume       = 5,
	pages        = {247--287},
	doi          = {10.1007/s41884-021-00046-6},
	issn         = {2511-2481},
	url          = {https://link.springer.com/10.1007/s41884-021-00046-6},
	abstract     = {<p> We study the problem of optimal transport in tropical geometry and define the Wasserstein- <italic>p</italic> distances in the continuous metric measure space setting of the tropical projective torus. We specify the tropical metric--a combinatorial metric that has been used to study of the tropical geometric space of phylogenetic trees--as the ground metric and study the cases of <inline-formula> <alternatives> <tex-math>\$$p=1,2$$</tex-math> <math> <mrow> <mi>p</mi> <mo>=</mo> <mn>1</mn> <mo>,</mo> <mn>2</mn> </mrow> </math> </alternatives> </inline-formula> in detail. The case of <inline-formula> <alternatives> <tex-math>$$p=1$$</tex-math> <math> <mrow> <mi>p</mi> <mo>=</mo> <mn>1</mn> </mrow> </math> </alternatives> </inline-formula> gives an efficient computation of the infinitely-many geodesics on the tropical projective torus, while the case of <inline-formula> <alternatives> <tex-math>$$p=2$\$</tex-math> <math> <mrow> <mi>p</mi> <mo>=</mo> <mn>2</mn> </mrow> </math> </alternatives> </inline-formula> gives a form for Fr\'{e}chet means and a general inner product structure. Our results also provide theoretical foundations for geometric insight a statistical framework in a tropical geometric setting. We construct explicit algorithms for the computation of the tropical Wasserstein-1 and 2 distances and prove their convergence. Our results provide the first study of the Wasserstein distances and optimal transport in tropical geometry. Several numerical examples are provided. </p>},
	issue        = 1
}
@article{ZhangYiqun2022,
	title        = {Visualization and investigation of the erosion process for natural gas hydrate using water jet through experiments and simulation},
	author       = {Yiqun Zhang and Xiaoya Wu and Xiao Hu and Bo Zhang and Jingsheng Lu and Panpan Zhang and Gensheng Li and Shouceng Tian and Xinming Li},
	year         = 2022,
	journal      = {Energy Reports},
	publisher    = {Elsevier Ltd},
	volume       = 8,
	pages        = {202--216},
	doi          = {10.1016/j.egyr.2021.11.235},
	issn         = 23524847,
	url          = {https://doi.org/10.1016/j.egyr.2021.11.235},
	abstract     = {Natural Gas Hydrate (NGH) and Hydrate-bearing Sediments (HBS) are emerging as an important potential energy resource. Radial Jet Drilling (RJD) technology, turning sharply in the casing and drilling laterals by using water jet, is a valid approach to solve problems of high cost, low efficiency during the exploitation of NGHs. The performance of water jet drilling remains unclear, and traditional finite element methods cannot accurately depict the water jet drilling ability due to mesh distortion. This paper analyzes the water jet erosion process of NGH and HBS. Experiments on the erosion of reconstituted gas hydrates are conducted and visualized in both submerged and submerged confining pressure conditions. Subsequently, two coupled nozzle–target models are solved by Arbitrary Lagrangian Eulerian (ALE) and Smooth Particle Hydrodynamics (SPH) methods. The flow field, the deformation and erosion of the hydrates induced by water jet are simulated. The experimental results show that there are specific shapes of cylindrical erosion pits for NGH and HBS. The numerical results are consistent with the experiments, which proves the effectiveness of water jet exploring hydrate resources. The submerged condition and the confining pressure condition will hinder the erosion efficiency, and the critical erosion velocities for both HBS and NGH are obtained. ALE method has superior accuracy in modeling the damaged area and erosion pit characteristics; while SPH method, has advantages in showing the motion state of the single particles and unstable and discontinuous flow field. This paper provides a good guidance for understanding the water jet drilling performance and selecting the appropriate simulation method in NGH reservoirs development.},
	keywords     = {Hydrate-bearing sediment,Multilateral well,Natural gas hydrate,Radial jet drilling,Water jet}
}
@article{Guerin2022,
	title        = {Gradient Terrain Authoring},
	author       = {Eric Gu\'{e}rin and Adrien Peytavie and Simon Masnou and Julie Digne and Basile Sauvage and James Gain and Eric Galin},
	year         = 2022,
	month        = 5,
	journal      = {Computer Graphics Forum},
	volume       = 41,
	pages        = {85--95},
	doi          = {10.1111/cgf.14460},
	issn         = {0167-7055},
	url          = {https://onlinelibrary.wiley.com/doi/10.1111/cgf.14460},
	abstract     = {<p>Digital terrains are a foundational element in the computer-generated depiction of natural scenes. Given the variety and complexity of real-world landforms, there is a need for authoring solutions that achieve perceptually realistic outcomes without sacrificing artistic control. In this paper, we propose setting aside the elevation domain in favour of modelling in the gradient domain. Such a slope-based representation is height independent and allows a seamless blending of disparate landforms from procedural, simulation, and real-world sources. For output, an elevation model can always be recovered using Poisson reconstruction, which can include Dirichlet conditions to constrain the elevation of points and curves.</p>},
	issue        = 2
}
@phdthesis{Isheden2022,
	title        = {Hydraulic Erosion Simulation on the GPU for 3D terrains},
	author       = {Sebastian Isheden},
	year         = 2022,
	url          = {https://www.diva-portal.org/smash/get/diva2:1646074/FULLTEXT01.pdf}
}
@article{Pascual2022,
	title        = {Inferring topological operations on generalized maps: Application to subdivision schemes},
	author       = {Romain Pascual and Hakim Belhaouari and Agn\`{e}s Arnould and Pascale Le Gall},
	year         = 2022,
	journal      = {Graphics and Visual Computing},
	publisher    = {Elsevier Ltd.},
	volume       = 6,
	pages        = 200049,
	doi          = {10.1016/j.gvc.2022.200049},
	issn         = 26666294,
	url          = {https://doi.org/10.1016/j.gvc.2022.200049},
	keywords     = {topology-based geometric modeling}
}
@inproceedings{Dodik2022,
	title        = {Sex and Gender in the Computer Graphics Research Literature},
	author       = {Ana Dodik and Silvia Sell\'{a}n and Theodore Kim and Amanda Phillips},
	year         = 2022,
	month        = 8,
	booktitle    = {Special Interest Group on Computer Graphics and Interactive Techniques Conference Talks},
	publisher    = {ACM},
	volume       = 108,
	pages        = {1--2},
	doi          = {10.1145/3532836.3536227},
	isbn         = 9781450393713,
	url          = {https://dl.acm.org/doi/10.1145/3532836.3536227},
	abstract     = {<p>Concerns that algorithms may discriminate against certain groups have led to numerous efforts to `blind' the algorithm to race. We argue that this intuitive perspective is misleading and may do harm. Our primary result is exceedingly simple, yet often overlooked. A preference for fairness should not change the choice of estimator. Equity preferences can change how the estimated prediction function is used (e.g., different threshold for different groups) but the function itself should not change. We show in an empirical example for college admissions that the inclusion of variables such as race can increase both equity and efficiency.</p>},
	city         = {New York, NY, USA}
}
@article{Koschier2022,
	title        = {A Survey on SPH Methods in Computer Graphics},
	author       = {Dan Koschier and Jan Bender and Barbara Solenthaler and Matthias Teschner},
	year         = 2022,
	journal      = {Computer Graphics Forum},
	volume       = 41,
	pages        = {737--760},
	doi          = {10.1111/cgf.14508},
	issn         = 14678659,
	abstract     = {Throughout the past decades, the graphics community has spent major resources on the research and development of physics simulators on the mission to computer-generate behaviors achieving outstanding visual effects or to make the virtual world indistinguishable from reality. The variety and impact of recent research based on Smoothed Particle Hydrodynamics (SPH) demonstrates the concept's importance as one of the most versatile tools for the simulation of fluids and solids. With this survey, we offer an overview of the developments and still-active research on physics simulation methodologies based on SPH that has not been addressed in previous SPH surveys. Following an introduction about typical SPH discretization techniques, we provide an overview over the most used incompressibility solvers and present novel insights regarding their relation and conditional equivalence. The survey further covers recent advances in implicit and particle-based boundary handling and sampling techniques. While SPH is best known in the context of fluid simulation we discuss modern concepts to augment the range of simulatable physical characteristics including turbulence, highly viscous matter, deformable solids, as well as rigid body contact handling. Besides the purely numerical approaches, simulation techniques aided by machine learning are on the rise. Thus, the survey discusses recent data-driven approaches and the impact of differentiable solvers on artist control. Finally, we provide context for discussion by outlining existing problems and opportunities to open up new research directions.},
	issue        = 2,
	keywords     = {CCS Concepts,\textbullet{} Computing methodologies \rightarrow{} Physical simulation}
}
@article{Guerrero2022,
	title        = {MatFormer: A Generative Model for Procedural Materials},
	author       = {Paul Guerrero and Milo\v{s} Ha\v{s}an and Kalyan Sunkavalli and Radom\'{\i}r Mech and Tamy Boubekeur and Niloy J. Mitra},
	year         = 2022,
	journal      = {ACM Transactions on Graphics},
	publisher    = {Association for Computing Machinery},
	volume       = 41,
	doi          = {10.1145/3528223.3530173},
	issn         = 15577368,
	url          = {https://arxiv.org/pdf/2207.01044.pdf},
	abstract     = {Procedural material graphs are a compact, parameteric, and resolution-independent representation that are a popular choice for material authoring. However, designing procedural materials requires significant expertise and publicly accessible libraries contain only a few thousand such graphs. We present MatFormer, a generative model that can produce a diverse set of high-quality procedural materials with complex spatial patterns and appearance. While procedural materials can be modeled as directed (operation) graphs, they contain arbitrary numbers of heterogeneous nodes with unstructured, often long-range node connections, and functional constraints on node parameters and connections. MatFormer addresses these challenges with a multi-stage transformer-based model that sequentially generates nodes, node parameters, and edges, while ensuring the semantic validity of the graph. In addition to generation, MatFormer can be used for the auto-completion and exploration of partial material graphs. We qualitatively and quantitatively demonstrate that our method outperforms alternative approaches, in both generated graph and material quality.},
	issue        = 4,
	keywords     = {Generative models,Node graphs,Procedural materials,Transformers}
}
@unpublished{Hartley2022,
	title        = {Algorithmes d'\'{e}rosion pour la g\'{e}n\'{e}ration de terrains 3D},
	author       = {Marc Hartley and Christophe Fiorio and Nicolas Mellado and Noura Faraj},
	year         = 2022,
	pages        = {1--6}
}
@article{Bailly2022,
	title        = {Genetic-WFC: Extending Wave Function Collapse With Genetic Search},
	author       = {Raphael Bailly and Guillaume Levieux},
	year         = 2022,
	journal      = {IEEE Transactions on Games},
	publisher    = {IEEE},
	pages        = {1--10},
	doi          = {10.1109/TG.2022.3192930},
	issn         = 24751510,
	abstract     = {This paper presents Genetic-WFC, a procedural level generation algorithm that mixes genetic optimization with Wave Function Collapse, a local adjacency constraints propagation algorithm. We use a synthetic player to evaluate the novelty, safety and complexity of the generated levels. Novelty is maximized when the synthetic player goes on tiles not visited for a long time, safety is related to how far it can see, and complexity evaluates the variability of the surrounding tiles. WFC extracts constraints from example levels, and allows us to perform the genetic search on levels with few local asset placement errors, while using as little level design rules as possible. We show that we are able to rely on WFC while optimizing the results, first by influencing WFC asset selection and then by re-encoding the chosen modules back to our genotype, in order to optimize crossover. We compare the fitness curves and best maps of our method with other approaches. We then visually explore the kind of levels we are able to generate by sampling different values of safety and complexity, giving a glimpse of the variability that our approach is able to reach.},
	keywords     = {Complexity theory,Games,Genetic algorithm,Genetic algorithms,Maintenance engineering,Optimization,Safety,Wave functions,level design,player experience,procedural content generation,variability,video games,wave function collapse}
}
@article{Potokar2022,
	title        = {HoloOcean: An Underwater Robotics Simulator},
	author       = {Easton Potokar and Spencer Ashford and Michael Kaess and Joshua G. Mangelson},
	year         = 2022,
	journal      = {Proceedings - IEEE International Conference on Robotics and Automation},
	pages        = {3040--3046},
	doi          = {10.1109/ICRA46639.2022.9812353},
	isbn         = 9781728196817,
	issn         = 10504729,
	url          = {https://www.cs.cmu.edu/~kaess/pub/Potokar22icra.pdf},
	abstract     = {Due to the difficulty and expense of underwater field trials, a high fidelity underwater simulator is a necessity for testing and developing algorithms. To fill this need, we present HoloOcean, an open source underwater simulator, built upon Unreal Engine 4 (UE4). HoloOcean comes equipped with multi-agent support, various sensor implementations of common underwater sensors, and simulated communications support. We also implement a novel sonar sensor model that leverages an octree representation of the environment for efficient and realistic sonar imagery generation. Due to being built upon UE4, new environments are straightforward to add, enabling easy extensions to be built. Finally, HoloOcean is controlled via a simple python interface, allowing simple installation via pip, and requiring few lines of code to execute simulations.}
}
@article{WangBeibei2022,
	title        = {Position-free multiple-bounce computations for smith microfacet BSDFs},
	author       = {Beibei Wang and Wenhua Jin and Jiahui Fan and Jian Yang and Nicolas Holzschuch and Ling Qi Yan},
	year         = 2022,
	journal      = {ACM Transactions on Graphics},
	volume       = 41,
	pages        = {1--14},
	doi          = {10.1145/3528223.3530112},
	issn         = 15577368,
	url          = {https://wangningbei.github.io/2022/MBBRDF_files/paper_MBBRDF.pdf},
	abstract     = {Bidirectional Scattering Distribution Functions (BSDFs) encode how a material reflects or transmits the incoming light. The most commonly used model is the microfacet BSDF. It computes the material response from the microgeometry of the surface assuming a single bounce on specular microfacets. The original model ignores multiple bounces on the microgeometry, resulting in an energy loss, especially for rough materials. In this paper, we present a new method to compute the multiple bounces inside the microgeometry, eliminating this energy loss. Our method relies on a position-free formulation of multiple bounces inside the microgeometry. We use an explicit mathematical definition of the path space that describes single and multiple bounces in a uniform way. We then study the behavior of light on the different vertices and segments in the path space, leading to a reciprocal multiple-bounce description of BSDFs. Furthermore, we present practical, unbiased Monte Carlo estimators to compute multiple scattering. Our method is less noisy than existing algorithms for computing multiple scattering. It is almost noise-free with a very-low sampling rate, from 2 to 4 samples per pixel (spp).},
	issue        = 4,
	keywords     = {full-spherical,microfacet,multiple-bounce,position-free}
}
@article{Fu2022,
	title        = {Characteristics and evaluation of coastal erosion vulnerability of typical coast on Hainan Island},
	author       = {Guo Wei Fu and Chao Cao and Kai Zhe Fu and Yan Wei Song and Kun Yuan and Xiao Ming Wan and Zi Ang Zhu and Zhao Fan Wang and Zan Hui Huang},
	year         = 2022,
	journal      = {Frontiers in Marine Science},
	volume       = 9,
	pages        = {1--19},
	doi          = {10.3389/fmars.2022.1061769},
	issn         = 22967745,
	abstract     = {Coastal erosion vulnerability assessment is widely used to assess the loss degree of coastal zone caused by erosion, and plays an important role in coastal natural resources protection, planning, management and decision-making. Based on the natural and social characteristics of the east coast of Qiongdong and the coastal erosion vulnerability index (CVI) method, this study selected 8 assessment indicators, such as shoreline change rate (U1). The Delphi method and the entropy weight method were used to calculate the comprehensive index weight, combined with CVI method and geographic information system (GIS) technology, to quantitatively evaluate the temporal and spatial distribution characteristics of typical coastal erosion vulnerability such as coral reefs in the east of Hainan Island. The study area was divided into 5 grades: very low (31\%), low (10\%), moderate (28\%), high (24\%) and high vulnerability (7\%), and the overall performance was moderate erosion vulnerability. The research showed that the interannual downward rate erosion of beach (U3) and the rate of change of the isobath (U2) of the beach were the main controlling factors affecting the vulnerability of coastal erosion in the study area, and the coastal dynamic factor had a greater impact than the other two factors. As a natural barrier, the coral reefs in the study area had good wave absorption and energy reduction, and the coral reef coasts showed low coastal erosion vulnerability, due to the complex hydrodynamic characteristics, estuary coasts is the most vulnerable areas. The verification results of the ROC-AUC method showed that the accuracy of erosion vulnerability was 68.9\%, which provided an important reference for the ecological restoration of tropical coral reef biological coasts and the development and management of the Hainan Qiongdong coastal zone.},
	issue        = {December},
	keywords     = {Hainan Island,coastal erosion vulnerability,coral reef coast,human activities,index method}
}
@article{Bouwmeester2022,
	title        = {Spatial patterns of reef fishes and corals in the thermally extreme waters of Qatar},
	author       = {Jessica Bouwmeester and Radhouane Ben-Hamadou and Pedro Range and Fahad Al Jamali and John A. Burt},
	year         = 2022,
	journal      = {Frontiers in Marine Science},
	volume       = 9,
	pages        = {1--14},
	doi          = {10.3389/fmars.2022.989841},
	issn         = 22967745,
	abstract     = {The Persian Gulf is a thermally extreme environment in which reef corals have adapted to survive through temperature ranges that would be lethal to corals from other regions. Despite offering a unique opportunity to better understand how corals from other regions may adapt in the future, through a changing climate, much of the Gulf coral and fish communities remain to be described. In the southwestern Gulf nation of Qatar few reef sites have been described to date. We here characterize reef communities from 16 sites around the Qatar Peninsula, encompassing depths from 3 to 25m. We found the healthiest coral reef communities to be in deeper offshore reefs, with high coral and fish species richness and high coral abundance, likely a result of their occurrence below summer thermocline depths and distance from urban pressures. In contrast, we found shallow reefs, both nearshore and offshore, to have low species richness and abundance relative to deeper reefs, presumably due to impacts from recurrent bleaching events and development pressures over recent decades. The results of this work underscore the Qatar Peninsula as being at the biogeographic epicenter of the wider Gulf. However, further temperature increases may push both fishes and corals over their physiological limits. Management efforts at both the regional and global level are needed to reduce thermal stressors and preserve the rich reef ecosystems found in the waters surrounding Qatar.},
	issue        = {September},
	keywords     = {Arabian Gulf,Persian Gulf,Scleractinia,climate change,coral communities,fish communities,thermal adaptation}
}
@article{Buckee2022,
	title        = {Daily timing of low tide drives seasonality in intertidal emersion mortality risk},
	author       = {Joanna Buckee and Yasha Hetzel and William Edge and Jennifer Verduin and Chari Pattiaratchi},
	year         = 2022,
	journal      = {Frontiers in Marine Science},
	volume       = 9,
	pages        = {1--21},
	doi          = {10.3389/fmars.2022.904191},
	issn         = 22967745,
	abstract     = {Sea level exerts a fundamental influence on the intertidal zone, where organisms are subject to immersion and emersion at varying timescales and frequencies. While emersed, intertidal organisms are exposed to atmospheric stressors which show marked diurnal and seasonal variability, therefore the daily and seasonal timing of low water is a key determinant of survival and growth in this zone. Using the example of shallow coral reefs, the coincidence of emersion with selected stressors was investigated for eight locations around the Australian coastline. Hourly water levels (1992 – 2016) from a high-resolution sea level hindcast (http://sealevelx.ems.uwa.edu.au), were linked to maximum surface solar radiation data from the Copernicus ERA5 atmospheric model and minimum atmospheric temperature observations from the Australian Bureau of Meteorology to identify seasonal patterns and historical occurrence of coral emersion mortality risk. Local tidal characteristics were found to dictate the time of day when low water, and therefore emersion mortality risk occurs, varying on a seasonal and regional basis. In general, risk was found to be greatest during the Austral spring when mean sea levels are lowest and a phase change in solar tidal constituents occurs. For all Great Barrier Reef sites, low tide occurs close to midday during winter and midnight in the summer, which may be fundamental factor supporting the historical bio-geographical development of the reef. Interannual variability in emersion mortality risk was mostly driven by non-tidal factors, particularly along the West Coast where El Ni\~{n}o events are associated with lower mean sea levels. This paper highlights the importance of considering emersion history when assessing intertidal environments, including shallow coral reef platform habitats, where critical low water events intrinsically influence coral health and cover. The study addresses a fundamental knowledge gap in both the field of water level science and intertidal biology in relation to the daily timing of low tide, which varies predictably on a seasonal and regional basis.},
	issue        = {September},
	keywords     = {El Ni\~{n}o southern oscillation,coral reef disturbance,coral reef formation,sea level variability,sub-aerial exposure,tidal regime}
}
@article{Tamborrino2022,
	title        = {Spatial distribution and morphometry of the Namibian coral mounds controlled by the hydrodynamic regime and outer-shelf topography},
	author       = {Leonardo Tamborrino and J\"{u}rgen Titschack and Claudia Wienberg and Sam Purkis and Gregor P. Eberli and Dierk Hebbeln},
	year         = 2022,
	journal      = {Frontiers in Marine Science},
	volume       = 9,
	pages        = {1--20},
	doi          = {10.3389/fmars.2022.877616},
	issn         = 22967745,
	abstract     = {Cold-water corals mounds develop over millennial timescales as a result of sustained coral growth and concurrent with sediment deposition within their coral frameworks. So far, coral mounds have been primarily investigated as deep-sea biodiversity hotspots and geo-biological paleo-archives, whereas their morphological appearance and spatial arrangement have received much less attention. Here, we analysed the spatial distribution and the morphometry of coral mounds that developed on the Namibian shelf during a single short period dating back to the Early. The spatial distribution of these ``early-stage'' mounds and their morphological characteristics revealed a hierarchy of three different patterns. These comprise an alongslope mound distribution at a regional scale (first-order pattern), a topography-steered downslope alignment of mounds at a local scale (second-order pattern), and a hydrodynamic-controlled downslope orientation of the individual mounds at a mound scale (third-order pattern). In addition, because the Namibian mounds rarely exceed 20 m in height, key steps in the development of early-stage coral mounds (e.g. elongation, merging, limited gain in height compared to lateral extension) have been identified. With increasing size, coral mounds are more elongated, parallel to the prevailing tidal system, which is interpreted to reflect the transition from an ``inherited'' to a ``developed'' mound morphology. Besides supporting this earlier hypothesis on mound development, we could show that this transition takes place when the Namibian coral mounds reach ~150 m in length and ~8 m in height. This study reveals that the spatial-morphological appearance of coral mounds, often treated as a descriptive information, can provide valid information to understand their formation.},
	issue        = {October},
	keywords     = {cold-water corals,coral mound formation,internal tides/waves,morphometry,spatial analysis,underlying topography}
}
@article{Studivan2022,
	title        = {Reef Sediments Can Act As a Stony Coral Tissue Loss Disease Vector},
	author       = {Michael S. Studivan and Ashley M. Rossin and Ewelina Rubin and Nash Soderberg and Daniel M. Holstein and Ian C. Enochs},
	year         = 2022,
	journal      = {Frontiers in Marine Science},
	volume       = 8,
	pages        = {1--15},
	doi          = {10.3389/fmars.2021.815698},
	issn         = 22967745,
	abstract     = {Stony coral tissue loss disease (SCTLD) was first observed in 2014 near Virginia Key in Miami-Dade County, Florida. Field sampling, lab experiments, and modeling approaches have suggested that reef sediments may play a role in SCTLD transmission, though a positive link has not been tested experimentally. We conducted an ex situ transmission assay using a statistically-independent disease apparatus to test whether reef sediments can transmit SCTLD in the absence of direct contact between diseased and healthy coral tissue. We evaluated two methods of sediment inoculation: batch inoculation of sediments collected from southeast Florida using whole colonies of diseased Montastraea cavernosa, and individual inoculations of sediments following independent, secondary infections of \sim{}5 cm2 coral fragments. Healthy fragments of the coral species Orbicella faveolata and M. cavernosa were exposed to these diseased sediment treatments, as well as direct disease contact and healthy sediment controls. SCTLD transmission was observed for both batch and individual diseased sediment inoculation treatments, albeit with lower proportions of infected individuals as compared to disease contact controls. The time to onset of lesions was significantly different between species and among disease treatments, with the most striking infections occurring in the individual diseased sediment treatment in under 24 h. Following infection, tissue samples were confirmed for the presence of SCTLD signs via histological examination, and sediment subsamples were analyzed for microbial community variation between treatments, identifying 16 SCTLD indicator taxa in sediments associated with corals experiencing tissue loss. This study demonstrated that reef sediments can indeed transmit SCTLD through indirect exposure between diseased and healthy corals, and adds credence to the assertion that SCTLD transmission occurs via an infectious agent or agents. This study emphasizes the critical need to understand the roles that sediment microbial communities and coastal development activities may have on the persistence of SCTLD throughout the endemic zone, especially in the context of management and conservation strategies in Florida and the wider Caribbean.},
	issue        = {January},
	keywords     = {16S,ballast water,disease reservoir,disease transmission,disease vector,histology,microbial communities,sedimentation}
}
@article{Mcclanahan2022,
	title        = {Forecasting Climate Sanctuaries for Securing the Future of Coral Reefs},
	author       = {Tim Mcclanahan and Emily Darling and Remy Oddenyo and Gautam Surya and Maria Beger and Helen Fox5 and Stacy Jupiter6 and Lizzie Mcleod7 and Lisa Mcmanus8 and Robert Van Woesik9 and Hedley Grantham3 and Cheryl Logan and Joseph Maina and Vardhan Patankar and Amelia Wenger1 and Jens Zinke},
	year         = 2022,
	journal      = {Vibrant Oceans Initiative Whitepaper},
	url          = {https://coral.org/wp-content/uploads/2022/04/50-Reefs-Science-whitepaper.pdf},
	abstract     = {Since the launch of the 50 Reefs portfolio in 2018, the world's coral reefs have experienced continued climate change impacts that have led to mass coral bleaching and mortality. Drawing on thirty years of research, we highlight the environmental and biological factors that predict the ongoing climate impacts of coral reefs, and explore the potential for adaptation, acclimation and stress tolerance of coral reefs. We propose to expand the 50 Reefs approach into three types of climate change sanctuaries: avoidance, resistance, and recovery refugia. While previous efforts have typically focused on avoidance sanctuaries, defined as coral reef locations that have until now avoided climate-change related stresses and are predicted to experience less future acceleration of stresses (e.g., the 50 Reefs), there is a renewed urgency to safeguard locations that can also display resistance to climate exposure or show rapid recovery after bleaching events. The 50 Reefs portfolio remains a good investment for avoidance sanctuaries but becomes more robust when resistance and recovery sanctuaries are included. We recommend that future portfolios should include reefs with broader environmental, ecological, and genetic characteristics that specifically underscore resistance and recovery. However, testing the predictions of these models remains crucial in order to evaluate the expectation that reefs within proposed sanctuaries are healthier (i.e., coral cover and reef fish biomass above key thresholds, higher diversity) than reefs outside of proposed sanctuaries. Ultimately, a holistic approach integrating sanctuaries and ecosystem services can inform how investments in coral reef conservation can safeguard key reef functions of maintained carbonate production of reef corals, coral adaptation/acclimation processes, and reef fisheries production. As impacts of climate change accelerate and result in ecological surprises or adaptation/acclimation mechanisms, future modeling efforts should go beyond excess heat and temperatures to integrate globally comparable datasets of ecological surveys, hydrodynamic modeling, genetics, and remotely sensed environmental data layers. We conclude with specific recommendations for governments, funders, conservation organizations, and stakeholders on how to promote the persistence and survival of tropical coral reefs in order to minimize the loss of reef services to humanity under the increasing stress of climate change. These recommendations include: Continue with the 50 Reefs approach (i.e., climate change avoidance sanctuaries) as a priority for investment in coral reef conservation. Expand the 50 Reefs conservation portfolio for climate change to include coral resistance and recovery sanctuaries. Increase support for regional evaluations of the health of the 50 Reefs portfolio, and sustainable financing initiatives to support the implementation of regional portfolios. Catalyze large-scale, data-driven coral reef monitoring efforts to test and develop new models and predictions of climate sanctuaries. Use the latest climate coral reef science to guide investments, especially as the impacts of climate change accelerate and produce novel environmental stresses and responses among reefs. Embrace a holistic approach to the management of 50 Reefs sites, including connections to broader seascapes, fisheries and water quality management, mitigation of other pressures (e.g., industrial development), so that effective and equitable management has measurable benefits for coral reefs and coastal communities.},
	issue        = {April}
}
@article{Bachman2022,
	title        = {A global atlas of potential thermal refugia for coral reefs generated by internal gravity waves},
	author       = {Scott D. Bachman and Joan A. Kleypas and Mark Erdmann and Edy Setyawan},
	year         = 2022,
	journal      = {Frontiers in Marine Science},
	volume       = 9,
	pages        = {1--13},
	doi          = {10.3389/fmars.2022.921879},
	issn         = 22967745,
	abstract     = {Coral reefs are highly threatened by ocean warming and the majority are likely to be lost in less than three decades. A first step in maximizing reef conservation through this period is to identify where coral reefs are more likely to survive rising ocean temperatures, such as locations that experience lower temperatures than surrounding regions, high temperature variability, and high food supply. Such conditions are often the result of naturally occurring internal gravity waves (IGWs), oscillatory subsurface disturbances that can entrain cooler and/or nutrient-rich subsurface waters and cause high frequency temperature fluctuations. These features usually remain undetected because they occur subsurface and at spatial scales of O(1 km) and smaller. To shed light on where IGWs are likely to impact temperature conditions within coral reef regions, we present an analysis of data from the LLC4320, a massive high resolution (1/48\r{}; < 2.5~km) numerical global ocean simulation. The results highlight strong regional differences in the incidence of IGW-induced temperature variability. The analysis also reveals that thermal refugia are limited to depths where high temperature variability coincides with the actual reef depth and may not persist year-round. Assuming 10-m depth as the nominal reef depth, reef regions likely to benefit from IGW-induced cooling occur in SE Asia and the Coral Triangle, the Gal\'{a}pagos, along the Pacific shelf of Central America, and isolated locations worldwide. Such refugia are rare within the Atlantic reef sector. An interactive global atlas showing the results of this study has been made freely available online at https://ncar.github.io/coral-viz/.},
	issue        = {July},
	keywords     = {coral reefs,global atlas,internal gravity waves,temperature variability,thermal refugia}
}
@article{Przeslawski2022,
	title        = {Broad distribution of spider-shaped lebensspuren along the Australian continental margin},
	author       = {Rachel Przeslawski},
	year         = 2022,
	journal      = {Frontiers in Marine Science},
	volume       = 9,
	pages        = {1--5},
	doi          = {10.3389/fmars.2022.1086193},
	issn         = 22967745,
	abstract     = {During feeding and burrowing, many epibenthic and infaunal animals bioturbate sediments and form a range of traces called lebensspuren (German for `life traces'), defined as any type of sedimentary structure produced by a living organism. During a 2020 survey along western Australia in the Gascoyne Marine Park, a distinct trace was observed several times, identical to the `spider trace' observed in a 2007 survey along eastern Australia, over 4000~km away. The purpose of this brief note is to document and describe the occurrence of this unique and distinctive type of lebensspuren and to discuss ways in which similar observations may be effectively shared to increase our understanding of deep-sea biology.},
	issue        = {December},
	keywords     = {ROV,deep-sea,ichnology,trace fossils,underwater imagery}
}
@article{Wakwella2022,
	title        = {Managing Watersheds for Coral Reefs and Public Health: A Vibrant Oceans Initiative Whitepaper},
	author       = {A Wakwella and A Wegner and S Jupiter and J Lamb and ...},
	year         = 2022,
	journal      = {Wildlife Conservative \ldots{}},
	pages        = {1--22},
	url          = {https://repository.fnu.ac.fj/id/eprint/42/},
	abstract     = {\ldots{} by the Fijian government as the three plagues: leptospirosis, typhoid, and dengue (hereafter \ldots{} for ecosystem services: practice learns from theory and theory can learn from practice.'' Oryx \ldots{}},
	issue        = {March}
}
@article{Gros2022,
	title        = {Vulnerable, but Still Poorly Known, Marine Ecosystems: How to Make Distribution Models More Relevant and Impactful for Conservation and Management of VMEs?},
	author       = {Charley Gros and Jan Jansen and Piers K. Dunstan and Dirk C. Welsford and Nicole A. Hill},
	year         = 2022,
	journal      = {Frontiers in Marine Science},
	volume       = 9,
	pages        = {1--12},
	doi          = {10.3389/fmars.2022.870145},
	issn         = 22967745,
	abstract     = {Human activity puts our oceans under multiple stresses, whose impacts are already significantly affecting biodiversity and physicochemical properties. Consequently, there is an increased international focus on the conservation and sustainable use of oceans, including the protection of fragile benthic biodiversity hotspots in the deep sea, identified as vulnerable marine ecosystems (VMEs). International VME risk assessment and conservation efforts are hampered because we largely do not know where VMEs are located. VME distribution modelling has increasingly been recommended to extend our knowledge beyond sparse observations. Nevertheless, the adoption of VME distribution models in spatial management planning and conservation remains limited. This work critically reviews VME distribution modelling studies, and recommends promising avenues to make VME models more relevant and impactful for policy and management decision making. First, there is an important interplay between the type of VME data used to build models and how the generated maps can be used in making management decisions, which is often ignored by model-builders. Overall, there is a need for more precise VME data for production of reliable models. We provide specific guidelines for seven common applications of VME distribution modelling to improve the matching between the modelling and the user need. Second, the current criteria to identify VME often rely on subjective thresholds, which limits the transparency, transferability and effective applicability of distribution models in protection measures. We encourage scientists towards founding their models on: (i) specific and quantitative definitions of what constitute a VME, (ii) site conservation value assessment in relation to VME multi-taxon spatial predictions, and (iii) explicitly mapping vulnerability. Along with the recent increase in both deep-sea biological and environmental data quality and quantity, these modelling recommendations can lead towards more cohesive summaries of VME's spatial distributions and their relative vulnerability, which should facilitate a more effective protection of these ecosystems, as has been mandated by numerous international agreements.},
	issue        = {June},
	keywords     = {environmental impact assessment,habitat suitability model,marine conservation,species distribution model,vulnerable marine ecosystems}
}
@article{Morato2022,
	title        = {Modelling the Dispersion of Seafloor Massive Sulphide Mining Plumes in the Mid Atlantic Ridge Around the Azores},
	author       = {Telmo Morato and Manuela Juliano and Christopher K. Pham and Marina Carreiro-Silva and In\^{e}s Martins and Ana Cola\c{c}o},
	year         = 2022,
	journal      = {Frontiers in Marine Science},
	volume       = 9,
	pages        = {1--18},
	doi          = {10.3389/fmars.2022.910940},
	issn         = 22967745,
	abstract     = {It is increasingly recognised that deep-sea mining of seafloor massive sulphides (SMS) could become an important source of mineral resources. These operations will remove the targeted substrate and produce potentially toxic plumes from in situ seabed excavation and from the return water pumped back down to the seafloor. However, the spatial extent of the impact of deep-sea mining is still uncertain because few field experiments and models of plume dispersion have been conducted. In this study, we used three-dimensional hydrodynamic models of the Azores region together with a theoretical commercial mining operation of polymetallic SMS to simulate the potential dispersal of plumes originating from different phases of mining operations, and to assess the magnitude of potential impacts. Although the model simulations presented here were subject to many caveats, they did reveal some important patterns. The model projected marked differences among sites making generalisations about plume-dispersal patterns in mid-ocean ridges difficult. Nevertheless, the models predicted large horizontal and vertical plume-dispersals above the thresholds adopted. Persistent plumes (temporal frequency >50\%, i.e., 6 months out of 12 months) were projected to disperse an average linear distance of 10 to 20~km, cover an area of 17 to 150 km2, and extend more than 800~m in the water column. In fact, the model projected that plumes may disperse beyond the licensed mining areas, reach the flanks and summits of nearby topographic features, and extend into the bathypelagic, mesopelagic, and epipelagic environments. Modelled plume-dispersal overlaps with the predicted distribution of cold-water corals and with existing fishing activities. These potential impacts would be of particular concern in regions such as the Azores, where local populations are highly dependent on the sea for their livelihoods. The findings of this study are an important initial step towards understanding the nature and magnitude of deep-sea mining impacts in space and time.},
	issue        = {July},
	keywords     = {MOHID,Mid Atlantic Ridge,deep-sea,hydrodynamic model,mining,sediment plumes,spatial extent of impacts}
}
@article{Liu2022,
	title        = {The Formation of Atolls: New Insights From Numerical Simulations},
	author       = {Jinlong Liu and Jody M. Webster and Tristan Salles and Shuhong Wang and Yikai Ma and Weihai Xu and Gang Li and Wen Yan},
	year         = 2022,
	journal      = {Journal of Geophysical Research: Earth Surface},
	volume       = 127,
	doi          = {10.1029/2022JF006812},
	issn         = 21699011,
	abstract     = {Several theories have been proposed to explain atoll formation. While karst dissolution during glacial periods and preferential coral reef accretion along raised bank margins during deglaciations and interglacials have been invoked to explain atoll formation, the respective roles of karst dissolution and reef margin construction in atoll formation have not been adequately evaluated by simulations. In this study, we conducted three-dimensional numerical simulations of the Quaternary development of Meiji Atoll in the southern South China Sea based on interpreted data from a 2020-m-deep borehole drilled on its northeast rim in 2018. Our results suggest that the origin of atolls is more likely due to spatially differential dissolution across margin and interior areas (i.e., minimal along margins and maximal in bank centers) rather than preferential reef accretion along margins of flat-topped banks. Preferential reef accretion along margins of flat-topped banks that can result in central lagoons and atoll morphology can hardly result in the formation of lagoonal patch reefs that reach mean sea level. Preferential reef accretion along margins is mainly predicated on the karst-induced morphology that has a central depression surrounded by raised rims, that is, using antecedent karst morphologies. If topographic highs in the lagoon are similar in elevation to the margins, reef accretion on these topographic highs can be similar to that observed on the margins, resulting in lagoonal patch reefs that reach mean sea level. Our simulation shows that spatially differential dissolution across margin and interior areas is a critical driver of worldwide central lagoons and atoll formation.},
	issue        = 8,
	keywords     = {atoll origin,coral reef accretion,karst dissolution,numerical modeling}
}
@article{Rajasekaran2022,
	title        = {PTRM: Perceived Terrain Realism Metric},
	author       = {Suren Deepak Rajasekaran and Hao Kang and Martin \c{C}ad\'{\i}k and Eric Galin and Eric Gu\'{e}rin and Adrien Peytavie and Pavel Slav\'{\i}k and Bedrich Benes},
	year         = 2022,
	journal      = {ACM Transactions on Applied Perception},
	volume       = 19,
	pages        = {1--22},
	doi          = {10.1145/3514244},
	issn         = 15443965,
	abstract     = {Terrains are visually prominent and commonly needed objects in many computer graphics applications. While there are many algorithms for synthetic terrain generation, it is rather difficult to assess the realism of a generated output. This article presents a first step toward the direction of perceptual evaluation for terrain models. We gathered and categorized several classes of real terrains, and we generated synthetic terrain models using computer graphics methods. The terrain geometries were rendered by using the same texturing, lighting, and camera position. Two studies on these image sets were conducted, ranking the terrains perceptually, and showing that the synthetic terrains are perceived as lacking realism compared to the real ones. We provide insight into the features that affect the perceived realism by a quantitative evaluation based on localized geomorphology-based landform features (geomorphons) that categorize terrain structures such as valleys, ridges, hollows, and so forth. We show that the presence or absence of certain features has a significant perceptual effect. The importance and presence of the terrain features were confirmed by using a generative deep neural network that transferred the features between the geometric models of the real terrains and the synthetic ones. The feature transfer was followed by another perceptual experiment that further showed their importance and effect on perceived realism. We then introduce Perceived Terrain Realism Metrics (PTRM), which estimates human-perceived realism of a terrain represented as a digital elevation map by relating the distribution of terrain features with their perceived realism. This metric can be used on a synthetic terrain, and it will output an estimated level of perceived realism. We validated the proposed metrics on real and synthetic data and compared them to the perceptual studies.},
	issue        = 2,
	keywords     = {Procedural modeling,feature transfer,neural networks,terrains,visual perception}
}
@article{Hachette2022,
	title        = {Automatic shape adjustment at joints for the implicit skinning},
	author       = {Olivier Hachette and Florian Canezin and Rodolphe Vaillant and Nicolas Mellado and Lo\"{\i}c Barthe},
	year         = 2022,
	journal      = {Computers and Graphics (Pergamon)},
	publisher    = {Elsevier Ltd.},
	volume       = 102,
	pages        = {300--308},
	doi          = {10.1016/j.cag.2021.10.018},
	issn         = {00978493},
	url          = {https://doi.org/10.1016/j.cag.2021.10.018},
	abstract     = {The implicit skinning is a geometric interactive skinning method, for skeleton-based animations, enabling plausible deformations at joints while resolving skin self-collisions. Even though requiring a few user interactions to be adequately parameterized, some efforts have to be spent on the edition of the shapes at joints In this research, we introduce a dedicated optimization framework for automatically adjusting the shape of the surfaces generating the deformations at joints when they are rotated during an animation. This approach directly fits in the implicit skinning pipeline and it has no impact on the algorithm performance during animation. Starting from the mesh partition of the mesh representing the animated character, we propose a dedicated hole filling algorithm based on a particle system and a power crust meshing. We then introduce a procedure optimizing the shape of the filled mesh when it rotates at the joint level. This automatically generates plausible skin deformation when joints are rotated without the need of extra user editing.},
	keywords     = {Geometric modeling,Shape deformation,Skinning}
}
@article{Kench2022,
	title        = {Sustained coral reef growth in the critical wave dissipation zone of a Maldivian atoll},
	author       = {Paul S. Kench and Edward P. Beetham and Tracey Turner and Kyle M. Morgan and Susan D. Owen and Roger F. McLean},
	year         = 2022,
	journal      = {Communications Earth and Environment},
	publisher    = {Springer US},
	volume       = 3,
	pages        = {1--12},
	doi          = {10.1038/s43247-021-00338-w},
	issn         = 26624435,
	abstract     = {Sea-level rise is expected to outpace the capacity of coral reefs to grow and maintain their wave protection function, exacerbating coastal flooding and erosion of adjacent shorelines and threatening coastal communities. Here we present a new method that yields highly-resolved direct measurements of contemporary reef accretion on a Maldivian atoll reef rim, the critical zone that induces wave breaking. Results incorporate the suite of physical and ecological processes that contribute to reef accumulation and show growth rates vary from 6.6 \pm{} 12.5 mm.y-1 on the reef crest, and up to 3.1 \pm{} 10.2 mm.y-1, and -0.5 \pm{} 1.8 mm.yr-1 on the outer and central reef flat respectively. If these short-term results are maintained over decades, the reef crest could keep pace with current sea-level rise. Findings highlight the need to resolve contemporary reef accretion at the critical wave dissipation zone to improve predictions of future reef growth, and re-evaluate exposure of adjacent shorelines to coastal hazards.},
	issue        = 1
}
@article{WangKai2022,
	title        = {The Shape Part Slot Machine: Contact-Based Reasoning for~Generating 3D Shapes from~Parts},
	author       = {Kai Wang and Paul Guerrero and Vladimir G. Kim and Siddhartha Chaudhuri and Minhyuk Sung and Daniel Ritchie},
	year         = 2022,
	journal      = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume       = {13663 LNCS},
	pages        = {610--626},
	doi          = {10.1007/978-3-031-20062-5_35},
	isbn         = 9783031200618,
	issn         = 16113349,
	url          = {https://arxiv.org/pdf/2112.00584.pdf},
	abstract     = {We present the Shape Part Slot Machine, a new method for assembling novel 3D shapes from existing parts by performing contact-based reasoning. Our method represents each shape as a graph of ``slots,'' where each slot is a region of contact between two shape parts. Based on this representation, we design a graph-neural-network-based model for generating new slot graphs and retrieving compatible parts, as well as a gradient-descent-based optimization scheme for assembling the retrieved parts into a complete shape that respects the generated slot graph. This approach does not require any semantic part labels; interestingly, it also does not require complete part geometries--reasoning about the slots proves sufficient to generate novel, high-quality 3D shapes. We demonstrate that our method generates shapes that outperform existing modeling-by-assembly approaches regarding quality, diversity, and structural complexity.}
}
@article{Corso2022,
	title        = {Non-random orientation of Pocillopora colonies on forereefs of Moorea, French Polynesia},
	author       = {Jack Corso and Beverly J. French and Clinton B. Edwards and Nicole E. Pedersen and Brian J. Zgliczynski and Serge Planes and Stephen Pacala and Stuart A. Sandin},
	year         = 2022,
	journal      = {Marine Ecology Progress Series},
	publisher    = {Inter-Research},
	volume       = 693,
	pages        = {177--182},
	doi          = {10.3354/meps14078},
	issn         = 16161599,
	abstract     = {Morphological variation in scleractinian corals has been variously ascribed to genetic differentiation and phenotypic plasticity, with a likely influence of both factors. Experimental approaches have dominated studies of phenotypic plasticity, for example with asymmetrical colony formation resulting from exposure to experimentally imposed unidirectional water flow. However, it has been difficult to disentangle the effects of competition for space between sessile organisms from the influence of physical forcing on coral morphologies in situ. To this end, we investigated morphological variation of coral colonies of the genus Pocillopora on reefs in Moorea, French Polynesia, where recovery (by 2018) after near complete loss of coral cover on the forereef in 2010 was driven predominantly by recruitment and growth of Pocillopora. We employed a large-area imaging approach at 8 study sites in the forereef of Moorea, constructing digital models of 100 m2 benthic plots to describe the orientation of ~400 individual colonies of Pocillopora. Results demonstrate that Pocillopora colonies on the forereef of Moorea exhibit non-random orientations, with a systematic orientation of the major axis that lies approximately perpendicular to the 20-30 m isobath.},
	keywords     = {Coral,Hydrodynamics,Morphology,Phenotypic plasticity,Photogrammetry}
}
@inproceedings{Chen2022,
	title        = {Go Green: General Regularized Green's Functions for Elasticity},
	author       = {Jiong Chen and Mathieu Desbrun},
	year         = 2022,
	month        = 8,
	booktitle    = {Special Interest Group on Computer Graphics and Interactive Techniques Conference Proceedings},
	publisher    = {ACM},
	pages        = {1--8},
	doi          = {10.1145/3528233.3530726},
	isbn         = 9781450393379,
	url          = {https://dl.acm.org/doi/10.1145/3528233.3530726},
	abstract     = {The fundamental solutions (Green's functions) of linear elasticity for an infinite and isotropic media are ubiquitous in interactive graphics applications that cannot afford the computational costs of volumetric meshing and finite-element simulation. For instance, the recent work of de Goes and James [2017] leveraged these Green's functions to formulate sculpting tools capturing in real-time broad and physically-plausible deformations more intuitively and realistically than traditional editing brushes. In this paper, we extend this family of Green's functions by exploiting the anisotropic behavior of general linear elastic materials, where the relationship between stress and strain in the material depends on its orientation. While this more general framework prevents the existence of analytical expressions for its fundamental solutions, we show that a finite sum of spherical harmonics can be used to decompose a Green's function, which can be further factorized into directional, radial, and material-dependent terms. From such a decou-pling, we show how to numerically derive sculpting brushes to generate anisotropic deformation and finely control their falloff profiles in real-time.},
	city         = {New York, NY, USA},
	keywords     = {Green's functions,anisotropic material,elasticity,regularization,spherical harmonics.\textasteriskcentered0mm}
}
@article{Shadrick2022,
	title        = {Sea-level rise will likely accelerate rock coast cliff retreat rates},
	author       = {Jennifer R. Shadrick and Dylan H. Rood and Martin D. Hurst and Matthew D. Piggott and Bethany G. Hebditch and Alexander J. Seal and Klaus M. Wilcken},
	year         = 2022,
	month        = 12,
	journal      = {Nature Communications},
	publisher    = {Nature Research},
	volume       = 13,
	doi          = {10.1038/s41467-022-34386-3},
	issn         = 20411723,
	abstract     = {Coastal response to anthropogenic climate change is of central importance to the infrastructure and inhabitants in these areas. Despite being globally ubiquitous, the stability of rock coasts has been largely neglected, and the expected acceleration of cliff erosion following sea-level rise has not been tested with empirical data, until now. We have optimised a coastal evolution model to topographic and cosmogenic radionuclide data to quantify cliff retreat rates for the past 8000 years and forecast rates for the next century. Here we show that rates of cliff retreat will increase by up to an order of magnitude by 2100 according to current predictions of sea-level rise: an increase much greater than previously predicted. This study challenges conventional coastal management practices by revealing that even historically stable rock coasts are highly sensitive to sea-level rise and should be included in future planning for global climate change response.},
	issue        = 1,
	pmid         = 36400787
}
@article{Franke2022,
	title        = {Procedural generation of 3D karst caves with speleothems},
	author       = {Kai Franke and Heinrich M\"{u}ller},
	year         = 2022,
	month        = 2,
	journal      = {Computers and Graphics (Pergamon)},
	publisher    = {Elsevier Ltd},
	volume       = 102,
	pages        = {533--545},
	doi          = {10.1016/j.cag.2021.10.002},
	issn         = {00978493},
	abstract     = {A comprehensive method for generating natural looking virtual karst caves is presented. The method includes the network and the local shape of cave passages, the appearance of the wall surface, and speleothems like stalactites. It favors efficient explicit phenomenological modeling over detailed physical modeling and simulation of the long-lasting real process of cave formation, which would be impractical. Speleothems are placed considering the suitability of local conditions of the environment. Appropriately designed grid-based data structures efficiently handle the challenge of different scales of caves. An implementation of the method is used to experimentally demonstrate that virtual karst caves of the major real-world types can be generated with practicable computing time and memory requirements as well as interactively visualized and walked through.},
	keywords     = {Computational modeling,Geographic visualization,Procedural environment generation}
}
@article{ZhangJian2022,
	title        = {Authoring multi-style terrain with global-to-local control},
	author       = {Jian Zhang and Chen Li and Peichi Zhou and Changbo Wang and Gaoqi He and Hong Qin},
	year         = 2022,
	month        = 1,
	journal      = {Graphical Models},
	publisher    = {Elsevier Inc.},
	volume       = 119,
	doi          = {10.1016/j.gmod.2021.101122},
	issn         = 15240703,
	abstract     = {The appearance styles of natural terrains vary significantly from region to region in real world, and there is a strong need to effectively produce realistic terrain with certain style in computer graphics. In this paper, we advocate a novel neural network approach to the rapid synthesis of multi-style terrains that could directly learn and infer from real terrain data. The key idea is to explicitly devise a conditional generative adversarial network (GAN) which encourages and favors the maximum-distance embedding of acquired styles in the latent space. Towards this functionality, we first collect a dataset that exhibits apparent terrain style diversity in their style attributes. Second, we design multiple discriminators that can distinguish different terrain styles. Third, we employ discriminators to extract terrain features in different spatial scales, so that the developed generator can produce new terrains by fusing the finer-scale and coarser-scale styles. In our experiments, we collect 10 typical terrain datasets from real terrain data that cover a wide range of regions. Our approach successfully generates realistic terrains with global-to-local style control. The experimental results have confirmed our neural network can produce natural terrains with high fidelity, which are user-friendly to style interpolation and style mixing for the terrain authoring task.},
	keywords     = {Generative adversarial network (GAN),Shape modeling,Terrain authoring}
}
@phdthesis{BaillyThesis,
	title        = {G\'{e}n\'{e}ration proc\'{e}durale de niveaux de jeu alliant approche constructive et optimisation},
	author       = {Rapha\"{e}l Bailly},
	year         = 2022,
	month        = 12,
	url          = {https://theses.hal.science/tel-03971457},
	city         = {Angoul\^{e}me},
	institution  = {Conservatoire National des Arts et M\'{e}tiers}
}
@article{Lima2022,
	title        = {A grammar-based optimization approach for walkable urban fabrics considering pedestrian accessibility and infrastructure cost},
	author       = {Fernando T. Lima and Nathan C. Brown and Jos\'{e} P. Duarte},
	year         = 2022,
	month        = 6,
	journal      = {Environment and Planning B: Urban Analytics and City Science},
	publisher    = {SAGE Publications Ltd},
	volume       = 49,
	pages        = {1489--1506},
	doi          = {10.1177/23998083211048496},
	issn         = 23998091,
	abstract     = {Designing urban areas that provide smaller distances to their amenities is a key factor toward more walkable environments. Moreover, this is a critical aspect of climate-resilient urban planning since it is broadly assumed that areas with greater walkability discourage automobile usage and reduce CO2 emissions. Generative and data-driven design approaches, in turn, increase designers' ability to explore wider sets of potential solutions. In this sense, identifying designs with an optimized performance out of the vast possibilities that computation can provide is crucial. Shape grammars are a formal method of shape generation that facilitate the elaboration of complex patterns and meaningful designs. This paper hypothesizes that coupling shape grammars with multi-objective optimization can help address trade-offs and decision-making in urban design. It focuses on the pedestrian accessibility and infrastructure cost (as estimated by cumulative street length) trade-off in urban fabrics as a case study to verify the suitability of a grammar-based optimization approach for more dynamic and efficient solution-finding in urban design. Our findings suggest that a grammar-based optimization approach is helpful in addressing urban trade-offs as it could be used to filter the design space and provide optimal alternative fabric layouts with increased pedestrian accessibility and decreased infrastructure cost.},
	issue        = 5,
	keywords     = {Shape grammars,infrastructure cost,multi-objective optimization,urban fabrics,walkability}
}
@article{Huang2022,
	title        = {Climate change and ecological engineering jointly induced vegetation greening in global karst regions from 2001 to 2020},
	author       = {Jing Huang and Zhongxi Ge and Yuqing Huang and Xuguang Tang and Zhan Shi and Peiyu Lai and Zengjing Song and Binfei Hao and Hong Yang and Mingguo Ma},
	year         = 2022,
	month        = 6,
	journal      = {Plant and Soil},
	publisher    = {Springer Science and Business Media Deutschland GmbH},
	volume       = 475,
	pages        = {193--212},
	doi          = {10.1007/s11104-021-05054-0},
	issn         = 15735036,
	abstract     = {Backgrounds: Vegetation dynamics play a dominant role in the global carbon cycle and climate, especially in vulnerable karst ecosystem. Many studies have examined the~past several decades changes in vegetation greenness and the associated with climate drivers. Yet, few studies have analyzed the vegetation change in global karst regions particularly in the last decades when climate change and anthropogenic disturbance widely occurred. Methods: In this study, we investigated the spatio-temporal variations in vegetation dynamic using the Seasonally Integrated Normalized Difference Vegetation Index (SINDVI) and examined their relationship with climate changes using correlation analysis, the ordinary least squares method investigate the variation trends and the Mann-Kendal test to detect the turning points from 2001 to 2020. Results: As expected, there were greening trends in global karst SINDVI from 2001 to 2020, with significant increasing trends in China (range = 0.836, P < 0.05), Europe (range = 0.456, P < 0.05) and many other regions. According to correlation analyses, SINDVI was water-limited in arid and semi-arid regions, such as Middle East and central Asia, and temperature-limited in northern high-latitude. Conclusions: Our results suggest that anthropogenic activities were mainly responsible for the~increasing vegetation greenness in tailoring management measures (e.g., Ecological Engineering, the Grain to Green Project) in China and Europe, and~intensive farm in Middle East. Coupling warming temperature and increasing precipitation, southeastern Asia and Russia showed increasing trends in SINDVI. In general, climate factors were the dominant drivers for the variation in vegetation greenness in globally karst regions during research period.},
	issue        = {1-2},
	keywords     = {Climate factors,Global karst regions,Human activities,SINDVI,Vegetation greenness trends}
}
@article{Zhu2022,
	title        = {Controllable blending of line and polygon skeleton-based convolution surfaces with finite support kernels},
	author       = {Xiaoqiang Zhu and Qi Chen and Sihu Liu and Chenjie Fan and Chenze Song and Junjie Zhang and Dan Zeng and Xiaogang Jin},
	year         = 2022,
	month        = 8,
	journal      = {Computers and Graphics (Pergamon)},
	publisher    = {Elsevier Ltd},
	volume       = 106,
	pages        = {98--109},
	doi          = {10.1016/j.cag.2022.05.016},
	issn         = {00978493},
	abstract     = {We present a novel approach to control the blending of line and polygon skeleton-based convolution surfaces using locally varying Ratio of Support radius and Thickness (RST). With our method, solutions for local convolution surface approximation with prescribed surface thickness and support radii can be derived analytically. In addition, iso-surface shrinkage can be avoided by offsetting the endpoints of line skeletons and the edges of polygon skeletons. Our RST-based blending for convolution surfaces is local and can generate desired blending effects while approximating shapes with a specified thickness. Moreover, our method is intuitive and users can control the blending by adjusting the skeletal radius or the support radius of the finite support kernel independently. As our blending utilizes convolution integration only without requiring any extra composition operators, it allows for successive convolution blending operations to create complex shapes.},
	keywords     = {Convolution surfaces,Implicit surface blending,Semi-analytical solutions,Support radius}
}
@inproceedings{Lim2022,
	title        = {Visually Improved Erosion Algorithm for the Procedural Generation of Tile-based Terrain},
	author       = {Fong Yuan Lim and Yu Wei Tan and Anand Bhojan},
	year         = 2022,
	booktitle    = {Proceedings of the International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications},
	publisher    = {Science and Technology Publications, Lda},
	volume       = 1,
	pages        = {49--59},
	doi          = {10.5220/0010799700003124},
	isbn         = 9789897585555,
	issn         = 21844321,
	abstract     = {Procedural terrain generation is the process of generating a digital representation of terrain using a computer program or procedure, with little to no human guidance. This paper proposes a procedural terrain generation algorithm based on a graph representation of fluvial erosion that offers several novel improvements over existing algorithms. Namely, the use of a height constraint map with two types of locally defined constraint strengths; the ability to specify a realistic erosion strength via level of rainfall; and the ability to carve realistic gorges. These novelties allow it to generate more varied and realistic terrain by integrating additional parameters and simulation processes, while being faster and offering more flexibility and ease of use to terrain designers due to the nature and intuitiveness of these new parameters and processes. This paper additionally reviews some common metrics used to evaluate terrain generators, and suggests a completely new one that contributes to a more holistic evaluation.},
	keywords     = {Erosion,Games,Generation,Modelling,Natural,PCG,Procedural,Terrain,Virtual World}
}
@article{Niese2022,
	title        = {Procedural Urban Forestry},
	author       = {Till Niese and S\"{o}ren Pirk and Matthias Albrecht and Bedrich Benes and Oliver Deussen},
	year         = 2022,
	month        = 4,
	journal      = {ACM Transactions on Graphics},
	publisher    = {Association for Computing Machinery},
	volume       = 41,
	doi          = {10.1145/3502220},
	issn         = 15577368,
	abstract     = {The placement of vegetation plays a central role in the realism of virtual scenes. We introduce procedural placement models (PPMs) for vegetation in urban layouts. PPMs are environmentally sensitive to city geometry and allow identifying plausible plant positions based on structural and functional zones in an urban layout. PPMs can either be directly used by defining their parameters or learned from satellite images and land register data. This allows us to populate urban landscapes with complex 3D vegetation and enhance existing approaches for generating urban landscapes. Our framework's effectiveness is shown through examples of large-scale city scenes and close-ups of individually grown tree models. We validate the results generated with our framework with a perceptual user study and its usability based on urban scene design sessions with expert users.},
	issue        = 2,
	keywords     = {Urban models,procedural generation,urban forestry,vegetation}
}
@article{Raateland2022,
	title        = {DCGrid: An Adaptive Grid Structure for Memory-Constrained Fluid Simulation on the GPU},
	author       = {Wouter Raateland and Torsten H\"{a}drich and Jorge Alejandro Amador Herrera and Daniel T. Banuti and Wojciech Pa\l{}ubicki and S\"{o}ren Pirk and Klaus Hildebrandt and Dominik L. Michels},
	year         = 2022,
	month        = 5,
	journal      = {Proceedings of the ACM on Computer Graphics and Interactive Techniques},
	publisher    = {Association for Computing Machinery},
	volume       = 5,
	doi          = {10.1145/3522608},
	issn         = 25776193,
	abstract     = {We introduce Dynamic Constrained Grid (DCGrid), a hierarchical and adaptive grid structure for fluid simulation combined with a scheme for effectively managing the grid adaptations. DCGrid is designed to be implemented on the GPU and used in high-performance simulations. Specifically, it allows us to efficiently vary and adjust the grid resolution across the spatial domain and to rapidly evaluate local stencils and individual cells in a GPU implementation. A special feature of DCGrid is that the control of the grid adaption is modeled as an optimization under a constraint on the maximum available memory, which addresses the memory limitations in GPU-based simulation. To further advance the use of DCGrid in high-performance simulations, we complement DCGrid with an efficient scheme for approximating collisions between fluids and static solids on cells with different resolutions. We demonstrate the effectiveness of DCGrid for smoke flows and complex cloud simulations in which terrain-atmosphere interaction requires working with cells of varying resolution and rapidly changing conditions. Finally, we compare the performance of DCGrid to that of alternative adaptive grid structures.},
	issue        = 1,
	keywords     = {Adaptive grid,Fluid simulation,Hierarchical solver,Real-time simulation}
}
@article{Wojtek2022,
	title        = {Ecoclimates: Climate-Response Modeling of Vegetation},
	author       = {Wojtek Pa\l{}ubicki and Mi\l{}osz Makowski and Weronika Gajda and Torsten H\"{a}drich and Dominik L. Michels and S\"{o}ren Pirk},
	year         = 2022,
	month        = 7,
	journal      = {ACM Transactions on Graphics},
	publisher    = {Association for Computing Machinery},
	volume       = 41,
	doi          = {10.1145/3528223.3530146},
	issn         = 15577368,
	abstract     = {One of the greatest challenges to mankind is understanding the underlying principles of climate change. Over the last years, the role of forests in climate change has received increased attention. This is due to the observation that not only the atmosphere has a principal impact on vegetation growth but also that vegetation is contributing to local variations of weather resulting in diverse microclimates. The interconnection of plant ecosystems and weather is described and studied as ecoclimates. In this work we take steps towards simulating ecoclimates by modeling the feedback loops between vegetation, soil, and atmosphere. In contrast to existing methods that only describe the climate at a global scale, our model aims at simulating local variations of climate. Specifically, we model tree growth interactively in response to gradients of water, temperature and light. As a result, we are able to capture a range of ecoclimate phenomena that have not been modeled before, including geomorphic controls, forest edge effects, the Foehn effect and spatial vegetation patterning. To validate the plausibility of our method we conduct a comparative analysis to studies from ecology and climatology. Consequently, our method advances the state-of-the-art of generating highly realistic outdoor landscapes of vegetation.},
	issue        = 4,
	keywords     = {cloud simulation,fluid dynamics,interactive modeling,natural phenomena,physics-based modeling and simulation,plant ecosystems,vegetation modeling,weather simulation}
}
@article{Betley2021,
	title        = {Assessing human well-being constructs with environmental and equity aspects: A review of the landscape},
	author       = {Erin C. Betley and Amanda Sigouin and Pua'ala Pascua and Samantha H. Cheng and Kenneth Iain MacDonald and Felicity Arengo and Yildiz Aumeeruddy-Thomas and Sophie Caillon and Marney E. Isaac and Stacy D. Jupiter and Alexander Mawyer and Manuel Mejia and Alexandria C. Moore and Delphine Renard and Lea S\'{e}bastien and Nadav Gazit and Eleanor J. Sterling},
	year         = 2023,
	month        = 12,
	journal      = {People and Nature},
	volume       = 5,
	pages        = {1756--1773},
	doi          = {10.1002/pan3.10293},
	issn         = {2575-8314},
	url          = {https://besjournals.onlinelibrary.wiley.com/doi/10.1002/pan3.10293},
	abstract     = {<p> <list> <list-item> <p>Decades of theory and scholarship on the concept of human well-being have informed a proliferation of approaches to assess well-being and support public policy aimed at sustainability and improving quality of life.</p> </list-item> <list-item> <p>Human well-being is multidimensional, and well-being emerges when the dimensions and interrelationships interact as a system. In this paper, we illuminate two crucial components of well-being that are often excluded from policy because of their relative difficulty to measure and manage: equity and interrelationships between humans and the environment.</p> </list-item> <list-item> <p>We use a mixed-methods approach to review and summarize progress to date in developing well-being constructs (including frameworks and methods) that address these two components.</p> </list-item> <list-item> <p>Well-being frameworks that do not consider the environment, or interrelationships between people and their environment, are not truly measuring well-being in all its dimensions.</p> </list-item> <list-item> <p>Use of equity lenses to assess well-being frameworks aligns with increasing efforts to more holistically characterize well-being and to guide sustainability management in ethical and equitable ways.</p> </list-item> <list-item> <p>Based on the findings of our review, we identify several pathways forward for the development and implementation of well-being frameworks that can inform efforts to leverage well-being for public policy.</p> </list-item> </list> </p>},
	issue        = 6
}
@inproceedings{Hartley2023,
	title        = {Flexible Terrain Erosion : A Fluid Simulation-Independent Approach for 3D Terrain Procedural Generation Compatible with Multiple Representations},
	author       = {Marc Hartley and Noura Faraj and Nicolas Mellado and Christophe Fiorio},
	year         = 2023,
	booktitle    = {SMI}
}
@article{Lutz2023,
	title        = {Preserving the autocovariance of texture tilings using importance sampling},
	author       = {Nicolas Lutz and Basile Sauvage and Jean Michel Dischler},
	year         = 2023,
	journal      = {Computer Graphics Forum},
	volume       = 42,
	pages        = {347--358},
	doi          = {10.1111/cgf.14766},
	issn         = 14678659,
	abstract     = {By-example aperiodic tilings are popular texture synthesis techniques that allow a fast, on-the-fly generation of unbounded and non-periodic textures with an appearance matching an arbitrary input sample called the ``exemplar''. But by relying on uniform random sampling, these algorithms fail to preserve the autocovariance function, resulting in correlations that do not match the ones in the exemplar. The output can then be perceived as excessively random. In this work, we present a new method which can well preserve the autocovariance function of the exemplar. It consists in fetching contents with an importance sampler taking the explicit autocovariance function as the probability density function (pdf) of the sampler. Our method can be controlled for increasing or decreasing the randomness aspect of the texture. Besides significantly improving synthesis quality for classes of textures characterized by pronounced autocovariance functions, we moreover propose a real-time tiling and blending scheme that permits the generation of high-quality textures faster than former algorithms with minimal downsides by reducing the number of texture fetches.},
	issue        = 2,
	keywords     = {CCS Concepts,Texturing,\textbullet{} Computing methodologies \rightarrow{} Rendering}
}
@article{Csébfalvi2023,
	title        = {One Step Further Beyond Trilinear Interpolation and Central Differences: Triquadratic Reconstruction and its Analytic Derivatives at the Cost of One Additional Texture Fetch},
	author       = {Bal\'{a}zs Cs\'{e}bfalvi},
	year         = 2023,
	journal      = {Computer Graphics Forum},
	volume       = 42,
	pages        = {191--200},
	doi          = {10.1111/cgf.14753},
	issn         = 14678659,
	abstract     = {Recently, it has been shown that the quality of GPU-based trilinear volume resampling can be significantly improved if the six additional trilinear samples evaluated for the gradient estimation also contribute to the reconstruction of the underlying function [Cs\'{e}19]. Although this improvement increases the approximation order from two to three without any extra cost, the continuity order remains C0. In this paper, we go one step further showing that a C1 continuous triquadratic B-spline reconstruction and its analytic partial derivatives can be evaluated by taking only one more trilinear sample into account. Thus, our method is the first volume-resampling technique that is nearly as fast as trilinear interpolation combined with on-the-fly central differencing, but provides a higher-quality reconstruction together with a consistent analytic gradient calculation. Furthermore, we show that our fast evaluation scheme can also be adapted to the Mitchell-Netravali [MN88] notch filter, for which a fast GPU implementation has not been known so far.},
	issue        = 2,
	keywords     = {CCS Concepts,Image processing,Texturing,\textbullet{} Computing methodologies \rightarrow{} Volumetric models}
}
@article{Wei2023,
	title        = {Robust Pointset Denoising of Piecewise-Smooth Surfaces through Line Processes},
	author       = {Jiayi Wei and Jiong Chen and Damien Rohmer and Pooran Memari and Mathieu Desbrun},
	year         = 2023,
	journal      = {Computer Graphics Forum},
	volume       = 42,
	pages        = {175--189},
	doi          = {10.1111/cgf.14752},
	issn         = 14678659,
	abstract     = {Denoising is a common, yet critical operation in geometry processing aiming at recovering high-fidelity models of piecewise-smooth objects from noise-corrupted pointsets. Despite a sizable literature on the topic, there is a dearth of approaches capable of processing very noisy and outlier-ridden input pointsets for which no normal estimates and no assumptions on the underlying geometric features or noise type are provided. In this paper, we propose a new robust-statistics approach to denoising pointsets based on line processes to offer robustness to noise and outliers while preserving sharp features possibly present in the data. While the use of robust statistics in denoising is hardly new, most approaches rely on prescribed filtering using data-independent blending expressions based on the spatial and normal closeness of samples. Instead, our approach deduces a geometric denoising strategy through robust and regularized tangent plane fitting of the initial pointset, obtained numerically via alternating minimizations for efficiency and reliability. Key to our variational approach is the use of line processes to identify inliers vs. outliers, as well as the presence of sharp features. We demonstrate that our method can denoise sampled piecewise-smooth surfaces for levels of noise and outliers at which previous works fall short.},
	issue        = 2,
	keywords     = {CCS Concepts,\textbullet{} Computing methodologies \rightarrow{} Point-based models}
}
@article{Sorgente2023,
	title        = {A Survey of Indicators for Mesh Quality Assessment},
	author       = {T. Sorgente and S. Biasotti and G. Manzini and M. Spagnuolo},
	year         = 2023,
	journal      = {Computer Graphics Forum},
	volume       = 42,
	pages        = {461--483},
	doi          = {10.1111/cgf.14779},
	issn         = 14678659,
	abstract     = {We analyze the joint efforts made by the geometry processing and the numerical analysis communities in the last decades to define and measure the concept of ``mesh quality''. Researchers have been striving to determine how, and how much, the accuracy of a numerical simulation or a scientific computation (e.g., rendering, printing, modeling operations) depends on the particular mesh adopted to model the problem, and which geometrical features of the mesh most influence the result. The goal was to produce a mesh with good geometrical properties and the lowest possible number of elements, able to produce results in a target range of accuracy. We overview the most common quality indicators, measures, or metrics that are currently used to evaluate the goodness of a discretization and drive mesh generation or mesh coarsening/refinement processes. We analyze a number of local and global indicators, defined over two- and three-dimensional meshes with any type of elements, distinguishing between simplicial, quadrangular/hexahedral, and generic polytopal elements. We also discuss mesh optimization algorithms based on the above indicators and report common libraries for mesh analysis and quality-driven mesh optimization.},
	issue        = 2,
	keywords     = {CCS Concepts,Numerical analysis,\textbullet{} Computing methodologies \rightarrow{} Modeling and simulatio,\textbullet{} Mathematics of computing \rightarrow{} Mesh generation}
}
@article{Alonso2023,
	title        = {Real-time rendering and physics of complex dynamic terrains modeled as CSG trees of DEMs carved with spheres},
	author       = {Jes\'{u}s Alonso and Robert Joan-Arinyo and Antoni Chica},
	year         = 2023,
	month        = 8,
	journal      = {Computers and Graphics (Pergamon)},
	publisher    = {Elsevier Ltd},
	volume       = 114,
	pages        = {306--315},
	doi          = {10.1016/j.cag.2023.06.019},
	issn         = {00978493},
	abstract     = {We present a novel proposal for modeling complex dynamic terrains that offers real-time rendering, dynamic updates and physical interaction of entities simultaneously. We can capture any feature from landscapes including tunnels, overhangs and caves, and we can conduct a total destruction of the terrain. Our approach is based on a Constructive Solid Geometry tree, where a set of spheres are subtracted from a base Digital Elevation Model. Erosions on terrain are easily and efficiently carried out with a spherical sculpting tool with pixel-perfect accuracy. Real-time rendering performance is achieved by applying a one-direction CPU–GPU communication strategy and using the standard depth and stencil buffer functionalities provided by any graphics processor.},
	keywords     = {CSG,Terrain erosion,Terrain modeling}
}
@article{Rusconi2023,
	title        = {The effect of a rocky terrain for CubeSat landing on asteroid surfaces},
	author       = {Martina Rusconi and Fabio Ferrari and Francesco Topputo},
	year         = 2023,
	month        = 1,
	journal      = {Advances in Space Research},
	publisher    = {Elsevier Ltd},
	volume       = 71,
	pages        = {829--844},
	doi          = {10.1016/j.asr.2022.10.056},
	issn         = 18791948,
	abstract     = {The paper describes a general modelling procedure to build a simulation tool to investigate contact motion of a CubeSat on an asteroid surface. We investigate landing performance and landing success for the case of elastic rocky terrain and flat surfaces. As a case study, we focus on the disposal of ESA's Hera Milani CubeSat by landing on the moon of Didymos binary asteroid system. The simulation environment includes the modelling of real shape and 6-DOF motion of the lander, the shape-based gravity models of Didymos and Dimorphos and rocks on surface, that are generated as physical obstacles. Trends and estimates on the performance of the landing phase and the most relevant effects on the outcome of the soil interaction process, are inferred. The statistical results on settling time, dispersion area and motion characteristics, such as number of bounces, show and quantify the effect of rocks on a successful passive and permanent landing.},
	issue        = 1,
	keywords     = {AIDA,Asteroid,Ballistic landing,Contact dynamics,Rocky terrain,Simulation}
}
@article{Cordonnier2023,
	title        = {Forming Terrains by Glacial Erosion},
	author       = {Guillaume Cordonnier and Guillaume Jouvet and Adrien Peytavie and Jean Braun and Marie-Paule Cani and Bedrich Benes and Eric Galin and Eric Gu\'{e}rin and James Gain},
	year         = 2023,
	journal      = {ACM Transactions on Graphics},
	volume       = 42,
	pages        = 14,
	doi          = {10.1145/3592422ï},
	url          = {https://doi.org/10.1145/3592422.},
	abstract     = {We introduce the first solution for simulating the formation and evolution of glaciers, together with their attendant erosive effects, for periods covering the combination of glacial and inter-glacial cycles. Our efficient solution includes both a fast yet accurate deep learning-based estimation of high-order ice flows and a new, multi-scale advection scheme enabling us to account for the distinct time scales at which glaciers reach equilibrium compared to eroding the terrain. We combine the resulting glacial erosion model with finer-scale erosive phenomena to account for the transport of debris flowing from cliffs. This enables us to model the formation of terrain shapes not previously adequately modeled in Computer Graphics, ranging from U-shaped and hanging valleys to fjords and glacial lakes.},
	issue        = 4,
	keywords     = {Erosion,Glacial Erosion,Landscape,Simulation of Natural Phenomena,Terrain}
}
@article{Schott2023,
	title        = {Large-scale Terrain Authoring through Interactive Erosion Simulation},
	author       = {Hugo Schott and Axel Paris and Lucie Fournier and Eric Gu\'{e}rin and Eric Galin},
	year         = 2023,
	month        = 10,
	journal      = {ACM Transactions on Graphics},
	publisher    = {inPress},
	volume       = 42,
	pages        = {1--15},
	doi          = {10.1145/3592787},
	issn         = {0730-0301},
	url          = {https://dl.acm.org/doi/10.1145/3592787},
	abstract     = {<p>Large-scale terrains are essential in the definition of virtual worlds. Given the diversity of landforms and the geomorphological complexity, there is a need for authoring techniques offering hydrological consistency without sacrificing user control. In this article, we bridge the gap between large-scale erosion simulation and authoring into an efficient framework. We set aside modeling in the elevation domain in favour of the uplift domain and compute emerging reliefs by simulating the stream power erosion. Our simulation relies on a fast yet accurate approximation of drainage area and flow routing to compute the erosion interactively, which allows for incremental authoring. Our model provides landscape artists with tools for shaping mountain ranges and valleys, such as copy-and-paste operations; warping for imitating folds and faults; and point and curve elevation constraints to precisely sculpt ridges or carve river networks. It also lends itself to inverse procedural modeling by reconstructing the uplift from an input digital elevation model and allows hydrologically consistent blending between terrain patches.</p>},
	issue        = 5,
	keywords     = {Erosion Simulation,Landscapes}
}
@unpublished{Gailleton2023,
	title        = {CHONK 1.0: landscape evolution framework: cellular automata meets graph theory},
	author       = {Boris Gailleton and Luca Malatesta and Guillaume Cordonnier and Jean Braun},
	year         = 2023,
	doi          = {10.5194/egusphere-2022-1394},
	url          = {https://doi.org/10.5194/egusphere-2022-1394},
	abstract     = {Landscape Evolution Models (LEMs) are prime tools to simulate the evolution of source-to-sink systems through ranges of spatial and temporal scales. Plethora of different empirical laws have been successfully applied to describe the different parts of these systems: fluvial erosion, sediment transport and deposition, hillslope diffusion, or hydrology. Numerical frameworks exist to facilitate the combination of different subsets of laws, mostly by superposing grids of fluxes calculated independently. However the exercise becomes increasingly challenging when the different laws are interconnected: for exam-5 ple when a lake breaks the upstream-downstream continuum of the amount of sediment and water it receives and transmits; or when erosional efficiency depends of the composition of a sediment flux affected by multiple processes. In this contribution, we present a method mixing the advantages of cellular-automata and graph theory to address such cases. We demonstrate how the former guarantees finite knowledge of all fluxes independently from the process-law implemented in the model while the latter offer a wide range of tools to process numerical landscapes, including landscapes with closed basins. We provide 10 three scenario largely benefiting from our method: i) one where lake systems are primary controls on Landscape evolution, ii) one where sediment provenance is closely monitored through the stratigraphy and iii) one where heterogeneous provenance influences fluvial incision dynamically. We finally outline the way forward to make this method more generic and flexible.}
}
@article{Gomez2023,
	title        = {The Game of Go: A Cellular Automata Approach},
	author       = {Jos\'{e} Manuel Gomez Soto and Diego Delgado Avila},
	year         = 2023,
	journal      = {Journal of Cellular Automata},
	volume       = {0},
	pages        = {1--21},
	abstract     = {This paper shows a way to play the game of Go using cellular automata. To do this, we consider the best move depending on the player's style: offensive, defensive, or neutral. The best move is characterized by the importance of the next points: Chain growth, growth of degrees of freedom , reduction of opponent's degrees of freedom or capture of oppo-nent's stones. We use cellular automata to compute these problems for each possible move and determine the next move. We also use cellular automata to evaluate the board at each moment and determine which player wins in the endgame.},
	keywords     = {Cellular automata,game of Go}
}
@article{Oron2023,
	title        = {How monster storms shape fringing reefs: Observations from the 2020 Middle East Cyclone},
	author       = {Shai Oron and Derya Akkaynak and Beverly N. Goodman Tchernov and Yonathan Shaked},
	year         = 2023,
	month        = 7,
	journal      = {Ecosphere},
	publisher    = {John Wiley and Sons Inc},
	volume       = 14,
	doi          = {10.1002/ecs2.4602},
	issn         = 21508925,
	abstract     = {In March 2020, an unusually intense storm system struck the Gulf of Aqaba-Eilat, resulting in severe shoreline damage. This brief account examines post-storm observations of inconsistent damage patterns and structural changes along a specific coastal stretch located at the south beach of Eilat. Certain sections of the coastline experienced direct impact from extreme waves on the south-southeast-facing shallow reef, resulting in areas where rocks were completely stripped of corals due to sediment backwash. Conversely, areas characterized by ridges and deep troughs saw the loss of branching corals and some massive colonies, while many small corals survived. A neighboring area with a well-developed fringing reef suffered lesser damage. Between the severely affected shallow reef and the robust fringing reef lies an unconsolidated slope that migrated eastward by at least 2 m following the storm, incorporating numerous coral colonies dislodged by the event. We propose that this slope advances with each major storm occurrence, influencing the characteristics of nearby shores and coral reefs. This case demonstrates how storm events, in conjunction with geomorphology, have a cumulative and significant impact not only on the structure of coral communities but also on the fundamental shape of coral reefs themselves. As climate change amplifies the range, intensity, and frequency of storms, comprehending these processes becomes increasingly crucial.},
	issue        = 7,
	keywords     = {climate change,coral reefs,cyclone,disturbance,reef development,storm}
}
@article{Perche2023a,
	title        = {Authoring Terrains with Spatialised Style},
	author       = {Simon Perche and Adrien Peytavie and Bedrich Benes and Eric Galin and Eric Gu\'{e}rin},
	year         = 2023,
	month        = 10,
	journal      = {Computer Graphics Forum},
	publisher    = {John Wiley and Sons Inc},
	volume       = 42,
	doi          = {10.1111/cgf.14936},
	issn         = 14678659,
	abstract     = {Various terrain modelling methods have been proposed for the past decades, providing efficient and often interactive authoring tools. However, they seldom include any notion of style, which is critical for designers in the entertainment industry. We introduce a new generative network method that bridges the gap between automatic terrain synthesis and authoring, providing a versatile set of authoring tools allowing spatialised style. We build upon the StyleGAN2 architecture and extend it with authoring tools. Given an input sketch or existing elevation map, our method generates a terrain with features that can be authored, enhanced, and augmented using interactive brushes and style manipulation tools. The strength of our approach lies in the versatility and interoperability of the different tools. We validate our method quantitatively with drainage calculation against other previous techniques and qualitatively by asking users to follow a prompt or freely create a terrain.},
	issue        = 7,
	keywords     = {CCS Concepts,Shape modeling,\textbullet{} Computing methodologies \rightarrow{} Shape inference}
}
@article{Perche2023b,
	title        = {StyleDEM: a Versatile Model for Authoring Terrains},
	author       = {Simon Perche and Adrien Peytavie and Bedrich Benes and Eric Galin and Eric Gu\'{e}rin},
	year         = 2023,
	month        = 4,
	url          = {http://arxiv.org/abs/2304.09626},
	abstract     = {Many terrain modelling methods have been proposed for the past decades, providing efficient and often interactive authoring tools. However, they generally do not include any notion of style, which is a critical aspect for designers in the entertainment industry. We introduce StyleDEM, a new generative adversarial network method for terrain synthesis and authoring, with a versatile toolbox of authoring methods with style. This method starts from an input sketch or an existing terrain. It outputs a terrain with features that can be authored using interactive brushes and enhanced with additional tools such as style manipulation or super-resolution. The strength of our approach resides in the versatility and interoperability of the toolbox.}
}
@phdthesis{ParisThesis,
	title        = {Modeling and simulating virtual terrains},
	author       = {Axel Paris},
	year         = 2023,
	month        = 3,
	url          = {https://theses.hal.science/tel-04502530},
	city         = {Lyon},
	institution  = {Universit\'{e} Claude Bernard Lyon 1},
	keywords     = {Implicit Surfaces,Landscape,Procedural Modeling}
}
@article{He2023,
	title        = {GlobalMapper: Arbitrary-Shaped Urban Layout Generation},
	author       = {Liu He and Daniel Aliaga},
	year         = 2023,
	journal      = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
	pages        = {454--464},
	abstract     = {Modeling and designing urban building layouts is of significant interest in computer vision, computer graphics, and urban applications. A building layout consists of a set of buildings in city blocks defined by a network of roads. We observe that building layouts are discrete structures, consisting of multiple rows of buildings of various shapes, and are amenable to skeletonization for mapping arbitrary city block shapes to a canonical form. Hence, we propose a fully automatic approach to building layout generation using graph attention networks. Our method generates realistic urban layouts given arbitrary road networks, and enables conditional generation based on learned priors. Our results, including user study, demonstrate superior performance as compared to prior layout generation networks, support arbitrary city block and varying building shapes as demonstrated by generating layouts for 28 large cities.}
}
@article{Deng2023,
	title        = {CityGen: Infinite and Controllable 3D City Layout Generation},
	author       = {Jie Deng and Wenhao Chai and Jianshu Guo and Qixuan Huang and Wenhao Hu and Jenq-Neng Hwang and Gaoang Wang},
	year         = 2023,
	month        = 12,
	url          = {http://arxiv.org/abs/2312.01508},
	abstract     = {City layout generation has recently gained significant attention. The goal of this task is to automatically generate the layout of a city scene, including elements such as roads, buildings, vegetation, as well as other urban infrastructures. Previous methods using VAEs or GANs for 3D city layout generation offer limited diversity and constrained interactivity, only allowing users to selectively regenerate parts of the layout, which greatly limits customization. In this paper, we propose CityGen, a novel end-to-end framework for infinite, diverse and controllable 3D city layout generation.First, we propose an outpainting pipeline to extend the local layout to an infinite city layout. Then, we utilize a multi-scale diffusion model to generate diverse and controllable local semantic layout patches. The extensive experiments show that CityGen achieves state-of-the-art (SOTA) performance under FID and KID in generating an infinite and controllable 3D city layout. CityGen demonstrates promising applicability in fields like smart cities, urban planning, and digital simulation.}
}
@inproceedings{Michel2023,
	title        = {MesoGen: Designing Procedural On-Surface Stranded Mesostructures},
	author       = {\'{E}lie Michel and Tamy Boubekeur},
	year         = 2023,
	month        = 7,
	booktitle    = {Proceedings - SIGGRAPH 2023 Conference Papers},
	publisher    = {Association for Computing Machinery, Inc},
	doi          = {10.1145/3588432.3591496},
	abstract     = {Three-dimensional mesostructures enrich coarse macrosurfaces with complex features, which are 3D geometry with arbitrary topology in essence, but are expected to be self-similar with no tiling artifacts, just like texture-based material models. This is a challenging task, as no existing modeling tool provides the right constraints in the design phase to ensure such properties while maintaining real-time editing capabilities. In this paper, we propose MesoGen, a novel tile-centric authoring approach for the design of procedural mesostructures featuring non-periodic self-similarity while being represented as a compact and GPU-friendly model. We ensure by construction the continuity of the mesostructure: the user designs a set of atomic tiles by drawing 2D cross-sections on the interfaces between tiles, and selecting pairs of cross-sections to be connected as strands, i.e., 3D sweep surfaces. In parallel, a tiling engine continuously fills the shell space of the macrosurface with the so-defined tile set while ensuring that only matching interfaces are in contact. Moreover, the engine suggests to the user the addition of new tiles whenever the problem happens to be over-constrained. As a result, our method allows for the rapid creation of complex, seamless procedural mesostructure and is particularly adapted for wicker-like ones, often impossible to achieve with scattering-based mesostructure synthesis methods.},
	keywords     = {3D mesostructure,Interactive shape modeling,shell mapping,tilling}
}
@phdthesis{Sainio2023,
	title        = {Terrain generation algorithms},
	author       = {Niko Sainio},
	year         = 2023,
	city         = {Tampere},
	institution  = {Tampere University}
}
@inproceedings{Gousie2023,
	title        = {A Modified Dem for Representing Overhanging Terrain},
	author       = {Michael B. Gousie and Hannah Lord},
	year         = 2023,
	booktitle    = {International Geoscience and Remote Sensing Symposium (IGARSS)},
	publisher    = {Institute of Electrical and Electronics Engineers Inc.},
	volume       = {2023-July},
	pages        = {5615--5618},
	doi          = {10.1109/IGARSS52108.2023.10281407},
	isbn         = 9798350320107,
	abstract     = {We propose a modified Digital Elevation Model (DEM) that stores additional data to adequately represent overhanging terrain. The DEM contains one additional line in the header information that describes the encoding of the data for any overhanging structures, arches, or caves. This additional data is then appended to the end of the normal DEM file. We describe a procedural approach to render arches using this modified DEM. This procedure can thereby generate terrain from ground truth data as opposed to many current methods. The new DEM is backward compatible except for the one additional line in the header; it is also space efficient, needing minimal data necessary for representing the overhanging terrain, thus keeping the file size at O(n2 ).},
	keywords     = {Terrain,digital elevation model,file format,modeling,overhangs}
}
@article{Perche2023,
	title        = {StyleDEM: a Versatile Model for Authoring Terrains},
	author       = {Simon Perche and Adrien Peytavie and Bedrich Benes and Eric Galin and Eric Gu\'{e}rin},
	year         = 2023,
	month        = 4,
	url          = {http://arxiv.org/abs/2304.09626},
	abstract     = {Many terrain modelling methods have been proposed for the past decades, providing efficient and often interactive authoring tools. However, they generally do not include any notion of style, which is a critical aspect for designers in the entertainment industry. We introduce StyleDEM, a new generative adversarial network method for terrain synthesis and authoring, with a versatile toolbox of authoring methods with style. This method starts from an input sketch or an existing terrain. It outputs a terrain with features that can be authored using interactive brushes and enhanced with additional tools such as style manipulation or super-resolution. The strength of our approach resides in the versatility and interoperability of the toolbox.}
}
@article{Taylor2023,
	title        = {Real-Time Sand Dune Simulation},
	author       = {Brennen Taylor and John Keyser},
	year         = 2023,
	month        = 5,
	journal      = {Proceedings of the ACM on Computer Graphics and Interactive Techniques},
	publisher    = {Association for Computing Machinery},
	volume       = 6,
	doi          = {10.1145/3585510},
	issn         = 25776193,
	abstract     = {We present a novel real-time method for simulating aeolian sand transport and dune propagation. Our method is a GPU-based extension of the Desertscapes Simulation sand propagation model to additionally capture echo dunes and obstacle interaction. We validate our method by comparing it against an existing study of echo dune evolution in a wind tunnel environment. Additionally, we demonstrate the significantly improved performance of our method via comparison to the existing, CPU-based method. Lastly, we validate our method by comparing it to a published study exploring the evolution of dunes in a bidirectional wind environment driven by an offline, cellular autonoma based method. We conclude that the presented method is a simple and helpful tool for users in multiple domains who wish to capture physically plausible desertscape evolution in real time.},
	issue        = 1,
	keywords     = {GPU,real-time,sand-dunes,simulation}
}
@inproceedings{Maggioli2023,
	title        = {A Physically-inspired Approach to the Simulation of Plant Wilting},
	author       = {Filippo Maggioli and Jonathan Klein and Torsten H\"{a}drich and Emanuele Rodol\`{a} and Wojtek Pa\l{}ubicki and S\"{o}ren Pirk and Dominik L. Michels},
	year         = 2023,
	month        = 12,
	booktitle    = {Proceedings - SIGGRAPH Asia 2023 Conference Papers, SA 2023},
	publisher    = {Association for Computing Machinery, Inc},
	doi          = {10.1145/3610548.3618218},
	isbn         = 9798400703157,
	abstract     = {Plants are among the most complex objects to be modeled in computer graphics. While a large body of work is concerned with structural modeling and the dynamic reaction to external forces, our work focuses on the dynamic deformation caused by plant internal wilting processes. To this end, we motivate the simulation of water transport inside the plant which is a key driver of the wilting process. We then map the change of water content in individual plant parts to branch stiffness values and obtain the wilted plant shape through a position based dynamics simulation. We show, that our approach can recreate measured wilting processes and does so with a higher fidelity than approaches ignoring the internal water flow. Realistic plant wilting is not only important in a computer graphics context but can also aid the development of machine learning algorithms in agricultural applications through the generation of synthetic training data.},
	keywords     = {Diffusion Models,Digital Plants,Plant Modeling,Plant Wilting,Position Based Dynamics (PBD).}
}
@article{Chen2023,
	title        = {Integrating Topographic Skeleton into Deep Learning for Terrain Reconstruction from GDEM and Google Earth Image},
	author       = {Kai Chen and Chun Wang and Mingyue Lu and Wen Dai and Jiaxin Fan and Mengqi Li and Shaohua Lei},
	year         = 2023,
	month        = 9,
	journal      = {Remote Sensing},
	publisher    = {Multidisciplinary Digital Publishing Institute (MDPI)},
	volume       = 15,
	doi          = {10.3390/rs15184490},
	issn         = 20724292,
	abstract     = {The topographic skeleton is the primary expression and intuitive understanding of topographic relief. This study integrated a topographic skeleton into deep learning for terrain reconstruction. Firstly, a topographic skeleton, such as valley, ridge, and gully lines, was extracted from a global digital elevation model (GDEM) and Google Earth Image (GEI). Then, the Conditional Generative Adversarial Network (CGAN) was used to learn the elevation sequence information between the topographic skeleton and high-precision 5 m DEMs. Thirdly, different combinations of topographic skeletons extracted from 5 m, 12.5 m, and 30 m DEMs and a 1 m GEI were compared for reconstructing 5 m DEMs. The results show the following: (1) from the perspective of the visual effect, the 5 m DEMs generated with the three combinations (5 m DEM + 1 m GEI, 12.5 m DEM + 1 m GEI, and 30 m DEM + 1 m GEI) were all similar to the original 5 m DEM (reference data), which provides a markedly increased level of terrain detail information when compared to the traditional interpolation methods; (2) from the perspective of elevation accuracy, the 5 m DEMs reconstructed by the three combinations have a high correlation (>0.9) with the reference data, while the vertical accuracy of the 12.5 m DEM + 1 m GEI combination is obviously higher than that of the 30 m DEM + 1 m GEI combination; and (3) from the perspective of topographic factors, the distribution trends of the reconstructed 5 m DEMs are all close to the reference data in terms of the extracted slope and aspect. This study enhances the quality of open-source DEMs and introduces innovative ideas for producing high-precision DEMs. Among the three combinations, we recommend the 12.5 m DEM + 1 m GEI combination for DEM reconstruction due to its relative high accuracy and open access. In regions where a field survey of high-precision DEMs is difficult, open-source DEMs combined with GEI can be used in high-precision DEM reconstruction.},
	issue        = 18,
	keywords     = {GDEM,Google Earth Image,deep learning,terrain reconstruction,the Loess Plateau of China}
}
@book{Papadimitriou2023,
	title        = {Modelling Landscape Dynamics},
	author       = {Fivos Papadimitriou},
	year         = 2023,
	publisher    = {Springer Fachmedien Wiesbaden},
	doi          = {10.1007/978-3-658-42496-1},
	isbn         = {978-3-658-42495-4},
	url          = {https://link.springer.com/10.1007/978-3-658-42496-1},
	city         = {Wiesbaden}
}
@article{Fattahi2023,
	title        = {Optimizing urban layouts through computational generative design: density distribution and shape optimization},
	author       = {Saba Fattahi Tabasi and Hamid Reza Rafizadeh and Ali Andaji Garmaroudi and Saeed Banihashemi},
	year         = 2023,
	journal      = {Architectural Engineering and Design Management},
	publisher    = {Taylor and Francis Ltd.},
	doi          = {10.1080/17452007.2023.2243272},
	issn         = 17527589,
	abstract     = {The density distribution in an urban matrix is one of the significant issues which affects other urban living factors such as building lighting, energy consumption and residents' interactions. The research toward achieving the optimum density distribution has received attention for the last decade. However, developing a generative approach that provides more freedom for the formation of the plans and incorporates adaptability in different land blocks is still missing. To address such a gap, this study proposes an adaptable approach developing the formation of residential blocks. This formation is according to the pre-defined size and shape of the land, and sought performance objectives. Hence, a suite of applications including Grasshopper, Python and Ladybug were applied in a residential block of Tehran as a case study. The purpose is to develop a new density distribution increasing view quality, visual privacy, and solar gain. For the optimization process, a genetic algorithm was applied utilizing the topology optimization technique. The results of the optimization process highlight the significance of this research since the developed alternatives are more efficient in terms of improving the view quality, visual privacy and increasing the solar gain. This achievement expands the potential of this research to be applied in different case studies and with different design and development objectives in order to develop better shape plans of building blocks.},
	keywords     = {Generative design,density distribution,parametric design,shape optimization,solar radiation,urban shape generation}
}
@article{Candy2023,
	title        = {Small-scale oxygen distribution patterns in a coral reef},
	author       = {Adam S. Candy and Shannara K. Taylor Parkins and Fleur C. Van Duyl and Benjamin Mueller and Milou G.I. Arts and Will Barnes and Marie Carstensen and Yun J.H. Scholten and Yusuf C. El-Khaled and Christian Wild and Linda Wegley Kelly and Craig E. Nelson and Stuart A. Sandin and Mark J.A. Vermeij and Forest L. Rohwer and Cristian Picioreanu and Paolo Stocchi and Andreas F. Haas},
	year         = 2023,
	journal      = {Frontiers in Marine Science},
	publisher    = {Frontiers Media S.A.},
	volume       = 10,
	doi          = {10.3389/fmars.2023.1135686},
	issn         = 22967745,
	abstract     = {One mechanism giving fleshy algae a competitive advantage over corals during reef degradation is algal-induced and microbially-mediated hypoxia (typically less than 69.5 \mathrm{\mu}mol oxygen L-1). During hypoxic conditions oxygen availability becomes insufficient to sustain aerobic respiration in most metazoans. Algae are more tolerant of low oxygen conditions and may outcompete corals weakened by hypoxia. A key question on the ecological importance of this mechanism remains unanswered: How extensive are local hypoxic zones in highly turbulent aquatic environments, continuously flushed by currents and wave surge? To better understand the concert of biological, chemical, and physical factors that determine the abundance and distribution of oxygen in this environment, we combined 3D imagery, flow measurements, macro- and micro-organismal abundance estimates, and experimentally determined biogenic oxygen and carbon fluxes as input values for a 3D bio-physical model. The model was first developed and verified for controlled flume experiments containing coral and algal colonies in direct interaction. We then developed a three-dimensional numerical model of an existing coral reef plot off the coast of Cura\c{c}ao where oxygen concentrations for comparison were collected in a small-scale grid using fiberoptic oxygen optodes. Oxygen distribution patterns given by the model were a good predictor for in situ concentrations and indicate widespread localized differences exceeding 50 \mathrm{\mu}mol L-1 over distances less than a decimeter. This suggests that small-scale hypoxic zones can persist for an extended period of time in the turbulent environment of a wave- and surge- exposed coral reef. This work highlights how the combination of three-dimensional imagery, biogenic fluxes, and fluid dynamic modeling can provide a powerful tool to illustrate and predict the distribution of analytes (e.g., oxygen or other bioactive substances) in a highly complex system.},
	keywords     = {3D imagery,coral reef,hydrodynamics,hypoxia,microbial ecology}
}
@article{Hu2023,
	title        = {Terrain Diffusion Network: Climatic-Aware Terrain Generation with Geological Sketch Guidance},
	author       = {Zexin Hu and Kun Hu and Clinton Mo and Lei Pan and Zhiyong Wang},
	year         = 2023,
	month        = 8,
	url          = {http://arxiv.org/abs/2308.16725},
	abstract     = {Sketch-based terrain generation seeks to create realistic landscapes for virtual environments in various applications such as computer games, animation and virtual reality. Recently, deep learning based terrain generation has emerged, notably the ones based on generative adversarial networks (GAN). However, these methods often struggle to fulfill the requirements of flexible user control and maintain generative diversity for realistic terrain. Therefore, we propose a novel diffusion-based method, namely terrain diffusion network (TDN), which actively incorporates user guidance for enhanced controllability, taking into account terrain features like rivers, ridges, basins, and peaks. Instead of adhering to a conventional monolithic denoising process, which often compromises the fidelity of terrain details or the alignment with user control, a multi-level denoising scheme is proposed to generate more realistic terrains by taking into account fine-grained details, particularly those related to climatic patterns influenced by erosion and tectonic activities. Specifically, three terrain synthesisers are designed for structural, intermediate, and fine-grained level denoising purposes, which allow each synthesiser concentrate on a distinct terrain aspect. Moreover, to maximise the efficiency of our TDN, we further introduce terrain and sketch latent spaces for the synthesizers with pre-trained terrain autoencoders. Comprehensive experiments on a new dataset constructed from NASA Topology Images clearly demonstrate the effectiveness of our proposed method, achieving the state-of-the-art performance. Our code and dataset will be publicly available.}
}
@article{Lemiere2023,
	title        = {Combinatorial Maps, a New Framework to Model Agroforestry Systems},
	author       = {La\"{e}titia Lemiere and Marc Jaeger and Marie Gosme and G\'{e}rard Subsol},
	year         = 2023,
	journal      = {Plant Phenomics},
	publisher    = {American Association for the Advancement of Science},
	volume       = 5,
	pages        = {0120},
	doi          = {10.34133/plantphenomics.0120},
	issn         = 26436515,
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S2643651524001158},
	abstract     = {Agroforestry systems are complex due to the diverse interactions between their elements, and they develop over several decades. Existing numerical models focus either on the structure or on the functions of agroforestry systems. However, these both aspects are necessary, as function influences structure and vice versa. Here, we present a representation of agroforestry systems based on combinatorial maps (which are a type of multidimensional graphs), that allows conceptualizing the structure-function relationship at the agroecosystem scale. We show that such a model can represent the structure of agroforestry systems at multiple scales and its evolution through time. We propose an implementation of this framework, coded in Python, which is available on GitHub. In the future, this framework could be coupled with knowledge based or with biophysical simulation models to predict the production of ecosystem services. The code can also be integrated into visualization tools. Combinatorial maps seem promising to provide a unifying and generic description of agroforestry systems, including their structure, functions and dynamics, with the possibility to translate to and from other representations.}
}
@article{Rammer2024,
	title        = {The individual-based forest landscape and disturbance model iLand: Overview, progress, and outlook},
	author       = {Werner Rammer and Dominik Thom and Martin Baumann and Kristin Braziunas and Christina Dollinger and Jonas Kerber and Johannes Mohr and Rupert Seidl},
	year         = 2024,
	month        = 9,
	journal      = {Ecological Modelling},
	publisher    = {Elsevier B.V.},
	volume       = 495,
	doi          = {10.1016/j.ecolmodel.2024.110785},
	issn         = {03043800},
	abstract     = {Forest ecosystems are changing rapidly, and landscape-level processes such as disturbance and dispersal are key drivers of change. Consequently, forest landscape models are important tools for studying forest trajectories under changing environmental conditions and their impacts on ecosystem service provisioning. Here, we synthesize 12 years of development and application of the individual-based forest landscape and disturbance model iLand. Specifically, we describe the fundamental model logic and give an overview of model components introduced over the years. Additionally, we outline how to initialize, evaluate and parameterize the model for new applications. iLand is a process-based forest landscape model that simulates forest dynamics at the level of individual trees. It accounts for continuous processes (tree growth, mortality, and regeneration) as well as discontinuous disturbances (wind, wildfire, and biotic agents) and forest management. Simulations span multiple spatial and temporal scales, from individual trees to landscapes of 105 hectares, and from hourly disturbance dynamics to centuries of forest development. Environmental conditions are represented by daily climate data and high-resolution soil information. The model was designed for flexibly addressing a wide range of research questions, features a rich graphical user interface and comprehensive scripting support. The model is open source and comes with extensive online model documentation. iLand has hitherto been applied in 50 peer-reviewed simulation studies across three continents. Applications primarily focused on the effects of climate change, disturbances and forest management on forest dynamics, ecosystem service provisioning and forest biodiversity. Future model development could address the representation of belowground processes, biotic interactions, and landscape dynamics beyond forest ecosystems. We conclude that process-based simulation of landscape-scale forest dynamics at the level of individual trees has proven a valuable approach of forest landscape modeling.},
	keywords     = {Agent-based modeling,Forest dynamics,Landscape modeling,Model application,Model development,Model evaluation,Model initialization,Model parameterization,Simulation modeling}
}
@article{Tzathas2024,
	title        = {Physically-based analytical erosion for fast terrain generation},
	author       = {Petros Tzathas and Boris Gailleton and Philippe Steer and Guillaume Cordonnier},
	year         = 2024,
	journal      = {Computer Graphics Forum},
	publisher    = {John Wiley and Sons Inc},
	doi          = {10.1111/cgf.15033},
	issn         = 14678659,
	abstract     = {Terrain generation methods have long been divided between procedural and physically-based. Procedural methods build upon the fast evaluation of a mathematical function but suffer from a lack of geological consistency, while physically-based simulation enforces this consistency at the cost of thousands of iterations unraveling the history of the landscape. In particular, the simulation of the competition between tectonic uplift and fluvial erosion expressed by the stream power law raised recent interest in computer graphics as this allows the generation and control of consistent large-scale mountain ranges, albeit at the cost of a lengthy simulation. In this paper, we explore the analytical solutions of the stream power law and propose a method that is both physically-based and procedural, allowing fast and consistent large-scale terrain generation. In our approach, time is no longer the stopping criterion of an iterative process but acts as the parameter of a mathematical function, a slider that controls the aging of the input terrain from a subtle erosion to the complete replacement by a fully formed mountain range. While analytical solutions have been proposed by the geomorphology community for the 1D case, extending them to a 2D heightmap proves challenging. We propose an efficient implementation of the analytical solutions with a multigrid accelerated iterative process and solutions to incorporate landslides and hillslope processes – two erosion factors that complement the stream power law.},
	keywords     = {CCS Concepts,\textbullet{} Computing methodologies \rightarrow{} Shape modeling}
}
@article{Schott2024,
	title        = {Terrain Amplification using Multi Scale Erosion},
	author       = {Hugo Schott and Eric Galin and Eric Gu\'{e}rin and Axel Paris and Adrien Peytavie},
	year         = 2024,
	month        = 7,
	journal      = {ACM Transactions on Graphics},
	volume       = 43,
	pages        = {1--12},
	doi          = {10.1145/3658200},
	issn         = {0730-0301},
	url          = {https://dl.acm.org/doi/10.1145/3658200},
	abstract     = {<p>Modeling high-resolution terrains is a perennial challenge in the creation of virtual worlds. In this paper, we focus on the amplification of a low-resolution input terrain into a high-resolution, hydrologically consistent terrain featuring complex patterns by a multi-scale approach. Our framework combines the best of both worlds, relying on physics-inspired erosion models producing consistent erosion landmarks and introducing control at different scales, thus bridging the gap between physics-based erosion simulations and multi-scale procedural modeling. The method uses a fast and accurate approximation of different simulations, including thermal, stream power erosion and deposition performed at different scales to obtain a range of effects. Our approach provides landscape designers with tools for amplifying mountain ranges and valleys with consistent details.</p>},
	issue        = 4,
	keywords     = {Erosion Simulation,Landscapes}
}
@article{Hartley2024,
	title        = {Flexible terrain erosion},
	author       = {Marc Hartley and Nicolas Mellado and Christophe Fiorio and Noura Faraj},
	year         = 2024,
	month        = 7,
	journal      = {Visual Computer},
	publisher    = {Springer Science and Business Media Deutschland GmbH},
	doi          = {10.1007/s00371-024-03444-w},
	issn         = {01782789},
	abstract     = {In this paper, we present a novel particle-based method for simulating erosion on various terrain representations, including height fields, voxel grids, material layers, and implicit terrains. Our approach breaks down erosion into two key processes--terrain alteration and material transport--allowing for flexibility in simulation. We utilize independent particles governed by basic particle physics principles, enabling efficient parallel computation. For increased precision, a vector field can adjust particle speed, adaptable for realistic fluid simulations or user-defined control. We address material alteration in 3D terrains with a set of equations applicable across diverse models, requiring only per-particle specifications for size, density, coefficient of restitution, and sediment capacity. Our modular algorithm is versatile for real-time and offline use, suitable for both 2.5D and 3D terrains.},
	keywords     = {Erosion processes,Natural phenomena,Procedural modeling,Terrain morphing}
}
@phdthesis{GossetThesis,
	title        = {M\'{e}thodes et mod\`{e}les pour l'\'{e}laboration automatis\'{e}e de graphes de connaissances dans le domaine juridique : application aux ressources juridiques et juridico-pratiques des collectivit\'{e}s locales et territoriales},
	author       = {Camille Gosset},
	year         = 2024,
	city         = {Montpellier},
	institution  = {Universit\'{e} de Montpellier}
}
@phdthesis{JarryThesis,
	title        = {Estimation de l'\'{e}volution de la pauvret\'{e} par apprentissage profond \& imagerie satellitaire},
	author       = {Robin Jarry},
	year         = 2024,
	month        = 9,
	city         = {Montpellier},
	institution  = {Universit\'{e} de Montpellier}
}
@phdthesis{GrenierThesis,
	title        = {G\'{e}n\'{e}ration proc\'{e}durale et rendu en temps r\'{e}el de motifs structur\'{e}s},
	author       = {Charline Grenier},
	year         = 2024,
	month        = 3,
	city         = {Strasbourg},
	institution  = {Universit\'{e} de Strasbourg}
}
@article{Grenier2024,
	title        = {Real-time Terrain Enhancement with Controlled Procedural Patterns},
	author       = {Charline Grenier and \'{E}ric Gu\'{e}rin and \'{E}ric Galin and Basile Sauvage},
	year         = 2024,
	month        = 2,
	journal      = {Computer Graphics Forum},
	publisher    = {John Wiley and Sons Inc},
	volume       = 43,
	doi          = {10.1111/cgf.14992},
	issn         = 14678659,
	abstract     = {Assisting the authoring of virtual terrains is a perennial challenge in the creation of convincing synthetic landscapes. Particularly, there is a need for augmenting artist-controlled low-resolution models with consistent relief details. We present a structured noise that procedurally enhances terrains in real time by adding spatially varying erosion patterns. The patterns can be cascaded, i.e. narrow ones are nested into large ones. Our model builds upon the Phasor noise, which we adapt to the specific characteristics of terrains (water flow, slope orientation). Relief details correspond to the underlying terrain characteristics and align with the slope to preserve the coherence of generated landforms. Moreover, our model allows for artist control, providing a palette of control maps, and can be efficiently implemented in graphics hardware, thus allowing for real-time synthesis and rendering, therefore permitting effective and intuitive authoring.},
	issue        = 1,
	keywords     = {geometric modelling,modelling,natural phenomena,real-time rendering,rendering}
}
@techreport{HmidyThesis,
	title        = {Une nouvelle fonction d'agr\'{e}gation intervalliste et son utilisation comme mod\`{e}le d'apprentissage automatique pour la r\'{e}gression},
	author       = {Yassine Hmidy},
	year         = 2024,
	month        = 12,
	abstract     = {[William PUECH, Pofesseur des Universit\'{e}s] [Pr\'{e}sident du jury] [Christophe MARSALA , Professeur des Universit\'{e}s] [Rapporteur] [Gilles MAURIS, Ma\^{\i}tre de conf\'{e}rence] [Rapporteur] [Agn\`{e}s RICO, Ma\^{\i}tre de conf\'{e}rence] [Membre du jury]},
	city         = {Montpellier},
	institution  = {Universit\'{e} de Montpellier}
}
@article{Gouy2024,
	title        = {KarstNSim: A graph-based method for 3D geologically-driven simulation of karst networks},
	author       = {Augustin Gouy and Pauline Collon and Vincent Bailly-Comte and Eric Galin and Christophe Antoine and Beno\^{\i}t Thebault and Philippe Landrein},
	year         = 2024,
	month        = 3,
	journal      = {Journal of Hydrology},
	publisher    = {Elsevier B.V.},
	volume       = 632,
	doi          = {10.1016/j.jhydrol.2024.130878},
	issn         = {00221694},
	abstract     = {In karst aquifers, groundwater flow is highly influenced by the interconnected underground cavities and conduits that form the karst network. Modeling karst flows requires the use of spatially distributed approaches accounting for these networks. Their exploration is, however, often complex, and mapping them using indirect methods such as geophysical ones has proven challenging. To overcome these limitations, stochastically simulating discrete karst networks should account for the uncertainties on conduit position and geometry. Only a few existing methods can reproduce realistic and diverse karst morphologies. In this work, we propose a new algorithm, KarstNSim, for simulating discrete karst networks, that incorporates field data to generate a range of possible karst network geometries. It relies on the computation of the shortest path between the inlets and outlets of the network with the use of an anisotropic cost function defined on an n-nearest neighbor graph conformal to geological and structural heterogeneities. This cost function represents the physico-chemical processes that govern speleogenesis – such as erosion and chemical weathering – providing simplified control over the geometry of the generated networks. Our approach reproduces the vadose-phreatic partition visible in the karst networks, by generating sub-vertical conduits in the unsaturated zone and sub-horizontal ones in the saturated part. It encompasses geological parameters such as inception surfaces, fractures, permeability, and solubility of layers, along with considering the hydrological context of recharge by assigning relative weights to the inlets. We simulate various synthetic models to demonstrate the influence of different input parameters on the spatial organization of the past and present karst flows. We also apply KarstNSim to a real case study – the Ribeaucourt system (Meuse, France) – and use available data to generate realistic karst networks. The lack of knowledge on the Ribeaucourt network geometry is alleviated by the use of multiple scenarios corresponding to different sets of weights in the cost function, resulting in a variety of network morphologies which represent the uncertainty on the real geometry. The geometrical and topological metrics computed on the simulated networks generally overlap with those of real ones, suggesting the reliability of the method.},
	keywords     = {Cost function,Karst network,Morphology,Shortest path,Stochastic simulations}
}
@article{Feng2024,
	title        = {Modelling internal erosion using 2D smoothed particle hydrodynamics (SPH)},
	author       = {Ruofeng Feng and Georgios Fourtakas and Benedict D. Rogers and Domenico Lombardi},
	year         = 2024,
	month        = 8,
	journal      = {Journal of Hydrology},
	publisher    = {Elsevier B.V.},
	volume       = 639,
	doi          = {10.1016/j.jhydrol.2024.131558},
	issn         = {00221694},
	abstract     = {This paper presents a stabilised multi-phase smoothed particle hydrodynamics (SPH) model applicable to seepage-induced internal erosion and the resulting deformation in soils. Based on the continuum mixture theory, a new single-layer SPH model in the u-w-p formulation is derived for the mathematical description of the erodible porous material. A new modified constitutive model is formulated to account for the influence of erosion on the mechanical behaviour of soils. Extensions of a first-order consistent boundary condition as well as the diffusion algorithm for hydro-mechanical coupling in SPH are also proposed to accommodate the analysis of erosion-transport process. A novel viscous dissipation term is designed to mitigate the numerical instability commonly encountered in coupled problems. In contrast to existing stabilisation terms in the SPH literature, which operate on both the bulk component and shear component, this new stabilisation term offers the possibility to increase the dissipation of unphysical oscillation due to the shear deformation. The proposed method is validated through a series of benchmark tests. The results demonstrate the effectiveness of the proposed approach in addressing the coupled problem in porous materials involving multi-phase flow, phase interaction/transfer, and large deformation with enhanced accuracy, stability, and robustness.},
	keywords     = {DualSPHysics,Internal erosion,Large deformation,Seepage flow,Smoothed particle hydrodynamics (SPH),Unsaturated porous materials}
}
@article{Jain2024b,
	title        = {Efficient Debris-flow Simulation for Steep Terrain Erosion},
	author       = {Aryamaan Jain and Bedrich Benes and Guillaume Cordonnier},
	year         = 2024,
	journal      = {ACM Transactions on Graphics},
	volume       = 2024,
	pages        = 11,
	doi          = {10.1145/3658213ï},
	url          = {https://hal.science/hal-04574826},
	abstract     = {Erosion simulation is a common approach used for generating and author-ing mountainous terrains. While water is considered the primary erosion factor, its simulation fails to capture steep slopes near the ridges. In these low-drainage areas, erosion is often approximated with slope-reducing erosion , which yields unrealistically uniform slopes. However, geomorphology observed that another process dominates the low-drainage areas: erosion by debris flow, which is a mixture of mud and rocks triggered by strong climatic events. We propose a new method to capture the interactions between debris flow and fluvial erosion thanks to a new mathematical formulation for debris flow erosion derived from geomorphology and a unified GPU algorithm for erosion and deposition. In particular, we observe that sediment and debris deposition tend to intersect river paths, which motivates the design of a new, approximate flow routing algorithm on the GPU to estimate the water path out of these newly formed depressions. We demonstrate that debris flow carves distinct patterns in the form of erosive scars on steep slopes and cones of deposited debris competing with fluvial erosion downstream.},
	issue        = 4,
	keywords     = {Debris Flow,Deposition,Erosion,Flow Routing,Simulation,Terrain}
}
@article{Peytavie2024a,
	title        = {DeadWood: Including Disturbance and Decay in the Depiction of Digital Nature},
	author       = {Adrien Peytavie and James Gain and Eric Gu\'{e}rin and Oscar Argudo and Eric Galin},
	year         = 2024,
	month        = 4,
	journal      = {ACM Transactions on Graphics},
	volume       = 43,
	pages        = {1--19},
	doi          = {10.1145/3641816},
	issn         = {0730-0301},
	url          = {https://dl.acm.org/doi/10.1145/3641816},
	abstract     = {<p> The creation of truly believable simulated natural environments remains an unsolved problem in Computer Graphics. This is, in part, due to a lack of visual variety. In nature, apart from variation due to abiotic and biotic growth factors, a significant role is played by disturbance events, such as fires, windstorms, disease, and death and decay processes, which give rise to both standing dead trees (snags) and downed woody debris (logs). For instance, snags constitute on average 10\% of unmanaged forests by basal area, and logs account for 2 <inline-formula content-type="math/tex"> <tex-math notation="LaTeX" version="MathJax">\(\frac\{1\}\{2\}\)</tex-math> </inline-formula> times this quantity. </p>},
	issue        = 2,
	keywords     = {Ecosystem simulation,natural phenomena}
}
@article{Rosset2024,
	title        = {Windblown sand around obstacles – simulation and validation of deposition patterns},
	author       = {Nicolas Rosset and Regis Duvigneau and Adrien Bousseau and Guillaume Cordonnier},
	year         = 2024,
	month        = 5,
	journal      = {Proceedings of the ACM on Computer Graphics and Interactive Techniques},
	publisher    = {Association for Computing Machinery},
	volume       = 7,
	doi          = {10.1145/3651284},
	issn         = 25776193,
	abstract     = {Sand dunes are iconic landmarks of deserts, but can also put human infrastructures at risk, for instance by forming near buildings or roads. We present a simulator of sand erosion and deposition to predict how dunes form around and behind obstacles under wind. Inspired by both computer graphics and geo-sciences, our algorithm couples a fast wind flow simulation with physical laws of sand saltation and avalanching, which suffices to reproduce characteristic patterns of sand deposition. In particular, we validate our approach via a qualitative comparison of the erosion and deposition patterns produced by our simulator against real-world patterns measured by prior work under controlled conditions.},
	issue        = 1,
	keywords     = {Fluid simulation,Landscape,Sand deposition,Sand dunes}
}
@article{Amador2024,
	title        = {Cyclogenesis: Simulating Hurricanes and Tornadoes},
	author       = {Jorge Alejandro Amador Herrera and Jonathan Klein and Daoming Liu and Wojtek Pa\l{}ubicki and S\"{o}ren Pirk and Dominik L. Michels},
	year         = 2024,
	month        = 7,
	journal      = {ACM Transactions on Graphics},
	publisher    = {Association for Computing Machinery},
	volume       = 43,
	doi          = {10.1145/3658149},
	issn         = 15577368,
	abstract     = {Cyclones are large-scale phenomena that result from complex heat and water transfer processes in the atmosphere, as well as from the interaction of multiple hydrometeors, i.e., water and ice particles. When cyclones make landfall, they are considered natural disasters and spawn dread and awe alike. We propose a physically-based approach to describe the 3D development of cyclones in a visually convincing and physically plausible manner. Our approach allows us to capture large-scale heat and water continuity, turbulent microphysical dynamics of hydrometeors, and mesoscale cyclonic processes within the planetary boundary layer. Modeling these processes enables us to simulate multiple hurricane and tornado phenomena. We evaluate our simulations quantitatively by comparing to real data from storm soundings and observations of hurricane landfall from climatology research. Additionally, qualitative comparisons to previous methods are performed to validate the different parts of our scheme. In summary, our model simulates cyclogenesis in a comprehensive way that allows us to interactively render animations of some of the most complex weather events.},
	issue        = 4,
	keywords     = {cyclonic phenomena,fluid simulation,hurricanes,tornadoes,turbulence modeling,weather phenomena}
}
@article{Maesumi2024,
	title        = {One Noise to Rule Them All: Learning a Unified Model of Spatially-Varying Noise Patterns},
	author       = {Arman Maesumi and Dylan Hu and Krishi Saripalli and Vladimir Kim and Matthew Fisher and Soren Pirk and Daniel Ritchie},
	year         = 2024,
	month        = 7,
	journal      = {ACM Transactions on Graphics},
	publisher    = {Association for Computing Machinery},
	volume       = 43,
	doi          = {10.1145/3658195},
	issn         = 15577368,
	abstract     = {Procedural noise is a fundamental component of computer graphics pipelines, offering a flexible way to generate textures that exhibit "natural"random variation. Many different types of noise exist, each produced by a separate algorithm. In this paper, we present a single generative model which can learn to generate multiple types of noise as well as blend between them. In addition, it is capable of producing spatially-varying noise blends despite not having access to such data for training. These features are enabled by training a denoising diffusion model using a novel combination of data augmentation and network conditioning techniques. Like procedural noise generators, the model's behavior is controllable via interpretable parameters plus a source of randomness. We use our model to produce a variety of visually compelling noise textures. We also present an application of our model to improving inverse procedural material design; using our model in place of fixed-type noise nodes in a procedural material graph results in higher-fidelity material reconstructions without needing to know the type of noise in advance.},
	issue        = 4,
	keywords     = {deep generative model,procedural noise,texture acquisition,texture synthesis}
}
@inproceedings{Kusupati2024,
	title        = {Semantic Shape Editing with Parametric Implicit Templates},
	author       = {Uday Kusupati and Mathieu Gaillard and Jean Marc Thiery and Adrien Kaiser},
	year         = 2024,
	month        = 7,
	booktitle    = {Proceedings - SIGGRAPH 2024 Conference Papers},
	publisher    = {Association for Computing Machinery, Inc},
	doi          = {10.1145/3641519.3657421},
	isbn         = 9798400705250,
	abstract     = {We propose a semantic shape editing method to edit 3D triangle meshes using parametric implicit surface templates, benefiting from the many advantages offered by analytical implicit representations, such as infinite resolution and boolean or blending operations. We propose first a template fitting method to optimize its parameters to best capture the input mesh. For subsequent template edits, our novel mesh deformation method allows tracking the template's 0-set even when featuring anisotropic stretch and/or local volume change. We make few assumptions on the template implicit fields and only strictly require continuity. We demonstrate applications to interactive semantic shape editing and semantic mesh retargeting.},
	keywords     = {implicit fields,mesh deformation,parametric templates}
}
@article{Azulai2024,
	title        = {Feature discrimination learning transfers to noisy displays in complex stimuli},
	author       = {Orly Azulai and Lilach Shalev and Carmel Mevorach},
	year         = 2024,
	month        = 3,
	journal      = {Frontiers in Cognition},
	publisher    = {Frontiers Media SA},
	volume       = 3,
	doi          = {10.3389/fcogn.2024.1349505}
}
@article{Xu2024,
	title        = {FusionDeformer: text-guided mesh deformation using diffusion models},
	author       = {Hao Xu and Yiqian Wu and Xiangjun Tang and Jing Zhang and Yang Zhang and Zhebin Zhang and Chen Li and Xiaogang Jin},
	year         = 2024,
	month        = 7,
	journal      = {Visual Computer},
	publisher    = {Springer Science and Business Media Deutschland GmbH},
	volume       = 40,
	pages        = {4701--4712},
	doi          = {10.1007/s00371-024-03463-7},
	issn         = {01782789},
	abstract     = {Mesh deformation has a wide range of applications, including character creation, geometry modelling, deforming animation, and morphing. Recently, mesh deformation methods based on CLIP models demonstrated the ability to perform automatic text-guided mesh deformation. However, using 2D guidance to deform a 3D mesh attempts to solve an ill-posed problem and leads to distortion and unsmoothness, which cannot be eliminated by CLIP-based methods because they focus on semantic-aware features and cannot identify these artefacts. To this end, we propose FusionDeformer, a novel automatic text-guided mesh deformation method that leverages diffusion models. The deformation is achieved by Score Distillation Sampling, which minimizes the KL-divergence between the distribution of rendered deformed mesh and the text-conditioned distribution. To alleviate the intrinsic ill-posed problem, we incorporate two approaches into our framework. The first approach involves combining multiple orthogonal views into a single image, providing robust deformation while avoiding the need for additional memory. The second approach incorporates a new regularization to address the unsmooth artefacts. Our experimental results show that the proposed method can generate high-quality, smoothly deformed meshes that align precisely with the input text description while preserving the topological relationships. Additionally, our method offers a text2morphing approach to animation design, enabling common users to produce special effects animation.},
	issue        = 7,
	keywords     = {Diffusion model,Mesh deformation,Score Distillation Sampling}
}
@article{Pretorius2024,
	title        = {Volcanic Skies: coupling explosive eruptions with atmospheric simulation to create consistent skyscapes},
	author       = {P. C. Pretorius and J. Gain and M. Lastic and G. Cordonnier and J. Chen and D. Rohmer and M. P. Cani},
	year         = 2024,
	month        = 5,
	journal      = {Computer Graphics Forum},
	publisher    = {John Wiley and Sons Inc},
	volume       = 43,
	doi          = {10.1111/cgf.15034},
	issn         = 14678659,
	abstract     = {Explosive volcanic eruptions rank among the most terrifying natural phenomena, and are thus frequently depicted in films, games, and other media, usually with a bespoke once-off solution. In this paper, we introduce the first general-purpose model for bi-directional interaction between the atmosphere and a volcano plume. In line with recent interactive volcano models, we approximate the plume dynamics with Lagrangian disks and spheres and the atmosphere with sparse layers of 2D Eulerian grids, enabling us to focus on the transfer of physical quantities such as temperature, ash, moisture, and wind velocity between these sub-models. We subsequently generate volumetric animations by noise-based procedural upsampling keyed to aspects of advection, convection, moisture, and ash content to generate a fully-realized volcanic skyscape. Our model captures most of the visually salient features emerging from volcano-sky interaction, such as windswept plumes, enmeshed cap, bell and skirt clouds, shockwave effects, ash rain, and sheathes of lightning visible in the dark.},
	issue        = 2,
	keywords     = {CCS Concepts,Procedural animation,\textbullet{} Computer Graphics \rightarrow{} Physical simulation}
}
@article{Haibt2024,
	title        = {End-to-end digital twin creation of the archaeological landscape in Uruk-Warka (Iraq)},
	author       = {Max Haibt},
	year         = 2024,
	journal      = {International Journal of Digital Earth},
	publisher    = {Taylor and Francis Ltd.},
	volume       = 17,
	doi          = {10.1080/17538947.2024.2324964},
	issn         = 17538955,
	abstract     = {This article demonstrates recent technological advancements enabling the creation of digital twins for expansive real-world terrains. Focusing on the archaeological site Uruk-Warka in southern Iraq the German Archaeological Institute deployed the Delta Quad Pro, a winged UAV equipped with vertical take-off and landing capabilities. This UAV captured 32,000 aerial images of the ancient city and its immediate environment. Each image was precisely geotagged using an integrated DGNSS receiver. Utilizing advanced 3D photogrammetry software, we synthesized these images into a single georeferenced model. The outcome was a detailed triangulated mesh, comprising of one billion triangles and 1024 8k-resolution texture files, representing a 40 square kilometers terrain. When rendered in a game-engine and applying the new technologies Nanite and Streaming Virtual Texture, this massive dataset can be visualized in real-time. The result is `Uruk-VR,' a digital twin of the Uruk-Warka archaeological site, most of which has never been investigated. Basic tools have been implemented to annotate features and measure distances within the Uruk-VR. The methodologies showcased here are scalable for creating digital twins of diverse terrains. Uruk-VR's potential extends to research, education and conservation, exemplifying how game engines can seamlessly integrate vast and diverse geospatial data in 3D space.},
	issue        = 1,
	keywords     = {3D photogrammetry,Digital twin,UAV,archaeology,unreal engine,world heritage}
}
@techreport{Jain2024a,
	title        = {FastFlow: GPU Acceleration of Flow and Depression Routing for Landscape Simulation},
	author       = {Aryamaan Jain and Bernhard Kerbl and James Gain and Brandon Finley and Guillaume Cordonnier FastFlow and Guillaume Cordonnier},
	year         = 2024,
	journal      = {COMPUTER GRAPHICS forum},
	volume       = 43,
	url          = {https://hal.science/hal-04684270v1},
	abstract     = {Terrain analysis plays an important role in computer graphics, hydrology and geomorphology. In particular, analyzing the path of material flow over a terrain with consideration of local depressions is a precursor to many further tasks in erosion, river formation, and plant ecosystem simulation. For example, fluvial erosion simulation used in terrain modeling computes water discharge to repeatedly locate erosion channels for soil removal and transport. Despite its significance, traditional methods face performance constraints, limiting their broader applicability. In this paper, we propose a novel GPU flow routing algorithm that computes the water discharge in O(log n) iterations for a terrain with n vertices (assuming n processors). We also provide a depression routing algorithm to route the water out of local minima formed by depressions in the terrain, which converges in O(log 2 n) iterations. Our implementation of these algorithms leads to a 5\texttimes{} speedup for flow routing and 34\texttimes{} to 52\texttimes{} speedup for depression routing compared to previous work on a 1024 2 terrain, enabling interactive control of terrain simulation.},
	issue        = 7,
	keywords     = {2024,43 (7) \"{\i}\textquestiondown{}\textquestiondown{}hal-04684270\"{\i}\textquestiondown{}\textquestiondown{} CCS Concepts \textbullet{} Computing methodologies \rightarrow{} Shape modeling; Massively parallel algorithms;,GPU Acceleration of Flow and Depression Routing for Landscape Simulation Computer Graphics Forum}
}
@article{Rabich2024,
	title        = {FPO++: efficient encoding and rendering of dynamic neural radiance fields by analyzing and enhancing Fourier PlenOctrees},
	author       = {Saskia Rabich and Patrick Stotko and Reinhard Klein},
	year         = 2024,
	month        = 7,
	journal      = {Visual Computer},
	publisher    = {Springer Science and Business Media Deutschland GmbH},
	volume       = 40,
	pages        = {4777--4788},
	doi          = {10.1007/s00371-024-03475-3},
	issn         = {01782789},
	abstract     = {Fourier PlenOctrees have shown to be an efficient representation for real-time rendering of dynamic neural radiance fields (NeRF). Despite its many advantages, this method suffers from artifacts introduced by the involved compression when combining it with recent state-of-the-art techniques for training the static per-frame NeRF models. In this paper, we perform an in-depth analysis of these artifacts and leverage the resulting insights to propose an improved representation. In particular, we present a novel density encoding that adapts the Fourier-based compression to the characteristics of the transfer function used by the underlying volume rendering procedure and leads to a substantial reduction of artifacts in the dynamic model. We demonstrate the effectiveness of our enhanced Fourier PlenOctrees in the scope of quantitative and qualitative evaluations on synthetic and real-world scenes.},
	issue        = 7,
	keywords     = {Dynamic scenes,Encoding,Fourier transform,Neural radiance fields,Real-time rendering}
}
@article{Yang2024,
	title        = {Unerosion: Simulating Terrain Evolution Back in Time},
	author       = {Zhanyu Yang and Guillaume Cordonnier and Marie-Paule Cani and Christian Perrenoud and Bedrich Benes},
	year         = 2024,
	journal      = {Computer Graphics Forum},
	volume       = 2024,
	pages        = 43,
	doi          = {10.1111/cgf.15182ï},
	abstract     = {Figure 1: A terrain that has been eroded (left) by fluvial and thermal erosion is uneroded by automatically tracing the direction of the main flow (indicated by the arrows) to its previous state. Abstract While the past of terrain cannot be known precisely because an effect can result from many different causes, exploring these possible pasts opens the way to numerous applications ranging from movies and games to paleogeography. We introduce unero-sion, an attempt to recover plausible past topographies from an input terrain represented as a height field. Our solution relies on novel algorithms for the backward simulation of different processes: fluvial erosion, sedimentation, and thermal erosion. This is achieved by re-formulating the equations of erosion and sedimentation so that they can be simulated back in time. These algorithms can be combined to account for a succession of climate changes backward in time, while the possible ambiguities provide editing options to the user. Results show that our solution can approximately reverse different types of erosion while enabling users to explore a variety of alternative pasts. Using a chronology of climatic periods to inform us about the main erosion phenomena, we also went back in time using real measured terrain data. We checked the consistency with geological findings, namely the height of river beds hundreds of thousands of years ago.},
	issue        = 8,
	keywords     = {CCS Concepts \textbullet{} Computing methodologies \rightarrow{} Shape modeling; Keywords: Terrain,Erosion,Simulation of Natural Phenomena}
}
@techreport{Kedadry2024,
	title        = {Fast simulation of viscous lava flow using Green's functions as a smoothing kernel},
	author       = {Y Kedadry and G Cordonnier},
	year         = 2024,
	abstract     = {We present a novel approach to simulate large-scale lava flow in real-time. We use a depth-averaged model from numerical vul-canology to simplify the problem to 2.5D using a single layer of particle with thickness. Yet, lava flow simulation is challenging due to its strong viscosity which introduces computational instabilities. We solve the associated partial differential equations with approximated Green's functions and observe that this solution acts as a smoothing kernel. We use this kernel to diffuse the velocity based on Smoothed Particle Hydrodynamics. This yields a representation of the velocity that implicitly accounts for horizontal viscosity which is otherwise neglected in standard depth-average models. We demonstrate that our method efficiently simulates large-scale lava flows in real-time.},
	keywords     = {Real-time simulation}
}
@article{Voigtlander2024,
	title        = {Quantifying Earth's Topography: Steeper and Larger Than Projected in Digital Terrain Models},
	author       = {Anne Voigtl\"{a}nder and Aljoscha Rheinwalt and Stefanie Tofelde},
	year         = 2024,
	month        = 7,
	journal      = {Geophysical Research Letters},
	publisher    = {John Wiley and Sons Inc},
	volume       = 51,
	doi          = {10.1029/2024GL109517},
	issn         = 19448007,
	abstract     = {Grid- or pixel-based models, used across various scientific disciplines from microscopic to planetary scales, contain an unquantified error that bias our interpretation of the data. The error is produced by projecting 3D data onto a 2D grid. For Digital Terrain Models (DTMs) the projection error affects all slope-dependent topographic metrics, like surface area or slope angle. Due to the proportionality of the error to the cosine of the slope, we can correct for it. We quantify the error and test the correction using synthetic landscapes for which we have analytical solutions of their metrics. Application to real-world landscapes in California, reveal the systematic underestimation of surface area by up to a third, and mean slope angles by up to 10\textdegree{} in steep topography in current DTMs. Correcting projection errors allow for true estimates of surface areas and slope distributions enabling physics-based models of surface processes at any spatial scale.},
	issue        = 14,
	keywords     = {Earth surface processes,failure analysis,remote sensing,topographic metrics}
}
@article{Barzegar2024,
	title        = {InceptCurves: curve reconstruction using an inception network},
	author       = {Saeedeh Barzegar~Khalilsaraei and Alexander Komar and Jianmin Zheng and Ursula Augsd\"{o}rfer},
	year         = 2024,
	month        = 7,
	journal      = {Visual Computer},
	publisher    = {Springer Science and Business Media Deutschland GmbH},
	volume       = 40,
	pages        = {4805--4815},
	doi          = {10.1007/s00371-024-03477-1},
	issn         = {01782789},
	abstract     = {Curve reconstruction is a fundamental task in many visual computing applications. In this paper, a data-driven approach for curve reconstruction is proposed. We present an inception layered deep neural network structure, capable of learning simultaneously the number of control points and their positions in order to reconstruct the curve. To train the network, a large set of general synthetic data is generated. The reconstructed uniform B-spline closely approximates any arbitrary input curve, with or without intersections. Because the network predicts the number of control points required for the B-spline reconstruction, redundancy is reduced in the curve representation. We demonstrate our approach on various examples.},
	issue        = 7,
	keywords     = {B-splines,Curve reconstruction,Machine learning,Subdivision curves}
}
@misc{Alvarado2024,
	title        = {TRAIL: Simulating the impact of human locomotion on natural landscapes},
	author       = {Eduardo Alvarado and Oscar Argudo and Damien Rohmer and Marie Paule Cani and Nuria Pelechano},
	year         = 2024,
	month        = 7,
	journal      = {Visual Computer},
	publisher    = {Springer Science and Business Media Deutschland GmbH},
	volume       = 40,
	pages        = {5029--5041},
	doi          = {10.1007/s00371-024-03506-z},
	issn         = {01782789},
	abstract     = {Human and animal presence in natural landscapes is initially revealed by the immediate impact of their locomotion, from footprints to crushed grass. In this work, we present an approach to model the effects of virtual characters on natural terrains, focusing on the impact of human locomotion. We introduce a lightweight solution to compute accurate foot placement on uneven ground and infer dynamic foot pressure from kinematic animation data and the mass of the character. A ground and vegetation model enables us to effectively simulate the local impact of locomotion on soft soils and plants over time, resulting in the formation of visible paths. As our results show, we can parameterize various soil materials and vegetation types validated with real-world data. Our method can be used to significantly increase the realism of populated natural landscapes and the sense of presence in virtual applications and games.},
	issue        = 7,
	keywords     = {Character animation,Natural phenomena}
}
@article{Flor2024,
	title        = {Spectral reordering for faster elasticity simulations},
	author       = {Alon Flor and Mridul Aanjaneya},
	year         = 2024,
	month        = 7,
	journal      = {Visual Computer},
	publisher    = {Springer Science and Business Media Deutschland GmbH},
	volume       = 40,
	pages        = {5067--5077},
	doi          = {10.1007/s00371-024-03513-0},
	issn         = {01782789},
	abstract     = {We present a novel method for faster physics simulations of elastic solids. Our key idea is to reorder the unknown variables according to the Fiedler vector (i.e., the second-smallest eigenvector) of the combinatorial Laplacian. It is well known in the geometry processing community that the Fiedler vector brings together vertices that are geometrically nearby, causing fewer cache misses when computing differential operators. However, to the best of our knowledge, this idea has not been exploited to accelerate simulations of elastic solids which require an expensive linear (or non-linear) system solve at every time step. The cost of computing the Fiedler vector is negligible, thanks to an algebraic Multigrid-preconditioned Conjugate Gradients (AMGPCG) solver. We observe that our AMGPCG solver requires approximately 1~s for computing the Fiedler vector for a mesh with approximately 50K vertices or 100K tetrahedra. Our method provides a speed-up between 10\% – 30\% at every time step, which can lead to considerable savings, noting that even modest simulations of elastic solids require at least 240 time steps. Our method is easy to implement and can be used as a plugin for speeding up existing physics simulators for elastic solids, as we demonstrate through our experiments using the Vega library and the ADMM solver, which use different algorithms for elasticity.},
	issue        = 7,
	keywords     = {Elasticity,Fiedler vector,Laplacian,Multigrid solver,Physics simulation,Reordering}
}
@inproceedings{Hu2024,
	title        = {Generative Terrain Authoring with Mid-air Hand Sketching in Virtual Reality},
	author       = {Yushen Hu and Keru Wang and Yuli Shao and Jan Plass and Zhu Wang and Ken Perlin},
	year         = 2024,
	month        = 10,
	booktitle    = {30th ACM Symposium on Virtual Reality Software and Technology},
	publisher    = {ACM},
	pages        = {1--10},
	doi          = {10.1145/3641825.3687736},
	isbn         = 9798400705359,
	url          = {https://dl.acm.org/doi/10.1145/3641825.3687736},
	city         = {New York, NY, USA}
}
@article{Hou2024,
	title        = {The Spatial and Temporal Dynamics of Soil Conservation and Its Influencing Factors in the Ten Tributaries of the Upper Yellow River, China},
	author       = {Xianglong Hou and Hui Yang and Jiansheng Cao},
	year         = 2024,
	month        = 10,
	journal      = {Water (Switzerland)},
	publisher    = {Multidisciplinary Digital Publishing Institute (MDPI)},
	volume       = 16,
	doi          = {10.3390/w16202888},
	issn         = 20734441,
	abstract     = {Soil erosion is a global environmental problem, and soil conservation is the prevention of soil loss from erosion. The Ten Kongduis (kongdui is the translation of ``short-term flood gullies'' in Mongolian) are ten tributaries in the upper Inner Mongolia section of the Yellow River Basin. The study of the spatial and temporal variability in soil conservation in the Ten Kongduis is of extraordinary scientific significance both in terms of the discipline and for the ecological and environmental management of the region. With the InVEST model, the characteristics of the spatial and temporal variations in soil conservation service in the Ten Kongduis since 2000 and how rainfall and land use have influenced soil conservation were analyzed. The results show that both avoided erosion and avoided export varied considerably between years. The minimum values of avoided erosion and avoided export were both in 2015, with values of 17.59 \texttimes{} 106 t and 0.92 \texttimes{} 106 t, respectively. The maximum value of avoided erosion was 57.03 \texttimes{} 106 t in 2020 and that of avoided export was 4.08 \texttimes{} 106 t in 2000. Spatially, avoided export was primarily found in the upper reaches of the east–central portion of the study area, and avoided erosion, with values of >40 t\cdot{}(ha\cdot{}yr)-1, was in the upper east–central portion of the study area, followed by the upper west–central portion. The difference between upstream and downstream was larger in the western part of the study area. The effect of rainfall was dominant and positive in both avoided erosion and avoided export. The relationships between the rain erosivity factor and the values of avoided erosion and avoided export were significantly positive. Where more erosion occurs, more erosion is retained. Soil that has been eroded away from slopes under vegetation or other water conservation measures may not necessarily be transported to the stream channel in the current year. These conclusions will help us to have a clearer understanding of where sediments are generated and transported and provide a scientific basis for soil and water conservation and ecosystem safety management of watersheds.},
	issue        = 20,
	keywords     = {InVEST model,Ten Kongduis,land use,rainfall erosivity,sediment delivery ratio}
}
@article{Li2024,
	title        = {Interactive effect of soil dispersity and rainfall intensity on splash erosion: Insights from laboratory tests},
	author       = {Xingyao Li and Henghui Fan and Pengwei Wang and Xingyu Zhang and Anbin Li and Xiujuan Yang and Genguang Zhang},
	year         = 2024,
	month        = 4,
	journal      = {Catena},
	publisher    = {Elsevier B.V.},
	volume       = 238,
	doi          = {10.1016/j.catena.2024.107843},
	issn         = {03418162},
	abstract     = {Dispersive soil is a common problematic soil that segregates in water, resulting in instability of slopes and posing significant threats to the safety of earth structures. However, there is a limited amount of research on the hydraulic erosion of dispersive soil. Splash erosion is the initial stage of hydraulic erosion. A clear understanding of splash erosion is crucial for investigating dispersive soil hydraulic erosion. This study explored the influence of soil dispersity and rainfall intensity on the characteristics of splash erosion by conducting consecutive single-drop rainfall tests on artificially prepared non-dispersive and dispersive soil samples with varying sodium carbonate content. High-speed cameras and single-lens reflex (SLR) cameras were used to capture the variations of the splash crown, splash pan, and splash crater. Results showed that the content of sodium carbonate significantly affected splash erosion. High soil dispersity resulted in smaller masses of splashed soil material and infiltration water, but a larger mass of splashed water. It also led to a smaller volume and depth of the splash crater. The critical value of the content of sodium carbonate for soil dispersity discrimination was 0.15 \%, the same as the threshold for the splash process to stop significant changes. The shape of the splash crown also helped analyze the process of splash erosion and was relevant to the splash crater shape. Increasing soil dispersity diminished the impact of rainfall intensity on splash erosion. These findings provide new comprehension of the mechanism of splash erosion of dispersive soil and lay a foundation for the systematic study of hydraulic erosion of dispersive soil in engineering slopes.},
	keywords     = {Dispersive soil,Single drop rainfall,Splash crater,Splash crown,Splash erosion}
}
@article{Morris2024,
	title        = {A Model for Spatially Explicit Landscape Configuration and Ecosystem Service Performance, ESMAX: Model Description and Explanation},
	author       = {Richard Morris and Shannon Davis and Gwen-A\"{e}lle Grelet and Crile Doscher and Pablo Gregorini},
	year         = 2024,
	month        = 1,
	journal      = {Sustainability},
	publisher    = {Multidisciplinary Digital Publishing Institute (MDPI)},
	volume       = 16,
	pages        = 876,
	doi          = {10.3390/su16020876},
	issn         = {2071-1050},
	url          = {https://www.mdpi.com/2071-1050/16/2/876},
	abstract     = {<p>It is critical that we move our understanding of the ecosystem services (ESs) produced by landscapes from the present abundance of analysis to a fundamental basis of design. This involves enhancing the ability to understand and model the interconnected, coevolving system of humans and the rest of nature, thus contributing to the design of sustainable landscapes. In this paper, we hypothesise that the spatial configuration of landscape components (the size and arrangement of tree clumps, paddocks, crops, water features, etc.) impacts the production of regulating ESs, which in turn have a leveraging effect on provisioning and cultural ESs. Drawing on the precepts of Ecological Field Theory, we present the development and implications of a conceptual Geographic Information System (GIS)-based model, ESMAX, that utilises the idiosyncratic distance-decay characteristics of regulating ESs. These `ES fields' are visualised as radiating into the landscape from their source components, addressing a gap in biophysical reality that has been identified as a shortcoming of existing ES modelling based on landcover proxies. Hypothetical landscape arrangements of simplified landscape components are tested with ESMAX across three regulating ESs: cooling effect, nitrogen retention, and habitat provision. The model calculates the overall ES performance of each landscape arrangement by tabulating the ES fields produced and, critically, the nonlinear response where fields overlap. The results indicate a primary sensitivity to the size of components and a secondary sensitivity to the arrangement of components. Consequently, ESMAX can be used to design landscape configurations that (1) maximise the production of specific regulating ESs and (2) improve the utilisation of natural ES-producing resources.</p>},
	issue        = 2,
	keywords     = {GIS,biophysical gap,ecosystem services,landscape ecology,landscape multifunctionality,spatial configuration}
}

@article{Turing1952,
   author = {Alan Turing},
   doi = {10.1098/rstb.1952.0012},
   issn = {2054-0280},
   issue = {641},
   journal = {Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences},
   month = {8},
   pages = {37-72},
   title = {The chemical basis of morphogenesis},
   volume = {237},
   url = {https://royalsocietypublishing.org/doi/10.1098/rstb.1952.0012},
   year = {1952}
}

@inproceedings{Ostromoukhov2007,
   abstract = {Figure 1: (Left) Each sampling point of this blue-noise distribution sits on exactly one polyomino. (Right) A set of equiareal polyominoes can be directly mapped on a sphere and hierarchically subdivided (two consecutive levels of subdivision are shown). The method allows fast low-noise low-artifact importance sampling of arbitrary HDR functions (a Gaussian spot is shown on the rightmost sphere). Abstract We present a new general-purpose method for fast hierarchical importance sampling with blue-noise properties. Our approach is based on self-similar tiling of the plane or the surface of a sphere with rectifiable polyominoes. Sampling points are associated with polyominoes, one point per polyomino. Each polyomino is re-cursively subdivided until the desired local density of samples is reached. A numerical code generated during the subdivision process is used for thresholding to accept or reject the sample. The exact position of the sampling point within the polyomino is determined according to a structural index, which indicates the poly-omino's local neighborhood. The variety of structural indices and associated sampling point positions are computed during the off-line optimization process, and tabulated. Consequently, the sampling itself is extremely fast. The method allows both deterministic and pseudo-non-deterministic sampling. It can be successfully applied in a large variety of graphical applications, where fast sampling with good spectral and visual properties is required. The prime application is rendering.},
   author = {Victor Ostromoukhov},
   city = {New York, NY, USA},
   doi = {10.1145/1275808.1276475},
   isbn = {9781450378369},
   issue = {3},
   booktitle = {ACM SIGGRAPH 2007 papers},
   keywords = {Blue noise,Deterministic sampling,Importance sampling,Non-periodic tiling,Polyominoes},
   month = {7},
   pages = {78},
   publisher = {ACM},
   title = {Sampling with polyominoes},
   volume = {26},
   url = {https://dl.acm.org/doi/10.1145/1275808.1276475},
   year = {2007}
}
@article{Ebeida2011,
   abstract = {We solve the problem of generating a uniform Poisson-disk sampling that is both maximal and unbiased over bounded non-convex domains. To our knowledge this is the first provably correct algorithm with time and space dependent only on the number of points produced. Our method has two phases, both based on classical dartthrowing. The first phase uses a background grid of square cells to rapidly create an unbiased, near-maximal covering of the domain. The second phase completes the maximal covering by calculating the connected components of the remaining uncovered voids, and by using their geometry to efficiently place unbiased samples that cover them. The second phase converges quickly, overcoming a common difficulty in dart-throwing methods. The deterministic memory is O(n) and the expected running time is O(n log n), where n is the output size, the number of points in the final sample. Our serial implementation verifies that the log n dependence is minor, and nearly O(n) performance for both time and memory is achieved in practice. We also present a parallel implementation on GPUs to demonstrate the parallel-friendly nature of our method, which achieves 2.4× the performance of our serial version. © 2011 ACM.},
   author = {Mohamed S. Ebeida and Andrew A. Davidson and Anjul Patney and Patrick M. Knupp and Scott A. Mitchell and John D. Owens},
   doi = {10.1145/1964921.1964944},
   isbn = {9781450309431},
   issn = {07300301},
   issue = {4},
   journal = {ACM Transactions on Graphics},
   keywords = {Blue noise,Linear complexity,Maximal,Poisson disk,Provable convergence,Sampling},
   month = {7},
   title = {Efficient maximal poisson-disk sampling},
   volume = {30},
   year = {2011}
}
@article{Kopf2006,
   abstract = { Well distributed point sets play an important role in a variety of computer graphics contexts, such as anti-aliasing, global illumination, halftoning, non-photorealistic rendering, point-based modeling and rendering, and geometry processing. In this paper, we introduce a novel technique for rapidly generating large point sets possessing a blue noise Fourier spectrum and high visual quality. Our technique generates non-periodic point sets, distributed over arbitrarily large areas. The local density of a point set may be prescribed by an arbitrary target density function, without any preset bound on the maximum density. Our technique is deterministic and tile-based; thus, any local portion of a potentially infinite point set may be consistently regenerated as needed. The memory footprint of the technique is constant, and the cost to generate any local portion of the point set is proportional to the integral over the target density in that area. These properties make our technique highly suitable for a variety of real-time interactive applications, some of which are demonstrated in the paper.Our technique utilizes a set of carefully constructed progressive and recursive blue noise Wang tiles. The use of Wang tiles enables the generation of infinite non-periodic tilings. The progressive point sets inside each tile are able to produce spatially varying point densities. Recursion allows our technique to adaptively subdivide tiles only where high density is required, and makes it possible to zoom into point sets by an arbitrary amount, while maintaining a constant apparent density. },
   author = {Johannes Kopf and Daniel Cohen-Or and Oliver Deussen and Dani Lischinski},
   doi = {10.1145/1141911.1141916},
   issn = {0730-0301},
   issue = {3},
   journal = {ACM Transactions on Graphics},
   keywords = {Poisson disk distribution,Wang tiles,anti-aliasing,blue noise,non-periodic tiling,object positioning,sampling,stip-pling,texture synthesis},
   month = {7},
   pages = {509-518},
   title = {Recursive Wang tiles for real-time blue noise},
   volume = {25},
   url = {https://dl.acm.org/doi/10.1145/1141911.1141916},
   year = {2006}
}
@inproceedings{McCool1992,
   author = {Micheal McCool and Eugene Fiume},
   city = {Vancouver},
   doi = {10.20380/GI1992.12},
   isbn = {0-9695338-1-0},
   issn = {0713-5424},
   booktitle = {Graphics Interface '92},
   pages = {94-105},
   publisher = {Canadian Human-Computer Communications Society},
   title = {Hierarchical Poisson disk sampling distributions},
   year = {1992}
}
@article{Wei2008,
   abstract = {Sampling is important for a variety of graphics applications include rendering, imaging, and geometry processing. However, producing sample sets with desired efficiency and blue noise statistics has been a major challenge, as existing methods are either sequential with limited speed, or are parallel but only through pre-computed datasets and thus fall short in producing samples with blue noise statistics. We present a Poisson disk sampling algorithm that runs in parallel and produces all samples on the fly with desired blue noise properties. Our main idea is to subdivide the sample domain into grid cells and we draw samples concurrently from multiple cells that are sufficiently far apart so that their samples cannot conflict one another. We present a parallel implementation of our algorithm running on a GPU with constant cost per sample and constant number of computation passes for a target number of samples. Our algorithm also works in arbitrary dimension, and allows adaptive sampling from a user-specified importance field. Furthermore, our algorithm is simple and easy to implement, and runs faster than existing techniques. © 2008 ACM.},
   author = {Li Yi Wei},
   doi = {10.1145/1360612.1360619},
   issn = {07300301},
   issue = {3},
   journal = {ACM Transactions on Graphics},
   keywords = {Blue noise,GPU techniques,Parallel computation,Poisson disk,Sampling,Texture synthesis},
   month = {8},
   title = {Parallel Poisson disk sampling},
   volume = {27},
   year = {2008}
}
@inproceedings{Mitchell2012,
   abstract = {We introduce three natural and well-defined generalizations of maximal Poisson-disk sampling. The first is to decouple the disk-free (inhibition) radius from the max-imality (coverage) radius. Selecting a smaller inhibition radius than the coverage radius yields samples which mix advantages of Poisson-disk and uniform-random samplings. The second generalization yields hierarchical samplings, by scaling inhibition and coverage radii by an abstract parameter, e.g. time. The third generalization is to allow the radii to vary spatially, according to a formally characterized sizing function. We state bounds on edge lengths and angles in a Delaunay triangulation of the points, dependent on the ratio of inhibition to coverage radii, or the sizing function's Lipschitz constant. Hierarchical samplings have distributions similar to those created directly. 1 Maximal Poisson-disk Sampling A sampling is a set of ordered points taken from a domain at random. Each point is the center of a disk that precludes additional points inside it, but points are otherwise chosen uniformly. The sampling is maximal if the entire domain is covered by disks. Together these define maximal Poisson-disk sampling (MPS). More formally, a sampling X = (x i) n i=1 , x i ∈ Ω satisfies the inhibition or empty disk property if ∀i < j ≤ n, |x i − x j | ≥ r. (1) The set of uncovered points is defined to be S(X) = \{y ∈ Ω : |y − x i | ≥ r, i = 1..n\}. (2) A sampling X is maximal if S(X) is empty: S(X) = ∅. (3) Given a non-maximal sampling, the next sample is bias-free if the probability of selecting it from any uncovered subregion is proportional to the subregion's area, i.e., ∀A ⊂ S(X) : P (x n+1 ∈ A | X) = |A| |S(X)|. (4) * We generalize these equations: decoupling the radii in the empty disk and uncovered equations; scaling the radii for a hierarchy of denser samplings; and varying the radii spatially by a sizing function. The purpose of this short paper is to introduce these generalizations in a mathematically consistent way. Examples illustrate the properties of the resulting output distributions. For simplicity our language is two-dimensional, e.g. "disks" instead of "spheres," but the definitions are general dimensional. Also for simplicity, we consider only periodic (or free-boundary) domains. These domains are used in some applications: computer graphics texture synthesis and mesh generation of material grains. 2 Motivation and Previous Work An MPS sampling is a separated-yet-dense point set: points are not too close together and lie throughout the entire domain. This is an efficient way to distribute a fixed budget of points. In mesh generation, separated-yet-dense points yield Delaunay triangulations (DT) with provable quality bounds [4, 9, 19]. Delaunay Refinement (DR) [20] introduces points to improve DT triangle quality and a separated-yet-dense point set follows. Variations of DR provide adaptivity and sizing control [16]. DR is usually deterministic; although regions of acceptable points have been characterized [12, 13], and one may select from regions randomly to improve tetrahedron quality [5], randomized point positions are not a traditional requirement. However, random meshes are of independent interest for certain applications; e.g. in some fracture mechanics methods, cracks propagate only along mesh edges. Meshes from MPS produce more physically realistic cracks [1, 2, 8, 7]. Ensembles of MPS meshes can model natural material strength variations. In a sphere packing no two disks overlap. If the disk radii satisfy a Lipschitz condition then a quality mesh results [19]. As in MPS and in reverse to DR, algorithms add disks until the packing is (nearly) maximal, and a good-quality DT follows. A fixed-r MPS sampling is a sphere packing: halve the disk radius r so no disks overlap. We define four new spatial variations for MPS, however none are equivalent to maximal sphere packings. Conflicts are defined by disks containing each other's centers; for unequal radii this is not equivalent to non-overlapping 1/2-radii disks. Also, we achieve a},
   author = {Scott A Mitchell and Alexander Rand and Mohamed S Ebeida and Chandrajit Bajaj},
   city = {Charlottetown},
   booktitle = {CCCG},
   month = {8},
   title = {Variable Radii Poisson-Disk Sampling},
   year = {2012}
}
@article{Deussen2000,
   abstract = {We present a method for computer generated pen-and-ink illustrations by the simulation of stippling. In a stipple drawing, dots are used to represent tone and also material of surfaces. We create such drawings by generating an initial dot set which is then processed by a relaxation method based on Voronoi diagrams. The point patterns generated are approximations of Poisson disc distributions and can also be used for integrating functions or the positioning of objects. We provide an editor similar to paint systems for interactively creating stipple drawings. This makes it possible to create such drawings within a matter of hours, instead of days or even weeks when the drawing is done manually.},
   author = {Oliver Deussen and Stefan Hiller and Cornelius Van Overveld and Thomas Strothotte},
   doi = {10.1111/1467-8659.00396},
   issn = {01677055},
   issue = {3},
   journal = {Computer Graphics Forum},
   month = {8},
   pages = {41-50},
   publisher = {Blackwell Sci Ltd},
   title = {Floating points: a method for computing stipple drawings},
   volume = {19},
   year = {2000}
}

@article{Nelson2012,
   abstract = {Introduction: Spatially explicit ecological research has increased substantially in the past 20 years. Most spatial approaches require the definition of a spatial neighbourhood or the region over which spatial relationships are modelled or assessed. Spatial neighbourhood definitions impact analysis results, and there are benefits in considering neighbourhood definitions that better capture ecological processes. The goal of this research is to present a simple and flexible approach in constraining ecological spatial neighbourhoods using terrain data. Methods: Using watershed boundaries, we can restrict spatial neighbourhoods from combining populations or processes that should be separated by terrain effects. We demonstrate the need for ecological constraints by way of a simulation study and highlight our approach with a case study examining mountain pine beetle (Dendroctonus ponderosae, Coleoptera; Hopkins) infestation hot spots. Results: Our results demonstrate how failure to constrain neighbourhoods can lead to errors when the spatial signals from unrelated populations are mixed. Also, unconstrained spatial neighbourhoods can unintentionally detect spatial relationships across many scales. Conclusions: There will be benefits to studies that develop new, ecology-based approaches in defining spatial neighbourhoods that better illuminate ecological function of phenomena under study. © 2012 Nelson and Robertson.},
   author = {Trisalyn A. Nelson and Colin Robertson},
   doi = {10.1186/2192-1709-1-3},
   issn = {21921709},
   issue = {1},
   journal = {Ecological Processes},
   keywords = {hot spots,spatial analysis,spatial ecology,spatial weights,topography},
   pages = {1-11},
   publisher = {Springer Verlag},
   title = {Refining spatial neighbourhoods to capture terrain effects},
   volume = {1},
   year = {2012}
}
@book{Okubo2001,
   author = {Akira Okubo and Simon A. Levin},
   city = {New York, NY},
   doi = {10.1007/978-1-4757-4978-6},
   isbn = {978-1-4419-3151-1},
   publisher = {Springer New York},
   title = {Diffusion and Ecological Problems: Modern Perspectives},
   volume = {14},
   url = {http://link.springer.com/10.1007/978-1-4757-4978-6},
   year = {2001}
}

@misc{Peters2020,
   abstract = {It is commonly accepted that vegetation patterns and water supply mutually define each other. In mangroves, soil water salinity and the corresponding osmotic potential are the main drivers of plant water supply. Below-ground processes thus may be key for the structure and dynamics of mangrove stands. Nevertheless, existing simulation models describing mangrove forest dynamics do not quantify the water uptake of the single plant from the soil and traditionally neglect any feedback of the vegetation on the water availability, but instead use empirical, statistical models for plant competition affecting growth. We provide a brief review on the state of the art of mangrove forest models with an emphasis on how below-ground processes are regarded. We follow mainly two directions: (1) phenomenological concepts for competition for below-ground resources and (2) assessing the impact of salinity and water supply on the vegetation and possible feedback mechanisms from the vegetation to the below-ground conditions. We hypothesise that a coupled vegetation-groundwater model would avail us to better understand the dynamics and properties of mangrove systems, their capability to persist or rehabilitate under stressful hydrological conditions, as well as their response to environmental changes related to the groundwater system and transport. The benefits of such a joint approach would (i) constitute an intrinsic below-ground competition description close to the governing processes and (ii) concurrently exploit secondary, constraining information from vegetation patterns to derive a new concept to acquire knowledge on subsurface heterogeneity and parametrisation. The aim of this paper is to lay the theoretical groundwork and guidelines for future modellers to follow in the creation of a more realistic mangrove model coupling above- and below-ground processes. The proposed modelling approach has the potential to be useful for a broad audience based particularly in forest sciences and plant ecology in general, but also for hydrodynamic modelling (e.g. subsurface flow and transport detected by vegetation patterns as above-ground proxy).},
   author = {Ronny Peters and Marc Walther and Catherine Lovelock and Jiang Jiang and Uta Berger},
   doi = {10.1007/s11273-020-09733-0},
   issn = {15729834},
   issue = {4},
   journal = {Wetlands Ecology and Management},
   keywords = {Below-ground competition,Groundwater modelling,Individual-based modelling,Mangroves,Model coupling,Salinity},
   month = {8},
   pages = {697-712},
   publisher = {Springer},
   title = {The interplay between vegetation and water in mangroves: new perspectives for mangrove stand modelling and ecological research},
   volume = {28},
   year = {2020}
}

@article{Li2023,
   abstract = {Computer graphics has dedicated a considerable amount of effort to generating realistic models of trees and plants. Many existing methods leverage procedural modeling algorithms - that often consider biological findings - to generate branching structures of individual trees. While the realism of tree models generated by these algorithms steadily increases, most approaches neglect to model the root system of trees. However, the root system not only adds to the visual realism of tree models but also plays an important role in the development of trees. In this paper, we advance tree modeling in the following ways: First, we define a physically-plausible soil model to simulate resource gradients, such as water and nutrients. Second, we propose a novel developmental procedural model for tree roots that enables us to emergently develop root systems that adapt to various soil types. Third, we define long-distance signaling to coordinate the development of shoots and roots. We show that our advanced procedural model of tree development enables - for the first time - the generation of trees with their root systems.},
   author = {Bosheng Li and Jonathan Klein and Dominik L. Michels and Bedrich Benes and Sören Pirk and Wojtek Pałubicki},
   doi = {10.1145/3592145},
   issn = {15577368},
   issue = {4},
   journal = {ACM Transactions on Graphics},
   keywords = {botanical tree models,interactive modeling,natural phenomena,physics-based modeling and simulation,root and shoot system,vegetation modeling},
   month = {8},
   publisher = {Association for Computing Machinery},
   title = {Rhizomorph: The Coordinated Function of Shoots and Roots},
   volume = {42},
   year = {2023}
}


@article{Uriarte2004,
   abstract = {1 We quantified neighbourhood effects on sapling growth for 60 tree species in the 50-ha plot in Barro Colorado Island, Panama. Additionally, we tested whether target sapling growth responds to taxonomic or functional identity of neighbouring species by comparing four alternate models (that all neighbours have equivalent effects on the target; that conspecific and heterospecific neighbours have distinct effects; that heterospecific neighbours can be divided into confamilials and non-confamilials; and that they can be divided according to their response to light availability). 2 Over half of the species (34 out of 60) analysed were consistent with all neighbours having equivalent effects on the target. This may result from diffuse evolution allowing tolerance of a large number of neighbouring species or could be a statistical artefact of over-clumping species into large neighbour groups (e.g. heterospecific neighbours). 3 Other species supported models that differentiated between conspecific and heterospecific (n = 6) or between confamilial vs. non-confamilial (n = 5) neighbours and, in general, effects of neighbours were stronger if they were more closely related to the target. Where target species differentiated between neighbours from different light guilds (n = 15), effects were stronger if both belonged to the same guild (i.e. both gap requiring or both shade tolerant). 4 Despite the fact that the majority of species did not respond to the identity of neighbours, all differed in their response to the degree of crowding. Our results suggest that the response of target species to crowding, rather than individual species effects on targets, may be subject to selection. 5 Variation among species in response to crowding or to the identity of neighbouring species is likely to contribute to the maintenance of species diversity in tropical forests.},
   author = {María Uriarte and Richard Condit and Charles D. Canham and Stephen P. Hubbell},
   doi = {10.1111/j.0022-0477.2004.00867.x},
   issn = {00220477},
   issue = {2},
   journal = {Journal of Ecology},
   keywords = {Barro Colorado Island,Density-dependence,Ecological equivalence,Neighbourhood effects,Neutral theory},
   month = {4},
   pages = {348-360},
   title = {A spatially explicit model of sapling growth in a tropical forest: Does the identity of neighbours matter?},
   volume = {92},
   year = {2004}
}
@article{Das2012,
   abstract = {Tree growth and competition play central roles in forest dynamics. Yet models of competition often neglect important variation in species-specific responses. Furthermore, functions used to model changes in growth rate with size do not always allow for potential complexity. Using a large data set from old-growth forests in California, models were parameterized relating growth rate to tree size and competition for four common species. Several functions relating growth rate to size were tested. Competition models included parameters for tree size, competitor size, and competitor distance. Competitive strength was allowed to vary by species. The best ranked models (using Akaike's information criterion) explained between 18\% and 40\% of the variance in growth rate, with each species showing a strong response to competition. Models indicated that relationships between competition and growth varied substantially among species. The results also suggested that the relationship between growth rate and tree size can be complex and that how we model it can affect not only our ability to detect that complexity but also whether we obtain misleading results. In this case, for three of four species, the best model captured an apparent and unexpected decline in potential growth rate for the smallest trees in the data set.},
   author = {Adrian Das},
   doi = {10.1139/x2012-142},
   issn = {00455067},
   issue = {11},
   journal = {Canadian Journal of Forest Research},
   month = {11},
   pages = {1983-1995},
   title = {The effect of size and competition on tree growth rate in old-growth coniferous forests},
   volume = {42},
   year = {2012}
}

@inbook{Cosner2008,
   abstract = {Reaction-diffusion equations are widely used as models for spatial effects in ecology. They support three important types of ecological phenomena: the existence of a minimal patch size necessary to sustain a population, the propagation of wavefronts corresponding to biological invasions, and the formation of spatial patterns in the distributions of populations in homogeneous environments. Reaction-diffusion equations can be analyzed by means of methods from the theory of partial differential equations and dynamical systems. we will discuss the derivation of reaction-diffusion models in ecology, sketch the basic aspects of their analysis, and describe some of their applications and mathematical properties. 3.1 Introduction 3.1.1 General Description of Models Reaction-diffusion equations arise as models for the densities of substances or organisms that disperse through space by Brownian motion, random walks, hydrodynamic turbulence, or similar mechanisms, and that react to each other and their surroundings in ways that affect their local densities. Reaction-diffusion models are in themselves deterministic, but they can be derived as limits of stochastic processes under suitable scaling. Specifically, they provide a modeling approach that allows us to translate assumptions about stochastic local movement into deterministic descriptions of global densities. Reaction-diffusion models are spatially explicit, describe population densities, and treat space and time as continuous. These features distinguish them from other types of spatial models such as interacting particle systems, integrodifference models, and metapopulation models. There are three major types of ecological phenomena that are supported by reaction-diffusion equations: the existence of a minimal patch size necessary to support a population, the presence of traveling wavefronts corresponding to biological invasions, and the formation of spatial patterns. In what follows I will discuss how reaction-diffusion models},
   author = {C. Cosner},
   doi = {10.1007/978-3-540-74331-6_3},
   pages = {77-115},
   title = {Reaction-Diffusion Equations and Ecological Modeling},
   url = {http://link.springer.com/10.1007/978-3-540-74331-6_3},
   year = {2008}
}

@article{Burger2020,
   abstract = {The propagation of a forest fire can be described by a convection–diffusion–reaction problem in two spatial dimensions, where the unknowns are the local temperature and the portion of fuel consumed as functions of spatial position and time. This model can be solved numerically in an efficient way by a linearly implicit–explicit (IMEX) method to discretize the convection and nonlinear diffusion terms combined with a Strang-type operator splitting to handle the reaction term. This method is applied to several variants of the model with variable, nonlinear diffusion functions, where it turns out that increasing diffusivity (with respect to a given base case) significantly enlarges the portion of fuel burnt within a given time while choosing an equivalent constant diffusivity or a degenerate one produces comparable results for that quantity. In addition, the effect of spatial heterogeneity as described by a variable topography is studied. The variability of topography influences the local velocity and direction of wind. It is demonstrated how this variability affects the direction and speed of propagation of the wildfire and the location and size of the area of fuel consumed. The possibility to solve the base model efficiently is utilized for the computation of so-called risk maps. Here the risk associated with a given position in a sub-area of the computational domain is quantified by the rapidity of consumption of a given amount of fuel by a fire starting in that position. As a result, we obtain that, in comparison with the planar case and under the same wind conditions, the model predicts a higher risk for those areas where both the variability of topography (as expressed by the gradient of its height function) and the wind velocity are influential. In general, numerical simulations show that in all cases the risk map with for a non-planar topography includes areas with a reduced risk as well as such with an enhanced risk as compared to the planar case.},
   author = {Raimund Bürger and Elvis Gavilán and Daniel Inzunza and Pep Mulet and Luis Miguel Villada},
   doi = {10.3390/math8101674},
   issn = {22277390},
   issue = {10},
   journal = {Mathematics},
   keywords = {Convection–diffusion–reaction problem,Forest fire model,Implicit–explicit time integration,Nonlinear diffusion function,Numerical solution,Risk map,Topography,Weighted essentially non-oscillatory reconstruction},
   month = {10},
   pages = {1-20},
   publisher = {MDPI AG},
   title = {Exploring a convection–diffusion–reaction model of the propagation of forest fires: Computation of risk maps for heterogeneous environments},
   volume = {8},
   year = {2020}
}

@article{Shoji2002,
   abstract = {Turing mechanism explains the formation of striped patterns in a uniform field in which two substances interact locally and diffuse randomly. In a twin paper, to explain the directionality of stripes on fish skin in closely related species, we studied the effect of anisotropic diffusion of the two substances on the direction of stripes, in the cases in which both substances have high diffusivity in the same direction. In this paper, we study the direction of stripes in more general situations in which the diffusive direction may differ between the two substances. We derive a formula for the direction of stripes, based on a heuristic argument of unstable modes of deviation from the uniform steady state. We confirm the accuracy of the formula by computer simulations. When the diffusive direction is different between two substances, the directions of stripes in the spatial pattern change smoothly with the magnitude of anisotropy of two substances. When the diffusive direction of the two substances is the same, the stripes are formed either parallel or perpendicular to the common diffusive direction, depending on the relative magnitude of the anisotropy. The transition between these two phases occurs sharply. © 2002 Elsevier Science Ltd.},
   author = {Hiroto Shoji and Yoh Iwasa and Atushi Mochizuki and Shigeru Kondo},
   doi = {10.1006/jtbi.2001.2480},
   issn = {00225193},
   issue = {4},
   journal = {Journal of Theoretical Biology},
   pages = {549-561},
   pmid = {11851367},
   publisher = {Elsevier},
   title = {Directionality of stripes formed by anisotropic reaction-diffusion models},
   volume = {214},
   year = {2002}
}

@article{Verhulst1844,
   author = {P.-F. Verhulst},
   journal = {Nouveaux mémoires de l'Académie Royale des sciences et Belles-Lettres de Bruxelles},
   title = {Recherches mathématiques sur la loi d'accroissement de la population},
   year = {1844}
}

@book{Brauer2012,
   author = {Fred Brauer and Carlos Castillo-Chavez},
   city = {New York, NY},
   doi = {10.1007/978-1-4614-1686-9},
   isbn = {978-1-4614-1685-2},
   publisher = {Springer New York},
   title = {Mathematical Models in Population Biology and Epidemiology},
   volume = {40},
   url = {https://link.springer.com/10.1007/978-1-4614-1686-9},
   year = {2012}
}

@article{Ramos2024,
   abstract = {The effects of relaxation, convection, and anisotropy on a two-dimensional, two-equation system of nonlinearly coupled, second-order hyperbolic, advection–reaction–diffusion equations are studied numerically by means of a three-time-level linearized finite difference method. The formulation utilizes a frame-indifferent constitutive equation for the heat and mass diffusion fluxes, taking into account the tensorial character of the thermal diffusivity of heat and mass diffusion. This approach results in a large system of linear algebraic equations at each time level. It is shown that the effects of relaxation are small although they may be noticeable initially if the relaxation times are smaller than the characteristic residence, diffusion, and reaction times. It is also shown that the anisotropy associated with one of the dependent variables does not have an important role in the reaction wave dynamics, whereas the anisotropy of the other dependent variable results in transitions from spiral waves to either large or small curvature reaction fronts. Convection is found to play an important role in the reaction front dynamics depending on the vortex circulation and radius and the anisotropy of the two dependent variables. For clockwise-rotating vortices of large diameter, patterns similar to those observed in planar mixing layers have been found for anisotropic diffusion tensors.},
   author = {Juan I. Ramos},
   doi = {10.3390/computation12110214},
   issn = {20793197},
   issue = {11},
   journal = {Computation},
   keywords = {Rankine vortex fields,advection–reaction–diffusion equations,anisotropic diffusion,relaxation,second-order hyperbolic,time-linearized finite difference method},
   month = {11},
   publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
   title = {Effects of Anisotropy, Convection, and Relaxation on Nonlinear Reaction-Diffusion Systems},
   volume = {12},
   year = {2024}
}

@article{Humphries2014,
   abstract = {While evidence for optimal random search patterns, known as Lévy walks, in empirical movement data is mounting for a growing list of taxa spanning motile cells to humans, there is still much debate concerning the theoretical generality of Lévy walk optimisation. Here, using a new and robust simulation environment, we investigate in the most detailed study to date (24×106 simulations) the foraging and search efficiencies of 2-D Lévy walks with a range of exponents, target resource distributions and several competing models. We find strong and comprehensive support for the predictions of the Lévy flight foraging hypothesis and in particular for the optimality of inverse square distributions of move step-lengths across a much broader range of resource densities and distributions than previously realised. Further support for the evolutionary advantage of Lévy walk movement patterns is provided by an investigation into the 'feast and famine' effect, with Lévy foragers in heterogeneous environments experiencing fewer long 'famines' than other types of searchers. Therefore overall, optimal Lévy foraging results in more predictable resources in unpredictable environments. © 2014 Elsevier Ltd.},
   author = {Nicolas E. Humphries and David W. Sims},
   doi = {10.1016/j.jtbi.2014.05.032},
   issn = {10958541},
   journal = {Journal of Theoretical Biology},
   keywords = {Composite Brownian,Movement,Power-law,Predator,Simulation},
   month = {10},
   pages = {179-193},
   pmid = {24882791},
   publisher = {Academic Press},
   title = {Optimal foraging strategies: Lévy walks balance searching and patch exploitation under a very broad range of conditions},
   volume = {358},
   year = {2014}
}
@inbook{Chechkin2008,
   abstract = {This multi-author reference work provides a unique introduction to the currently emerging, highly interdisciplinary field of those transport processes that cannot be described by using standard methods of statistical mechanics. It comprehensively summarizes topics ranging from mathematical foundations of anomalous dynamics to the most recent experiments in this field. In so doing, this monograph extracts and emphasizes common principles and methods from many different disciplines while providing up-to-date coverage of this new field of research, considering such diverse applications as plasma. Anomalous Transport; Contents; Preface; List of Contributors; 1 In Memoriam: Radu Balescu; 1.1 Radu Balescu's Abstract for the Conference on Anomalous Transport in Bad Honnef; 1.2 The Scientific Career of Radu Balescu by Boris Weyssow; 1.3 My Memory of Radu Balescu by Angelo Vulpiani; 1.4 My Memory of Radu Balescu by Francesco Mainardi; 1.5 In Memoriam: Radu Balescu by Raul Sánchez; 1.6 Remembering Radu Balescu by Diego del-Castillo-Negrete; References; Part I Fractional Calculus and Stochastic Theory; Introduction to Part I; 2 Threefold Introduction to Fractional Derivatives.},
   author = {Alexei V. Chechkin and Ralf Metzler and Joseph Klafter and Vsevolod Yu. Gonchar},
   doi = {10.1002/9783527622979.ch5},
   isbn = {9783527407224},
   booktitle = {Anomalous Transport},
   month = {7},
   pages = {129-162},
   publisher = {Wiley},
   title = {Introduction to the Theory of Lévy Flights},
   url = {https://onlinelibrary.wiley.com/doi/10.1002/9783527622979.ch5},
   year = {2008}
}

@article{Katriel2021,
   abstract = {Dispersal-induced growth (DIG) occurs when two populations with time-varying growth rates, each of which, when isolated, would become extinct, are able to persist and grow exponentially when dispersal among the two populations is present. This work provides a mathematical exploration of this surprising phenomenon, in the context of a deterministic model with periodic variation of growth rates, and characterizes the factors which are important in generating the DIG effect and the corresponding conditions on the parameters involved.},
   author = {Guy Katriel},
   doi = {10.1007/s00285-022-01791-7},
   month = {4},
   title = {Dispersal-induced growth in a time-periodic environment},
   url = {http://arxiv.org/abs/2104.01589 http://dx.doi.org/10.1007/s00285-022-01791-7},
   year = {2021}
}

@article{Zhu2023,
   abstract = {Plant population spread has fundamental ecological and evolutionary importance. Both determinants of plant population spread, fecundity and dispersal, can be density-dependent, which should cause feedback between population densities and spread dynamics. Yet it is poorly understood how density-dependence affects key characteristics of spread: spread rate at which the location of the furthest forward individual moves, edge depth (the geographical area over which individuals contribute to spread) and population continuity (occupancy of the spreading population). We present a general modelling framework for analysing the effects of density-dependent fecundity and dispersal on population spread and parameterize this framework with experimental data from a common-garden experiment using five wind-dispersed plant species grown at different densities. Our model shows that density-dependent fecundity and dispersal strongly affect all three population spread characteristics for both exponential and lognormal dispersal kernels. Spread rate and edge depth are strongly correlated but show weaker correlations with population continuity. Positive density-dependence of fecundity increases all three spread characteristics. Increasingly positive density-dependence of dispersal increases spread rate and edge depth but generally decreases population continuity. Density-dependent fecundity and dispersal are largely additive in their effect on spread characteristics. For population continuity, the joint effects of density-dependent fecundity and dispersal are somewhat contingent on the dispersal kernel. The common-garden experiment and the experimentally parameterized mechanistic dispersal model revealed density-dependent fecundity and dispersal across study species. All study species exhibited negatively density-dependent fecundity, but they differed qualitatively in the density-dependence of dispersal distance and probability of long-distance dispersal. The negative density-dependence of fecundity and dispersal found for three species reinforced each other in reducing spread rate and edge depth. The positively density-dependent dispersal found for two species markedly increased spread rate and edge depth. Population continuity was hardly affected by population density in all study species except Crepis sancta in which it was strongly reduced by negatively density-dependent fecundity. Synthesis. Density-dependent fecundity and seed dispersal profoundly alter population spread. In particular, positively density-dependent dispersal should promote the spread and genetic diversity of plant populations migrating under climate change but also complicate the control of invasive species.},
   author = {Jinlei Zhu and Nataša Lukić and Jörn Pagel and Frank M. Schurr},
   doi = {10.1111/1365-2745.14142},
   issn = {13652745},
   issue = {8},
   journal = {Journal of Ecology},
   keywords = {common garden experiment,invasion by extremes,mechanistic model,plant invasion,population dynamics,range expansion,range filling,seed dispersal by wind},
   month = {8},
   pages = {1735-1748},
   publisher = {John Wiley and Sons Inc},
   title = {Density dependence of seed dispersal and fecundity profoundly alters the spread dynamics of plant populations},
   volume = {111},
   year = {2023}
}

@article{Peterson2024,
   abstract = {Context: Seascape connectivity refers to how the spatial configuration of marine habitats facilitates or hinders the movement of organisms, nutrients, materials or energy. Predicting and ranking potential connectivity among habitat patches for coral reef fishes helps to understand how reef fishes could utilize and connect multiple habitat types through the flow of nutrients, energy and biomass across the wider seascape during foraging movements. Objectives: To advance a spatially explicit understanding of connectivity linkages within a tropical atoll system by modeling, mapping and quantifying potential seascape connectivity for two locally abundant herbivorous reef fish species, the parrotfish, Chlorurus spilurus (pahoro hohoni or pa’ati pa’apa’a auahi), and the surgeonfish, Acanthurus triostegus (manini). Methods: We applied a two-step modeling approach by first mapping habitat suitability for the focal species. A graph-theoretic modeling technique was then applied to model and measure the contribution of benthic habitat patches to species-specific potential connectivity within the seascape. Results: Habitat suitability was higher and less fragmented for C. spilurus than for A. triostegus. Potential ecological connectivity estimates for C. spilurus were higher across the entire seascape, with differences between species likely driven by local-scale benthic habitat patch configuration and species home ranges. Hotspots of ecological connectivity across the atoll were mapped for both species. Conclusions: Despite advances in the application of graph-theoretic techniques in the coastal environment, few marine conservation and restoration measures currently integrate spatial information on ecological connectivity. This two-step spatial modeling approach holds great potential for rapid application of connectivity modeling at multiple spatial scales, which may predict ecological responses to conservation actions including active habitat restoration.},
   author = {Emily A. Peterson and Courtney E. Stuart and Simon J. Pittman and Cassandra E. Benkwitt and Nicholas A.J. Graham and Yadvinder Malhi and Teva Salmon and Benoit Stoll and Sam J. Purkis and Lisa M. Wedding},
   doi = {10.1007/s10980-024-01936-7},
   issn = {15729761},
   issue = {8},
   journal = {Landscape Ecology},
   keywords = {Ecological modeling,MaxEnt,Remote sensing,Restoration ecology,Seascape connectivity},
   month = {8},
   publisher = {Springer Science and Business Media B.V.},
   title = {Graph-theoretic modeling reveals connectivity hotspots for herbivorous reef fishes in a restored tropical island system},
   volume = {39},
   year = {2024}
}
@article{Minor2008,
   abstract = {Connectivity of habitat patches is thought to be important for movement of genes, individuals, populations, and species over multiple temporal and spatial scales. We used graph theory to characterize multiple aspects of landscape connectivity in a habitat network in the North Carolina Piedmont (U.S.A). We compared this landscape with simulated networks with known topology, resistance to disturbance, and rate of movement. We introduced graph measures such as compartmentalization and clustering, which can be used to identify locations on the landscape that may be especially resilient to human development or areas that may be most suitable for conservation. Our analyses indicated that for songbirds the Piedmont habitat network was well connected. Furthermore, the habitat network had commonalities with planar networks, which exhibit slow movement, and scale-free networks, which are resistant to random disturbances. These results suggest that connectivity in the habitat network was high enough to prevent the negative consequences of isolation but not so high as to allow rapid spread of disease. Our graph-theory framework provided insight into regional and emergent global network properties in an intuitive and visual way and allowed us to make inferences about rates and paths of species movements and vulnerability to disturbance. This approach can be applied easily to assessing habitat connectivity in any fragmented or patchy landscape. © 2008 Society for Conservation Biology.},
   author = {Emily S. Minor and Dean L. Urban},
   doi = {10.1111/j.1523-1739.2007.00871.x},
   issn = {08888892},
   issue = {2},
   journal = {Conservation Biology},
   keywords = {Dispersal,Fragmented landscapes,Graph theory,Habitat connectivity,Habitat network,Network theory,Spread of disturbance},
   month = {4},
   pages = {297-307},
   pmid = {18241238},
   title = {A graph-theory framework for evaluating landscape connectivity and conservation planning},
   volume = {22},
   year = {2008}
}
@article{Boussange2022,
   abstract = {Differentiation mechanisms are influenced by the properties of the landscape over which individuals interact, disperse and evolve. Here, we investigate how habitat connectivity and habitat heterogeneity affect phenotypic differentiation by formulating a stochastic eco-evolutionary model where individuals are structured over a spatial graph. We combine analytical insights into the eco-evolutionary dynamics with numerical simulations to understand how the graph topology and the spatial distribution of habitat types affect differentiation. We show that not only low connectivity but also heterogeneity in connectivity promotes neutral differentiation, due to increased competition in highly connected vertices. Habitat assortativity, a measure of habitat spatial auto-correlation in graphs, additionally drives differentiation under habitat-dependent selection. While assortative graphs systematically amplify adaptive differentiation, they can foster or depress neutral differentiation depending on the migration regime. By formalising the eco-evolutionary and spatial dynamics of biological populations on graphs, our study establishes fundamental links between landscape features and phenotypic differentiation.},
   author = {Victor Boussange and Loïc Pellissier},
   doi = {10.1038/s42003-022-03595-3},
   issn = {23993642},
   issue = {1},
   journal = {Communications Biology},
   month = {12},
   pmid = {35794362},
   publisher = {Nature Research},
   title = {Eco-evolutionary model on spatial graphs reveals how habitat structure affects phenotypic differentiation},
   volume = {5},
   year = {2022}
}
@article{Duflot2018,
   abstract = {In response to the negative effects of habitat fragmentation on biodiversity, habitat network conservation and restoration has become a central objective in conservation planning. Evaluating landscape functional connectivity and mapping habitat networks are key steps for implementing effective actions, but both remain challenging. Habitat suitability models (HSM) and spatial graphs provide conservation managers with useful information for landscape planning. To tackle their respective drawbacks, we proposed to combine HSM and spatial graphs in a four-step methodological framework: (i) collect and prepare input data; (ii) model habitat suitability using MaxEnt to map the species’ habitat suitability index (HSI); (iii) transform the HSI map into spatial graph inputs using GIS; and, (iv) perform spatial graph connectivity analysis using Graphab. The outputs of this species-specific and quantitative approach were maps of the species’ habitat network. Habitat patches and dispersal linkages were ranked according to their importance for overall habitat availability and landscape connectivity. This prioritization identified locations where conservation biologists and landscape planners should focus conservation and restoration efforts. This framework is illustrated here with a case study on the woodlark (Lullula arborea) - a bird species - in a French Mediterranean area, and the method's limitations and alternatives are discussed. The quantitative-based graphical outputs of the framework can valuably support decision-making for landscape planning, complement local expert opinion, and encourage appropriate stakeholders to cooperate at regional scale.},
   author = {Rémi Duflot and Catherine Avon and Philip Roche and Laurent Bergès},
   doi = {10.1016/j.jnc.2018.08.005},
   issn = {16171381},
   journal = {Journal for Nature Conservation},
   keywords = {Cost distance,Habitat network,Landscape connectivity,Landscape graph,Least-cost path,Species distribution model},
   month = {12},
   pages = {38-47},
   publisher = {Elsevier GmbH},
   title = {Combining habitat suitability models and spatial graphs for more effective landscape conservation planning: An applied methodological framework and a species case study},
   volume = {46},
   year = {2018}
}
@article{Foltete2019,
   abstract = {Ecological networks are tools for conservation planning that rely on the concept of connectivity. Criticisms leveled at them are that they are widely used in a dogmatic way regardless of how they compare against other tools and that their efficiency is rarely assessed. I propose to include landscape graphs in the debate because they are designed to be operational models of ecological networks. I outline the key features of landscape graphs that can be matched with some of these criticisms: weighting of patches and links to take the landscape matrix into account, integrated metrics dealing with both connectivity and amount of habitat, and the possibility of including them in a decision-support system based on scenario analyses. I conclude that criticisms of ecological networks reveal the lack of diffusion of modeling tools such as landscape graphs, and that approaches such as participatory modeling bringing together scientists and practitioners could be one way to improve matters.},
   author = {Jean Christophe Foltête},
   doi = {10.1016/j.landusepol.2018.04.020},
   issn = {02648377},
   journal = {Land Use Policy},
   keywords = {Connectivity,Decision support,Ecological networks,Landscape graphs,Spatial modeling},
   month = {1},
   pages = {391-394},
   publisher = {Elsevier Ltd},
   title = {How ecological networks could benefit from landscape graphs: A response to the paper by Spartaco Gippoliti and Corrado Battisti},
   volume = {80},
   year = {2019}
}
@article{Clauzel2020,
   abstract = {Habitat restoration is one of the actions to reduce landscape fragmentation by promoting connectivity and thus biodiversity. But knowing where to implement these habitats is a major issue and planners lack guidance for answering this question, in particular when it involves multiple species and over a large area. We proposed to combine biological data, habitat suitability models and spatial graphs to improve multiscale and multispecies connectivity in Ile-de-France, a highly artificialized region of 12,000 km2. The framework consisted of i) modeling habitat suitability for eight pond-dwelling species (Alytes obstetricans, Bufo bufo, Epidalea calamita, Hyla arborea, Rana temporaria, Salamandra salamandra, Triturus cristatus, and Natrix natrix), ii) modeling the ecological network for each species, iii) prioritizing each sampling point depending on the gain in connectivity if a new pond was created there and iv) combining single-species results to identify the areas that could improve multispecies connectivity. The multivariate statistical analysis revealed that transitional forest environments appeared to be the most strategic areas for improving multispecific connectivity (at least for 5 species). Targeted addition of habitat within an ecological network can increase habitat density in deficient areas and reconnect network sub-parts. This approach is therefore promising to guide conservation actions and “no net loss” biodiversity measures, especially the final stage of offset in the mitigation hierarchy.},
   author = {Céline Clauzel and Claire Godet},
   doi = {10.1016/j.biocon.2020.108713},
   issn = {00063207},
   journal = {Biological Conservation},
   keywords = {Amphibians,Biodiversity offset,Functional connectivity,Habitat suitability models,Landscape graphs,Multispecies approach},
   month = {10},
   publisher = {Elsevier Ltd},
   title = {Combining spatial modeling tools and biological data for improved multispecies assessment in restoration areas},
   volume = {250},
   year = {2020}
}
@article{Hamonic2021,
   abstract = {In this paper we consider the problem of optimizing the ecological connectivity of a landscape under a budget constraint by improving habitat areas and ecological corridors between them. We consider a formulation of this problem in terms of graphs in which vertices represent the habitat areas and arcs represent a probability of connection between two areas that depend on the quality of the respective corridor. We propose a new generalized flow model that improves existing models for this problem and an efficient preprocessing algorithm that reduces the size of the graphs on which generalized flows is computed. Reported numerical experiments highlight the benefice of these two contributions on computation times and show that larger problems can be solved using them. Our experiments also show that several variants of greedy algorithms perform relatively well on practical instances while they return arbitrary bad solutions in the worst case.},
   author = {François Hamonic and Cécile Albert and Basile Couëtoux and Yann Vaxès},
   month = {9},
   title = {Optimizing the ecological connectivity of landscapes with generalized flow models and preprocessing},
   url = {http://arxiv.org/abs/2109.06622},
   year = {2021}
}

@misc{Urban2009,
   abstract = {Graph theory is a body of mathematics dealing with problems of connectivity, flow, and routing in networks ranging from social groups to computer networks. Recently, network applications have erupted in many fields, and graph models are now being applied in landscape ecology and conservation biology, particularly for applications couched in metapopulation theory. In these applications, graph nodes represent habitat patches or local populations and links indicate functional connections among populations (i.e. via dispersal). Graphs are models of more complicated real systems, and so it is appropriate to review these applications from the perspective of modelling in general. Here we review recent applications of network theory to habitat patches in landscape mosaics. We consider (1) the conceptual model underlying these applications; (2) formalization and implementation of the graph model; (3) model parameterization; (4) model testing, insights, and predictions available through graph analyses; and (5) potential implications for conservation biology and related applications. In general, and for a variety of ecological systems, we find the graph model a remarkably robust framework for applications concerned with habitat connectivity. We close with suggestions for further work on the parameterization and validation of graph models, and point to some promising analytic insights. © 2009 Blackwell Publishing Ltd/CNRS.},
   author = {Dean L. Urban and Emily S. Minor and Eric A. Treml and Robert S. Schick},
   doi = {10.1111/j.1461-0248.2008.01271.x},
   issn = {1461023X},
   issue = {3},
   journal = {Ecology Letters},
   keywords = {Connectivity,Conservation,Graph theory,Habitat,Landscape,Metapopulation,Network analysis},
   month = {3},
   pages = {260-273},
   pmid = {19161432},
   title = {Graph models of habitat mosaics},
   volume = {12},
   year = {2009}
}

@inbook{Westoby1984,
   author = {Mark Westoby},
   doi = {10.1016/S0065-2504(08)60171-3},
   isbn = {0120139146},
   pages = {167-225},
   publisher = {Academic Press},
   title = {The Self-Thinning Rule},
   url = {https://linkinghub.elsevier.com/retrieve/pii/S0065250408601713},
   year = {1984}
}

@article{Ogden2017,
   author = {Fred L. Ogden and Myron B. Allen and Wencong Lai and Jianting Zhu and Mookwon Seo and Craig C. Douglas and Cary A. Talbot},
   doi = {10.1002/2017MS000931},
   issn = {19422466},
   issue = {2},
   journal = {Journal of Advances in Modeling Earth Systems},
   keywords = {equation,hydrology,mathematics,modeling,solution,vadose},
   month = {6},
   pages = {1473-1487},
   publisher = {Blackwell Publishing Ltd},
   title = {The soil moisture velocity equation},
   volume = {9},
   year = {2017}
}

@inbook{WulffJensen2018,
   abstract = {This paper proposes a novel framework for improving procedural generation of 3D landscapes using machine learning. We utilized a Deep Convolutional Generative Adversarial Network (DC-GAN) to generate heightmaps. The network was trained on a dataset consisting of Digital Elevation Maps (DEM) of the alps. During map generation, the batch size and learning rate were optimized for the most efficient and satisfying map production. The diversity of the final output was tested against Perlin noise using Mean Square Error [1] and Structure Similarity Index [2]. Perlin noise is especially interesting as it has been used to generate game maps in previous productions [3, 4]. The diversity test showed the generated maps had a significantly greater diversity than the Perlin noise maps. Afterwards the heightmaps was converted to 3D maps in Unity3D. The 3D maps’ perceived realism and videogame usability was pilot tested, showing a promising future for DC-GAN generated 3D landscapes.},
   author = {Andreas Wulff-Jensen and Niclas Nerup Rant and Tobias Nordvig Møller and Jonas Aksel Billeskov},
   doi = {10.1007/978-3-319-76908-0_9},
   booktitle = {Interactivity, Game Creation, Design, Learning, and Innovation},
   month = {1},
   pages = {85-94},
   publisher = {Springer},
   title = {Deep Convolutional Generative Adversarial Network for Procedural 3D Landscape Generation Based on DEM},
   year = {2018}
}

@article{Goodfellow2014,
   abstract = { Generative adversarial networks are a kind of artificial intelligence algorithm designed to solve the generative modeling problem. The goal of a generative model is to study a collection of training examples and learn the probability distribution that generated them. Generative Adversarial Networks (GANs) are then able to generate more examples from the estimated probability distribution. Generative models based on deep learning are common, but GANs are among the most successful generative models (especially in terms of their ability to generate realistic high-resolution images). GANs have been successfully applied to a wide variety of tasks (mostly in research settings) but continue to present unique challenges and research opportunities because they are based on game theory while most other approaches to generative modeling are based on optimization. },
   author = {Ian Goodfellow and Jean Pouget-Abadie and Mehdi Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron Courville and Yoshua Bengio},
   doi = {10.48550/arXiv.1406.2661},
   issue = {11},
   journal = {Advances in Neural Information Processing Systems},
   month = {6},
   pages = {139-144},
   title = {Generative adversarial networks},
   volume = {3},
   url = {https://dl.acm.org/doi/10.1145/3422622},
   year = {2014}
}

@article{Lyons2024,
   author = {Mitchell B. Lyons and Nicholas J. Murray and Emma V. Kennedy and Eva M. Kovacs and Carolina Castro-Sanguino and Stuart R. Phinn and Rodney Borrego Acevedo and Alexandra Ordoñez Alvarez and Chantel Say and Paul Tudman and Kathryn Markey and Meredith Roe and Robert F. Canto and Helen E. Fox and Brianna Bambic and Zoë Lieb and Gregory P. Asner and Paulina M. Martin and David E. Knapp and Jiwei Li and Matthew Skone and Eldan Goldenberg and Kirk Larsen and Chris M. Roelfsema},
   doi = {10.1016/j.crsus.2024.100015},
   issn = {29497906},
   issue = {2},
   journal = {Cell Reports Sustainability},
   month = {2},
   pages = {100015},
   publisher = {Elsevier BV},
   title = {New global area estimates for coral reefs from high-resolution mapping},
   volume = {1},
   year = {2024}
}

@inbook{Tomascik1997,
   author = {Tomas Tomascik and Anmarie Janice Mah and Anugerah Nontji and Mohammad Kasim Moosa},
   doi = {10.1093/oso/9780198501855.003.0006},
   booktitle = {The Ecology of the Indonesian Seas},
   month = {7},
   pages = {207-232},
   publisher = {Oxford University PressOxford},
   title = {Coral Reef Origins: The Theories},
   url = {https://academic.oup.com/book/52768/chapter/421867308},
   year = {1997}
}

@techReport{Korner2014,
   author = {Christian Körner and Eva M Spehn and Harald Bugmann and Eth Zurich},
   title = {Mountain Systems},
   url = {https://www.researchgate.net/publication/238663492},
   year = {2014}
}

@article{Panagiotou2020,
   abstract = {Procedural 3D Terrain generation has become a necessity in open world games, as it can provide unlimited content, through a functionally infinite number of different areas, for players to explore. In our approach, we use Generative Adversarial Networks (GAN) to yield realistic 3D environments based on the distribution of remotely sensed images of landscapes, captured by satellites or drones. Our task consists of synthesizing a random but plausible RGB satellite image and generating a corresponding Height Map in the form of a 3D point cloud that will serve as an appropriate mesh of the landscape. For the first step, we utilize a GAN trained with satellite images that manages to learn the distribution of the dataset, creating novel satellite images. For the second part, we need a one-to-one mapping from RGB images to Digital Elevation Models (DEM). We deploy a Conditional Generative Adversarial network (CGAN), which is the state-of-the-art approach to image-to-image translation, to generate a plausible height map for every randomly generated image of the first model. Combining the generated DEM and RGB image, we are able to construct 3D scenery consisting of a plausible height distribution and colorization, in relation to the remotely sensed landscapes provided during training.},
   author = {Emmanouil Panagiotou and Eleni Charou},
   month = {10},
   title = {Procedural 3D Terrain Generation using Generative Adversarial Networks},
   url = {http://arxiv.org/abs/2010.06411},
   year = {2020}
}

@article{Sisodia2022,
   abstract = {Multimedia applications, such as virtual reality models and video games, are increasingly interested in the ability to generate and author realistic virtual terrain automatically. In this paper, the author proposes a pipeline for a realistic two-dimensional terrain authoring framework that is powered by several different generative models that are applied one after the other. Two-dimensional role-playing games will benefit from this ability to create multiple high-resolution terrain variants from a single input image and to interpolate between terrains while keeping the terrains that are generated close to how the data is distributed in the real world.},
   author = {Yogendra Sisodia},
   doi = {10.54105/ijainn.F1060.102622},
   issn = {25827626},
   issue = {6},
   journal = {Indian Journal of Artificial Intelligence and Neural Networking},
   month = {10},
   pages = {1-3},
   title = {GAN-Generated Terrain for Game Assets},
   volume = {2},
   url = {https://www.ijainn.latticescipub.com/portfolio-item/f1060102622/},
   year = {2022}
}
@inproceedings{Spick2019,
   abstract = {Source code summarization involves creating brief descriptions of source code in natural language. These descriptions are a key component of software documentation such as JavaDocs. Automatic code summarization is a prized target of software engineering research, due to the high value summaries have to programmers and the simultaneously high cost of writing and maintaining documentation by hand. Current work is almost all based on machine models trained via big data input. Large datasets of examples of code and summaries of that code are used to train an e.g. encoder-decoder neural model. Then the output predictions of the model are evaluated against a set of reference summaries. The input is code not seen by the model, and the prediction is compared to a reference. The means by which a prediction is compared to a reference is essentially word overlap, calculated via a metric such as BLEU or ROUGE. The problem with using word overlap is that not all words in a sentence have the same importance, and many words have synonyms. The result is that calculated similarity may not match the perceived similarity by human readers. In this paper, we conduct an experiment to measure the degree to which various word overlap metrics correlate to human-rated similarity of predicted and reference summaries. We evaluate alternatives based on current work in semantic similarity metrics and propose recommendations for evaluation of source code summarization.},
   author = {Ryan Spick and James Walker},
   city = {New York, NY, USA},
   doi = {10.1145/3359998.3369407},
   isbn = {9781450370035},
   booktitle = {European Conference on Visual Media Production},
   keywords = {automatic documentation generation,evaluation metrics,source code summarization},
   month = {12},
   pages = {1-10},
   publisher = {ACM},
   title = {Realistic and Textured Terrain Generation using GANs},
   volume = {2022-March},
   url = {https://dl.acm.org/doi/10.1145/3359998.3369407},
   year = {2019}
}

@inproceedings{Park2019,
   abstract = {We propose GauGAN, a GAN-based image synthesis model that can generate photo-realistic images given an input semantic layout. It is built on spatially-adaptive normalization, a simple but effective normalization layer. Previous methods directly feed the semantic layout as input to the deep network, which is then processed through stacks of convolution, normalization, and non-linearity layers. We show that this is sub-optimal as the normalization layers tend to "wash away'' semantic information. To address the issue, we propose using the input layout for modulating the activations in normalization layers through a spatially-adaptive, learned transformation. Our proposed method outperforms the previous methods by a large margin. Furthermore, the new method enables natural extension to control the style of the synthesized images. Given a style guide image, our style encoder network captures the style into a latent code, which our image generator network combines with the semantic layout via spatially-adaptive normalization to generate a photo-realistic image that respects both the style of the guide image and content of the semantic layout. Our method will enable people without drawing skills to effectively express their imagination. GauGAN in the inference time is a simple convolutional neural network. It runs real-time on most modern GPU cards. GauGAN is one of the recent research efforts in advancing GANs for real-time image rendering. We believe this is of interest to the SIGGRAPH and real-time communities.},
   author = {Taesung Park and Ming-Yu Liu and Ting-Chun Wang and Jun-Yan Zhu},
   city = {New York, NY, USA},
   doi = {10.1145/3306305.3332370},
   isbn = {9781450363150},
   booktitle = {ACM SIGGRAPH 2019 Real-Time Live!},
   month = {7},
   pages = {1-1},
   publisher = {ACM},
   title = {GauGAN},
   url = {https://dl.acm.org/doi/10.1145/3306305.3332370},
   year = {2019}
}

@article{Radford2015,
   abstract = {In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised learning with CNNs has received less attention. In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning. We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.},
   author = {Alec Radford and Luke Metz and Soumith Chintala},
   month = {11},
   title = {Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks},
   url = {http://arxiv.org/abs/1511.06434},
   year = {2015}
}


@article{Mirza2014,
   abstract = {Generative Adversarial Nets [8] were recently introduced as a novel way to train generative models. In this work we introduce the conditional version of generative adversarial nets, which can be constructed by simply feeding the data, y, we wish to condition on to both the generator and discriminator. We show that this model can generate MNIST digits conditioned on class labels. We also illustrate how this model could be used to learn a multi-modal model, and provide preliminary examples of an application to image tagging in which we demonstrate how this approach can generate descriptive tags which are not part of training labels.},
   author = {Mehdi Mirza and Simon Osindero},
   month = {11},
   title = {Conditional Generative Adversarial Nets},
   url = {http://arxiv.org/abs/1411.1784},
   year = {2014}
}


@article{Olsen2009,
   abstract = {User interfaces in modeling have traditionally followed the WIMP (Window, Icon, Menu, Pointer) paradigm. Though functional and very powerful, they can also be cumbersome and daunting to a novice user, and creating a complex model requires considerable expertise and effort. A recent trend is toward more accessible and natural interfaces, which has lead to sketch-based interfaces for modeling (SBIM). The goal is to allow sketches-hasty freehand drawings-to be used in the modeling process, from rough model creation through to fine detail construction. Mapping a 2D sketch to a 3D modeling operation is a difficult task, rife with ambiguity. To wit, we present a categorization based on how a SBIM application chooses to interpret a sketch, of which there are three primary methods: to create a 3D model, to add details to an existing model, or to deform and manipulate a model. Additionally, in this paper we introduce a survey of sketch-based interfaces focused on 3D geometric modeling applications. The canonical and recent works are presented and classified, including techniques for sketch acquisition, filtering, and interpretation. The survey also provides an overview of some specific applications of SBIM and a discussion of important challenges and open problems for researchers to tackle in the coming years. © 2008 Elsevier Ltd. All rights reserved.},
   author = {Luke Olsen and Faramarz F. Samavati and Mario Costa Sousa and Joaquim A. Jorge},
   doi = {10.1016/j.cag.2008.09.013},
   issn = {00978493},
   issue = {1},
   journal = {Computers and Graphics (Pergamon)},
   keywords = {Interface design,Perception,Sketch-based modeling},
   pages = {85-103},
   publisher = {Elsevier Ltd},
   title = {Sketch-based modeling: A survey},
   volume = {33},
   year = {2009}
}

@article{Cook2009,
   abstract = {As 3-D modeling applications transition from engineering environments into the hands of artists, designers, and the consumer market, there is an increasing demand for more intuitive interfaces. In response, 3-D modeling and interface design communities have begun to develop systems based on traditional artistic techniques, particularly sketching. Collectively this growing field of research has come to be known as sketch-based modeling, however the name belies a diversity of promising techniques and unique approaches. This paper presents a survey of current research in sketch-based modeling, including a basic introduction to the topic, the challenges of sketch-based input, and an examination of a number of popular approaches, including representative examples and a general analysis of the benefits and challenges inherent to each. © 2009 Elsevier B.V. All rights reserved.},
   author = {Matthew T. Cook and Arvin Agah},
   doi = {10.1016/j.intcom.2009.05.004},
   issn = {09535438},
   issue = {3},
   journal = {Interacting with Computers},
   keywords = {3-D modeling,Human computer interaction,Interaction styles,Sketch-based modeling,User interface},
   pages = {201-211},
   publisher = {Elsevier},
   title = {A survey of sketch-based 3-D modeling techniques},
   volume = {21},
   year = {2009}
}

@article{Natali2014,
   abstract = {We propose a method for sketching and visualizing geological models by sequentially defining stratigraphic layers, where each layer represents a unique erosion or deposition event. Evolution of rivers and deltas is important for geologists when interpreting the stratigraphy of the subsurface, in particular for hydrocarbon exploration. We illustratively visualize mountains, basins, lakes, rivers and deltas, and how they change the morphology of a terrain during their evolution. We present a compact representation of the model and a novel rendering algorithm that allows us to obtain an interactive and illustrative layer-cake visualization. A user study has been performed to evaluate our method. © 2014 Elsevier Ltd.},
   author = {Mattia Natali and Tore Grane Klausen and Daniel Patel},
   doi = {10.1016/j.cageo.2014.02.010},
   issn = {00983004},
   journal = {Computers and Geosciences},
   keywords = {Fluvial deposition,Illustrative visualization,Stratigraphic evolution},
   month = {6},
   pages = {40-48},
   title = {Sketch-based modelling and visualization of geological deposition},
   volume = {67},
   year = {2014}
}

@inproceedings{Xiao2025,
   author = {Tianyi Xiao and Yizi Chen and Sailin Zhong and Peter Kiefer and Jakub Krukar and Kevin Gonyop Kim and Lorenz Hurni and Angela Schwering and Martin Raubal},
   city = {New York, NY, USA},
   doi = {10.1145/3706598.3713467},
   isbn = {9798400713941},
   booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
   month = {4},
   pages = {1-24},
   publisher = {ACM},
   title = {Sketch2Terrain: AI-Driven Real-Time Terrain Sketch Mapping in Augmented Reality},
   url = {https://dl.acm.org/doi/10.1145/3706598.3713467},
   year = {2025}
}

@article{Mou2018,
   abstract = {In this paper we tackle a very novel problem, namely height estimation from a single monocular remote sensing image, which is inherently ambiguous, and a technically ill-posed problem, with a large source of uncertainty coming from the overall scale. We propose a fully convolutional-deconvolutional network architecture being trained end-to-end, encompassing residual learning, to model the ambiguous mapping between monocular remote sensing images and height maps. Specifically, it is composed of two parts, i.e., convolutional sub-network and deconvolutional sub-network. The former corresponds to feature extractor that transforms the input remote sensing image to high-level multidimensional feature representation, whereas the latter plays the role of a height generator that produces height map from the feature extracted from the convolutional sub-network. Moreover, to preserve fine edge details of estimated height maps, we introduce a skip connection to the network, which is able to shuttle low-level visual information, e.g., object boundaries and edges, directly across the network. To demonstrate the usefulness of single-view height prediction, we show a practical example of instance segmentation of buildings using estimated height map. This paper, for the first time in the remote sensing community, attempts to estimate height from monocular vision. The proposed network is validated using a large-scale high resolution aerial image data set covered an area of Berlin. Both visual and quantitative analysis of the experimental results demonstrate the effectiveness of our approach.},
   author = {Lichao Mou and Xiao Xiang Zhu},
   month = {2},
   title = {IM2HEIGHT: Height Estimation from Single Monocular Imagery via Fully Residual Convolutional-Deconvolutional Network},
   url = {http://arxiv.org/abs/1802.10249},
   year = {2018}
}
